{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a8bc990-ebc5-46bd-bab4-f4091ce5b834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../script/\")\n",
    "\n",
    "import Functions\n",
    "from Engine import Engine\n",
    "from GTGP import GTGP\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report,accuracy_score,confusion_matrix,f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import importlib\n",
    "from time import time\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbad47da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.utils import shuffle\n",
    "def plot_roc_curve(true_y, y_prob):\n",
    "    \"\"\"\n",
    "    plots the roc curve based of the probabilities\n",
    "    \"\"\"\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(true_y, y_prob)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    print(roc_auc_score(true_y,prob[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c114de92",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "feedaa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/vowel.tsv\",delimiter='\\t')\n",
    "X = df.iloc[:,:-1].to_numpy().astype(\"float\")\n",
    "y = df.iloc[:,-1].to_numpy().astype(\"int\")\n",
    "\n",
    "seeds = [10086, 200,500,30506,30405,30420,10056,7059,40965,5398,869543,83491,823190,\n",
    "         48392,2810,48392,3498210,483902,859032,12890,538920,86954,54309,6504,9840,\n",
    "         219805,548,2981,432890,5438908,219094,5843902,60854,979,12890,2108,4093]\n",
    "train_size = 0.7\n",
    "dataset = 'vowel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9822d726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8     90\n",
       "2     90\n",
       "1     90\n",
       "0     90\n",
       "5     90\n",
       "6     90\n",
       "3     90\n",
       "9     90\n",
       "4     90\n",
       "10    90\n",
       "7     90\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a2341bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(y,yt):\n",
    "    le = LabelEncoder()\n",
    "    ohe = OneHotEncoder()\n",
    "    y_train = le.fit_transform(y)\n",
    "    y_one_hot = ohe.fit_transform(y_train.reshape(-1,1))\n",
    "    \n",
    "    y_test = le.transform(yt)\n",
    "    yt_one_hot = ohe.transform(y_test.reshape(-1,1))\n",
    "    \n",
    "    return y_train,y_test,y_one_hot,yt_one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdd30c5",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f418f618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 125 1\n",
      "53 247 2\n",
      "82 390 3\n",
      "107 513 4\n",
      "133 629 5\n",
      "158 740 6\n",
      "181 843 7\n",
      "205 973 8\n",
      "224 1058 9\n",
      "248 1174 10\n",
      "275 1291 11\n",
      "293 1387 12\n",
      "311 1483 13\n",
      "333 1591 14\n",
      "349 1669 15\n",
      "374 1810 16\n",
      "394 1904 17\n",
      "418 2024 18\n",
      "438 2130 19\n",
      "460 2262 20\n",
      "476 2346 21\n",
      "494 2460 22\n",
      "513 2557 23\n",
      "531 2653 24\n",
      "548 2748 25\n",
      "565 2835 26\n",
      "578 2900 27\n",
      "595 2977 28\n",
      "614 3070 29\n",
      "637 3207 30\n",
      "658 3336 31\n",
      "675 3429 32\n",
      "695 3535 33\n",
      "710 3620 34\n",
      "729 3723 35\n",
      "738 3770 36\n",
      "755 3865 37\n",
      "769 3939 38\n",
      "782 4010 39\n",
      "795 4083 40\n",
      "810 4174 41\n",
      "820 4234 42\n",
      "833 4303 43\n",
      "846 4382 44\n",
      "865 4497 45\n",
      "881 4585 46\n",
      "896 4672 47\n",
      "911 4755 48\n",
      "928 4850 49\n",
      "943 4943 50\n",
      "959 5041 51\n",
      "978 5152 52\n",
      "989 5205 53\n",
      "999 5253 54\n",
      "1011 5323 55\n",
      "1031 5443 56\n",
      "1047 5537 57\n",
      "1061 5625 58\n",
      "1074 5706 59\n",
      "1088 5788 60\n",
      "1102 5876 61\n",
      "1113 5941 62\n",
      "1127 6029 63\n",
      "1141 6113 64\n",
      "1152 6182 65\n",
      "1163 6255 66\n",
      "1178 6340 67\n",
      "1192 6424 68\n",
      "1201 6475 69\n",
      "1213 6541 70\n",
      "1227 6617 71\n",
      "1242 6706 72\n",
      "1256 6788 73\n",
      "1273 6905 74\n",
      "1285 6981 75\n",
      "1298 7070 76\n",
      "1308 7130 77\n",
      "1319 7201 78\n",
      "1330 7272 79\n",
      "1340 7344 80\n",
      "1352 7426 81\n",
      "1365 7519 82\n",
      "1379 7609 83\n",
      "1395 7707 84\n",
      "1405 7773 85\n",
      "1419 7863 86\n",
      "1431 7931 87\n",
      "1437 7963 88\n",
      "1448 8028 89\n",
      "1459 8093 90\n",
      "1471 8161 91\n",
      "1483 8239 92\n",
      "1497 8321 93\n",
      "1509 8387 94\n",
      "1518 8450 95\n",
      "1529 8505 96\n",
      "1539 8569 97\n",
      "1547 8613 98\n",
      "1556 8672 99\n",
      "1564 8716 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 29.68863330871531 \ttest: 0.9427609427609428 65.80960913920526\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 8.259996803163666 \ttest: 0.9595959595959596 50.968905913193765\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 3.6208465029779306 \ttest: 0.9595959595959596 45.83274260896343\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 1.9850856292418124 \ttest: 0.9595959595959596 43.23799464754218\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.2404243457413702 \ttest: 0.9595959595959596 41.6640920946696\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        63\n",
      "           1    1.00000   1.00000   1.00000        63\n",
      "           2    1.00000   1.00000   1.00000        63\n",
      "           3    1.00000   1.00000   1.00000        63\n",
      "           4    1.00000   1.00000   1.00000        63\n",
      "           5    1.00000   1.00000   1.00000        63\n",
      "           6    1.00000   1.00000   1.00000        63\n",
      "           7    1.00000   1.00000   1.00000        63\n",
      "           8    1.00000   1.00000   1.00000        63\n",
      "           9    1.00000   1.00000   1.00000        63\n",
      "          10    1.00000   1.00000   1.00000        63\n",
      "\n",
      "    accuracy                        1.00000       693\n",
      "   macro avg    1.00000   1.00000   1.00000       693\n",
      "weighted avg    1.00000   1.00000   1.00000       693\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   0.92593   0.96154        27\n",
      "           1    0.93103   1.00000   0.96429        27\n",
      "           2    1.00000   1.00000   1.00000        27\n",
      "           3    0.96000   0.88889   0.92308        27\n",
      "           4    1.00000   0.92593   0.96154        27\n",
      "           5    0.95833   0.85185   0.90196        27\n",
      "           6    0.87097   1.00000   0.93103        27\n",
      "           7    0.96296   0.96296   0.96296        27\n",
      "           8    1.00000   1.00000   1.00000        27\n",
      "           9    0.90000   1.00000   0.94737        27\n",
      "          10    1.00000   1.00000   1.00000        27\n",
      "\n",
      "    accuracy                        0.95960       297\n",
      "   macro avg    0.96212   0.95960   0.95943       297\n",
      "weighted avg    0.96212   0.95960   0.95943       297\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1564\n",
      "Average of depth: 1.9514066496163682\n",
      "Number of nodes: 8716\n",
      "26 116 1\n",
      "53 241 2\n",
      "78 356 3\n",
      "104 484 4\n",
      "129 603 5\n",
      "155 735 6\n",
      "180 858 7\n",
      "198 944 8\n",
      "226 1078 9\n",
      "247 1189 10\n",
      "268 1302 11\n",
      "291 1417 12\n",
      "315 1547 13\n",
      "339 1657 14\n",
      "359 1771 15\n",
      "380 1874 16\n",
      "396 1964 17\n",
      "418 2074 18\n",
      "434 2178 19\n",
      "453 2285 20\n",
      "476 2416 21\n",
      "496 2520 22\n",
      "516 2642 23\n",
      "534 2742 24\n",
      "555 2867 25\n",
      "571 2947 26\n",
      "589 3043 27\n",
      "604 3118 28\n",
      "619 3195 29\n",
      "634 3268 30\n",
      "654 3374 31\n",
      "674 3490 32\n",
      "691 3589 33\n",
      "703 3675 34\n",
      "720 3756 35\n",
      "738 3872 36\n",
      "756 3958 37\n",
      "774 4066 38\n",
      "789 4147 39\n",
      "810 4262 40\n",
      "825 4345 41\n",
      "838 4408 42\n",
      "854 4506 43\n",
      "868 4574 44\n",
      "885 4675 45\n",
      "898 4754 46\n",
      "916 4874 47\n",
      "933 4967 48\n",
      "949 5061 49\n",
      "961 5129 50\n",
      "978 5218 51\n",
      "992 5302 52\n",
      "1004 5392 53\n",
      "1021 5497 54\n",
      "1035 5587 55\n",
      "1048 5664 56\n",
      "1056 5712 57\n",
      "1069 5789 58\n",
      "1082 5874 59\n",
      "1097 5969 60\n",
      "1112 6052 61\n",
      "1123 6111 62\n",
      "1134 6174 63\n",
      "1146 6248 64\n",
      "1158 6322 65\n",
      "1170 6392 66\n",
      "1186 6488 67\n",
      "1197 6555 68\n",
      "1210 6630 69\n",
      "1221 6695 70\n",
      "1234 6788 71\n",
      "1245 6851 72\n",
      "1255 6899 73\n",
      "1267 6969 74\n",
      "1285 7087 75\n",
      "1298 7168 76\n",
      "1310 7234 77\n",
      "1325 7331 78\n",
      "1341 7421 79\n",
      "1353 7489 80\n",
      "1365 7561 81\n",
      "1378 7648 82\n",
      "1389 7709 83\n",
      "1400 7770 84\n",
      "1412 7844 85\n",
      "1424 7924 86\n",
      "1436 8010 87\n",
      "1444 8054 88\n",
      "1454 8128 89\n",
      "1468 8222 90\n",
      "1482 8310 91\n",
      "1498 8406 92\n",
      "1513 8497 93\n",
      "1525 8575 94\n",
      "1537 8653 95\n",
      "1552 8746 96\n",
      "1565 8841 97\n",
      "1579 8921 98\n",
      "1591 8989 99\n",
      "1604 9062 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.9985569985569985 26.799819895552645 \ttest: 0.9461279461279462 61.20982712924999\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 7.4933238269521265 \ttest: 0.9528619528619529 46.55451494977534\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 3.28828144070664 \ttest: 0.9528619528619529 41.438210472040836\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 1.801101062155079 \ttest: 0.9528619528619529 38.83711880118588\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.1246103991310332 \ttest: 0.9528619528619529 37.251411851711495\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        63\n",
      "           1    1.00000   1.00000   1.00000        63\n",
      "           2    1.00000   1.00000   1.00000        63\n",
      "           3    1.00000   1.00000   1.00000        63\n",
      "           4    1.00000   1.00000   1.00000        63\n",
      "           5    1.00000   1.00000   1.00000        63\n",
      "           6    1.00000   1.00000   1.00000        63\n",
      "           7    1.00000   1.00000   1.00000        63\n",
      "           8    1.00000   1.00000   1.00000        63\n",
      "           9    1.00000   1.00000   1.00000        63\n",
      "          10    1.00000   1.00000   1.00000        63\n",
      "\n",
      "    accuracy                        1.00000       693\n",
      "   macro avg    1.00000   1.00000   1.00000       693\n",
      "weighted avg    1.00000   1.00000   1.00000       693\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        27\n",
      "           1    1.00000   0.96296   0.98113        27\n",
      "           2    1.00000   0.96296   0.98113        27\n",
      "           3    0.96000   0.88889   0.92308        27\n",
      "           4    0.96154   0.92593   0.94340        27\n",
      "           5    0.81818   1.00000   0.90000        27\n",
      "           6    0.92000   0.85185   0.88462        27\n",
      "           7    0.89286   0.92593   0.90909        27\n",
      "           8    0.96429   1.00000   0.98182        27\n",
      "           9    1.00000   1.00000   1.00000        27\n",
      "          10    1.00000   0.96296   0.98113        27\n",
      "\n",
      "    accuracy                        0.95286       297\n",
      "   macro avg    0.95608   0.95286   0.95322       297\n",
      "weighted avg    0.95608   0.95286   0.95322       297\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1604\n",
      "Average of depth: 1.976932668329177\n",
      "Number of nodes: 9062\n",
      "30 142 1\n",
      "60 272 2\n",
      "85 399 3\n",
      "111 513 4\n",
      "138 656 5\n",
      "163 771 6\n",
      "190 902 7\n",
      "212 1016 8\n",
      "232 1106 9\n",
      "254 1202 10\n",
      "275 1311 11\n",
      "300 1444 12\n",
      "321 1551 13\n",
      "340 1648 14\n",
      "356 1724 15\n",
      "380 1850 16\n",
      "399 1945 17\n",
      "419 2045 18\n",
      "438 2136 19\n",
      "452 2212 20\n",
      "468 2284 21\n",
      "487 2393 22\n",
      "506 2494 23\n",
      "524 2600 24\n",
      "545 2705 25\n",
      "561 2801 26\n",
      "581 2917 27\n",
      "600 3020 28\n",
      "615 3103 29\n",
      "628 3190 30\n",
      "643 3271 31\n",
      "660 3350 32\n",
      "677 3443 33\n",
      "693 3529 34\n",
      "707 3623 35\n",
      "721 3697 36\n",
      "741 3819 37\n",
      "756 3926 38\n",
      "773 4017 39\n",
      "785 4081 40\n",
      "800 4164 41\n",
      "814 4244 42\n",
      "828 4326 43\n",
      "845 4411 44\n",
      "856 4478 45\n",
      "872 4570 46\n",
      "884 4630 47\n",
      "900 4726 48\n",
      "916 4826 49\n",
      "929 4901 50\n",
      "943 4977 51\n",
      "958 5068 52\n",
      "977 5173 53\n",
      "992 5270 54\n",
      "1011 5393 55\n",
      "1026 5500 56\n",
      "1035 5543 57\n",
      "1048 5616 58\n",
      "1062 5702 59\n",
      "1077 5795 60\n",
      "1090 5866 61\n",
      "1105 5961 62\n",
      "1119 6045 63\n",
      "1136 6148 64\n",
      "1147 6209 65\n",
      "1159 6277 66\n",
      "1172 6362 67\n",
      "1191 6485 68\n",
      "1201 6551 69\n",
      "1215 6639 70\n",
      "1228 6718 71\n",
      "1242 6812 72\n",
      "1255 6873 73\n",
      "1273 6987 74\n",
      "1286 7054 75\n",
      "1301 7157 76\n",
      "1315 7245 77\n",
      "1328 7316 78\n",
      "1339 7391 79\n",
      "1349 7453 80\n",
      "1358 7504 81\n",
      "1367 7555 82\n",
      "1378 7626 83\n",
      "1389 7695 84\n",
      "1401 7765 85\n",
      "1413 7845 86\n",
      "1424 7920 87\n",
      "1435 7991 88\n",
      "1451 8081 89\n",
      "1463 8159 90\n",
      "1473 8221 91\n",
      "1487 8307 92\n",
      "1504 8396 93\n",
      "1515 8473 94\n",
      "1527 8539 95\n",
      "1540 8616 96\n",
      "1555 8713 97\n",
      "1566 8784 98\n",
      "1576 8840 99\n",
      "1590 8914 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 28.199374510536618 \ttest: 0.936026936026936 73.19213610436597\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 7.644594138874625 \ttest: 0.9427609427609428 57.567389354710585\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 3.316924441402391 \ttest: 0.9427609427609428 51.912863636963\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 1.8107628555271387 \ttest: 0.9461279461279462 48.971204201785056\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.1294468965631936 \ttest: 0.9461279461279462 47.14100929711618\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        63\n",
      "           1    1.00000   1.00000   1.00000        63\n",
      "           2    1.00000   1.00000   1.00000        63\n",
      "           3    1.00000   1.00000   1.00000        63\n",
      "           4    1.00000   1.00000   1.00000        63\n",
      "           5    1.00000   1.00000   1.00000        63\n",
      "           6    1.00000   1.00000   1.00000        63\n",
      "           7    1.00000   1.00000   1.00000        63\n",
      "           8    1.00000   1.00000   1.00000        63\n",
      "           9    1.00000   1.00000   1.00000        63\n",
      "          10    1.00000   1.00000   1.00000        63\n",
      "\n",
      "    accuracy                        1.00000       693\n",
      "   macro avg    1.00000   1.00000   1.00000       693\n",
      "weighted avg    1.00000   1.00000   1.00000       693\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.92593   0.92593   0.92593        27\n",
      "           1    1.00000   1.00000   1.00000        27\n",
      "           2    1.00000   0.96296   0.98113        27\n",
      "           3    0.96000   0.88889   0.92308        27\n",
      "           4    1.00000   0.92593   0.96154        27\n",
      "           5    0.88462   0.85185   0.86792        27\n",
      "           6    0.79310   0.85185   0.82143        27\n",
      "           7    0.96429   1.00000   0.98182        27\n",
      "           8    0.96429   1.00000   0.98182        27\n",
      "           9    0.96429   1.00000   0.98182        27\n",
      "          10    0.96429   1.00000   0.98182        27\n",
      "\n",
      "    accuracy                        0.94613       297\n",
      "   macro avg    0.94734   0.94613   0.94621       297\n",
      "weighted avg    0.94734   0.94613   0.94621       297\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1590\n",
      "Average of depth: 1.9647798742138365\n",
      "Number of nodes: 8914\n",
      "27 133 1\n",
      "56 272 2\n",
      "78 374 3\n",
      "104 496 4\n",
      "131 625 5\n",
      "157 749 6\n",
      "183 869 7\n",
      "210 1006 8\n",
      "232 1108 9\n",
      "257 1233 10\n",
      "279 1341 11\n",
      "298 1424 12\n",
      "318 1526 13\n",
      "336 1596 14\n",
      "358 1710 15\n",
      "381 1811 16\n",
      "404 1942 17\n",
      "427 2057 18\n",
      "443 2143 19\n",
      "466 2260 20\n",
      "481 2341 21\n",
      "498 2432 22\n",
      "512 2514 23\n",
      "533 2629 24\n",
      "552 2730 25\n",
      "568 2818 26\n",
      "585 2913 27\n",
      "603 3013 28\n",
      "624 3136 29\n",
      "642 3254 30\n",
      "655 3319 31\n",
      "665 3375 32\n",
      "684 3486 33\n",
      "702 3580 34\n",
      "718 3656 35\n",
      "734 3746 36\n",
      "752 3846 37\n",
      "764 3926 38\n",
      "781 4017 39\n",
      "795 4087 40\n",
      "809 4157 41\n",
      "828 4268 42\n",
      "843 4379 43\n",
      "856 4452 44\n",
      "872 4548 45\n",
      "887 4643 46\n",
      "906 4750 47\n",
      "917 4823 48\n",
      "933 4925 49\n",
      "949 5041 50\n",
      "966 5142 51\n",
      "981 5221 52\n",
      "995 5313 53\n",
      "1007 5383 54\n",
      "1024 5486 55\n",
      "1034 5536 56\n",
      "1046 5606 57\n",
      "1059 5691 58\n",
      "1074 5784 59\n",
      "1084 5840 60\n",
      "1098 5942 61\n",
      "1111 6027 62\n",
      "1127 6139 63\n",
      "1137 6199 64\n",
      "1152 6292 65\n",
      "1160 6342 66\n",
      "1174 6424 67\n",
      "1186 6494 68\n",
      "1196 6550 69\n",
      "1210 6632 70\n",
      "1225 6715 71\n",
      "1241 6823 72\n",
      "1251 6887 73\n",
      "1265 6965 74\n",
      "1278 7040 75\n",
      "1293 7141 76\n",
      "1303 7203 77\n",
      "1314 7272 78\n",
      "1321 7301 79\n",
      "1336 7398 80\n",
      "1347 7463 81\n",
      "1359 7533 82\n",
      "1371 7607 83\n",
      "1385 7689 84\n",
      "1397 7761 85\n",
      "1410 7848 86\n",
      "1423 7931 87\n",
      "1437 8025 88\n",
      "1450 8100 89\n",
      "1459 8153 90\n",
      "1471 8223 91\n",
      "1484 8306 92\n",
      "1494 8364 93\n",
      "1508 8440 94\n",
      "1520 8520 95\n",
      "1532 8598 96\n",
      "1545 8675 97\n",
      "1556 8740 98\n",
      "1570 8834 99\n",
      "1583 8915 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 29.674314997387164 \ttest: 0.9427609427609428 70.6940294312775\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 8.234299170905448 \ttest: 0.9562289562289562 54.88468817159298\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 3.599757698967507 \ttest: 0.9595959595959596 49.08323211470881\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 1.9700852530105424 \ttest: 0.9629629629629629 46.01623336930679\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.2297341401604323 \ttest: 0.9629629629629629 44.07909501888855\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        63\n",
      "           1    1.00000   1.00000   1.00000        63\n",
      "           2    1.00000   1.00000   1.00000        63\n",
      "           3    1.00000   1.00000   1.00000        63\n",
      "           4    1.00000   1.00000   1.00000        63\n",
      "           5    1.00000   1.00000   1.00000        63\n",
      "           6    1.00000   1.00000   1.00000        63\n",
      "           7    1.00000   1.00000   1.00000        63\n",
      "           8    1.00000   1.00000   1.00000        63\n",
      "           9    1.00000   1.00000   1.00000        63\n",
      "          10    1.00000   1.00000   1.00000        63\n",
      "\n",
      "    accuracy                        1.00000       693\n",
      "   macro avg    1.00000   1.00000   1.00000       693\n",
      "weighted avg    1.00000   1.00000   1.00000       693\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   0.96296   0.98113        27\n",
      "           1    1.00000   0.96296   0.98113        27\n",
      "           2    0.96154   0.92593   0.94340        27\n",
      "           3    1.00000   0.92593   0.96154        27\n",
      "           4    0.96296   0.96296   0.96296        27\n",
      "           5    0.93103   1.00000   0.96429        27\n",
      "           6    0.96000   0.88889   0.92308        27\n",
      "           7    0.93103   1.00000   0.96429        27\n",
      "           8    0.96429   1.00000   0.98182        27\n",
      "           9    0.90000   1.00000   0.94737        27\n",
      "          10    1.00000   0.96296   0.98113        27\n",
      "\n",
      "    accuracy                        0.96296       297\n",
      "   macro avg    0.96462   0.96296   0.96292       297\n",
      "weighted avg    0.96462   0.96296   0.96292       297\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1583\n",
      "Average of depth: 1.9772583701831965\n",
      "Number of nodes: 8915\n",
      "30 136 1\n",
      "56 254 2\n",
      "83 373 3\n",
      "110 508 4\n",
      "139 641 5\n",
      "167 789 6\n",
      "189 901 7\n",
      "215 1025 8\n",
      "238 1136 9\n",
      "264 1284 10\n",
      "285 1393 11\n",
      "305 1487 12\n",
      "329 1607 13\n",
      "348 1710 14\n",
      "370 1808 15\n",
      "387 1885 16\n",
      "411 2015 17\n",
      "428 2102 18\n",
      "447 2181 19\n",
      "469 2297 20\n",
      "488 2396 21\n",
      "507 2493 22\n",
      "527 2595 23\n",
      "544 2690 24\n",
      "562 2814 25\n",
      "584 2944 26\n",
      "602 3066 27\n",
      "618 3150 28\n",
      "631 3215 29\n",
      "648 3310 30\n",
      "665 3395 31\n",
      "675 3445 32\n",
      "692 3546 33\n",
      "706 3630 34\n",
      "721 3715 35\n",
      "737 3803 36\n",
      "755 3891 37\n",
      "768 3956 38\n",
      "786 4052 39\n",
      "802 4158 40\n",
      "817 4255 41\n",
      "832 4346 42\n",
      "843 4413 43\n",
      "861 4509 44\n",
      "874 4586 45\n",
      "887 4683 46\n",
      "900 4756 47\n",
      "913 4823 48\n",
      "930 4912 49\n",
      "942 4990 50\n",
      "957 5073 51\n",
      "968 5134 52\n",
      "979 5191 53\n",
      "995 5277 54\n",
      "1009 5357 55\n",
      "1021 5417 56\n",
      "1036 5508 57\n",
      "1049 5579 58\n",
      "1061 5649 59\n",
      "1078 5744 60\n",
      "1089 5799 61\n",
      "1105 5891 62\n",
      "1116 5950 63\n",
      "1126 6030 64\n",
      "1140 6124 65\n",
      "1152 6196 66\n",
      "1166 6276 67\n",
      "1180 6360 68\n",
      "1190 6424 69\n",
      "1202 6490 70\n",
      "1211 6539 71\n",
      "1222 6612 72\n",
      "1236 6700 73\n",
      "1245 6767 74\n",
      "1259 6865 75\n",
      "1272 6944 76\n",
      "1286 7022 77\n",
      "1297 7093 78\n",
      "1313 7201 79\n",
      "1325 7269 80\n",
      "1337 7335 81\n",
      "1353 7423 82\n",
      "1362 7470 83\n",
      "1374 7554 84\n",
      "1387 7631 85\n",
      "1401 7715 86\n",
      "1416 7800 87\n",
      "1428 7876 88\n",
      "1442 7966 89\n",
      "1456 8046 90\n",
      "1469 8125 91\n",
      "1482 8202 92\n",
      "1495 8287 93\n",
      "1507 8359 94\n",
      "1524 8464 95\n",
      "1537 8535 96\n",
      "1551 8617 97\n",
      "1566 8710 98\n",
      "1580 8800 99\n",
      "1592 8878 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 29.52338925907513 \ttest: 0.9393939393939394 67.4100085650172\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 8.33541137872258 \ttest: 0.9461279461279462 51.64828131185489\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 3.6635359574902724 \ttest: 0.9528619528619529 45.90069735535381\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 2.0065233543213754 \ttest: 0.9528619528619529 42.918142873512664\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.2518573512256361 \ttest: 0.9528619528619529 41.073384738403306\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        63\n",
      "           1    1.00000   1.00000   1.00000        63\n",
      "           2    1.00000   1.00000   1.00000        63\n",
      "           3    1.00000   1.00000   1.00000        63\n",
      "           4    1.00000   1.00000   1.00000        63\n",
      "           5    1.00000   1.00000   1.00000        63\n",
      "           6    1.00000   1.00000   1.00000        63\n",
      "           7    1.00000   1.00000   1.00000        63\n",
      "           8    1.00000   1.00000   1.00000        63\n",
      "           9    1.00000   1.00000   1.00000        63\n",
      "          10    1.00000   1.00000   1.00000        63\n",
      "\n",
      "    accuracy                        1.00000       693\n",
      "   macro avg    1.00000   1.00000   1.00000       693\n",
      "weighted avg    1.00000   1.00000   1.00000       693\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.90000   1.00000   0.94737        27\n",
      "           1    0.96296   0.96296   0.96296        27\n",
      "           2    0.92593   0.92593   0.92593        27\n",
      "           3    1.00000   0.92593   0.96154        27\n",
      "           4    1.00000   0.96296   0.98113        27\n",
      "           5    0.93103   1.00000   0.96429        27\n",
      "           6    0.85714   0.88889   0.87273        27\n",
      "           7    1.00000   0.85185   0.92000        27\n",
      "           8    0.96429   1.00000   0.98182        27\n",
      "           9    0.96429   1.00000   0.98182        27\n",
      "          10    1.00000   0.96296   0.98113        27\n",
      "\n",
      "    accuracy                        0.95286       297\n",
      "   macro avg    0.95506   0.95286   0.95279       297\n",
      "weighted avg    0.95506   0.95286   0.95279       297\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1592\n",
      "Average of depth: 1.960427135678392\n",
      "Number of nodes: 8878\n",
      "30 134 1\n",
      "56 260 2\n",
      "81 377 3\n",
      "108 518 4\n",
      "134 638 5\n",
      "158 754 6\n",
      "183 905 7\n",
      "205 1039 8\n",
      "232 1162 9\n",
      "256 1292 10\n",
      "276 1408 11\n",
      "295 1499 12\n",
      "318 1594 13\n",
      "337 1695 14\n",
      "354 1804 15\n",
      "371 1889 16\n",
      "393 2005 17\n",
      "414 2116 18\n",
      "432 2204 19\n",
      "450 2294 20\n",
      "468 2376 21\n",
      "488 2486 22\n",
      "508 2598 23\n",
      "527 2705 24\n",
      "548 2808 25\n",
      "566 2902 26\n",
      "582 2990 27\n",
      "598 3102 28\n",
      "615 3197 29\n",
      "629 3271 30\n",
      "646 3364 31\n",
      "659 3457 32\n",
      "677 3559 33\n",
      "694 3650 34\n",
      "709 3731 35\n",
      "721 3791 36\n",
      "735 3885 37\n",
      "756 4006 38\n",
      "769 4081 39\n",
      "783 4169 40\n",
      "802 4280 41\n",
      "819 4387 42\n",
      "832 4460 43\n",
      "851 4583 44\n",
      "862 4642 45\n",
      "879 4735 46\n",
      "901 4863 47\n",
      "912 4918 48\n",
      "927 5009 49\n",
      "942 5086 50\n",
      "953 5149 51\n",
      "968 5254 52\n",
      "976 5300 53\n",
      "990 5388 54\n",
      "1001 5443 55\n",
      "1019 5555 56\n",
      "1033 5637 57\n",
      "1042 5686 58\n",
      "1056 5780 59\n",
      "1072 5884 60\n",
      "1084 5950 61\n",
      "1100 6040 62\n",
      "1119 6155 63\n",
      "1130 6210 64\n",
      "1142 6282 65\n",
      "1157 6373 66\n",
      "1170 6452 67\n",
      "1183 6527 68\n",
      "1193 6583 69\n",
      "1204 6638 70\n",
      "1220 6752 71\n",
      "1233 6821 72\n",
      "1248 6910 73\n",
      "1258 6962 74\n",
      "1268 7016 75\n",
      "1278 7080 76\n",
      "1289 7141 77\n",
      "1304 7234 78\n",
      "1319 7335 79\n",
      "1330 7402 80\n",
      "1345 7503 81\n",
      "1360 7598 82\n",
      "1374 7676 83\n",
      "1387 7769 84\n",
      "1403 7877 85\n",
      "1419 7973 86\n",
      "1430 8030 87\n",
      "1443 8109 88\n",
      "1455 8183 89\n",
      "1468 8270 90\n",
      "1483 8367 91\n",
      "1499 8459 92\n",
      "1513 8551 93\n",
      "1527 8627 94\n",
      "1541 8721 95\n",
      "1554 8790 96\n",
      "1565 8863 97\n",
      "1576 8946 98\n",
      "1585 8997 99\n",
      "1595 9057 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 27.392235611969156 \ttest: 0.9191919191919192 67.51983310242647\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 7.546884074120612 \ttest: 0.9427609427609428 52.7885886569065\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 3.308180325046911 \ttest: 0.9461279461279462 47.4891464897952\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 1.8156738380414426 \ttest: 0.9461279461279462 44.726784514392506\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.1359629879400344 \ttest: 0.9461279461279462 43.00452646906933\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        63\n",
      "           1    1.00000   1.00000   1.00000        63\n",
      "           2    1.00000   1.00000   1.00000        63\n",
      "           3    1.00000   1.00000   1.00000        63\n",
      "           4    1.00000   1.00000   1.00000        63\n",
      "           5    1.00000   1.00000   1.00000        63\n",
      "           6    1.00000   1.00000   1.00000        63\n",
      "           7    1.00000   1.00000   1.00000        63\n",
      "           8    1.00000   1.00000   1.00000        63\n",
      "           9    1.00000   1.00000   1.00000        63\n",
      "          10    1.00000   1.00000   1.00000        63\n",
      "\n",
      "    accuracy                        1.00000       693\n",
      "   macro avg    1.00000   1.00000   1.00000       693\n",
      "weighted avg    1.00000   1.00000   1.00000       693\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   0.88889   0.94118        27\n",
      "           1    0.96296   0.96296   0.96296        27\n",
      "           2    0.87097   1.00000   0.93103        27\n",
      "           3    0.92593   0.92593   0.92593        27\n",
      "           4    1.00000   0.85185   0.92000        27\n",
      "           5    0.96296   0.96296   0.96296        27\n",
      "           6    0.87097   1.00000   0.93103        27\n",
      "           7    1.00000   0.92593   0.96154        27\n",
      "           8    1.00000   0.96296   0.98113        27\n",
      "           9    0.90000   1.00000   0.94737        27\n",
      "          10    0.96154   0.92593   0.94340        27\n",
      "\n",
      "    accuracy                        0.94613       297\n",
      "   macro avg    0.95048   0.94613   0.94623       297\n",
      "weighted avg    0.95048   0.94613   0.94623       297\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1595\n",
      "Average of depth: 1.9836990595611286\n",
      "Number of nodes: 9057\n",
      "30 142 1\n",
      "59 275 2\n",
      "85 413 3\n",
      "108 528 4\n",
      "136 660 5\n",
      "158 786 6\n",
      "184 924 7\n",
      "207 1043 8\n",
      "233 1169 9\n",
      "258 1272 10\n",
      "281 1385 11\n",
      "306 1530 12\n",
      "326 1620 13\n",
      "349 1747 14\n",
      "373 1863 15\n",
      "393 1965 16\n",
      "417 2087 17\n",
      "436 2194 18\n",
      "458 2320 19\n",
      "471 2383 20\n",
      "488 2482 21\n",
      "504 2574 22\n",
      "527 2685 23\n",
      "540 2738 24\n",
      "559 2843 25\n",
      "580 2960 26\n",
      "599 3075 27\n",
      "613 3157 28\n",
      "634 3264 29\n",
      "654 3382 30\n",
      "672 3492 31\n",
      "689 3595 32\n",
      "705 3693 33\n",
      "720 3776 34\n",
      "732 3842 35\n",
      "747 3941 36\n",
      "762 4024 37\n",
      "782 4134 38\n",
      "797 4221 39\n",
      "811 4299 40\n",
      "825 4377 41\n",
      "836 4432 42\n",
      "856 4544 43\n",
      "868 4608 44\n",
      "882 4696 45\n",
      "898 4804 46\n",
      "914 4902 47\n",
      "929 4985 48\n",
      "939 5035 49\n",
      "951 5105 50\n",
      "965 5181 51\n",
      "973 5229 52\n",
      "983 5291 53\n",
      "991 5337 54\n",
      "1005 5409 55\n",
      "1020 5490 56\n",
      "1034 5580 57\n",
      "1048 5670 58\n",
      "1057 5727 59\n",
      "1071 5819 60\n",
      "1085 5903 61\n",
      "1097 5979 62\n",
      "1110 6054 63\n",
      "1124 6148 64\n",
      "1136 6222 65\n",
      "1148 6286 66\n",
      "1160 6350 67\n",
      "1173 6441 68\n",
      "1185 6513 69\n",
      "1200 6606 70\n",
      "1209 6657 71\n",
      "1218 6706 72\n",
      "1232 6798 73\n",
      "1243 6867 74\n",
      "1258 6962 75\n",
      "1272 7058 76\n",
      "1285 7131 77\n",
      "1301 7245 78\n",
      "1318 7368 79\n",
      "1329 7435 80\n",
      "1345 7527 81\n",
      "1353 7567 82\n",
      "1365 7639 83\n",
      "1378 7734 84\n",
      "1391 7815 85\n",
      "1399 7857 86\n",
      "1409 7917 87\n",
      "1421 7989 88\n",
      "1432 8068 89\n",
      "1447 8171 90\n",
      "1459 8257 91\n",
      "1469 8317 92\n",
      "1480 8382 93\n",
      "1492 8462 94\n",
      "1506 8556 95\n",
      "1520 8652 96\n",
      "1536 8764 97\n",
      "1552 8880 98\n",
      "1561 8933 99\n",
      "1575 9019 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 26.426631244775688 \ttest: 0.9191919191919192 75.30320412448214\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 7.207811327969104 \ttest: 0.9326599326599326 60.52240621303359\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 3.1420398427193748 \ttest: 0.9326599326599326 55.11936887879028\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 1.7196519043901857 \ttest: 0.936026936026936 52.26832353138598\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.0744003242666138 \ttest: 0.936026936026936 50.476119191333154\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        63\n",
      "           1    1.00000   1.00000   1.00000        63\n",
      "           2    1.00000   1.00000   1.00000        63\n",
      "           3    1.00000   1.00000   1.00000        63\n",
      "           4    1.00000   1.00000   1.00000        63\n",
      "           5    1.00000   1.00000   1.00000        63\n",
      "           6    1.00000   1.00000   1.00000        63\n",
      "           7    1.00000   1.00000   1.00000        63\n",
      "           8    1.00000   1.00000   1.00000        63\n",
      "           9    1.00000   1.00000   1.00000        63\n",
      "          10    1.00000   1.00000   1.00000        63\n",
      "\n",
      "    accuracy                        1.00000       693\n",
      "   macro avg    1.00000   1.00000   1.00000       693\n",
      "weighted avg    1.00000   1.00000   1.00000       693\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.96000   0.88889   0.92308        27\n",
      "           1    1.00000   0.92593   0.96154        27\n",
      "           2    0.92857   0.96296   0.94545        27\n",
      "           3    0.92857   0.96296   0.94545        27\n",
      "           4    0.88462   0.85185   0.86792        27\n",
      "           5    0.96296   0.96296   0.96296        27\n",
      "           6    0.92000   0.85185   0.88462        27\n",
      "           7    0.84375   1.00000   0.91525        27\n",
      "           8    0.96429   1.00000   0.98182        27\n",
      "           9    0.96296   0.96296   0.96296        27\n",
      "          10    0.96154   0.92593   0.94340        27\n",
      "\n",
      "    accuracy                        0.93603       297\n",
      "   macro avg    0.93793   0.93603   0.93586       297\n",
      "weighted avg    0.93793   0.93603   0.93586       297\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1575\n",
      "Average of depth: 1.9765079365079365\n",
      "Number of nodes: 9019\n",
      "27 141 1\n",
      "56 294 2\n",
      "83 439 3\n",
      "106 552 4\n",
      "135 673 5\n",
      "162 794 6\n",
      "187 923 7\n",
      "210 1042 8\n",
      "231 1129 9\n",
      "255 1235 10\n",
      "275 1319 11\n",
      "293 1395 12\n",
      "319 1525 13\n",
      "339 1639 14\n",
      "357 1721 15\n",
      "374 1802 16\n",
      "397 1921 17\n",
      "415 2023 18\n",
      "434 2114 19\n",
      "452 2224 20\n",
      "472 2328 21\n",
      "490 2436 22\n",
      "503 2505 23\n",
      "521 2605 24\n",
      "538 2682 25\n",
      "553 2765 26\n",
      "571 2861 27\n",
      "590 2954 28\n",
      "604 3030 29\n",
      "626 3172 30\n",
      "640 3250 31\n",
      "657 3341 32\n",
      "678 3456 33\n",
      "694 3546 34\n",
      "711 3633 35\n",
      "729 3741 36\n",
      "749 3873 37\n",
      "763 3961 38\n",
      "779 4043 39\n",
      "794 4126 40\n",
      "805 4187 41\n",
      "817 4249 42\n",
      "834 4360 43\n",
      "848 4444 44\n",
      "861 4519 45\n",
      "871 4577 46\n",
      "886 4662 47\n",
      "898 4724 48\n",
      "917 4845 49\n",
      "932 4940 50\n",
      "950 5036 51\n",
      "966 5126 52\n",
      "982 5222 53\n",
      "997 5307 54\n",
      "1008 5370 55\n",
      "1023 5467 56\n",
      "1039 5563 57\n",
      "1056 5654 58\n",
      "1069 5731 59\n",
      "1084 5814 60\n",
      "1096 5894 61\n",
      "1107 5953 62\n",
      "1124 6068 63\n",
      "1139 6153 64\n",
      "1153 6243 65\n",
      "1169 6343 66\n",
      "1180 6412 67\n",
      "1187 6447 68\n",
      "1196 6492 69\n",
      "1205 6543 70\n",
      "1215 6595 71\n",
      "1229 6679 72\n",
      "1241 6751 73\n",
      "1255 6829 74\n",
      "1269 6921 75\n",
      "1280 6982 76\n",
      "1293 7061 77\n",
      "1304 7130 78\n",
      "1314 7186 79\n",
      "1324 7248 80\n",
      "1332 7314 81\n",
      "1344 7390 82\n",
      "1357 7465 83\n",
      "1370 7544 84\n",
      "1376 7578 85\n",
      "1385 7621 86\n",
      "1396 7690 87\n",
      "1405 7743 88\n",
      "1419 7825 89\n",
      "1431 7901 90\n",
      "1446 7990 91\n",
      "1458 8060 92\n",
      "1472 8146 93\n",
      "1484 8214 94\n",
      "1498 8312 95\n",
      "1508 8386 96\n",
      "1517 8435 97\n",
      "1532 8528 98\n",
      "1544 8606 99\n",
      "1554 8672 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 29.51693752882744 \ttest: 0.9292929292929293 69.28630172879647\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 8.219242375549767 \ttest: 0.9461279461279462 54.075287026203696\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 3.61686602158893 \ttest: 0.9461279461279462 48.72625444116788\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 1.9866840934851195 \ttest: 0.9461279461279462 45.98229918896109\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.2427911696830292 \ttest: 0.9461279461279462 44.29277838136085\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        63\n",
      "           1    1.00000   1.00000   1.00000        63\n",
      "           2    1.00000   1.00000   1.00000        63\n",
      "           3    1.00000   1.00000   1.00000        63\n",
      "           4    1.00000   1.00000   1.00000        63\n",
      "           5    1.00000   1.00000   1.00000        63\n",
      "           6    1.00000   1.00000   1.00000        63\n",
      "           7    1.00000   1.00000   1.00000        63\n",
      "           8    1.00000   1.00000   1.00000        63\n",
      "           9    1.00000   1.00000   1.00000        63\n",
      "          10    1.00000   1.00000   1.00000        63\n",
      "\n",
      "    accuracy                        1.00000       693\n",
      "   macro avg    1.00000   1.00000   1.00000       693\n",
      "weighted avg    1.00000   1.00000   1.00000       693\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        27\n",
      "           1    0.96296   0.96296   0.96296        27\n",
      "           2    0.96296   0.96296   0.96296        27\n",
      "           3    0.88889   0.88889   0.88889        27\n",
      "           4    1.00000   0.85185   0.92000        27\n",
      "           5    0.81481   0.81481   0.81481        27\n",
      "           6    0.96154   0.92593   0.94340        27\n",
      "           7    0.93103   1.00000   0.96429        27\n",
      "           8    1.00000   1.00000   1.00000        27\n",
      "           9    0.90000   1.00000   0.94737        27\n",
      "          10    1.00000   1.00000   1.00000        27\n",
      "\n",
      "    accuracy                        0.94613       297\n",
      "   macro avg    0.94747   0.94613   0.94588       297\n",
      "weighted avg    0.94747   0.94613   0.94588       297\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1554\n",
      "Average of depth: 1.9639639639639639\n",
      "Number of nodes: 8672\n",
      "22 98 1\n",
      "50 230 2\n",
      "79 371 3\n",
      "103 481 4\n",
      "124 572 5\n",
      "149 703 6\n",
      "173 825 7\n",
      "199 953 8\n",
      "219 1049 9\n",
      "243 1181 10\n",
      "265 1301 11\n",
      "289 1421 12\n",
      "309 1525 13\n",
      "331 1629 14\n",
      "351 1735 15\n",
      "367 1823 16\n",
      "387 1923 17\n",
      "408 2050 18\n",
      "428 2138 19\n",
      "448 2222 20\n",
      "467 2347 21\n",
      "481 2425 22\n",
      "497 2523 23\n",
      "510 2596 24\n",
      "530 2706 25\n",
      "546 2792 26\n",
      "563 2887 27\n",
      "583 3009 28\n",
      "601 3109 29\n",
      "617 3205 30\n",
      "632 3278 31\n",
      "652 3398 32\n",
      "666 3466 33\n",
      "678 3536 34\n",
      "691 3613 35\n",
      "706 3698 36\n",
      "719 3787 37\n",
      "739 3893 38\n",
      "756 3990 39\n",
      "770 4070 40\n",
      "787 4163 41\n",
      "799 4245 42\n",
      "810 4304 43\n",
      "826 4402 44\n",
      "846 4502 45\n",
      "862 4596 46\n",
      "880 4706 47\n",
      "897 4793 48\n",
      "913 4895 49\n",
      "926 4978 50\n",
      "942 5072 51\n",
      "960 5188 52\n",
      "977 5297 53\n",
      "989 5379 54\n",
      "999 5421 55\n",
      "1010 5494 56\n",
      "1027 5589 57\n",
      "1043 5689 58\n",
      "1058 5774 59\n",
      "1069 5835 60\n",
      "1083 5927 61\n",
      "1096 6006 62\n",
      "1109 6071 63\n",
      "1122 6144 64\n",
      "1137 6235 65\n",
      "1151 6321 66\n",
      "1164 6402 67\n",
      "1181 6507 68\n",
      "1190 6568 69\n",
      "1204 6650 70\n",
      "1214 6724 71\n",
      "1224 6796 72\n",
      "1240 6882 73\n",
      "1251 6945 74\n",
      "1263 7017 75\n",
      "1273 7079 76\n",
      "1284 7148 77\n",
      "1299 7241 78\n",
      "1312 7328 79\n",
      "1325 7413 80\n",
      "1341 7507 81\n",
      "1352 7570 82\n",
      "1370 7670 83\n",
      "1383 7749 84\n",
      "1394 7828 85\n",
      "1404 7886 86\n",
      "1420 7986 87\n",
      "1435 8071 88\n",
      "1449 8153 89\n",
      "1456 8196 90\n",
      "1471 8285 91\n",
      "1484 8362 92\n",
      "1495 8435 93\n",
      "1511 8543 94\n",
      "1523 8603 95\n",
      "1536 8686 96\n",
      "1548 8762 97\n",
      "1559 8829 98\n",
      "1571 8903 99\n",
      "1585 8987 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 29.589638832543017 \ttest: 0.9494949494949495 63.775645947349204\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 7.9676628826125775 \ttest: 0.9595959595959596 47.612725636543225\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 3.4292969258630355 \ttest: 0.9595959595959596 41.92692035031177\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 1.860935279162454 \ttest: 0.9629629629629629 39.009925602225536\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.1557946850935554 \ttest: 0.9629629629629629 37.21745400865882\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        63\n",
      "           1    1.00000   1.00000   1.00000        63\n",
      "           2    1.00000   1.00000   1.00000        63\n",
      "           3    1.00000   1.00000   1.00000        63\n",
      "           4    1.00000   1.00000   1.00000        63\n",
      "           5    1.00000   1.00000   1.00000        63\n",
      "           6    1.00000   1.00000   1.00000        63\n",
      "           7    1.00000   1.00000   1.00000        63\n",
      "           8    1.00000   1.00000   1.00000        63\n",
      "           9    1.00000   1.00000   1.00000        63\n",
      "          10    1.00000   1.00000   1.00000        63\n",
      "\n",
      "    accuracy                        1.00000       693\n",
      "   macro avg    1.00000   1.00000   1.00000       693\n",
      "weighted avg    1.00000   1.00000   1.00000       693\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   0.88889   0.94118        27\n",
      "           1    0.93103   1.00000   0.96429        27\n",
      "           2    1.00000   1.00000   1.00000        27\n",
      "           3    1.00000   0.92593   0.96154        27\n",
      "           4    0.96296   0.96296   0.96296        27\n",
      "           5    0.92857   0.96296   0.94545        27\n",
      "           6    0.96000   0.88889   0.92308        27\n",
      "           7    0.87097   1.00000   0.93103        27\n",
      "           8    1.00000   1.00000   1.00000        27\n",
      "           9    0.96296   0.96296   0.96296        27\n",
      "          10    1.00000   1.00000   1.00000        27\n",
      "\n",
      "    accuracy                        0.96296       297\n",
      "   macro avg    0.96514   0.96296   0.96295       297\n",
      "weighted avg    0.96514   0.96296   0.96295       297\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1585\n",
      "Average of depth: 1.9735015772870663\n",
      "Number of nodes: 8987\n",
      "29 133 1\n",
      "56 258 2\n",
      "80 378 3\n",
      "105 497 4\n",
      "135 653 5\n",
      "162 794 6\n",
      "189 939 7\n",
      "209 1039 8\n",
      "233 1151 9\n",
      "255 1273 10\n",
      "279 1385 11\n",
      "302 1518 12\n",
      "322 1626 13\n",
      "344 1752 14\n",
      "363 1869 15\n",
      "383 1975 16\n",
      "407 2123 17\n",
      "426 2210 18\n",
      "447 2297 19\n",
      "466 2406 20\n",
      "484 2514 21\n",
      "501 2597 22\n",
      "520 2692 23\n",
      "535 2757 24\n",
      "551 2845 25\n",
      "572 2950 26\n",
      "589 3041 27\n",
      "611 3147 28\n",
      "629 3247 29\n",
      "647 3345 30\n",
      "666 3446 31\n",
      "678 3512 32\n",
      "694 3586 33\n",
      "709 3661 34\n",
      "728 3776 35\n",
      "746 3874 36\n",
      "763 3957 37\n",
      "779 4053 38\n",
      "792 4116 39\n",
      "801 4171 40\n",
      "815 4251 41\n",
      "830 4344 42\n",
      "843 4427 43\n",
      "853 4483 44\n",
      "864 4548 45\n",
      "880 4626 46\n",
      "894 4700 47\n",
      "911 4803 48\n",
      "922 4856 49\n",
      "938 4948 50\n",
      "952 5030 51\n",
      "964 5094 52\n",
      "980 5196 53\n",
      "992 5266 54\n",
      "1007 5349 55\n",
      "1016 5404 56\n",
      "1031 5495 57\n",
      "1042 5556 58\n",
      "1053 5617 59\n",
      "1068 5702 60\n",
      "1086 5798 61\n",
      "1096 5858 62\n",
      "1109 5951 63\n",
      "1121 6035 64\n",
      "1132 6088 65\n",
      "1147 6175 66\n",
      "1161 6285 67\n",
      "1172 6354 68\n",
      "1189 6479 69\n",
      "1200 6534 70\n",
      "1217 6629 71\n",
      "1233 6735 72\n",
      "1246 6808 73\n",
      "1260 6888 74\n",
      "1275 6987 75\n",
      "1289 7065 76\n",
      "1297 7117 77\n",
      "1311 7203 78\n",
      "1323 7279 79\n",
      "1336 7378 80\n",
      "1347 7449 81\n",
      "1358 7520 82\n",
      "1369 7585 83\n",
      "1378 7632 84\n",
      "1390 7704 85\n",
      "1400 7756 86\n",
      "1409 7817 87\n",
      "1420 7876 88\n",
      "1431 7941 89\n",
      "1441 7997 90\n",
      "1452 8062 91\n",
      "1463 8133 92\n",
      "1476 8224 93\n",
      "1489 8325 94\n",
      "1498 8382 95\n",
      "1507 8435 96\n",
      "1519 8509 97\n",
      "1535 8611 98\n",
      "1545 8667 99\n",
      "1552 8712 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 28.75013184657625 \ttest: 0.9393939393939394 67.85403491742814\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 7.798110152746864 \ttest: 0.9393939393939394 53.00881837354207\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 3.377386375559801 \ttest: 0.9461279461279462 47.623533403029825\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 1.84145729387154 \ttest: 0.9494949494949495 44.80063346715451\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.1477256371549833 \ttest: 0.9494949494949495 43.030089510841705\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        63\n",
      "           1    1.00000   1.00000   1.00000        63\n",
      "           2    1.00000   1.00000   1.00000        63\n",
      "           3    1.00000   1.00000   1.00000        63\n",
      "           4    1.00000   1.00000   1.00000        63\n",
      "           5    1.00000   1.00000   1.00000        63\n",
      "           6    1.00000   1.00000   1.00000        63\n",
      "           7    1.00000   1.00000   1.00000        63\n",
      "           8    1.00000   1.00000   1.00000        63\n",
      "           9    1.00000   1.00000   1.00000        63\n",
      "          10    1.00000   1.00000   1.00000        63\n",
      "\n",
      "    accuracy                        1.00000       693\n",
      "   macro avg    1.00000   1.00000   1.00000       693\n",
      "weighted avg    1.00000   1.00000   1.00000       693\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   0.92593   0.96154        27\n",
      "           1    1.00000   0.96296   0.98113        27\n",
      "           2    0.96429   1.00000   0.98182        27\n",
      "           3    1.00000   0.92593   0.96154        27\n",
      "           4    0.96296   0.96296   0.96296        27\n",
      "           5    0.92593   0.92593   0.92593        27\n",
      "           6    0.88889   0.88889   0.88889        27\n",
      "           7    0.81250   0.96296   0.88136        27\n",
      "           8    1.00000   0.96296   0.98113        27\n",
      "           9    0.93103   1.00000   0.96429        27\n",
      "          10    1.00000   0.92593   0.96154        27\n",
      "\n",
      "    accuracy                        0.94949       297\n",
      "   macro avg    0.95324   0.94949   0.95019       297\n",
      "weighted avg    0.95324   0.94949   0.95019       297\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1552\n",
      "Average of depth: 1.9606958762886597\n",
      "Number of nodes: 8712\n",
      "29 113 1\n",
      "56 264 2\n",
      "83 399 3\n",
      "110 518 4\n",
      "136 660 5\n",
      "158 772 6\n",
      "184 890 7\n",
      "207 1011 8\n",
      "228 1124 9\n",
      "251 1235 10\n",
      "271 1333 11\n",
      "293 1445 12\n",
      "315 1553 13\n",
      "339 1693 14\n",
      "362 1814 15\n",
      "381 1941 16\n",
      "401 2049 17\n",
      "417 2137 18\n",
      "439 2247 19\n",
      "458 2378 20\n",
      "476 2478 21\n",
      "494 2562 22\n",
      "508 2626 23\n",
      "524 2710 24\n",
      "544 2802 25\n",
      "561 2897 26\n",
      "579 3003 27\n",
      "602 3124 28\n",
      "623 3247 29\n",
      "637 3313 30\n",
      "653 3403 31\n",
      "670 3500 32\n",
      "685 3587 33\n",
      "707 3717 34\n",
      "723 3809 35\n",
      "737 3879 36\n",
      "751 3955 37\n",
      "767 4045 38\n",
      "785 4159 39\n",
      "801 4255 40\n",
      "815 4343 41\n",
      "827 4409 42\n",
      "845 4515 43\n",
      "859 4601 44\n",
      "873 4681 45\n",
      "892 4792 46\n",
      "907 4873 47\n",
      "916 4924 48\n",
      "930 5002 49\n",
      "948 5094 50\n",
      "964 5174 51\n",
      "978 5248 52\n",
      "992 5326 53\n",
      "1004 5402 54\n",
      "1020 5494 55\n",
      "1039 5609 56\n",
      "1052 5684 57\n",
      "1067 5791 58\n",
      "1082 5886 59\n",
      "1092 5940 60\n",
      "1109 6051 61\n",
      "1122 6122 62\n",
      "1138 6218 63\n",
      "1152 6286 64\n",
      "1158 6324 65\n",
      "1176 6430 66\n",
      "1190 6500 67\n",
      "1201 6573 68\n",
      "1217 6677 69\n",
      "1230 6756 70\n",
      "1242 6824 71\n",
      "1255 6905 72\n",
      "1264 6962 73\n",
      "1279 7041 74\n",
      "1292 7124 75\n",
      "1309 7237 76\n",
      "1321 7303 77\n",
      "1336 7406 78\n",
      "1352 7506 79\n",
      "1363 7571 80\n",
      "1377 7661 81\n",
      "1387 7721 82\n",
      "1398 7790 83\n",
      "1411 7887 84\n",
      "1421 7947 85\n",
      "1432 8022 86\n",
      "1445 8111 87\n",
      "1458 8186 88\n",
      "1468 8248 89\n",
      "1486 8360 90\n",
      "1496 8416 91\n",
      "1503 8453 92\n",
      "1514 8514 93\n",
      "1529 8603 94\n",
      "1543 8687 95\n",
      "1555 8751 96\n",
      "1563 8797 97\n",
      "1574 8866 98\n",
      "1585 8939 99\n",
      "1597 9019 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 25.555107114899236 \ttest: 0.9191919191919192 67.98873081575903\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 6.968650546257849 \ttest: 0.9292929292929293 52.67190891415886\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 3.0359885924969188 \ttest: 0.936026936026936 47.13270364605749\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 1.6618654806104685 \ttest: 0.9393939393939394 44.22501826758915\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.0384088893472507 \ttest: 0.9427609427609428 42.40069179100411\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        63\n",
      "           1    1.00000   1.00000   1.00000        63\n",
      "           2    1.00000   1.00000   1.00000        63\n",
      "           3    1.00000   1.00000   1.00000        63\n",
      "           4    1.00000   1.00000   1.00000        63\n",
      "           5    1.00000   1.00000   1.00000        63\n",
      "           6    1.00000   1.00000   1.00000        63\n",
      "           7    1.00000   1.00000   1.00000        63\n",
      "           8    1.00000   1.00000   1.00000        63\n",
      "           9    1.00000   1.00000   1.00000        63\n",
      "          10    1.00000   1.00000   1.00000        63\n",
      "\n",
      "    accuracy                        1.00000       693\n",
      "   macro avg    1.00000   1.00000   1.00000       693\n",
      "weighted avg    1.00000   1.00000   1.00000       693\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   0.96296   0.98113        27\n",
      "           1    0.96154   0.92593   0.94340        27\n",
      "           2    0.96296   0.96296   0.96296        27\n",
      "           3    0.96154   0.92593   0.94340        27\n",
      "           4    1.00000   0.96296   0.98113        27\n",
      "           5    0.86667   0.96296   0.91228        27\n",
      "           6    0.84615   0.81481   0.83019        27\n",
      "           7    0.85714   0.88889   0.87273        27\n",
      "           8    0.96429   1.00000   0.98182        27\n",
      "           9    0.96296   0.96296   0.96296        27\n",
      "          10    1.00000   1.00000   1.00000        27\n",
      "\n",
      "    accuracy                        0.94276       297\n",
      "   macro avg    0.94393   0.94276   0.94291       297\n",
      "weighted avg    0.94393   0.94276   0.94291       297\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1597\n",
      "Average of depth: 1.9693174702567313\n",
      "Number of nodes: 9019\n",
      "24 110 1\n",
      "53 235 2\n",
      "80 378 3\n",
      "102 470 4\n",
      "129 617 5\n",
      "155 739 6\n",
      "175 835 7\n",
      "197 947 8\n",
      "221 1079 9\n",
      "243 1195 10\n",
      "266 1314 11\n",
      "290 1434 12\n",
      "315 1555 13\n",
      "335 1657 14\n",
      "355 1759 15\n",
      "372 1840 16\n",
      "392 1936 17\n",
      "418 2064 18\n",
      "440 2180 19\n",
      "464 2300 20\n",
      "480 2388 21\n",
      "493 2453 22\n",
      "508 2532 23\n",
      "528 2642 24\n",
      "541 2721 25\n",
      "553 2783 26\n",
      "569 2863 27\n",
      "587 2959 28\n",
      "606 3076 29\n",
      "620 3154 30\n",
      "633 3221 31\n",
      "648 3300 32\n",
      "667 3389 33\n",
      "685 3493 34\n",
      "703 3605 35\n",
      "716 3670 36\n",
      "730 3738 37\n",
      "746 3840 38\n",
      "764 3956 39\n",
      "775 4037 40\n",
      "791 4143 41\n",
      "801 4197 42\n",
      "815 4275 43\n",
      "834 4394 44\n",
      "850 4490 45\n",
      "862 4554 46\n",
      "877 4643 47\n",
      "889 4703 48\n",
      "901 4771 49\n",
      "916 4860 50\n",
      "932 4954 51\n",
      "939 5003 52\n",
      "952 5076 53\n",
      "965 5149 54\n",
      "981 5253 55\n",
      "989 5301 56\n",
      "1004 5390 57\n",
      "1019 5469 58\n",
      "1036 5574 59\n",
      "1050 5666 60\n",
      "1062 5740 61\n",
      "1072 5794 62\n",
      "1087 5885 63\n",
      "1100 5946 64\n",
      "1116 6052 65\n",
      "1130 6150 66\n",
      "1143 6233 67\n",
      "1154 6294 68\n",
      "1167 6375 69\n",
      "1179 6445 70\n",
      "1196 6536 71\n",
      "1207 6621 72\n",
      "1221 6699 73\n",
      "1235 6783 74\n",
      "1244 6844 75\n",
      "1254 6912 76\n",
      "1267 6989 77\n",
      "1276 7046 78\n",
      "1289 7127 79\n",
      "1300 7188 80\n",
      "1310 7246 81\n",
      "1326 7350 82\n",
      "1338 7408 83\n",
      "1352 7494 84\n",
      "1368 7584 85\n",
      "1379 7647 86\n",
      "1391 7719 87\n",
      "1400 7770 88\n",
      "1413 7849 89\n",
      "1425 7925 90\n",
      "1435 7983 91\n",
      "1446 8054 92\n",
      "1458 8132 93\n",
      "1472 8214 94\n",
      "1480 8272 95\n",
      "1489 8325 96\n",
      "1507 8427 97\n",
      "1517 8493 98\n",
      "1531 8581 99\n",
      "1542 8648 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 30.18044030918982 \ttest: 0.9393939393939394 64.9557436481689\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 8.493925707153629 \ttest: 0.9595959595959596 50.031754015580034\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 3.739444666706843 \ttest: 0.9629629629629629 44.72360145634312\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 2.051528555655042 \ttest: 0.9629629629629629 41.990612439666336\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.2811373132809303 \ttest: 0.9629629629629629 40.312864375556586\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        63\n",
      "           1    1.00000   1.00000   1.00000        63\n",
      "           2    1.00000   1.00000   1.00000        63\n",
      "           3    1.00000   1.00000   1.00000        63\n",
      "           4    1.00000   1.00000   1.00000        63\n",
      "           5    1.00000   1.00000   1.00000        63\n",
      "           6    1.00000   1.00000   1.00000        63\n",
      "           7    1.00000   1.00000   1.00000        63\n",
      "           8    1.00000   1.00000   1.00000        63\n",
      "           9    1.00000   1.00000   1.00000        63\n",
      "          10    1.00000   1.00000   1.00000        63\n",
      "\n",
      "    accuracy                        1.00000       693\n",
      "   macro avg    1.00000   1.00000   1.00000       693\n",
      "weighted avg    1.00000   1.00000   1.00000       693\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.92593   0.92593   0.92593        27\n",
      "           1    1.00000   0.96296   0.98113        27\n",
      "           2    0.93103   1.00000   0.96429        27\n",
      "           3    0.96296   0.96296   0.96296        27\n",
      "           4    1.00000   0.92593   0.96154        27\n",
      "           5    1.00000   0.96296   0.98113        27\n",
      "           6    1.00000   0.88889   0.94118        27\n",
      "           7    0.87097   1.00000   0.93103        27\n",
      "           8    1.00000   0.96296   0.98113        27\n",
      "           9    0.96429   1.00000   0.98182        27\n",
      "          10    0.96429   1.00000   0.98182        27\n",
      "\n",
      "    accuracy                        0.96296       297\n",
      "   macro avg    0.96541   0.96296   0.96309       297\n",
      "weighted avg    0.96541   0.96296   0.96309       297\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1542\n",
      "Average of depth: 1.9623865110246432\n",
      "Number of nodes: 8648\n",
      "28 122 1\n",
      "53 241 2\n",
      "81 385 3\n",
      "104 492 4\n",
      "127 595 5\n",
      "150 704 6\n",
      "173 833 7\n",
      "202 982 8\n",
      "226 1108 9\n",
      "248 1208 10\n",
      "270 1332 11\n",
      "290 1446 12\n",
      "310 1548 13\n",
      "333 1667 14\n",
      "354 1772 15\n",
      "375 1881 16\n",
      "393 1969 17\n",
      "411 2055 18\n",
      "430 2160 19\n",
      "450 2256 20\n",
      "465 2335 21\n",
      "487 2441 22\n",
      "501 2517 23\n",
      "522 2624 24\n",
      "544 2742 25\n",
      "564 2866 26\n",
      "581 2955 27\n",
      "596 3036 28\n",
      "613 3123 29\n",
      "630 3208 30\n",
      "649 3309 31\n",
      "667 3409 32\n",
      "681 3481 33\n",
      "695 3555 34\n",
      "711 3649 35\n",
      "723 3719 36\n",
      "743 3839 37\n",
      "763 3961 38\n",
      "773 4017 39\n",
      "788 4108 40\n",
      "802 4180 41\n",
      "821 4301 42\n",
      "836 4382 43\n",
      "851 4457 44\n",
      "861 4525 45\n",
      "877 4617 46\n",
      "895 4713 47\n",
      "912 4808 48\n",
      "927 4881 49\n",
      "944 4982 50\n",
      "960 5072 51\n",
      "973 5143 52\n",
      "989 5249 53\n",
      "1009 5367 54\n",
      "1026 5496 55\n",
      "1038 5578 56\n",
      "1054 5682 57\n",
      "1067 5751 58\n",
      "1079 5821 59\n",
      "1094 5910 60\n",
      "1107 5983 61\n",
      "1123 6075 62\n",
      "1138 6172 63\n",
      "1153 6253 64\n",
      "1163 6309 65\n",
      "1181 6437 66\n",
      "1196 6526 67\n",
      "1208 6602 68\n",
      "1223 6699 69\n",
      "1234 6764 70\n",
      "1248 6854 71\n",
      "1258 6928 72\n",
      "1272 7004 73\n",
      "1282 7058 74\n",
      "1295 7141 75\n",
      "1306 7200 76\n",
      "1323 7311 77\n",
      "1332 7368 78\n",
      "1345 7441 79\n",
      "1355 7509 80\n",
      "1363 7557 81\n",
      "1379 7655 82\n",
      "1392 7728 83\n",
      "1405 7825 84\n",
      "1419 7915 85\n",
      "1430 7980 86\n",
      "1444 8060 87\n",
      "1456 8124 88\n",
      "1471 8219 89\n",
      "1482 8288 90\n",
      "1497 8375 91\n",
      "1509 8457 92\n",
      "1520 8536 93\n",
      "1533 8617 94\n",
      "1541 8671 95\n",
      "1554 8768 96\n",
      "1564 8832 97\n",
      "1574 8886 98\n",
      "1585 8947 99\n",
      "1596 9016 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 27.928062052057573 \ttest: 0.9259259259259259 68.69405088362403\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 7.746315908968667 \ttest: 0.9393939393939394 54.09373271302435\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 3.4143759126859563 \ttest: 0.9461279461279462 48.76278421527596\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 1.879598126023101 \ttest: 0.9494949494949495 45.93209267706887\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.1780403055441149 \ttest: 0.9494949494949495 44.14064608473289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        63\n",
      "           1    1.00000   1.00000   1.00000        63\n",
      "           2    1.00000   1.00000   1.00000        63\n",
      "           3    1.00000   1.00000   1.00000        63\n",
      "           4    1.00000   1.00000   1.00000        63\n",
      "           5    1.00000   1.00000   1.00000        63\n",
      "           6    1.00000   1.00000   1.00000        63\n",
      "           7    1.00000   1.00000   1.00000        63\n",
      "           8    1.00000   1.00000   1.00000        63\n",
      "           9    1.00000   1.00000   1.00000        63\n",
      "          10    1.00000   1.00000   1.00000        63\n",
      "\n",
      "    accuracy                        1.00000       693\n",
      "   macro avg    1.00000   1.00000   1.00000       693\n",
      "weighted avg    1.00000   1.00000   1.00000       693\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        27\n",
      "           1    0.96429   1.00000   0.98182        27\n",
      "           2    1.00000   0.88889   0.94118        27\n",
      "           3    0.92857   0.96296   0.94545        27\n",
      "           4    1.00000   0.92593   0.96154        27\n",
      "           5    0.88462   0.85185   0.86792        27\n",
      "           6    0.95833   0.85185   0.90196        27\n",
      "           7    0.81250   0.96296   0.88136        27\n",
      "           8    0.96429   1.00000   0.98182        27\n",
      "           9    1.00000   1.00000   1.00000        27\n",
      "          10    0.96429   1.00000   0.98182        27\n",
      "\n",
      "    accuracy                        0.94949       297\n",
      "   macro avg    0.95244   0.94949   0.94953       297\n",
      "weighted avg    0.95244   0.94949   0.94953       297\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1596\n",
      "Average of depth: 1.9786967418546366\n",
      "Number of nodes: 9016\n",
      "28 134 1\n",
      "54 256 2\n",
      "82 398 3\n",
      "108 514 4\n",
      "134 630 5\n",
      "159 747 6\n",
      "181 841 7\n",
      "204 958 8\n",
      "228 1064 9\n",
      "255 1197 10\n",
      "279 1313 11\n",
      "301 1427 12\n",
      "326 1570 13\n",
      "350 1716 14\n",
      "368 1792 15\n",
      "385 1875 16\n",
      "404 1976 17\n",
      "428 2100 18\n",
      "447 2205 19\n",
      "462 2280 20\n",
      "478 2372 21\n",
      "494 2472 22\n",
      "509 2551 23\n",
      "520 2598 24\n",
      "541 2701 25\n",
      "561 2809 26\n",
      "580 2892 27\n",
      "597 2983 28\n",
      "615 3079 29\n",
      "633 3169 30\n",
      "648 3254 31\n",
      "665 3345 32\n",
      "686 3466 33\n",
      "700 3544 34\n",
      "717 3647 35\n",
      "729 3719 36\n",
      "741 3783 37\n",
      "752 3830 38\n",
      "765 3907 39\n",
      "778 4004 40\n",
      "792 4078 41\n",
      "813 4179 42\n",
      "825 4249 43\n",
      "839 4315 44\n",
      "855 4405 45\n",
      "870 4492 46\n",
      "882 4558 47\n",
      "893 4617 48\n",
      "906 4688 49\n",
      "919 4773 50\n",
      "931 4847 51\n",
      "948 4954 52\n",
      "963 5037 53\n",
      "982 5166 54\n",
      "999 5267 55\n",
      "1012 5340 56\n",
      "1022 5396 57\n",
      "1034 5462 58\n",
      "1047 5525 59\n",
      "1061 5615 60\n",
      "1075 5701 61\n",
      "1084 5754 62\n",
      "1097 5827 63\n",
      "1109 5899 64\n",
      "1122 5968 65\n",
      "1137 6057 66\n",
      "1150 6126 67\n",
      "1165 6217 68\n",
      "1178 6288 69\n",
      "1193 6383 70\n",
      "1209 6491 71\n",
      "1221 6563 72\n",
      "1235 6645 73\n",
      "1243 6691 74\n",
      "1253 6765 75\n",
      "1264 6832 76\n",
      "1279 6923 77\n",
      "1291 6995 78\n",
      "1303 7071 79\n",
      "1318 7166 80\n",
      "1331 7233 81\n",
      "1341 7303 82\n",
      "1356 7402 83\n",
      "1366 7474 84\n",
      "1379 7555 85\n",
      "1393 7639 86\n",
      "1409 7749 87\n",
      "1424 7852 88\n",
      "1434 7918 89\n",
      "1450 8012 90\n",
      "1461 8083 91\n",
      "1469 8141 92\n",
      "1483 8231 93\n",
      "1494 8298 94\n",
      "1508 8384 95\n",
      "1521 8459 96\n",
      "1530 8518 97\n",
      "1545 8617 98\n",
      "1555 8679 99\n",
      "1566 8736 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.9985569985569985 29.80207627585834 \ttest: 0.9090909090909091 71.10724290406975\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 8.242039313955 \ttest: 0.9259259259259259 56.09357237431496\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 3.5823234558119856 \ttest: 0.936026936026936 50.73602046097769\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 1.9510653922544903 \ttest: 0.936026936026936 47.961339006419614\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.2135794747369273 \ttest: 0.9393939393939394 46.23875736031723\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        63\n",
      "           1    1.00000   1.00000   1.00000        63\n",
      "           2    1.00000   1.00000   1.00000        63\n",
      "           3    1.00000   1.00000   1.00000        63\n",
      "           4    1.00000   1.00000   1.00000        63\n",
      "           5    1.00000   1.00000   1.00000        63\n",
      "           6    1.00000   1.00000   1.00000        63\n",
      "           7    1.00000   1.00000   1.00000        63\n",
      "           8    1.00000   1.00000   1.00000        63\n",
      "           9    1.00000   1.00000   1.00000        63\n",
      "          10    1.00000   1.00000   1.00000        63\n",
      "\n",
      "    accuracy                        1.00000       693\n",
      "   macro avg    1.00000   1.00000   1.00000       693\n",
      "weighted avg    1.00000   1.00000   1.00000       693\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.84375   1.00000   0.91525        27\n",
      "           1    1.00000   0.96296   0.98113        27\n",
      "           2    0.96154   0.92593   0.94340        27\n",
      "           3    1.00000   0.92593   0.96154        27\n",
      "           4    1.00000   0.92593   0.96154        27\n",
      "           5    0.92000   0.85185   0.88462        27\n",
      "           6    0.84000   0.77778   0.80769        27\n",
      "           7    0.93103   1.00000   0.96429        27\n",
      "           8    0.93103   1.00000   0.96429        27\n",
      "           9    0.93103   1.00000   0.96429        27\n",
      "          10    1.00000   0.96296   0.98113        27\n",
      "\n",
      "    accuracy                        0.93939       297\n",
      "   macro avg    0.94167   0.93939   0.93901       297\n",
      "weighted avg    0.94167   0.93939   0.93901       297\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1566\n",
      "Average of depth: 1.9546615581098339\n",
      "Number of nodes: 8736\n",
      "28 122 1\n",
      "54 252 2\n",
      "79 381 3\n",
      "105 507 4\n",
      "133 645 5\n",
      "154 746 6\n",
      "180 886 7\n",
      "200 1000 8\n",
      "225 1127 9\n",
      "251 1279 10\n",
      "274 1388 11\n",
      "294 1496 12\n",
      "315 1603 13\n",
      "336 1712 14\n",
      "356 1814 15\n",
      "375 1905 16\n",
      "391 1993 17\n",
      "407 2067 18\n",
      "425 2153 19\n",
      "442 2258 20\n",
      "462 2346 21\n",
      "482 2454 22\n",
      "499 2547 23\n",
      "519 2663 24\n",
      "540 2776 25\n",
      "556 2864 26\n",
      "576 2948 27\n",
      "590 3026 28\n",
      "611 3129 29\n",
      "629 3225 30\n",
      "643 3315 31\n",
      "659 3417 32\n",
      "674 3508 33\n",
      "688 3578 34\n",
      "700 3642 35\n",
      "713 3699 36\n",
      "730 3804 37\n",
      "745 3885 38\n",
      "762 4006 39\n",
      "779 4111 40\n",
      "793 4193 41\n",
      "811 4303 42\n",
      "828 4400 43\n",
      "844 4494 44\n",
      "860 4598 45\n",
      "876 4704 46\n",
      "889 4773 47\n",
      "901 4843 48\n",
      "922 4974 49\n",
      "938 5078 50\n",
      "954 5168 51\n",
      "966 5234 52\n",
      "974 5282 53\n",
      "988 5362 54\n",
      "1002 5458 55\n",
      "1016 5540 56\n",
      "1032 5626 57\n",
      "1043 5687 58\n",
      "1059 5775 59\n",
      "1073 5847 60\n",
      "1085 5911 61\n",
      "1097 5993 62\n",
      "1111 6085 63\n",
      "1122 6160 64\n",
      "1134 6236 65\n",
      "1148 6318 66\n",
      "1162 6402 67\n",
      "1174 6482 68\n",
      "1191 6587 69\n",
      "1202 6662 70\n",
      "1213 6729 71\n",
      "1227 6811 72\n",
      "1242 6912 73\n",
      "1257 7001 74\n",
      "1270 7080 75\n",
      "1284 7168 76\n",
      "1297 7245 77\n",
      "1310 7336 78\n",
      "1322 7406 79\n",
      "1335 7481 80\n",
      "1346 7558 81\n",
      "1358 7620 82\n",
      "1371 7697 83\n",
      "1385 7787 84\n",
      "1400 7876 85\n",
      "1405 7899 86\n",
      "1419 7991 87\n",
      "1429 8049 88\n",
      "1441 8123 89\n",
      "1454 8202 90\n",
      "1466 8280 91\n",
      "1481 8387 92\n",
      "1497 8501 93\n",
      "1509 8575 94\n",
      "1519 8627 95\n",
      "1533 8705 96\n",
      "1547 8805 97\n",
      "1555 8853 98\n",
      "1569 8949 99\n",
      "1585 9053 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 27.552658626197097 \ttest: 0.9494949494949495 65.65655999319056\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 7.6077309979703225 \ttest: 0.9562289562289562 50.25061585327826\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 3.328393018125391 \ttest: 0.9629629629629629 44.70220153087422\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 1.8231679197712918 \ttest: 0.9629629629629629 41.82715678549803\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.1386738390282365 \ttest: 0.9663299663299664 40.045235539623704\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        63\n",
      "           1    1.00000   1.00000   1.00000        63\n",
      "           2    1.00000   1.00000   1.00000        63\n",
      "           3    1.00000   1.00000   1.00000        63\n",
      "           4    1.00000   1.00000   1.00000        63\n",
      "           5    1.00000   1.00000   1.00000        63\n",
      "           6    1.00000   1.00000   1.00000        63\n",
      "           7    1.00000   1.00000   1.00000        63\n",
      "           8    1.00000   1.00000   1.00000        63\n",
      "           9    1.00000   1.00000   1.00000        63\n",
      "          10    1.00000   1.00000   1.00000        63\n",
      "\n",
      "    accuracy                        1.00000       693\n",
      "   macro avg    1.00000   1.00000   1.00000       693\n",
      "weighted avg    1.00000   1.00000   1.00000       693\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.96429   1.00000   0.98182        27\n",
      "           1    1.00000   0.96296   0.98113        27\n",
      "           2    0.93103   1.00000   0.96429        27\n",
      "           3    1.00000   0.92593   0.96154        27\n",
      "           4    1.00000   0.92593   0.96154        27\n",
      "           5    0.96429   1.00000   0.98182        27\n",
      "           6    1.00000   0.85185   0.92000        27\n",
      "           7    0.90000   1.00000   0.94737        27\n",
      "           8    1.00000   1.00000   1.00000        27\n",
      "           9    0.93103   1.00000   0.96429        27\n",
      "          10    0.96296   0.96296   0.96296        27\n",
      "\n",
      "    accuracy                        0.96633       297\n",
      "   macro avg    0.96851   0.96633   0.96607       297\n",
      "weighted avg    0.96851   0.96633   0.96607       297\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1585\n",
      "Average of depth: 1.9817034700315457\n",
      "Number of nodes: 9053\n",
      "27 121 1\n",
      "54 248 2\n",
      "81 389 3\n",
      "106 510 4\n",
      "131 637 5\n",
      "156 762 6\n",
      "182 900 7\n",
      "208 1034 8\n",
      "231 1149 9\n",
      "255 1295 10\n",
      "280 1410 11\n",
      "304 1522 12\n",
      "327 1655 13\n",
      "344 1744 14\n",
      "363 1839 15\n",
      "381 1933 16\n",
      "399 2027 17\n",
      "415 2103 18\n",
      "435 2207 19\n",
      "456 2324 20\n",
      "477 2441 21\n",
      "493 2529 22\n",
      "514 2654 23\n",
      "531 2729 24\n",
      "554 2854 25\n",
      "576 2962 26\n",
      "596 3054 27\n",
      "609 3117 28\n",
      "626 3202 29\n",
      "640 3280 30\n",
      "658 3372 31\n",
      "674 3458 32\n",
      "689 3549 33\n",
      "707 3639 34\n",
      "724 3732 35\n",
      "738 3812 36\n",
      "751 3893 37\n",
      "769 3997 38\n",
      "781 4071 39\n",
      "795 4151 40\n",
      "810 4244 41\n",
      "826 4332 42\n",
      "843 4431 43\n",
      "857 4511 44\n",
      "869 4581 45\n",
      "882 4662 46\n",
      "899 4761 47\n",
      "914 4840 48\n",
      "931 4925 49\n",
      "942 4988 50\n",
      "953 5045 51\n",
      "972 5148 52\n",
      "987 5239 53\n",
      "1002 5326 54\n",
      "1012 5380 55\n",
      "1026 5458 56\n",
      "1038 5528 57\n",
      "1055 5637 58\n",
      "1069 5715 59\n",
      "1078 5772 60\n",
      "1091 5867 61\n",
      "1104 5944 62\n",
      "1118 6034 63\n",
      "1131 6101 64\n",
      "1146 6188 65\n",
      "1155 6235 66\n",
      "1168 6326 67\n",
      "1179 6379 68\n",
      "1195 6483 69\n",
      "1205 6535 70\n",
      "1217 6607 71\n",
      "1228 6686 72\n",
      "1244 6770 73\n",
      "1254 6836 74\n",
      "1266 6912 75\n",
      "1279 6995 76\n",
      "1294 7068 77\n",
      "1306 7144 78\n",
      "1316 7210 79\n",
      "1330 7296 80\n",
      "1340 7344 81\n",
      "1352 7424 82\n",
      "1367 7515 83\n",
      "1380 7596 84\n",
      "1394 7678 85\n",
      "1408 7762 86\n",
      "1420 7836 87\n",
      "1435 7939 88\n",
      "1447 7999 89\n",
      "1457 8069 90\n",
      "1470 8150 91\n",
      "1484 8228 92\n",
      "1493 8285 93\n",
      "1503 8345 94\n",
      "1516 8428 95\n",
      "1526 8492 96\n",
      "1540 8582 97\n",
      "1555 8683 98\n",
      "1565 8749 99\n",
      "1579 8831 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.9985569985569985 28.744659043608657 \ttest: 0.9191919191919192 68.73325318984189\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 7.91722641107246 \ttest: 0.9326599326599326 54.462250950791926\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 3.447370116778587 \ttest: 0.9393939393939394 49.4188514996837\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 1.8815610759690715 \ttest: 0.9393939393939394 46.811846329352875\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.1724144919705752 \ttest: 0.9461279461279462 45.1946677627164\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        63\n",
      "           1    1.00000   1.00000   1.00000        63\n",
      "           2    1.00000   1.00000   1.00000        63\n",
      "           3    1.00000   1.00000   1.00000        63\n",
      "           4    1.00000   1.00000   1.00000        63\n",
      "           5    1.00000   1.00000   1.00000        63\n",
      "           6    1.00000   1.00000   1.00000        63\n",
      "           7    1.00000   1.00000   1.00000        63\n",
      "           8    1.00000   1.00000   1.00000        63\n",
      "           9    1.00000   1.00000   1.00000        63\n",
      "          10    1.00000   1.00000   1.00000        63\n",
      "\n",
      "    accuracy                        1.00000       693\n",
      "   macro avg    1.00000   1.00000   1.00000       693\n",
      "weighted avg    1.00000   1.00000   1.00000       693\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.87097   1.00000   0.93103        27\n",
      "           1    1.00000   0.92593   0.96154        27\n",
      "           2    0.92857   0.96296   0.94545        27\n",
      "           3    1.00000   0.92593   0.96154        27\n",
      "           4    1.00000   0.92593   0.96154        27\n",
      "           5    0.92308   0.88889   0.90566        27\n",
      "           6    0.88000   0.81481   0.84615        27\n",
      "           7    0.93103   1.00000   0.96429        27\n",
      "           8    0.96429   1.00000   0.98182        27\n",
      "           9    0.93103   1.00000   0.96429        27\n",
      "          10    1.00000   0.96296   0.98113        27\n",
      "\n",
      "    accuracy                        0.94613       297\n",
      "   macro avg    0.94809   0.94613   0.94586       297\n",
      "weighted avg    0.94809   0.94613   0.94586       297\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1579\n",
      "Average of depth: 1.96136795440152\n",
      "Number of nodes: 8831\n",
      "29 129 1\n",
      "56 266 2\n",
      "82 398 3\n",
      "106 514 4\n",
      "130 638 5\n",
      "156 770 6\n",
      "179 887 7\n",
      "202 1020 8\n",
      "228 1156 9\n",
      "253 1279 10\n",
      "276 1404 11\n",
      "298 1508 12\n",
      "320 1604 13\n",
      "344 1742 14\n",
      "367 1877 15\n",
      "389 1981 16\n",
      "412 2104 17\n",
      "434 2206 18\n",
      "450 2284 19\n",
      "472 2412 20\n",
      "489 2491 21\n",
      "503 2567 22\n",
      "524 2680 23\n",
      "544 2780 24\n",
      "565 2889 25\n",
      "581 2975 26\n",
      "602 3098 27\n",
      "615 3153 28\n",
      "633 3259 29\n",
      "650 3352 30\n",
      "663 3417 31\n",
      "679 3513 32\n",
      "698 3600 33\n",
      "714 3694 34\n",
      "732 3794 35\n",
      "744 3864 36\n",
      "762 3982 37\n",
      "776 4066 38\n",
      "793 4175 39\n",
      "808 4266 40\n",
      "824 4354 41\n",
      "840 4450 42\n",
      "855 4547 43\n",
      "874 4664 44\n",
      "890 4738 45\n",
      "901 4803 46\n",
      "914 4884 47\n",
      "931 4973 48\n",
      "944 5058 49\n",
      "959 5145 50\n",
      "973 5213 51\n",
      "986 5288 52\n",
      "1000 5374 53\n",
      "1014 5460 54\n",
      "1026 5542 55\n",
      "1036 5600 56\n",
      "1046 5656 57\n",
      "1057 5727 58\n",
      "1070 5814 59\n",
      "1077 5853 60\n",
      "1090 5930 61\n",
      "1105 6013 62\n",
      "1121 6113 63\n",
      "1133 6177 64\n",
      "1146 6268 65\n",
      "1153 6301 66\n",
      "1167 6391 67\n",
      "1180 6480 68\n",
      "1192 6540 69\n",
      "1206 6638 70\n",
      "1218 6704 71\n",
      "1231 6781 72\n",
      "1241 6833 73\n",
      "1253 6903 74\n",
      "1265 6969 75\n",
      "1275 7025 76\n",
      "1292 7128 77\n",
      "1307 7219 78\n",
      "1319 7295 79\n",
      "1332 7382 80\n",
      "1349 7487 81\n",
      "1362 7564 82\n",
      "1372 7626 83\n",
      "1384 7698 84\n",
      "1396 7778 85\n",
      "1403 7811 86\n",
      "1414 7878 87\n",
      "1424 7928 88\n",
      "1435 8001 89\n",
      "1448 8086 90\n",
      "1459 8153 91\n",
      "1475 8257 92\n",
      "1487 8329 93\n",
      "1500 8412 94\n",
      "1513 8497 95\n",
      "1521 8551 96\n",
      "1532 8626 97\n",
      "1546 8710 98\n",
      "1559 8799 99\n",
      "1574 8898 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 30.20576205083268 \ttest: 0.9730639730639731 58.671585347634476\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 8.50247035864016 \ttest: 0.9797979797979798 42.31363571968389\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 3.7486772237328103 \ttest: 0.9797979797979798 36.360809914787\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 2.0592147073229814 \ttest: 0.9797979797979798 33.22423291283838\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.287555453776898 \ttest: 0.9831649831649831 31.252965305046438\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        63\n",
      "           1    1.00000   1.00000   1.00000        63\n",
      "           2    1.00000   1.00000   1.00000        63\n",
      "           3    1.00000   1.00000   1.00000        63\n",
      "           4    1.00000   1.00000   1.00000        63\n",
      "           5    1.00000   1.00000   1.00000        63\n",
      "           6    1.00000   1.00000   1.00000        63\n",
      "           7    1.00000   1.00000   1.00000        63\n",
      "           8    1.00000   1.00000   1.00000        63\n",
      "           9    1.00000   1.00000   1.00000        63\n",
      "          10    1.00000   1.00000   1.00000        63\n",
      "\n",
      "    accuracy                        1.00000       693\n",
      "   macro avg    1.00000   1.00000   1.00000       693\n",
      "weighted avg    1.00000   1.00000   1.00000       693\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        27\n",
      "           1    1.00000   1.00000   1.00000        27\n",
      "           2    1.00000   0.96296   0.98113        27\n",
      "           3    1.00000   0.92593   0.96154        27\n",
      "           4    1.00000   1.00000   1.00000        27\n",
      "           5    0.90000   1.00000   0.94737        27\n",
      "           6    1.00000   0.92593   0.96154        27\n",
      "           7    1.00000   1.00000   1.00000        27\n",
      "           8    0.96429   1.00000   0.98182        27\n",
      "           9    0.96429   1.00000   0.98182        27\n",
      "          10    1.00000   1.00000   1.00000        27\n",
      "\n",
      "    accuracy                        0.98316       297\n",
      "   macro avg    0.98442   0.98316   0.98320       297\n",
      "weighted avg    0.98442   0.98316   0.98320       297\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1574\n",
      "Average of depth: 1.9523506988564168\n",
      "Number of nodes: 8898\n",
      "27 125 1\n",
      "53 261 2\n",
      "81 385 3\n",
      "107 501 4\n",
      "133 609 5\n",
      "159 743 6\n",
      "184 864 7\n",
      "205 971 8\n",
      "228 1080 9\n",
      "251 1201 10\n",
      "270 1280 11\n",
      "291 1397 12\n",
      "316 1530 13\n",
      "342 1656 14\n",
      "366 1782 15\n",
      "387 1887 16\n",
      "409 2009 17\n",
      "434 2130 18\n",
      "452 2208 19\n",
      "468 2294 20\n",
      "488 2404 21\n",
      "501 2479 22\n",
      "519 2563 23\n",
      "539 2657 24\n",
      "556 2752 25\n",
      "576 2868 26\n",
      "591 2957 27\n",
      "610 3066 28\n",
      "625 3147 29\n",
      "639 3225 30\n",
      "658 3346 31\n",
      "672 3426 32\n",
      "684 3490 33\n",
      "704 3596 34\n",
      "717 3655 35\n",
      "734 3758 36\n",
      "749 3851 37\n",
      "764 3944 38\n",
      "777 4019 39\n",
      "788 4084 40\n",
      "806 4184 41\n",
      "823 4277 42\n",
      "842 4382 43\n",
      "854 4450 44\n",
      "871 4561 45\n",
      "885 4651 46\n",
      "899 4745 47\n",
      "912 4826 48\n",
      "925 4895 49\n",
      "939 4971 50\n",
      "955 5089 51\n",
      "968 5174 52\n",
      "978 5230 53\n",
      "994 5324 54\n",
      "1006 5394 55\n",
      "1021 5505 56\n",
      "1037 5601 57\n",
      "1054 5706 58\n",
      "1069 5791 59\n",
      "1081 5873 60\n",
      "1095 5955 61\n",
      "1112 6052 62\n",
      "1124 6104 63\n",
      "1137 6179 64\n",
      "1146 6244 65\n",
      "1159 6325 66\n",
      "1176 6432 67\n",
      "1186 6492 68\n",
      "1199 6561 69\n",
      "1218 6662 70\n",
      "1230 6738 71\n",
      "1243 6813 72\n",
      "1259 6899 73\n",
      "1272 6992 74\n",
      "1281 7049 75\n",
      "1295 7123 76\n",
      "1306 7186 77\n",
      "1316 7242 78\n",
      "1328 7316 79\n",
      "1340 7388 80\n",
      "1349 7433 81\n",
      "1362 7508 82\n",
      "1370 7554 83\n",
      "1379 7603 84\n",
      "1393 7689 85\n",
      "1408 7782 86\n",
      "1422 7876 87\n",
      "1435 7975 88\n",
      "1447 8049 89\n",
      "1455 8095 90\n",
      "1468 8198 91\n",
      "1475 8239 92\n",
      "1490 8350 93\n",
      "1499 8397 94\n",
      "1512 8478 95\n",
      "1525 8567 96\n",
      "1535 8645 97\n",
      "1545 8701 98\n",
      "1560 8800 99\n",
      "1571 8857 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 29.6161599512103 \ttest: 0.9629629629629629 64.55607261263833\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 8.223109048941769 \ttest: 0.9663299663299664 49.264459581445\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 3.600345347704656 \ttest: 0.9629629629629629 43.90733437311038\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 1.9732095779664056 \ttest: 0.9629629629629629 41.16521148168065\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.2330948971857942 \ttest: 0.9595959595959596 39.48045142499223\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        63\n",
      "           1    1.00000   1.00000   1.00000        63\n",
      "           2    1.00000   1.00000   1.00000        63\n",
      "           3    1.00000   1.00000   1.00000        63\n",
      "           4    1.00000   1.00000   1.00000        63\n",
      "           5    1.00000   1.00000   1.00000        63\n",
      "           6    1.00000   1.00000   1.00000        63\n",
      "           7    1.00000   1.00000   1.00000        63\n",
      "           8    1.00000   1.00000   1.00000        63\n",
      "           9    1.00000   1.00000   1.00000        63\n",
      "          10    1.00000   1.00000   1.00000        63\n",
      "\n",
      "    accuracy                        1.00000       693\n",
      "   macro avg    1.00000   1.00000   1.00000       693\n",
      "weighted avg    1.00000   1.00000   1.00000       693\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.93103   1.00000   0.96429        27\n",
      "           1    1.00000   0.96296   0.98113        27\n",
      "           2    0.93103   1.00000   0.96429        27\n",
      "           3    1.00000   0.96296   0.98113        27\n",
      "           4    0.96429   1.00000   0.98182        27\n",
      "           5    0.96429   1.00000   0.98182        27\n",
      "           6    0.95238   0.74074   0.83333        27\n",
      "           7    0.83871   0.96296   0.89655        27\n",
      "           8    1.00000   0.96296   0.98113        27\n",
      "           9    1.00000   0.96296   0.98113        27\n",
      "          10    1.00000   1.00000   1.00000        27\n",
      "\n",
      "    accuracy                        0.95960       297\n",
      "   macro avg    0.96198   0.95960   0.95878       297\n",
      "weighted avg    0.96198   0.95960   0.95878       297\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1571\n",
      "Average of depth: 1.952896244430299\n",
      "Number of nodes: 8857\n",
      "27 143 1\n",
      "54 264 2\n",
      "81 389 3\n",
      "107 509 4\n",
      "135 629 5\n",
      "162 766 6\n",
      "183 867 7\n",
      "208 986 8\n",
      "232 1102 9\n",
      "253 1211 10\n",
      "279 1337 11\n",
      "300 1454 12\n",
      "317 1533 13\n",
      "339 1651 14\n",
      "359 1749 15\n",
      "369 1789 16\n",
      "394 1926 17\n",
      "412 2018 18\n",
      "429 2135 19\n",
      "451 2247 20\n",
      "470 2360 21\n",
      "485 2429 22\n",
      "504 2512 23\n",
      "515 2571 24\n",
      "532 2660 25\n",
      "548 2748 26\n",
      "563 2843 27\n",
      "579 2943 28\n",
      "592 3018 29\n",
      "613 3139 30\n",
      "632 3242 31\n",
      "648 3330 32\n",
      "662 3400 33\n",
      "680 3508 34\n",
      "692 3568 35\n",
      "712 3686 36\n",
      "726 3774 37\n",
      "739 3845 38\n",
      "754 3930 39\n",
      "771 4023 40\n",
      "786 4102 41\n",
      "799 4191 42\n",
      "816 4284 43\n",
      "832 4368 44\n",
      "847 4451 45\n",
      "862 4546 46\n",
      "879 4629 47\n",
      "894 4708 48\n",
      "905 4771 49\n",
      "920 4844 50\n",
      "930 4894 51\n",
      "941 4961 52\n",
      "951 5015 53\n",
      "964 5090 54\n",
      "974 5148 55\n",
      "986 5218 56\n",
      "1002 5334 57\n",
      "1010 5372 58\n",
      "1024 5466 59\n",
      "1039 5545 60\n",
      "1055 5641 61\n",
      "1065 5703 62\n",
      "1079 5783 63\n",
      "1095 5877 64\n",
      "1108 5950 65\n",
      "1121 6023 66\n",
      "1132 6076 67\n",
      "1145 6155 68\n",
      "1157 6233 69\n",
      "1172 6328 70\n",
      "1185 6409 71\n",
      "1198 6494 72\n",
      "1215 6591 73\n",
      "1222 6626 74\n",
      "1234 6690 75\n",
      "1241 6725 76\n",
      "1253 6803 77\n",
      "1261 6843 78\n",
      "1275 6919 79\n",
      "1289 7005 80\n",
      "1304 7094 81\n",
      "1321 7189 82\n",
      "1332 7260 83\n",
      "1344 7330 84\n",
      "1357 7413 85\n",
      "1367 7475 86\n",
      "1383 7575 87\n",
      "1394 7650 88\n",
      "1407 7747 89\n",
      "1418 7820 90\n",
      "1432 7904 91\n",
      "1448 8020 92\n",
      "1461 8105 93\n",
      "1476 8196 94\n",
      "1493 8301 95\n",
      "1504 8370 96\n",
      "1513 8427 97\n",
      "1522 8488 98\n",
      "1535 8579 99\n",
      "1549 8667 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 27.087280806520262 \ttest: 0.9494949494949495 64.87371238332292\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 7.43560284180411 \ttest: 0.9629629629629629 50.775974597268544\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 3.2467353459587773 \ttest: 0.9663299663299664 45.8661924461372\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 1.7748020003311709 \ttest: 0.9663299663299664 43.348566830191686\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.1065812231943277 \ttest: 0.9629629629629629 41.8006238868448\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        63\n",
      "           1    1.00000   1.00000   1.00000        63\n",
      "           2    1.00000   1.00000   1.00000        63\n",
      "           3    1.00000   1.00000   1.00000        63\n",
      "           4    1.00000   1.00000   1.00000        63\n",
      "           5    1.00000   1.00000   1.00000        63\n",
      "           6    1.00000   1.00000   1.00000        63\n",
      "           7    1.00000   1.00000   1.00000        63\n",
      "           8    1.00000   1.00000   1.00000        63\n",
      "           9    1.00000   1.00000   1.00000        63\n",
      "          10    1.00000   1.00000   1.00000        63\n",
      "\n",
      "    accuracy                        1.00000       693\n",
      "   macro avg    1.00000   1.00000   1.00000       693\n",
      "weighted avg    1.00000   1.00000   1.00000       693\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        27\n",
      "           1    1.00000   1.00000   1.00000        27\n",
      "           2    1.00000   0.96296   0.98113        27\n",
      "           3    1.00000   0.88889   0.94118        27\n",
      "           4    0.92308   0.88889   0.90566        27\n",
      "           5    0.93103   1.00000   0.96429        27\n",
      "           6    0.96296   0.96296   0.96296        27\n",
      "           7    0.92857   0.96296   0.94545        27\n",
      "           8    0.96429   1.00000   0.98182        27\n",
      "           9    0.92593   0.92593   0.92593        27\n",
      "          10    0.96429   1.00000   0.98182        27\n",
      "\n",
      "    accuracy                        0.96296       297\n",
      "   macro avg    0.96365   0.96296   0.96275       297\n",
      "weighted avg    0.96365   0.96296   0.96275       297\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1549\n",
      "Average of depth: 1.960619754680439\n",
      "Number of nodes: 8667\n",
      "23 113 1\n",
      "52 244 2\n",
      "78 376 3\n",
      "98 460 4\n",
      "124 592 5\n",
      "150 718 6\n",
      "173 821 7\n",
      "193 923 8\n",
      "215 1033 9\n",
      "240 1152 10\n",
      "263 1267 11\n",
      "289 1393 12\n",
      "311 1495 13\n",
      "332 1610 14\n",
      "353 1707 15\n",
      "375 1827 16\n",
      "393 1945 17\n",
      "406 2000 18\n",
      "425 2093 19\n",
      "445 2213 20\n",
      "460 2288 21\n",
      "478 2376 22\n",
      "492 2454 23\n",
      "514 2584 24\n",
      "527 2653 25\n",
      "548 2768 26\n",
      "567 2871 27\n",
      "586 2962 28\n",
      "606 3068 29\n",
      "618 3130 30\n",
      "639 3255 31\n",
      "653 3339 32\n",
      "669 3433 33\n",
      "685 3529 34\n",
      "700 3612 35\n",
      "715 3685 36\n",
      "729 3767 37\n",
      "747 3861 38\n",
      "763 3943 39\n",
      "781 4049 40\n",
      "796 4140 41\n",
      "812 4244 42\n",
      "829 4345 43\n",
      "840 4416 44\n",
      "852 4478 45\n",
      "869 4569 46\n",
      "884 4678 47\n",
      "899 4769 48\n",
      "916 4874 49\n",
      "936 4994 50\n",
      "948 5066 51\n",
      "961 5145 52\n",
      "980 5240 53\n",
      "994 5332 54\n",
      "1008 5410 55\n",
      "1021 5487 56\n",
      "1036 5586 57\n",
      "1046 5654 58\n",
      "1063 5753 59\n",
      "1078 5846 60\n",
      "1095 5925 61\n",
      "1105 5997 62\n",
      "1120 6082 63\n",
      "1132 6150 64\n",
      "1141 6199 65\n",
      "1156 6280 66\n",
      "1170 6376 67\n",
      "1185 6459 68\n",
      "1202 6566 69\n",
      "1215 6643 70\n",
      "1232 6750 71\n",
      "1246 6842 72\n",
      "1255 6899 73\n",
      "1271 7005 74\n",
      "1284 7076 75\n",
      "1300 7158 76\n",
      "1317 7259 77\n",
      "1331 7355 78\n",
      "1342 7418 79\n",
      "1356 7494 80\n",
      "1370 7584 81\n",
      "1381 7657 82\n",
      "1393 7723 83\n",
      "1407 7813 84\n",
      "1421 7909 85\n",
      "1434 7976 86\n",
      "1445 8037 87\n",
      "1455 8095 88\n",
      "1470 8184 89\n",
      "1478 8230 90\n",
      "1491 8323 91\n",
      "1502 8384 92\n",
      "1512 8450 93\n",
      "1527 8547 94\n",
      "1540 8630 95\n",
      "1554 8710 96\n",
      "1566 8784 97\n",
      "1576 8840 98\n",
      "1589 8929 99\n",
      "1599 8995 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 28.344748066345936 \ttest: 0.9393939393939394 65.07157417396934\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 7.629598344803698 \ttest: 0.9595959595959596 49.31138337520521\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 3.2806518705433643 \ttest: 0.9629629629629629 43.9061546849876\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 1.7795731644808117 \ttest: 0.9629629629629629 41.17371723700343\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.1052412904698308 \ttest: 0.9629629629629629 39.50767823109637\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        63\n",
      "           1    1.00000   1.00000   1.00000        63\n",
      "           2    1.00000   1.00000   1.00000        63\n",
      "           3    1.00000   1.00000   1.00000        63\n",
      "           4    1.00000   1.00000   1.00000        63\n",
      "           5    1.00000   1.00000   1.00000        63\n",
      "           6    1.00000   1.00000   1.00000        63\n",
      "           7    1.00000   1.00000   1.00000        63\n",
      "           8    1.00000   1.00000   1.00000        63\n",
      "           9    1.00000   1.00000   1.00000        63\n",
      "          10    1.00000   1.00000   1.00000        63\n",
      "\n",
      "    accuracy                        1.00000       693\n",
      "   macro avg    1.00000   1.00000   1.00000       693\n",
      "weighted avg    1.00000   1.00000   1.00000       693\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   0.96296   0.98113        27\n",
      "           1    1.00000   1.00000   1.00000        27\n",
      "           2    1.00000   1.00000   1.00000        27\n",
      "           3    0.96296   0.96296   0.96296        27\n",
      "           4    1.00000   0.88889   0.94118        27\n",
      "           5    1.00000   0.88889   0.94118        27\n",
      "           6    0.81250   0.96296   0.88136        27\n",
      "           7    0.92593   0.92593   0.92593        27\n",
      "           8    1.00000   1.00000   1.00000        27\n",
      "           9    0.96429   1.00000   0.98182        27\n",
      "          10    0.96429   1.00000   0.98182        27\n",
      "\n",
      "    accuracy                        0.96296       297\n",
      "   macro avg    0.96636   0.96296   0.96340       297\n",
      "weighted avg    0.96636   0.96296   0.96340       297\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1599\n",
      "Average of depth: 1.9593495934959348\n",
      "Number of nodes: 8995\n",
      "29 131 1\n",
      "44 186 2\n",
      "71 329 3\n",
      "99 461 4\n",
      "125 589 5\n",
      "154 756 6\n",
      "178 876 7\n",
      "198 986 8\n",
      "224 1118 9\n",
      "245 1221 10\n",
      "269 1341 11\n",
      "289 1443 12\n",
      "312 1568 13\n",
      "335 1701 14\n",
      "354 1820 15\n",
      "374 1914 16\n",
      "393 2025 17\n",
      "413 2137 18\n",
      "425 2185 19\n",
      "442 2278 20\n",
      "460 2370 21\n",
      "480 2480 22\n",
      "497 2581 23\n",
      "516 2690 24\n",
      "534 2774 25\n",
      "549 2871 26\n",
      "566 2960 27\n",
      "584 3060 28\n",
      "597 3117 29\n",
      "616 3226 30\n",
      "631 3321 31\n",
      "649 3433 32\n",
      "670 3552 33\n",
      "686 3654 34\n",
      "700 3728 35\n",
      "711 3787 36\n",
      "727 3885 37\n",
      "738 3936 38\n",
      "754 4012 39\n",
      "776 4138 40\n",
      "787 4191 41\n",
      "805 4299 42\n",
      "822 4384 43\n",
      "838 4482 44\n",
      "853 4571 45\n",
      "868 4676 46\n",
      "876 4714 47\n",
      "891 4799 48\n",
      "904 4872 49\n",
      "915 4935 50\n",
      "933 5027 51\n",
      "946 5098 52\n",
      "959 5185 53\n",
      "968 5240 54\n",
      "979 5303 55\n",
      "989 5355 56\n",
      "998 5402 57\n",
      "1007 5457 58\n",
      "1022 5542 59\n",
      "1034 5606 60\n",
      "1052 5698 61\n",
      "1066 5770 62\n",
      "1078 5856 63\n",
      "1089 5931 64\n",
      "1099 5995 65\n",
      "1113 6075 66\n",
      "1125 6153 67\n",
      "1138 6230 68\n",
      "1150 6316 69\n",
      "1162 6384 70\n",
      "1172 6442 71\n",
      "1187 6537 72\n",
      "1199 6609 73\n",
      "1212 6676 74\n",
      "1224 6740 75\n",
      "1234 6794 76\n",
      "1246 6872 77\n",
      "1257 6943 78\n",
      "1274 7046 79\n",
      "1285 7119 80\n",
      "1298 7186 81\n",
      "1312 7278 82\n",
      "1327 7367 83\n",
      "1337 7435 84\n",
      "1351 7521 85\n",
      "1362 7584 86\n",
      "1365 7601 87\n",
      "1380 7696 88\n",
      "1398 7808 89\n",
      "1412 7898 90\n",
      "1424 7972 91\n",
      "1434 8042 92\n",
      "1446 8122 93\n",
      "1461 8217 94\n",
      "1471 8277 95\n",
      "1488 8384 96\n",
      "1503 8469 97\n",
      "1519 8565 98\n",
      "1534 8648 99\n",
      "1550 8740 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 28.2242640161736 \ttest: 0.9461279461279462 68.67824676759642\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 7.8472117257083465 \ttest: 0.9494949494949495 53.69749589534983\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 3.453982736435281 \ttest: 0.9562289562289562 48.30012549155367\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 1.899409108869745 \ttest: 0.9562289562289562 45.46772400080458\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.1896915670569856 \ttest: 0.9562289562289562 43.694724328779\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        63\n",
      "           1    1.00000   1.00000   1.00000        63\n",
      "           2    1.00000   1.00000   1.00000        63\n",
      "           3    1.00000   1.00000   1.00000        63\n",
      "           4    1.00000   1.00000   1.00000        63\n",
      "           5    1.00000   1.00000   1.00000        63\n",
      "           6    1.00000   1.00000   1.00000        63\n",
      "           7    1.00000   1.00000   1.00000        63\n",
      "           8    1.00000   1.00000   1.00000        63\n",
      "           9    1.00000   1.00000   1.00000        63\n",
      "          10    1.00000   1.00000   1.00000        63\n",
      "\n",
      "    accuracy                        1.00000       693\n",
      "   macro avg    1.00000   1.00000   1.00000       693\n",
      "weighted avg    1.00000   1.00000   1.00000       693\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        27\n",
      "           1    1.00000   1.00000   1.00000        27\n",
      "           2    0.96296   0.96296   0.96296        27\n",
      "           3    0.84375   1.00000   0.91525        27\n",
      "           4    1.00000   0.85185   0.92000        27\n",
      "           5    0.95833   0.85185   0.90196        27\n",
      "           6    1.00000   0.92593   0.96154        27\n",
      "           7    0.90000   1.00000   0.94737        27\n",
      "           8    0.96429   1.00000   0.98182        27\n",
      "           9    0.96296   0.96296   0.96296        27\n",
      "          10    0.96296   0.96296   0.96296        27\n",
      "\n",
      "    accuracy                        0.95623       297\n",
      "   macro avg    0.95957   0.95623   0.95608       297\n",
      "weighted avg    0.95957   0.95623   0.95608       297\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1550\n",
      "Average of depth: 1.9658064516129032\n",
      "Number of nodes: 8740\n",
      "29 135 1\n",
      "58 278 2\n",
      "87 417 3\n",
      "117 559 4\n",
      "142 674 5\n",
      "164 788 6\n",
      "188 906 7\n",
      "213 1025 8\n",
      "235 1133 9\n",
      "259 1259 10\n",
      "283 1385 11\n",
      "299 1459 12\n",
      "322 1576 13\n",
      "341 1673 14\n",
      "365 1799 15\n",
      "385 1919 16\n",
      "405 2031 17\n",
      "424 2132 18\n",
      "444 2258 19\n",
      "461 2351 20\n",
      "477 2419 21\n",
      "496 2520 22\n",
      "515 2619 23\n",
      "529 2701 24\n",
      "543 2769 25\n",
      "563 2867 26\n",
      "578 2958 27\n",
      "599 3079 28\n",
      "618 3172 29\n",
      "632 3250 30\n",
      "649 3353 31\n",
      "671 3477 32\n",
      "688 3572 33\n",
      "708 3678 34\n",
      "725 3783 35\n",
      "738 3884 36\n",
      "758 4010 37\n",
      "770 4076 38\n",
      "788 4182 39\n",
      "800 4254 40\n",
      "819 4363 41\n",
      "836 4474 42\n",
      "851 4563 43\n",
      "865 4643 44\n",
      "881 4739 45\n",
      "896 4832 46\n",
      "912 4932 47\n",
      "923 5001 48\n",
      "937 5075 49\n",
      "948 5144 50\n",
      "961 5219 51\n",
      "975 5311 52\n",
      "991 5393 53\n",
      "1004 5470 54\n",
      "1015 5531 55\n",
      "1030 5618 56\n",
      "1046 5708 57\n",
      "1065 5821 58\n",
      "1075 5873 59\n",
      "1087 5939 60\n",
      "1104 6032 61\n",
      "1121 6135 62\n",
      "1136 6222 63\n",
      "1149 6297 64\n",
      "1164 6370 65\n",
      "1176 6436 66\n",
      "1192 6522 67\n",
      "1207 6615 68\n",
      "1221 6699 69\n",
      "1235 6785 70\n",
      "1243 6827 71\n",
      "1256 6916 72\n",
      "1270 7004 73\n",
      "1281 7073 74\n",
      "1297 7167 75\n",
      "1314 7276 76\n",
      "1325 7337 77\n",
      "1340 7418 78\n",
      "1352 7492 79\n",
      "1363 7559 80\n",
      "1374 7638 81\n",
      "1387 7711 82\n",
      "1400 7786 83\n",
      "1416 7896 84\n",
      "1431 7981 85\n",
      "1442 8068 86\n",
      "1455 8141 87\n",
      "1467 8211 88\n",
      "1482 8310 89\n",
      "1493 8385 90\n",
      "1508 8490 91\n",
      "1523 8581 92\n",
      "1533 8649 93\n",
      "1541 8689 94\n",
      "1553 8759 95\n",
      "1562 8808 96\n",
      "1575 8893 97\n",
      "1584 8952 98\n",
      "1598 9048 99\n",
      "1608 9114 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 28.89045492944148 \ttest: 0.9562289562289562 61.16657567386365\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 8.098469623282153 \ttest: 0.9595959595959596 46.496359077844865\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 3.564495615278347 \ttest: 0.9696969696969697 41.50730843598869\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 1.9598133452003006 \ttest: 0.9730639730639731 39.01260360330597\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.227419220587987 \ttest: 0.9696969696969697 37.509167418420375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        63\n",
      "           1    1.00000   1.00000   1.00000        63\n",
      "           2    1.00000   1.00000   1.00000        63\n",
      "           3    1.00000   1.00000   1.00000        63\n",
      "           4    1.00000   1.00000   1.00000        63\n",
      "           5    1.00000   1.00000   1.00000        63\n",
      "           6    1.00000   1.00000   1.00000        63\n",
      "           7    1.00000   1.00000   1.00000        63\n",
      "           8    1.00000   1.00000   1.00000        63\n",
      "           9    1.00000   1.00000   1.00000        63\n",
      "          10    1.00000   1.00000   1.00000        63\n",
      "\n",
      "    accuracy                        1.00000       693\n",
      "   macro avg    1.00000   1.00000   1.00000       693\n",
      "weighted avg    1.00000   1.00000   1.00000       693\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.96429   1.00000   0.98182        27\n",
      "           1    1.00000   1.00000   1.00000        27\n",
      "           2    1.00000   1.00000   1.00000        27\n",
      "           3    1.00000   1.00000   1.00000        27\n",
      "           4    0.83871   0.96296   0.89655        27\n",
      "           5    0.96296   0.96296   0.96296        27\n",
      "           6    1.00000   0.92593   0.96154        27\n",
      "           7    0.95833   0.85185   0.90196        27\n",
      "           8    1.00000   1.00000   1.00000        27\n",
      "           9    0.96296   0.96296   0.96296        27\n",
      "          10    1.00000   1.00000   1.00000        27\n",
      "\n",
      "    accuracy                        0.96970       297\n",
      "   macro avg    0.97157   0.96970   0.96980       297\n",
      "weighted avg    0.97157   0.96970   0.96980       297\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1608\n",
      "Average of depth: 1.9769900497512438\n",
      "Number of nodes: 9114\n",
      "29 137 1\n",
      "57 269 2\n",
      "81 391 3\n",
      "107 515 4\n",
      "133 655 5\n",
      "159 781 6\n",
      "185 897 7\n",
      "210 1028 8\n",
      "230 1132 9\n",
      "249 1223 10\n",
      "267 1319 11\n",
      "285 1411 12\n",
      "307 1525 13\n",
      "323 1605 14\n",
      "348 1744 15\n",
      "368 1862 16\n",
      "386 1958 17\n",
      "406 2058 18\n",
      "426 2154 19\n",
      "446 2246 20\n",
      "464 2354 21\n",
      "477 2429 22\n",
      "499 2547 23\n",
      "519 2663 24\n",
      "541 2775 25\n",
      "562 2898 26\n",
      "575 2963 27\n",
      "592 3050 28\n",
      "609 3129 29\n",
      "623 3201 30\n",
      "644 3312 31\n",
      "662 3412 32\n",
      "679 3503 33\n",
      "695 3583 34\n",
      "717 3703 35\n",
      "738 3828 36\n",
      "753 3925 37\n",
      "768 4006 38\n",
      "781 4083 39\n",
      "801 4195 40\n",
      "813 4261 41\n",
      "831 4365 42\n",
      "848 4472 43\n",
      "864 4582 44\n",
      "881 4677 45\n",
      "898 4778 46\n",
      "916 4880 47\n",
      "933 4981 48\n",
      "946 5046 49\n",
      "957 5103 50\n",
      "973 5187 51\n",
      "991 5303 52\n",
      "1005 5381 53\n",
      "1015 5437 54\n",
      "1032 5552 55\n",
      "1048 5656 56\n",
      "1060 5736 57\n",
      "1074 5814 58\n",
      "1085 5881 59\n",
      "1097 5951 60\n",
      "1106 6002 61\n",
      "1121 6085 62\n",
      "1135 6161 63\n",
      "1152 6264 64\n",
      "1165 6351 65\n",
      "1175 6419 66\n",
      "1187 6489 67\n",
      "1202 6582 68\n",
      "1216 6672 69\n",
      "1228 6736 70\n",
      "1241 6821 71\n",
      "1259 6925 72\n",
      "1272 7002 73\n",
      "1285 7077 74\n",
      "1295 7147 75\n",
      "1309 7251 76\n",
      "1321 7315 77\n",
      "1333 7393 78\n",
      "1346 7462 79\n",
      "1360 7540 80\n",
      "1378 7644 81\n",
      "1390 7710 82\n",
      "1406 7814 83\n",
      "1417 7873 84\n",
      "1432 7972 85\n",
      "1449 8075 86\n",
      "1457 8119 87\n",
      "1466 8188 88\n",
      "1482 8290 89\n",
      "1493 8359 90\n",
      "1506 8434 91\n",
      "1518 8498 92\n",
      "1528 8570 93\n",
      "1542 8662 94\n",
      "1558 8772 95\n",
      "1569 8841 96\n",
      "1581 8919 97\n",
      "1593 9001 98\n",
      "1603 9057 99\n",
      "1618 9146 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 28.51616707415979 \ttest: 0.9461279461279462 64.5362793600874\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 8.023287665048771 \ttest: 0.9562289562289562 48.17545669503058\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 3.5722012811380415 \ttest: 0.9595959595959596 42.152567709127254\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 1.977896953950419 \ttest: 0.9562289562289562 38.93680174220789\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.2437191685404954 \ttest: 0.9595959595959596 36.894485928307134\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        63\n",
      "           1    1.00000   1.00000   1.00000        63\n",
      "           2    1.00000   1.00000   1.00000        63\n",
      "           3    1.00000   1.00000   1.00000        63\n",
      "           4    1.00000   1.00000   1.00000        63\n",
      "           5    1.00000   1.00000   1.00000        63\n",
      "           6    1.00000   1.00000   1.00000        63\n",
      "           7    1.00000   1.00000   1.00000        63\n",
      "           8    1.00000   1.00000   1.00000        63\n",
      "           9    1.00000   1.00000   1.00000        63\n",
      "          10    1.00000   1.00000   1.00000        63\n",
      "\n",
      "    accuracy                        1.00000       693\n",
      "   macro avg    1.00000   1.00000   1.00000       693\n",
      "weighted avg    1.00000   1.00000   1.00000       693\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.93103   1.00000   0.96429        27\n",
      "           1    1.00000   0.96296   0.98113        27\n",
      "           2    0.93103   1.00000   0.96429        27\n",
      "           3    0.96296   0.96296   0.96296        27\n",
      "           4    0.92857   0.96296   0.94545        27\n",
      "           5    0.96296   0.96296   0.96296        27\n",
      "           6    1.00000   0.85185   0.92000        27\n",
      "           7    0.93103   1.00000   0.96429        27\n",
      "           8    1.00000   0.96296   0.98113        27\n",
      "           9    0.92593   0.92593   0.92593        27\n",
      "          10    1.00000   0.96296   0.98113        27\n",
      "\n",
      "    accuracy                        0.95960       297\n",
      "   macro avg    0.96123   0.95960   0.95941       297\n",
      "weighted avg    0.96123   0.95960   0.95941       297\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1618\n",
      "Average of depth: 1.9783683559950556\n",
      "Number of nodes: 9146\n",
      "27 119 1\n",
      "54 240 2\n",
      "78 360 3\n",
      "101 469 4\n",
      "125 593 5\n",
      "149 699 6\n",
      "172 822 7\n",
      "195 935 8\n",
      "221 1061 9\n",
      "244 1166 10\n",
      "269 1293 11\n",
      "291 1417 12\n",
      "316 1544 13\n",
      "333 1623 14\n",
      "353 1735 15\n",
      "375 1835 16\n",
      "396 1946 17\n",
      "416 2050 18\n",
      "433 2143 19\n",
      "455 2265 20\n",
      "476 2376 21\n",
      "498 2496 22\n",
      "517 2607 23\n",
      "533 2685 24\n",
      "555 2805 25\n",
      "570 2874 26\n",
      "589 2969 27\n",
      "612 3084 28\n",
      "629 3177 29\n",
      "647 3279 30\n",
      "662 3366 31\n",
      "673 3427 32\n",
      "690 3516 33\n",
      "704 3596 34\n",
      "719 3671 35\n",
      "731 3747 36\n",
      "748 3840 37\n",
      "767 3953 38\n",
      "782 4034 39\n",
      "797 4123 40\n",
      "810 4194 41\n",
      "823 4273 42\n",
      "836 4342 43\n",
      "853 4431 44\n",
      "873 4547 45\n",
      "888 4628 46\n",
      "905 4747 47\n",
      "920 4828 48\n",
      "937 4921 49\n",
      "951 4997 50\n",
      "964 5082 51\n",
      "979 5179 52\n",
      "992 5252 53\n",
      "1005 5321 54\n",
      "1016 5382 55\n",
      "1027 5447 56\n",
      "1040 5520 57\n",
      "1050 5576 58\n",
      "1061 5637 59\n",
      "1076 5732 60\n",
      "1088 5812 61\n",
      "1102 5894 62\n",
      "1115 5979 63\n",
      "1134 6108 64\n",
      "1146 6194 65\n",
      "1157 6259 66\n",
      "1168 6328 67\n",
      "1183 6417 68\n",
      "1199 6517 69\n",
      "1218 6628 70\n",
      "1233 6725 71\n",
      "1243 6777 72\n",
      "1254 6844 73\n",
      "1269 6939 74\n",
      "1278 6998 75\n",
      "1295 7101 76\n",
      "1304 7142 77\n",
      "1319 7233 78\n",
      "1331 7307 79\n",
      "1343 7371 80\n",
      "1356 7448 81\n",
      "1368 7514 82\n",
      "1378 7586 83\n",
      "1385 7625 84\n",
      "1398 7704 85\n",
      "1407 7765 86\n",
      "1419 7829 87\n",
      "1426 7862 88\n",
      "1439 7929 89\n",
      "1454 8032 90\n",
      "1464 8096 91\n",
      "1478 8192 92\n",
      "1496 8314 93\n",
      "1508 8388 94\n",
      "1520 8454 95\n",
      "1530 8522 96\n",
      "1542 8608 97\n",
      "1555 8697 98\n",
      "1570 8786 99\n",
      "1585 8883 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 25.336837000224733 \ttest: 0.9124579124579124 76.12805466565567\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 6.821224993085025 \ttest: 0.9259259259259259 62.12831359967011\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 2.970085489203018 \ttest: 0.9292929292929293 57.06570939114224\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 1.6265610905051715 \ttest: 0.9292929292929293 54.41011746361046\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.0170200618037446 \ttest: 0.9292929292929293 52.745280031624326\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        63\n",
      "           1    1.00000   1.00000   1.00000        63\n",
      "           2    1.00000   1.00000   1.00000        63\n",
      "           3    1.00000   1.00000   1.00000        63\n",
      "           4    1.00000   1.00000   1.00000        63\n",
      "           5    1.00000   1.00000   1.00000        63\n",
      "           6    1.00000   1.00000   1.00000        63\n",
      "           7    1.00000   1.00000   1.00000        63\n",
      "           8    1.00000   1.00000   1.00000        63\n",
      "           9    1.00000   1.00000   1.00000        63\n",
      "          10    1.00000   1.00000   1.00000        63\n",
      "\n",
      "    accuracy                        1.00000       693\n",
      "   macro avg    1.00000   1.00000   1.00000       693\n",
      "weighted avg    1.00000   1.00000   1.00000       693\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.90000   1.00000   0.94737        27\n",
      "           1    1.00000   1.00000   1.00000        27\n",
      "           2    1.00000   1.00000   1.00000        27\n",
      "           3    0.90909   0.74074   0.81633        27\n",
      "           4    0.96000   0.88889   0.92308        27\n",
      "           5    0.75000   0.77778   0.76364        27\n",
      "           6    0.85714   0.88889   0.87273        27\n",
      "           7    0.89286   0.92593   0.90909        27\n",
      "           8    1.00000   1.00000   1.00000        27\n",
      "           9    0.96429   1.00000   0.98182        27\n",
      "          10    1.00000   1.00000   1.00000        27\n",
      "\n",
      "    accuracy                        0.92929       297\n",
      "   macro avg    0.93031   0.92929   0.92855       297\n",
      "weighted avg    0.93031   0.92929   0.92855       297\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1585\n",
      "Average of depth: 1.959621451104101\n",
      "Number of nodes: 8883\n",
      "29 145 1\n",
      "56 276 2\n",
      "80 406 3\n",
      "107 529 4\n",
      "132 656 5\n",
      "157 781 6\n",
      "179 893 7\n",
      "201 985 8\n",
      "227 1105 9\n",
      "250 1218 10\n",
      "274 1340 11\n",
      "297 1455 12\n",
      "318 1560 13\n",
      "343 1687 14\n",
      "367 1805 15\n",
      "382 1890 16\n",
      "404 1986 17\n",
      "426 2086 18\n",
      "443 2185 19\n",
      "462 2292 20\n",
      "487 2417 21\n",
      "506 2520 22\n",
      "520 2606 23\n",
      "538 2702 24\n",
      "557 2805 25\n",
      "575 2897 26\n",
      "590 2988 27\n",
      "608 3092 28\n",
      "625 3191 29\n",
      "636 3248 30\n",
      "650 3330 31\n",
      "665 3409 32\n",
      "684 3514 33\n",
      "700 3594 34\n",
      "716 3688 35\n",
      "735 3797 36\n",
      "753 3879 37\n",
      "768 3972 38\n",
      "788 4074 39\n",
      "802 4146 40\n",
      "821 4253 41\n",
      "831 4311 42\n",
      "844 4392 43\n",
      "861 4493 44\n",
      "875 4575 45\n",
      "889 4661 46\n",
      "908 4782 47\n",
      "918 4834 48\n",
      "936 4928 49\n",
      "948 4994 50\n",
      "960 5080 51\n",
      "973 5161 52\n",
      "982 5216 53\n",
      "996 5302 54\n",
      "1013 5405 55\n",
      "1026 5470 56\n",
      "1045 5581 57\n",
      "1057 5655 58\n",
      "1073 5751 59\n",
      "1084 5828 60\n",
      "1096 5896 61\n",
      "1109 5983 62\n",
      "1121 6059 63\n",
      "1136 6150 64\n",
      "1149 6219 65\n",
      "1161 6303 66\n",
      "1175 6385 67\n",
      "1187 6473 68\n",
      "1202 6558 69\n",
      "1218 6648 70\n",
      "1232 6724 71\n",
      "1243 6795 72\n",
      "1255 6875 73\n",
      "1269 6969 74\n",
      "1279 7025 75\n",
      "1292 7102 76\n",
      "1306 7192 77\n",
      "1322 7298 78\n",
      "1333 7363 79\n",
      "1344 7432 80\n",
      "1355 7483 81\n",
      "1370 7588 82\n",
      "1379 7645 83\n",
      "1388 7702 84\n",
      "1398 7766 85\n",
      "1408 7828 86\n",
      "1424 7928 87\n",
      "1434 8012 88\n",
      "1447 8093 89\n",
      "1461 8175 90\n",
      "1475 8261 91\n",
      "1488 8346 92\n",
      "1503 8437 93\n",
      "1518 8538 94\n",
      "1528 8610 95\n",
      "1539 8689 96\n",
      "1551 8759 97\n",
      "1562 8824 98\n",
      "1570 8870 99\n",
      "1579 8923 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 27.214563883131145 \ttest: 0.9225589225589226 74.58715257389832\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 7.378220967398341 \ttest: 0.9292929292929293 59.35751274624828\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 3.208607977032112 \ttest: 0.936026936026936 53.80927107969493\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 1.753890570164179 \ttest: 0.936026936026936 50.897193006258476\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.0949481063639994 \ttest: 0.936026936026936 49.07198311257345\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        63\n",
      "           1    1.00000   1.00000   1.00000        63\n",
      "           2    1.00000   1.00000   1.00000        63\n",
      "           3    1.00000   1.00000   1.00000        63\n",
      "           4    1.00000   1.00000   1.00000        63\n",
      "           5    1.00000   1.00000   1.00000        63\n",
      "           6    1.00000   1.00000   1.00000        63\n",
      "           7    1.00000   1.00000   1.00000        63\n",
      "           8    1.00000   1.00000   1.00000        63\n",
      "           9    1.00000   1.00000   1.00000        63\n",
      "          10    1.00000   1.00000   1.00000        63\n",
      "\n",
      "    accuracy                        1.00000       693\n",
      "   macro avg    1.00000   1.00000   1.00000       693\n",
      "weighted avg    1.00000   1.00000   1.00000       693\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.93103   1.00000   0.96429        27\n",
      "           1    0.92308   0.88889   0.90566        27\n",
      "           2    0.89286   0.92593   0.90909        27\n",
      "           3    0.89286   0.92593   0.90909        27\n",
      "           4    0.92857   0.96296   0.94545        27\n",
      "           5    0.85714   0.88889   0.87273        27\n",
      "           6    0.95455   0.77778   0.85714        27\n",
      "           7    0.96429   1.00000   0.98182        27\n",
      "           8    1.00000   1.00000   1.00000        27\n",
      "           9    0.96154   0.92593   0.94340        27\n",
      "          10    1.00000   1.00000   1.00000        27\n",
      "\n",
      "    accuracy                        0.93603       297\n",
      "   macro avg    0.93690   0.93603   0.93533       297\n",
      "weighted avg    0.93690   0.93603   0.93533       297\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1579\n",
      "Average of depth: 1.9702343255224826\n",
      "Number of nodes: 8923\n",
      "27 119 1\n",
      "55 245 2\n",
      "76 368 3\n",
      "102 490 4\n",
      "126 600 5\n",
      "153 729 6\n",
      "180 856 7\n",
      "205 985 8\n",
      "226 1074 9\n",
      "247 1171 10\n",
      "269 1283 11\n",
      "292 1390 12\n",
      "307 1469 13\n",
      "329 1569 14\n",
      "345 1649 15\n",
      "366 1770 16\n",
      "389 1905 17\n",
      "411 2029 18\n",
      "432 2140 19\n",
      "450 2222 20\n",
      "471 2353 21\n",
      "491 2469 22\n",
      "510 2582 23\n",
      "529 2701 24\n",
      "543 2779 25\n",
      "558 2848 26\n",
      "579 2951 27\n",
      "590 3022 28\n",
      "608 3112 29\n",
      "622 3190 30\n",
      "638 3284 31\n",
      "648 3340 32\n",
      "663 3409 33\n",
      "683 3521 34\n",
      "703 3639 35\n",
      "713 3691 36\n",
      "728 3802 37\n",
      "748 3944 38\n",
      "764 4050 39\n",
      "778 4114 40\n",
      "792 4192 41\n",
      "808 4284 42\n",
      "822 4366 43\n",
      "833 4427 44\n",
      "847 4509 45\n",
      "860 4586 46\n",
      "874 4670 47\n",
      "890 4766 48\n",
      "908 4864 49\n",
      "926 4972 50\n",
      "938 5042 51\n",
      "951 5105 52\n",
      "966 5198 53\n",
      "982 5302 54\n",
      "998 5388 55\n",
      "1014 5482 56\n",
      "1024 5532 57\n",
      "1042 5640 58\n",
      "1053 5707 59\n",
      "1070 5796 60\n",
      "1084 5890 61\n",
      "1097 5963 62\n",
      "1108 6026 63\n",
      "1120 6096 64\n",
      "1128 6152 65\n",
      "1146 6274 66\n",
      "1157 6343 67\n",
      "1168 6402 68\n",
      "1179 6467 69\n",
      "1192 6550 70\n",
      "1207 6639 71\n",
      "1219 6709 72\n",
      "1230 6762 73\n",
      "1241 6819 74\n",
      "1249 6865 75\n",
      "1261 6939 76\n",
      "1277 7019 77\n",
      "1290 7096 78\n",
      "1301 7153 79\n",
      "1314 7234 80\n",
      "1321 7265 81\n",
      "1335 7361 82\n",
      "1353 7465 83\n",
      "1367 7539 84\n",
      "1380 7630 85\n",
      "1395 7715 86\n",
      "1413 7839 87\n",
      "1424 7904 88\n",
      "1435 7971 89\n",
      "1449 8047 90\n",
      "1462 8136 91\n",
      "1472 8194 92\n",
      "1482 8262 93\n",
      "1491 8315 94\n",
      "1501 8367 95\n",
      "1510 8422 96\n",
      "1522 8510 97\n",
      "1533 8567 98\n",
      "1549 8657 99\n",
      "1560 8736 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 29.159645275079427 \ttest: 0.9528619528619529 66.22653465873556\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 8.242847321597626 \ttest: 0.9629629629629629 51.11712397573774\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 3.629629864203816 \ttest: 0.9663299663299664 45.79056339164572\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 1.9893093230111507 \ttest: 0.9663299663299664 43.045926203060155\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.2413916240288971 \ttest: 0.9663299663299664 41.350880432204086\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        63\n",
      "           1    1.00000   1.00000   1.00000        63\n",
      "           2    1.00000   1.00000   1.00000        63\n",
      "           3    1.00000   1.00000   1.00000        63\n",
      "           4    1.00000   1.00000   1.00000        63\n",
      "           5    1.00000   1.00000   1.00000        63\n",
      "           6    1.00000   1.00000   1.00000        63\n",
      "           7    1.00000   1.00000   1.00000        63\n",
      "           8    1.00000   1.00000   1.00000        63\n",
      "           9    1.00000   1.00000   1.00000        63\n",
      "          10    1.00000   1.00000   1.00000        63\n",
      "\n",
      "    accuracy                        1.00000       693\n",
      "   macro avg    1.00000   1.00000   1.00000       693\n",
      "weighted avg    1.00000   1.00000   1.00000       693\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        27\n",
      "           1    1.00000   0.92593   0.96154        27\n",
      "           2    0.92857   0.96296   0.94545        27\n",
      "           3    0.96000   0.88889   0.92308        27\n",
      "           4    0.92857   0.96296   0.94545        27\n",
      "           5    1.00000   0.96296   0.98113        27\n",
      "           6    1.00000   1.00000   1.00000        27\n",
      "           7    1.00000   1.00000   1.00000        27\n",
      "           8    0.96429   1.00000   0.98182        27\n",
      "           9    0.89286   0.92593   0.90909        27\n",
      "          10    0.96429   1.00000   0.98182        27\n",
      "\n",
      "    accuracy                        0.96633       297\n",
      "   macro avg    0.96714   0.96633   0.96631       297\n",
      "weighted avg    0.96714   0.96633   0.96631       297\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1560\n",
      "Average of depth: 1.957051282051282\n",
      "Number of nodes: 8736\n",
      "29 133 1\n",
      "55 243 2\n",
      "82 370 3\n",
      "108 502 4\n",
      "135 633 5\n",
      "162 764 6\n",
      "183 865 7\n",
      "202 954 8\n",
      "224 1074 9\n",
      "244 1180 10\n",
      "267 1299 11\n",
      "291 1435 12\n",
      "309 1543 13\n",
      "330 1648 14\n",
      "355 1775 15\n",
      "374 1868 16\n",
      "398 1992 17\n",
      "416 2082 18\n",
      "433 2169 19\n",
      "454 2310 20\n",
      "476 2434 21\n",
      "494 2528 22\n",
      "511 2611 23\n",
      "524 2684 24\n",
      "545 2793 25\n",
      "564 2898 26\n",
      "582 3008 27\n",
      "601 3113 28\n",
      "621 3225 29\n",
      "638 3322 30\n",
      "654 3408 31\n",
      "670 3506 32\n",
      "689 3609 33\n",
      "709 3727 34\n",
      "725 3811 35\n",
      "744 3916 36\n",
      "758 3990 37\n",
      "772 4058 38\n",
      "789 4153 39\n",
      "808 4254 40\n",
      "819 4321 41\n",
      "834 4418 42\n",
      "854 4538 43\n",
      "868 4614 44\n",
      "884 4716 45\n",
      "901 4827 46\n",
      "912 4894 47\n",
      "923 4965 48\n",
      "936 5044 49\n",
      "948 5114 50\n",
      "965 5207 51\n",
      "980 5306 52\n",
      "994 5382 53\n",
      "1012 5488 54\n",
      "1021 5545 55\n",
      "1039 5651 56\n",
      "1050 5714 57\n",
      "1064 5794 58\n",
      "1074 5850 59\n",
      "1092 5960 60\n",
      "1103 6031 61\n",
      "1116 6110 62\n",
      "1129 6183 63\n",
      "1144 6264 64\n",
      "1154 6324 65\n",
      "1163 6385 66\n",
      "1175 6453 67\n",
      "1183 6501 68\n",
      "1197 6589 69\n",
      "1210 6652 70\n",
      "1221 6721 71\n",
      "1236 6816 72\n",
      "1249 6889 73\n",
      "1263 6963 74\n",
      "1275 7031 75\n",
      "1291 7127 76\n",
      "1304 7208 77\n",
      "1317 7289 78\n",
      "1329 7353 79\n",
      "1341 7425 80\n",
      "1360 7538 81\n",
      "1368 7590 82\n",
      "1381 7695 83\n",
      "1395 7783 84\n",
      "1411 7889 85\n",
      "1427 7989 86\n",
      "1442 8078 87\n",
      "1456 8168 88\n",
      "1467 8223 89\n",
      "1477 8279 90\n",
      "1489 8349 91\n",
      "1502 8436 92\n",
      "1516 8518 93\n",
      "1531 8613 94\n",
      "1544 8690 95\n",
      "1556 8762 96\n",
      "1569 8845 97\n",
      "1581 8915 98\n",
      "1595 9019 99\n",
      "1609 9107 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 27.2527980916761 \ttest: 0.9494949494949495 62.20989754816567\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 7.479364397500724 \ttest: 0.9663299663299664 46.07884295003599\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 3.258894809184725 \ttest: 0.9696969696969697 40.25082544305948\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 1.7821223209300388 \ttest: 0.9696969696969697 37.20271340412745\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.1125203574686888 \ttest: 0.9696969696969697 35.297647137752385\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        63\n",
      "           1    1.00000   1.00000   1.00000        63\n",
      "           2    1.00000   1.00000   1.00000        63\n",
      "           3    1.00000   1.00000   1.00000        63\n",
      "           4    1.00000   1.00000   1.00000        63\n",
      "           5    1.00000   1.00000   1.00000        63\n",
      "           6    1.00000   1.00000   1.00000        63\n",
      "           7    1.00000   1.00000   1.00000        63\n",
      "           8    1.00000   1.00000   1.00000        63\n",
      "           9    1.00000   1.00000   1.00000        63\n",
      "          10    1.00000   1.00000   1.00000        63\n",
      "\n",
      "    accuracy                        1.00000       693\n",
      "   macro avg    1.00000   1.00000   1.00000       693\n",
      "weighted avg    1.00000   1.00000   1.00000       693\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        27\n",
      "           1    1.00000   0.96296   0.98113        27\n",
      "           2    0.96429   1.00000   0.98182        27\n",
      "           3    0.96296   0.96296   0.96296        27\n",
      "           4    0.92857   0.96296   0.94545        27\n",
      "           5    0.89655   0.96296   0.92857        27\n",
      "           6    0.96000   0.88889   0.92308        27\n",
      "           7    0.96429   1.00000   0.98182        27\n",
      "           8    1.00000   1.00000   1.00000        27\n",
      "           9    1.00000   0.92593   0.96154        27\n",
      "          10    1.00000   1.00000   1.00000        27\n",
      "\n",
      "    accuracy                        0.96970       297\n",
      "   macro avg    0.97061   0.96970   0.96967       297\n",
      "weighted avg    0.97061   0.96970   0.96967       297\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1609\n",
      "Average of depth: 1.980733374766936\n",
      "Number of nodes: 9107\n",
      "28 128 1\n",
      "55 267 2\n",
      "81 413 3\n",
      "106 542 4\n",
      "136 688 5\n",
      "163 815 6\n",
      "186 930 7\n",
      "209 1051 8\n",
      "230 1152 9\n",
      "256 1296 10\n",
      "279 1397 11\n",
      "299 1515 12\n",
      "322 1612 13\n",
      "341 1707 14\n",
      "361 1823 15\n",
      "377 1915 16\n",
      "398 2028 17\n",
      "416 2122 18\n",
      "436 2208 19\n",
      "458 2322 20\n",
      "476 2406 21\n",
      "491 2493 22\n",
      "509 2587 23\n",
      "529 2685 24\n",
      "545 2767 25\n",
      "565 2865 26\n",
      "580 2962 27\n",
      "597 3055 28\n",
      "615 3175 29\n",
      "628 3252 30\n",
      "642 3316 31\n",
      "656 3394 32\n",
      "674 3500 33\n",
      "690 3588 34\n",
      "708 3696 35\n",
      "723 3791 36\n",
      "739 3885 37\n",
      "754 3970 38\n",
      "774 4074 39\n",
      "790 4162 40\n",
      "802 4224 41\n",
      "820 4316 42\n",
      "834 4400 43\n",
      "850 4482 44\n",
      "861 4549 45\n",
      "875 4637 46\n",
      "885 4713 47\n",
      "901 4815 48\n",
      "916 4902 49\n",
      "932 4996 50\n",
      "944 5068 51\n",
      "960 5168 52\n",
      "974 5256 53\n",
      "989 5343 54\n",
      "998 5400 55\n",
      "1016 5502 56\n",
      "1029 5573 57\n",
      "1041 5651 58\n",
      "1053 5725 59\n",
      "1068 5824 60\n",
      "1078 5878 61\n",
      "1093 5963 62\n",
      "1110 6084 63\n",
      "1124 6156 64\n",
      "1139 6243 65\n",
      "1151 6307 66\n",
      "1164 6394 67\n",
      "1176 6462 68\n",
      "1190 6546 69\n",
      "1203 6629 70\n",
      "1218 6724 71\n",
      "1235 6829 72\n",
      "1250 6918 73\n",
      "1259 6969 74\n",
      "1273 7043 75\n",
      "1284 7110 76\n",
      "1299 7203 77\n",
      "1318 7310 78\n",
      "1333 7401 79\n",
      "1347 7485 80\n",
      "1361 7567 81\n",
      "1372 7642 82\n",
      "1384 7700 83\n",
      "1394 7754 84\n",
      "1409 7851 85\n",
      "1419 7917 86\n",
      "1430 7994 87\n",
      "1442 8068 88\n",
      "1455 8155 89\n",
      "1467 8231 90\n",
      "1479 8303 91\n",
      "1489 8367 92\n",
      "1500 8444 93\n",
      "1512 8518 94\n",
      "1521 8575 95\n",
      "1534 8652 96\n",
      "1545 8729 97\n",
      "1557 8801 98\n",
      "1566 8848 99\n",
      "1583 8947 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 27.278128120043597 \ttest: 0.9225589225589226 70.49352354735379\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 7.413779347853955 \ttest: 0.9225589225589226 57.22410525826657\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 3.2324247060727616 \ttest: 0.9292929292929293 52.472040470859255\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 1.7691046858707908 \ttest: 0.9326599326599326 49.967969728409486\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.1049856103096394 \ttest: 0.9326599326599326 48.39396682696843\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        63\n",
      "           1    1.00000   1.00000   1.00000        63\n",
      "           2    1.00000   1.00000   1.00000        63\n",
      "           3    1.00000   1.00000   1.00000        63\n",
      "           4    1.00000   1.00000   1.00000        63\n",
      "           5    1.00000   1.00000   1.00000        63\n",
      "           6    1.00000   1.00000   1.00000        63\n",
      "           7    1.00000   1.00000   1.00000        63\n",
      "           8    1.00000   1.00000   1.00000        63\n",
      "           9    1.00000   1.00000   1.00000        63\n",
      "          10    1.00000   1.00000   1.00000        63\n",
      "\n",
      "    accuracy                        1.00000       693\n",
      "   macro avg    1.00000   1.00000   1.00000       693\n",
      "weighted avg    1.00000   1.00000   1.00000       693\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        27\n",
      "           1    0.96429   1.00000   0.98182        27\n",
      "           2    1.00000   0.96296   0.98113        27\n",
      "           3    0.89286   0.92593   0.90909        27\n",
      "           4    1.00000   0.88889   0.94118        27\n",
      "           5    0.95238   0.74074   0.83333        27\n",
      "           6    0.86207   0.92593   0.89286        27\n",
      "           7    0.88889   0.88889   0.88889        27\n",
      "           8    1.00000   1.00000   1.00000        27\n",
      "           9    0.90000   1.00000   0.94737        27\n",
      "          10    0.83333   0.92593   0.87719        27\n",
      "\n",
      "    accuracy                        0.93266       297\n",
      "   macro avg    0.93580   0.93266   0.93208       297\n",
      "weighted avg    0.93580   0.93266   0.93208       297\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1583\n",
      "Average of depth: 1.9703095388502843\n",
      "Number of nodes: 8947\n",
      "28 132 1\n",
      "55 273 2\n",
      "81 395 3\n",
      "109 523 4\n",
      "137 663 5\n",
      "162 776 6\n",
      "185 893 7\n",
      "207 991 8\n",
      "231 1105 9\n",
      "254 1232 10\n",
      "279 1363 11\n",
      "305 1501 12\n",
      "328 1616 13\n",
      "351 1725 14\n",
      "369 1815 15\n",
      "386 1904 16\n",
      "404 1998 17\n",
      "418 2076 18\n",
      "438 2172 19\n",
      "459 2277 20\n",
      "470 2342 21\n",
      "487 2431 22\n",
      "500 2504 23\n",
      "518 2606 24\n",
      "535 2711 25\n",
      "554 2818 26\n",
      "569 2901 27\n",
      "583 2979 28\n",
      "598 3062 29\n",
      "621 3189 30\n",
      "635 3277 31\n",
      "654 3370 32\n",
      "675 3487 33\n",
      "695 3601 34\n",
      "711 3701 35\n",
      "727 3783 36\n",
      "746 3884 37\n",
      "767 4009 38\n",
      "781 4103 39\n",
      "796 4186 40\n",
      "812 4272 41\n",
      "824 4330 42\n",
      "836 4390 43\n",
      "851 4481 44\n",
      "866 4564 45\n",
      "884 4672 46\n",
      "900 4764 47\n",
      "913 4833 48\n",
      "925 4909 49\n",
      "936 4974 50\n",
      "953 5073 51\n",
      "964 5140 52\n",
      "974 5192 53\n",
      "989 5277 54\n",
      "1008 5402 55\n",
      "1023 5483 56\n",
      "1037 5561 57\n",
      "1053 5663 58\n",
      "1066 5736 59\n",
      "1080 5816 60\n",
      "1092 5900 61\n",
      "1104 5974 62\n",
      "1117 6051 63\n",
      "1125 6095 64\n",
      "1138 6168 65\n",
      "1153 6261 66\n",
      "1164 6330 67\n",
      "1178 6414 68\n",
      "1189 6487 69\n",
      "1202 6566 70\n",
      "1215 6647 71\n",
      "1227 6733 72\n",
      "1239 6817 73\n",
      "1251 6891 74\n",
      "1265 6967 75\n",
      "1275 7025 76\n",
      "1291 7125 77\n",
      "1303 7193 78\n",
      "1316 7272 79\n",
      "1326 7328 80\n",
      "1337 7387 81\n",
      "1351 7469 82\n",
      "1360 7516 83\n",
      "1372 7576 84\n",
      "1385 7651 85\n",
      "1399 7745 86\n",
      "1412 7816 87\n",
      "1424 7886 88\n",
      "1438 7974 89\n",
      "1449 8047 90\n",
      "1465 8163 91\n",
      "1480 8268 92\n",
      "1492 8340 93\n",
      "1504 8410 94\n",
      "1516 8476 95\n",
      "1527 8545 96\n",
      "1541 8637 97\n",
      "1555 8727 98\n",
      "1570 8834 99\n",
      "1580 8902 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 27.36276749759325 \ttest: 0.9158249158249159 72.13411892063137\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 7.343706847818173 \ttest: 0.9259259259259259 56.74121773418954\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 3.175707668351725 \ttest: 0.9259259259259259 51.230573639458484\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 1.7298640423243412 \ttest: 0.9292929292929293 48.38242705467951\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.0773425449517462 \ttest: 0.936026936026936 46.619911054050846\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        63\n",
      "           1    1.00000   1.00000   1.00000        63\n",
      "           2    1.00000   1.00000   1.00000        63\n",
      "           3    1.00000   1.00000   1.00000        63\n",
      "           4    1.00000   1.00000   1.00000        63\n",
      "           5    1.00000   1.00000   1.00000        63\n",
      "           6    1.00000   1.00000   1.00000        63\n",
      "           7    1.00000   1.00000   1.00000        63\n",
      "           8    1.00000   1.00000   1.00000        63\n",
      "           9    1.00000   1.00000   1.00000        63\n",
      "          10    1.00000   1.00000   1.00000        63\n",
      "\n",
      "    accuracy                        1.00000       693\n",
      "   macro avg    1.00000   1.00000   1.00000       693\n",
      "weighted avg    1.00000   1.00000   1.00000       693\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.92857   0.96296   0.94545        27\n",
      "           1    0.96429   1.00000   0.98182        27\n",
      "           2    1.00000   0.92593   0.96154        27\n",
      "           3    0.92593   0.92593   0.92593        27\n",
      "           4    0.92857   0.96296   0.94545        27\n",
      "           5    0.89655   0.96296   0.92857        27\n",
      "           6    0.94737   0.66667   0.78261        27\n",
      "           7    0.79412   1.00000   0.88525        27\n",
      "           8    0.96429   1.00000   0.98182        27\n",
      "           9    1.00000   0.88889   0.94118        27\n",
      "          10    1.00000   1.00000   1.00000        27\n",
      "\n",
      "    accuracy                        0.93603       297\n",
      "   macro avg    0.94088   0.93603   0.93451       297\n",
      "weighted avg    0.94088   0.93603   0.93451       297\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1580\n",
      "Average of depth: 1.9727848101265824\n",
      "Number of nodes: 8902\n",
      "29 137 1\n",
      "56 264 2\n",
      "78 372 3\n",
      "104 504 4\n",
      "127 611 5\n",
      "150 718 6\n",
      "176 850 7\n",
      "199 971 8\n",
      "219 1069 9\n",
      "244 1190 10\n",
      "268 1306 11\n",
      "288 1410 12\n",
      "311 1531 13\n",
      "332 1646 14\n",
      "349 1721 15\n",
      "370 1824 16\n",
      "394 1942 17\n",
      "414 2052 18\n",
      "432 2150 19\n",
      "452 2274 20\n",
      "468 2348 21\n",
      "480 2406 22\n",
      "499 2505 23\n",
      "513 2571 24\n",
      "533 2675 25\n",
      "553 2765 26\n",
      "567 2833 27\n",
      "585 2935 28\n",
      "601 3019 29\n",
      "617 3105 30\n",
      "638 3228 31\n",
      "655 3337 32\n",
      "673 3429 33\n",
      "692 3530 34\n",
      "707 3611 35\n",
      "720 3696 36\n",
      "738 3796 37\n",
      "756 3894 38\n",
      "767 3953 39\n",
      "780 4016 40\n",
      "798 4130 41\n",
      "813 4235 42\n",
      "827 4325 43\n",
      "842 4414 44\n",
      "857 4517 45\n",
      "874 4620 46\n",
      "888 4692 47\n",
      "904 4782 48\n",
      "920 4868 49\n",
      "938 4986 50\n",
      "956 5096 51\n",
      "971 5195 52\n",
      "983 5261 53\n",
      "999 5343 54\n",
      "1015 5443 55\n",
      "1029 5523 56\n",
      "1038 5570 57\n",
      "1052 5654 58\n",
      "1065 5735 59\n",
      "1076 5800 60\n",
      "1088 5874 61\n",
      "1099 5939 62\n",
      "1107 5983 63\n",
      "1119 6041 64\n",
      "1138 6154 65\n",
      "1149 6229 66\n",
      "1159 6281 67\n",
      "1176 6380 68\n",
      "1189 6455 69\n",
      "1202 6534 70\n",
      "1216 6614 71\n",
      "1227 6681 72\n",
      "1239 6751 73\n",
      "1253 6839 74\n",
      "1268 6932 75\n",
      "1279 6999 76\n",
      "1290 7072 77\n",
      "1303 7159 78\n",
      "1313 7221 79\n",
      "1325 7283 80\n",
      "1335 7341 81\n",
      "1348 7416 82\n",
      "1362 7496 83\n",
      "1377 7593 84\n",
      "1390 7664 85\n",
      "1402 7740 86\n",
      "1415 7793 87\n",
      "1430 7894 88\n",
      "1444 7970 89\n",
      "1454 8030 90\n",
      "1466 8106 91\n",
      "1479 8173 92\n",
      "1490 8246 93\n",
      "1501 8307 94\n",
      "1506 8336 95\n",
      "1515 8383 96\n",
      "1528 8466 97\n",
      "1540 8536 98\n",
      "1550 8598 99\n",
      "1560 8658 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 27.08567744746997 \ttest: 0.9326599326599326 69.56930614824051\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 7.385600617813741 \ttest: 0.9461279461279462 54.18314568398654\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 3.2289062059504827 \ttest: 0.9461279461279462 48.61194168224756\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 1.770769475600161 \ttest: 0.9461279461279462 45.715908934751766\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.1077404087557707 \ttest: 0.9461279461279462 43.92024692781746\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        63\n",
      "           1    1.00000   1.00000   1.00000        63\n",
      "           2    1.00000   1.00000   1.00000        63\n",
      "           3    1.00000   1.00000   1.00000        63\n",
      "           4    1.00000   1.00000   1.00000        63\n",
      "           5    1.00000   1.00000   1.00000        63\n",
      "           6    1.00000   1.00000   1.00000        63\n",
      "           7    1.00000   1.00000   1.00000        63\n",
      "           8    1.00000   1.00000   1.00000        63\n",
      "           9    1.00000   1.00000   1.00000        63\n",
      "          10    1.00000   1.00000   1.00000        63\n",
      "\n",
      "    accuracy                        1.00000       693\n",
      "   macro avg    1.00000   1.00000   1.00000       693\n",
      "weighted avg    1.00000   1.00000   1.00000       693\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        27\n",
      "           1    1.00000   0.96296   0.98113        27\n",
      "           2    1.00000   0.96296   0.98113        27\n",
      "           3    1.00000   0.85185   0.92000        27\n",
      "           4    1.00000   0.92593   0.96154        27\n",
      "           5    0.85714   0.88889   0.87273        27\n",
      "           6    0.92308   0.88889   0.90566        27\n",
      "           7    0.81818   1.00000   0.90000        27\n",
      "           8    1.00000   1.00000   1.00000        27\n",
      "           9    0.90000   1.00000   0.94737        27\n",
      "          10    0.96154   0.92593   0.94340        27\n",
      "\n",
      "    accuracy                        0.94613       297\n",
      "   macro avg    0.95090   0.94613   0.94663       297\n",
      "weighted avg    0.95090   0.94613   0.94663       297\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1560\n",
      "Average of depth: 1.9474358974358974\n",
      "Number of nodes: 8658\n"
     ]
    }
   ],
   "source": [
    "def fit_trees():\n",
    "    learning_rate=0.1\n",
    "    max_depth=3\n",
    "    bins=8\n",
    "    lam=10\n",
    "\n",
    "    gtgp = GTGP(learning_rate=learning_rate,max_depth=max_depth,bins=bins,lam=lam)\n",
    "\n",
    "    total_size=10\n",
    "    elite_size = 10\n",
    "    epoch= 100\n",
    "    gp_epoch= 3\n",
    "    verbose = 1\n",
    "    tolerance=0.01\n",
    "\n",
    "    gtgp.fit(X_train,y_train,total_size=total_size,elite_size = elite_size,epoch=epoch,gp_epoch=gp_epoch,tolerance=tolerance,verbose=verbose)\n",
    "\n",
    "    retrain_epoch= 5\n",
    "    alpha=0\n",
    "    beta=1\n",
    "    gammer=0\n",
    "\n",
    "    verbose=1\n",
    "    gtgp.lam = 10\n",
    "    gtgp.retrain_estimators(X_test,y_test,retrain_epoch=retrain_epoch,alpha=alpha,beta=beta,gammer=gammer,verbose=verbose)\n",
    "\n",
    "    return gtgp\n",
    "\n",
    "with open('./benchmark/'+dataset+'.csv','a') as f:\n",
    "    for i in range(30):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size,stratify=y, random_state=seeds[i])\n",
    "        gtgp = fit_trees()\n",
    "\n",
    "        print(classification_report(y_train,np.argmax(gtgp.train_p,axis=1),digits=5))\n",
    "        print(classification_report(y_test,np.argmax(gtgp.test_p,axis=1),digits=5))\n",
    "\n",
    "        num_trees,depth,num_nodes = gtgp.print_model()\n",
    "\n",
    "        train_acc = accuracy_score(y_train,np.argmax(gtgp.train_p,axis=1))\n",
    "        test_acc = accuracy_score(y_test,np.argmax(gtgp.test_p,axis=1))\n",
    "        train_f1 = f1_score(y_train,np.argmax(gtgp.train_p,axis=1),average='macro')\n",
    "        test_f1 = f1_score(y_test,np.argmax(gtgp.test_p,axis=1),average='macro')\n",
    "\n",
    "        s = str(train_acc)+\",\"+str(test_acc)+\",\"+str(train_f1)+\",\"+str(test_f1)+\",\"+str(num_trees)+\",\"+str(depth)+\",\"+str(num_nodes)+\"\\n\"\n",
    "        f.writelines(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662e91a5",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ed15d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "661630ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('./benchmark_DC/'+dataset+'.csv','w') as f:\n",
    "        \n",
    "    for i in range(30):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size,stratify=y, random_state=seeds[i])\n",
    "        clf = DecisionTreeClassifier()\n",
    "        clf.fit(X_train,y_train)\n",
    "\n",
    "        num_trees = 1\n",
    "        depth = clf.tree_.max_depth\n",
    "        num_nodes = clf.tree_.node_count\n",
    "\n",
    "        train_acc = accuracy_score(y_train,clf.predict(X_train))\n",
    "        test_acc = accuracy_score(y_test,clf.predict(X_test))\n",
    "        train_f1 = f1_score(y_train,clf.predict(X_train),average='macro')\n",
    "        test_f1 = f1_score(y_test,clf.predict(X_test),average='macro')\n",
    "\n",
    "        s = str(train_acc)+\",\"+str(test_acc)+\",\"+str(train_f1)+\",\"+str(test_f1)+\",\"+str(num_trees)+\",\"+str(depth)+\",\"+str(num_nodes)+\"\\n\"\n",
    "        f.writelines(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63afbae1",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28fa8541",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acfdd7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./benchmark_xgb/'+dataset+'.csv','w') as f:\n",
    "    for i in range(30):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size,stratify=y, random_state=seeds[i])\n",
    "        xgb = xgboost.XGBClassifier(n_estimators=100,max_depth=6)\n",
    "        # xgb = xgboost.XGBClassifier(min_child_weight=0,max_depth=4)\n",
    "        # xgb = xgboost.XGBClassifier()\n",
    "        xgb.fit(X_train,y_train)\n",
    "\n",
    "        import json\n",
    "\n",
    "        def item_generator(json_input, lookup_key):\n",
    "            if isinstance(json_input, dict):\n",
    "                for k, v in json_input.items():\n",
    "                    if k == lookup_key:\n",
    "                        yield v\n",
    "                    else:\n",
    "                        yield from item_generator(v, lookup_key)\n",
    "            elif isinstance(json_input, list):\n",
    "                for item in json_input:\n",
    "                    yield from item_generator(item, lookup_key)\n",
    "\n",
    "        def tree_depth(json_text):\n",
    "            json_input = json.loads(json_text)\n",
    "            depths = list(item_generator(json_input, 'depth'))\n",
    "            return max(depths) + 1 if len(depths) != 0 else 1\n",
    "\n",
    "        train_acc = accuracy_score(y_train,xgb.predict(X_train))\n",
    "        test_acc = accuracy_score(y_test,xgb.predict(X_test))\n",
    "        train_f1 = f1_score(y_train,xgb.predict(X_train),average='macro')\n",
    "        test_f1 = f1_score(y_test,xgb.predict(X_test),average='macro')\n",
    "\n",
    "        booster = xgb.get_booster()\n",
    "\n",
    "        tree_df = booster.trees_to_dataframe()\n",
    "        depths = [tree_depth(x) for x in booster.get_dump(dump_format = \"json\")]\n",
    "        num_trees = len(depths)\n",
    "        depth = np.average(depths)\n",
    "        num_nodes = len(tree_df)\n",
    "\n",
    "        s = str(train_acc)+\",\"+str(test_acc)+\",\"+str(train_f1)+\",\"+str(test_f1)+\",\"+str(num_trees)+\",\"+str(depth)+\",\"+str(num_nodes)+\"\\n\"\n",
    "        f.writelines(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc363f99",
   "metadata": {},
   "source": [
    "# GDBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e6d3435",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef69c1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./benchmark_GBDT/'+dataset+'.csv','w') as f:\n",
    "    for i in range(30):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size,stratify=y, random_state=seeds[i])\n",
    "        # clf = GradientBoostingClassifier(n_estimators=1000)\n",
    "        clf = GradientBoostingClassifier()\n",
    "        clf.fit(X_train,y_train)\n",
    "\n",
    "        train_acc = accuracy_score(y_train,clf.predict(X_train))\n",
    "        test_acc = accuracy_score(y_test,clf.predict(X_test))\n",
    "        train_f1 = f1_score(y_train,clf.predict(X_train),average='macro')\n",
    "        test_f1 = f1_score(y_test,clf.predict(X_test),average='macro')\n",
    "\n",
    "        num_trees = len([ est for ests in clf.estimators_ for est in ests])\n",
    "        depth = np.average([ max(1,est.tree_.max_depth) for ests in clf.estimators_ for est in ests])\n",
    "        num_nodes = sum([ est.tree_.node_count for ests in clf.estimators_ for est in ests])\n",
    "\n",
    "        s = str(train_acc)+\",\"+str(test_acc)+\",\"+str(train_f1)+\",\"+str(test_f1)+\",\"+str(num_trees)+\",\"+str(depth)+\",\"+str(num_nodes)+\"\\n\"\n",
    "        f.writelines(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0ef54f",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c8623bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e3edfc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./benchmark_RF/'+dataset+'.csv','w') as f:\n",
    "    for i in range(30):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size,stratify=y, random_state=seeds[i])\n",
    "        rfc = RandomForestClassifier()\n",
    "        rfc.fit(X_train,y_train)\n",
    "\n",
    "        train_acc = accuracy_score(y_train,rfc.predict(X_train))\n",
    "        test_acc = accuracy_score(y_test,rfc.predict(X_test))\n",
    "        train_f1 = f1_score(y_train,rfc.predict(X_train),average='macro')\n",
    "        test_f1 = f1_score(y_test,rfc.predict(X_test),average='macro')\n",
    "\n",
    "        num_trees = len(rfc.estimators_)\n",
    "        depth = np.average([est.tree_.max_depth for est in rfc.estimators_])\n",
    "        num_nodes = sum([est.tree_.node_count for est in rfc.estimators_])\n",
    "\n",
    "        s = str(train_acc)+\",\"+str(test_acc)+\",\"+str(train_f1)+\",\"+str(test_f1)+\",\"+str(num_trees)+\",\"+str(depth)+\",\"+str(num_nodes)+\"\\n\"\n",
    "        f.writelines(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232dc3aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BStackGP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc-autonumbering": true,
  "toc-showcode": true,
  "toc-showmarkdowntxt": true,
  "vscode": {
   "interpreter": {
    "hash": "598cefc26d6e5a65b2978c65314d0610ea9dfe34c7d989c4b6d2528d500ccb7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
