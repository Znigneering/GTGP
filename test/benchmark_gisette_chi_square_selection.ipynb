{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a8bc990-ebc5-46bd-bab4-f4091ce5b834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../script/\")\n",
    "\n",
    "import Functions\n",
    "from Engine import Engine\n",
    "from GTGP import GTGP\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report,accuracy_score,confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import importlib\n",
    "from time import time\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbad47da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.utils import shuffle\n",
    "def plot_roc_curve(true_y, y_prob):\n",
    "    \"\"\"\n",
    "    plots the roc curve based of the probabilities\n",
    "    \"\"\"\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(true_y, y_prob)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    print(roc_auc_score(true_y,prob[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c114de92",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "feedaa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"../data/gisette_train.data\",delimiter=\" \",header=None).iloc[:,:-1].values\n",
    "y_train = pd.read_csv(\"../data/gisette_train.labels\",delimiter=\" \",header=None).values.flatten()\n",
    "y_train[y_train==-1] = 0\n",
    "\n",
    "X_test = pd.read_csv(\"../data/gisette_valid.data\",delimiter=\" \",header=None).iloc[:,:-1].values\n",
    "y_test = pd.read_csv(\"../data/gisette_valid.labels\",delimiter=\" \",header=None).values.flatten()\n",
    "y_test[y_test==-1] = 0\n",
    "\n",
    "\n",
    "dataset = 'gisette_chi_square_selection'\n",
    "# X_train, X_test_addition, y_train, y_test_addition = train_test_split(X_train, y_train, train_size=1000,stratify=y_train)\n",
    "# X_train, X_test_addition, y_train, y_test_addition = train_test_split(X_train, y_train, train_size=20,stratify=y_train)\n",
    "\n",
    "# X_test = np.concatenate([X_test,X_test_addition])\n",
    "# y_test = np.concatenate([y_test,y_test_addition])\n",
    "# y_train,y_test,y_train_one_hot,y_test_one_hot = to_one_hot(y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "302c45dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(y,yt):\n",
    "    le = LabelEncoder()\n",
    "    ohe = OneHotEncoder()\n",
    "    y_train = le.fit_transform(y)\n",
    "    y_one_hot = ohe.fit_transform(y_train.reshape(-1,1))\n",
    "    \n",
    "    y_test = le.transform(yt)\n",
    "    yt_one_hot = ohe.transform(y_test.reshape(-1,1))\n",
    "    \n",
    "    return y_train,y_test,y_one_hot,yt_one_hot\n",
    "\n",
    "def initial(y_one_hot):\n",
    "    init_log_odds = np.sum(y_one_hot,axis=0)/y_one_hot.shape[0]\n",
    "    \n",
    "    init_p = np.exp(init_log_odds)\n",
    "    init_p = init_p/(1+init_p)\n",
    "\n",
    "    return init_log_odds,init_p\n",
    "\n",
    "y_train,y_test,y_train_one_hot,y_test_one_hot = to_one_hot(y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41811bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "skb = SelectKBest(chi2,k=2500)\n",
    "X_train = skb.fit_transform(X_train,y_train)\n",
    "X_test = skb.transform(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662e91a5",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ed15d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfc38da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size,stratify=y, random_state=seeds[i])\n",
    "    y_train,y_test,y_train_one_hot,y_test_one_hot = to_one_hot(y_train,y_test)\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(X_train,y_train)\n",
    "\n",
    "    num_trees = 1\n",
    "    depth = clf.tree_.max_depth\n",
    "    num_nodes = clf.tree_.node_count\n",
    "\n",
    "    train_acc = accuracy_score(y_train,clf.predict(X_train))\n",
    "    test_acc = accuracy_score(y_test,clf.predict(X_test))\n",
    "    train_roc = roc_auc_score(y_train_one_hot.toarray(),clf.predict_proba(X_train))\n",
    "    test_roc = roc_auc_score(y_test_one_hot.toarray(),clf.predict_proba(X_test))\n",
    "\n",
    "    with open('./benchmark_DC/'+dataset+'.csv','a') as f:\n",
    "        s = str(train_acc)+\",\"+str(test_acc)+\",\"+str(train_roc)+\",\"+str(test_roc)+\",\"+str(num_trees)+\",\"+str(depth)+\",\"+str(num_nodes)+\"\\n\"\n",
    "        f.writelines(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63afbae1",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28fa8541",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ffdc577",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size,stratify=y, random_state=seeds[i])\n",
    "    \n",
    "    y_train,y_test,y_train_one_hot,y_test_one_hot = to_one_hot(y_train,y_test)\n",
    "    # xgb = xgboost.XGBClassifier(min_child_weight=0,max_depth=3,n_estimators=100)\n",
    "    # xgb = xgboost.XGBClassifier(min_child_weight=0,max_depth=4)\n",
    "    xgb = xgboost.XGBClassifier(n_estimators=1000)\n",
    "    xgb.fit(X_train,y_train)\n",
    "\n",
    "    import json\n",
    "\n",
    "    def item_generator(json_input, lookup_key):\n",
    "        if isinstance(json_input, dict):\n",
    "            for k, v in json_input.items():\n",
    "                if k == lookup_key:\n",
    "                    yield v\n",
    "                else:\n",
    "                    yield from item_generator(v, lookup_key)\n",
    "        elif isinstance(json_input, list):\n",
    "            for item in json_input:\n",
    "                yield from item_generator(item, lookup_key)\n",
    "\n",
    "    def tree_depth(json_text):\n",
    "        json_input = json.loads(json_text)\n",
    "        depths = list(item_generator(json_input, 'depth'))\n",
    "        return max(depths) + 1 if len(depths) != 0 else 1\n",
    "\n",
    "    train_acc = accuracy_score(y_train,xgb.predict(X_train))\n",
    "    test_acc = accuracy_score(y_test,xgb.predict(X_test))\n",
    "    train_roc = roc_auc_score(y_train_one_hot.toarray(),xgb.predict_proba(X_train))\n",
    "    test_roc = roc_auc_score(y_test_one_hot.toarray(),xgb.predict_proba(X_test))\n",
    "\n",
    "    booster = xgb.get_booster()\n",
    "\n",
    "    tree_df = booster.trees_to_dataframe()\n",
    "    depths = [tree_depth(x) for x in booster.get_dump(dump_format = \"json\")]\n",
    "    num_trees = len(depths)\n",
    "    depth = np.average(depths)\n",
    "    num_nodes = len(tree_df)\n",
    "\n",
    "    with open('./benchmark_xgb/'+dataset+'.csv','a') as f:\n",
    "        s = str(train_acc)+\",\"+str(test_acc)+\",\"+str(train_roc)+\",\"+str(test_roc)+\",\"+str(num_trees)+\",\"+str(depth)+\",\"+str(num_nodes)+\"\\n\"\n",
    "        f.writelines(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc363f99",
   "metadata": {},
   "source": [
    "# GDBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e6d3435",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a063f609",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size,stratify=y, random_state=seeds[i])\n",
    "    y_train,y_test,y_train_one_hot,y_test_one_hot = to_one_hot(y_train,y_test)\n",
    "    clf = GradientBoostingClassifier(n_estimators=1000)\n",
    "    # clf = GradientBoostingClassifier()\n",
    "    clf.fit(X_train,y_train)\n",
    "\n",
    "    train_acc = accuracy_score(y_train,clf.predict(X_train))\n",
    "    test_acc = accuracy_score(y_test,clf.predict(X_test))\n",
    "    train_roc = roc_auc_score(y_train_one_hot.toarray(),clf.predict_proba(X_train))\n",
    "    test_roc = roc_auc_score(y_test_one_hot.toarray(),clf.predict_proba(X_test))\n",
    "\n",
    "    num_trees = len([ est for ests in clf.estimators_ for est in ests])\n",
    "    depth = np.average([ max(1,est.tree_.max_depth) for ests in clf.estimators_ for est in ests])\n",
    "    num_nodes = sum([ est.tree_.node_count for ests in clf.estimators_ for est in ests])\n",
    "\n",
    "    with open('./benchmark_GBDT/'+dataset+'.csv','a') as f:\n",
    "        s = str(train_acc)+\",\"+str(test_acc)+\",\"+str(train_roc)+\",\"+str(test_roc)+\",\"+str(num_trees)+\",\"+str(depth)+\",\"+str(num_nodes)+\"\\n\"\n",
    "        f.writelines(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0ef54f",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8623bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b693a8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size,stratify=y, random_state=seeds[i])\n",
    "    y_train,y_test,y_train_one_hot,y_test_one_hot = to_one_hot(y_train,y_test)\n",
    "    rfc = RandomForestClassifier()\n",
    "    rfc.fit(X_train,y_train)\n",
    "\n",
    "    train_acc = accuracy_score(y_train,rfc.predict(X_train))\n",
    "    test_acc = accuracy_score(y_test,rfc.predict(X_test))\n",
    "    train_roc = roc_auc_score(y_train_one_hot.toarray(),rfc.predict_proba(X_train))\n",
    "    test_roc = roc_auc_score(y_test_one_hot.toarray(),rfc.predict_proba(X_test))\n",
    "\n",
    "    num_trees = len(rfc.estimators_)\n",
    "    depth = np.average([est.tree_.max_depth for est in rfc.estimators_])\n",
    "    num_nodes = sum([est.tree_.node_count for est in rfc.estimators_])\n",
    "\n",
    "    with open('./benchmark_RF/'+dataset+'.csv','a') as f:\n",
    "        s = str(train_acc)+\",\"+str(test_acc)+\",\"+str(train_roc)+\",\"+str(test_roc)+\",\"+str(num_trees)+\",\"+str(depth)+\",\"+str(num_nodes)+\"\\n\"\n",
    "        f.writelines(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0d2736",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BStackGP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc-autonumbering": true,
  "toc-showcode": true,
  "toc-showmarkdowntxt": true,
  "vscode": {
   "interpreter": {
    "hash": "598cefc26d6e5a65b2978c65314d0610ea9dfe34c7d989c4b6d2528d500ccb7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
