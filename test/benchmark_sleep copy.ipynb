{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a8bc990-ebc5-46bd-bab4-f4091ce5b834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../script/\")\n",
    "\n",
    "import Functions\n",
    "from Engine import Engine\n",
    "from GTGP import GTGP\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report,accuracy_score,confusion_matrix,f1_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import importlib\n",
    "from time import time\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbad47da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.utils import shuffle\n",
    "def plot_roc_curve(true_y, y_prob):\n",
    "    \"\"\"\n",
    "    plots the roc curve based of the probabilities\n",
    "    \"\"\"\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(true_y, y_prob)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    print(roc_auc_score(true_y,prob[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c114de92",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "feedaa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/sleep.tsv\",delimiter='\\t')\n",
    "X = df.iloc[:,:-1].to_numpy().astype(\"float\")\n",
    "y = df.iloc[:,-1].to_numpy().astype(\"int\")\n",
    "y[y==5] = 4\n",
    "\n",
    "\n",
    "seeds = [10086, 200,500,30506,30405,30420,10056,7059,40965,5398,869543,83491,823190,\n",
    "         48392,2810,48392,3498210,483902,859032,12890,538920,86954,54309,6504,9840,\n",
    "         219805,548,2981,432890,5438908,219094,5843902,60854,979,12890,2108,4093]\n",
    "train_size = 0.7\n",
    "dataset = 'sleep'\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,train_size=train_size,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdd30c5",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567172f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retain(gtgp):\n",
    "    retrain_epoch=10\n",
    "    alpha=0\n",
    "    beta=1\n",
    "    gammer=0\n",
    "\n",
    "    verbose=1\n",
    "    gtgp.lam = 10\n",
    "    gtgp.retrain_estimators(X_test,y_test,retrain_epoch=retrain_epoch,alpha=alpha,beta=beta,gammer=gammer,verbose=verbose)\n",
    "\n",
    "    return gtgp\n",
    "\n",
    "retain(gtgp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a9f94d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5 0.5 0.5 0.5 0.5]\n",
      " [0.5 0.5 0.5 0.5 0.5]\n",
      " [0.5 0.5 0.5 0.5 0.5]\n",
      " ...\n",
      " [0.5 0.5 0.5 0.5 0.5]\n",
      " [0.5 0.5 0.5 0.5 0.5]\n",
      " [0.5 0.5 0.5 0.5 0.5]]\n",
      "28 130 1\n",
      "54 256 2\n",
      "80 384 3\n",
      "105 491 4\n",
      "131 601 5\n",
      "158 726 6\n",
      "181 845 7\n",
      "203 951 8\n",
      "225 1053 9\n",
      "246 1162 10\n",
      "268 1274 11\n",
      "291 1385 12\n",
      "312 1492 13\n",
      "335 1623 14\n",
      "352 1710 15\n",
      "371 1817 16\n",
      "390 1924 17\n",
      "410 2028 18\n",
      "426 2110 19\n",
      "447 2221 20\n",
      "468 2328 21\n",
      "489 2451 22\n",
      "511 2559 23\n",
      "526 2648 24\n",
      "542 2734 25\n",
      "558 2788 26\n",
      "576 2874 27\n",
      "593 2955 28\n",
      "603 3011 29\n",
      "615 3083 30\n",
      "626 3156 31\n"
     ]
    }
   ],
   "source": [
    "def fit_trees():\n",
    "    learning_rate=0.3\n",
    "    max_depth=1\n",
    "    bins=8\n",
    "    lam=1\n",
    "\n",
    "    gtgp = GTGP(learning_rate=learning_rate,max_depth=max_depth,bins=bins,lam=lam)\n",
    "\n",
    "    total_size=10\n",
    "    elite_size = 10\n",
    "    epoch= 1000\n",
    "    gp_epoch= 3\n",
    "    verbose = 1\n",
    "    tolerance=0.001\n",
    "\n",
    "    gtgp.fit(X_train,y_train,total_size=total_size,elite_size = elite_size,epoch=epoch,gp_epoch=gp_epoch,tolerance=tolerance,verbose=verbose)\n",
    "    return gtgp\n",
    "\n",
    "def retain(gtgp):\n",
    "    retrain_epoch=10\n",
    "    alpha=0\n",
    "    beta=1\n",
    "    gammer=0\n",
    "\n",
    "    verbose=1\n",
    "    gtgp.lam = 10\n",
    "    gtgp.retrain_estimators(X_test,y_test,retrain_epoch=retrain_epoch,alpha=alpha,beta=beta,gammer=gammer,verbose=verbose)\n",
    "\n",
    "    return gtgp\n",
    "\n",
    "for i in range(1):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size,stratify=y, random_state=seeds[i])\n",
    "    gtgp = fit_trees()\n",
    "    retain(gtgp)\n",
    "\n",
    "    print(classification_report(y_train,np.argmax(gtgp.train_p,axis=1),digits=5))\n",
    "    print(classification_report(y_test,np.argmax(gtgp.test_p,axis=1),digits=5))\n",
    "\n",
    "    num_trees,depth,num_nodes = gtgp.print_model()\n",
    "\n",
    "    train_acc = accuracy_score(y_train,np.argmax(gtgp.train_p,axis=1))\n",
    "    test_acc = accuracy_score(y_test,np.argmax(gtgp.test_p,axis=1))\n",
    "    train_f1 = f1_score(y_train,np.argmax(gtgp.train_p,axis=1),average='macro')\n",
    "    test_f1 = f1_score(y_test,np.argmax(gtgp.test_p,axis=1),average='macro')\n",
    "\n",
    "\n",
    "    # with open('./benchmark/'+dataset+'.csv','a') as f:\n",
    "    #     s = str(train_acc)+\",\"+str(test_acc)+\",\"+str(train_f1)+\",\"+str(test_f1)+\",\"+str(num_trees)+\",\"+str(depth)+\",\"+str(num_nodes)+\"\\n\"\n",
    "    #     f.writelines(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f14a601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrain  1 :\n",
      "\ttrain: 0.7548661226141499 0.6274821919551506 \ttest: 0.7488748308312089 0.6214189032970736\n",
      "retrain  2 :\n",
      "\ttrain: 0.7618668645039455 0.6400869652166759 \ttest: 0.7529978283448211 0.6307157135406192\n",
      "retrain  3 :\n",
      "\ttrain: 0.764348823093006 0.6451088634314445 \ttest: 0.7550750637333585 0.6350920933811953\n",
      "retrain  4 :\n",
      "\ttrain: 0.7661023807917987 0.6485553497406842 \ttest: 0.7545400182544928 0.6352291517043385\n",
      "retrain  5 :\n",
      "\ttrain: 0.7671680043164497 0.6513021685292547 \ttest: 0.7551065369968212 0.6374691157705026\n",
      "retrain  6 :\n",
      "\ttrain: 0.768125716598098 0.6532198801134952 \ttest: 0.7554527428949108 0.6384632012484118\n",
      "retrain  7 :\n",
      "\ttrain: 0.7685978282862346 0.6545265911166034 \ttest: 0.7557674755295376 0.6392808930529283\n",
      "retrain  8 :\n",
      "\ttrain: 0.769150873406623 0.6557863315035366 \ttest: 0.7563025210084033 0.6401895625288861\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      7\u001b[0m gtgp\u001b[38;5;241m.\u001b[39mlam \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m----> 8\u001b[0m train_acc,test_acc,train_sse,test_sse \u001b[38;5;241m=\u001b[39m \u001b[43mgtgp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrain_estimators\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43mretrain_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretrain_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgammer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgammer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# verbose=0\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# gtgp.retrain_estimators(retrain_epoch=retrain_epoch,alpha=alpha,beta=beta,gammer=gammer,verbose=verbose)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zhouz\\OneDrive\\桌面\\Git\\GTGP\\test\\../script\\GTGP.py:124\u001b[0m, in \u001b[0;36mGTGP.retrain_estimators\u001b[1;34m(self, X_test, y_test, retrain_epoch, alpha, beta, gammer, verbose)\u001b[0m\n\u001b[0;32m    122\u001b[0m tree\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mlam \u001b[38;5;241m=\u001b[39m  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlam \u001b[38;5;241m+\u001b[39m beta \u001b[38;5;241m*\u001b[39m tree\u001b[38;5;241m.\u001b[39mnumNode \u001b[38;5;241m+\u001b[39m gammer \u001b[38;5;241m*\u001b[39m tree\u001b[38;5;241m.\u001b[39mdepth\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# t = time()\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_grads_bin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_one_hot\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;66;03m# print(\"grads\",time()-t)\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \n\u001b[0;32m    127\u001b[0m \u001b[38;5;66;03m# t = time()\u001b[39;00m\n\u001b[0;32m    128\u001b[0m log_odds,p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_log_p(grads,log_odds,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_rate)\n",
      "File \u001b[1;32mc:\\Users\\zhouz\\OneDrive\\桌面\\Git\\GTGP\\test\\../script\\Estimator.py:88\u001b[0m, in \u001b[0;36mEstimator_DC.set_grads_bin\u001b[1;34m(self, residual, p, alpha)\u001b[0m\n\u001b[0;32m     86\u001b[0m cover_bin \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mterminals:\n\u001b[1;32m---> 88\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[43mp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     89\u001b[0m     a \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmultiply(a,\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39ma)\n\u001b[0;32m     90\u001b[0m     c \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(a,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\zhouz\\anaconda3\\envs\\BStackGP\\Lib\\site-packages\\numpy\\matrixlib\\defmatrix.py:193\u001b[0m, in \u001b[0;36mmatrix.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 193\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndarray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zhouz\\anaconda3\\envs\\BStackGP\\Lib\\site-packages\\numpy\\matrixlib\\defmatrix.py:167\u001b[0m, in \u001b[0;36mmatrix.__array_finalize__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    162\u001b[0m     ret \u001b[38;5;241m=\u001b[39m N\u001b[38;5;241m.\u001b[39mndarray\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(subtype, shape, arr\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[0;32m    163\u001b[0m                             buffer\u001b[38;5;241m=\u001b[39marr,\n\u001b[0;32m    164\u001b[0m                             order\u001b[38;5;241m=\u001b[39morder)\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\n\u001b[1;32m--> 167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array_finalize__\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj):\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(obj, matrix) \u001b[38;5;129;01mand\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_getitem): \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "retrain_epoch=100\n",
    "alpha=1\n",
    "beta=1\n",
    "gammer=0\n",
    "\n",
    "verbose=1\n",
    "gtgp.lam = 10\n",
    "train_acc,test_acc,train_sse,test_sse = gtgp.retrain_estimators(X_test,y_test,retrain_epoch=retrain_epoch,alpha=alpha,beta=beta,gammer=gammer,verbose=verbose)\n",
    "\n",
    "\n",
    "# verbose=0\n",
    "# gtgp.retrain_estimators(retrain_epoch=retrain_epoch,alpha=alpha,beta=beta,gammer=gammer,verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac813a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------GTGP-------------\n",
      "Number of Trees: 15\n",
      "Number of nodes: 51\n"
     ]
    }
   ],
   "source": [
    "gtgp.print_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48eafb5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[( _add -> |11| |0| ),\n",
       " ( _minus -> |2| |6| ),\n",
       " ( _minus -> |3| |4| ),\n",
       " ( _divide -> |10| |2| ),\n",
       " ( _minus -> |6| |0| ),\n",
       " ( _multiply -> |5| |12| ),\n",
       " ( _divide -> |5| |10| ),\n",
       " ( _add -> |5| |10| ),\n",
       " ( _multiply -> |7| |10| ),\n",
       " ( _minus -> ( _add -> |1| |0| ) |6| ),\n",
       " ( _multiply -> |5| |4| ),\n",
       " ( _add -> |4| |5| ),\n",
       " ( _add -> |11| |4| ),\n",
       " ( _divide -> ( _add -> |12| |1| ) |2| ),\n",
       " ( _multiply -> |1| ( _minus -> |10| |5| ) )]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtgp.stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031fb085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   0.87500   0.93333         8\n",
      "           1    1.00000   0.66667   0.80000         3\n",
      "           2    0.86957   1.00000   0.93023        20\n",
      "           3    1.00000   1.00000   1.00000         4\n",
      "           4    1.00000   0.80000   0.88889         5\n",
      "\n",
      "    accuracy                        0.92500        40\n",
      "   macro avg    0.97391   0.86833   0.91049        40\n",
      "weighted avg    0.93478   0.92500   0.92289        40\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.67259   0.43087   0.52525      6408\n",
      "           1    0.19202   0.16311   0.17639      2716\n",
      "           2    0.68465   0.78335   0.73068     15809\n",
      "           3    0.70275   0.59723   0.64571      3250\n",
      "           4    0.34072   0.42813   0.37946      3590\n",
      "\n",
      "    accuracy                        0.60007     31773\n",
      "   macro avg    0.51855   0.48054   0.49150     31773\n",
      "weighted avg    0.60310   0.60007   0.59349     31773\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,np.argmax(gtgp.train_p,axis=1),digits=5))\n",
    "print(classification_report(y_test,np.argmax(gtgp.test_p,axis=1),digits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662e91a5",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ed15d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "661630ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size,stratify=y, random_state=seeds[i])\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(X_train,y_train)\n",
    "\n",
    "    num_trees = 1\n",
    "    depth = clf.tree_.max_depth\n",
    "    num_nodes = clf.tree_.node_count\n",
    "\n",
    "    train_acc = accuracy_score(y_train,clf.predict(X_train))\n",
    "    test_acc = accuracy_score(y_test,clf.predict(X_test))\n",
    "    train_f1 = f1_score(y_train,clf.predict(X_train),average='macro')\n",
    "    test_f1 = f1_score(y_test,clf.predict(X_test),average='macro')\n",
    "\n",
    "    with open('./benchmark_DC/'+dataset+'.csv','a') as f:\n",
    "        s = str(train_acc)+\",\"+str(test_acc)+\",\"+str(train_f1)+\",\"+str(test_f1)+\",\"+str(num_trees)+\",\"+str(depth)+\",\"+str(num_nodes)+\"\\n\"\n",
    "        f.writelines(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63afbae1",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28fa8541",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acfdd7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size,stratify=y, random_state=seeds[i])\n",
    "    # xgb = xgboost.XGBClassifier(min_child_weight=0,max_depth=3,n_estimators=100)\n",
    "    # xgb = xgboost.XGBClassifier(min_child_weight=0,max_depth=4)\n",
    "    xgb = xgboost.XGBClassifier()\n",
    "    xgb.fit(X_train,y_train)\n",
    "\n",
    "    import json\n",
    "\n",
    "    def item_generator(json_input, lookup_key):\n",
    "        if isinstance(json_input, dict):\n",
    "            for k, v in json_input.items():\n",
    "                if k == lookup_key:\n",
    "                    yield v\n",
    "                else:\n",
    "                    yield from item_generator(v, lookup_key)\n",
    "        elif isinstance(json_input, list):\n",
    "            for item in json_input:\n",
    "                yield from item_generator(item, lookup_key)\n",
    "\n",
    "    def tree_depth(json_text):\n",
    "        json_input = json.loads(json_text)\n",
    "        depths = list(item_generator(json_input, 'depth'))\n",
    "        return max(depths) + 1 if len(depths) != 0 else 1\n",
    "\n",
    "    train_acc = accuracy_score(y_train,xgb.predict(X_train))\n",
    "    test_acc = accuracy_score(y_test,xgb.predict(X_test))\n",
    "    train_f1 = f1_score(y_train,xgb.predict(X_train),average='macro')\n",
    "    test_f1 = f1_score(y_test,xgb.predict(X_test),average='macro')\n",
    "\n",
    "    booster = xgb.get_booster()\n",
    "\n",
    "    tree_df = booster.trees_to_dataframe()\n",
    "    depths = [tree_depth(x) for x in booster.get_dump(dump_format = \"json\")]\n",
    "    num_trees = len(depths)\n",
    "    depth = np.average(depths)\n",
    "    num_nodes = len(tree_df)\n",
    "\n",
    "    with open('./benchmark_xgb/'+dataset+'.csv','a') as f:\n",
    "        s = str(train_acc)+\",\"+str(test_acc)+\",\"+str(train_f1)+\",\"+str(test_f1)+\",\"+str(num_trees)+\",\"+str(depth)+\",\"+str(num_nodes)+\"\\n\"\n",
    "        f.writelines(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc363f99",
   "metadata": {},
   "source": [
    "# GDBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e6d3435",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef69c1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size,stratify=y, random_state=seeds[i])\n",
    "    clf = GradientBoostingClassifier()\n",
    "    # clf = GradientBoostingClassifier()\n",
    "    clf.fit(X_train,y_train)\n",
    "\n",
    "    train_acc = accuracy_score(y_train,clf.predict(X_train))\n",
    "    test_acc = accuracy_score(y_test,clf.predict(X_test))\n",
    "    train_f1 = f1_score(y_train,clf.predict(X_train),average='macro')\n",
    "    test_f1 = f1_score(y_test,clf.predict(X_test),average='macro')\n",
    "\n",
    "    num_trees = len([ est for ests in clf.estimators_ for est in ests])\n",
    "    depth = np.average([ max(1,est.tree_.max_depth) for ests in clf.estimators_ for est in ests])\n",
    "    num_nodes = sum([ est.tree_.node_count for ests in clf.estimators_ for est in ests])\n",
    "\n",
    "    with open('./benchmark_GBDT/'+dataset+'.csv','a') as f:\n",
    "        s = str(train_acc)+\",\"+str(test_acc)+\",\"+str(train_f1)+\",\"+str(test_f1)+\",\"+str(num_trees)+\",\"+str(depth)+\",\"+str(num_nodes)+\"\\n\"\n",
    "        f.writelines(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0ef54f",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8623bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3edfc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size,stratify=y, random_state=seeds[i])\n",
    "    rfc = RandomForestClassifier()\n",
    "    rfc.fit(X_train,y_train)\n",
    "\n",
    "    train_acc = accuracy_score(y_train,rfc.predict(X_train))\n",
    "    test_acc = accuracy_score(y_test,rfc.predict(X_test))\n",
    "    train_f1 = f1_score(y_train,rfc.predict(X_train),average='macro')\n",
    "    test_f1 = f1_score(y_test,rfc.predict(X_test),average='macro')\n",
    "\n",
    "    num_trees = len(rfc.estimators_)\n",
    "    depth = np.average([est.tree_.max_depth for est in rfc.estimators_])\n",
    "    num_nodes = sum([est.tree_.node_count for est in rfc.estimators_])\n",
    "\n",
    "    with open('./benchmark_RF/'+dataset+'.csv','a') as f:\n",
    "        s = str(train_acc)+\",\"+str(test_acc)+\",\"+str(train_f1)+\",\"+str(test_f1)+\",\"+str(num_trees)+\",\"+str(depth)+\",\"+str(num_nodes)+\"\\n\"\n",
    "        f.writelines(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49b66a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb3fc4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BStackGP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc-autonumbering": true,
  "toc-showcode": true,
  "toc-showmarkdowntxt": true,
  "vscode": {
   "interpreter": {
    "hash": "598cefc26d6e5a65b2978c65314d0610ea9dfe34c7d989c4b6d2528d500ccb7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
