{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a8bc990-ebc5-46bd-bab4-f4091ce5b834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../script/\")\n",
    "\n",
    "import Functions\n",
    "from Engine import Engine\n",
    "from GTGP import GTGP\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report,accuracy_score,confusion_matrix,f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import importlib\n",
    "from time import time\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbad47da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.utils import shuffle\n",
    "def plot_roc_curve(true_y, y_prob):\n",
    "    \"\"\"\n",
    "    plots the roc curve based of the probabilities\n",
    "    \"\"\"\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(true_y, y_prob)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    print(roc_auc_score(true_y,prob[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c114de92",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "feedaa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/haberman.tsv\",delimiter='\\t')\n",
    "X = df.iloc[:,:-1].to_numpy().astype(\"float\")\n",
    "y = df.iloc[:,-1].to_numpy().astype(\"int\")\n",
    "\n",
    "y[y==1] = 0\n",
    "y[y==2] = 1\n",
    "\n",
    "seeds = [10086, 200,500,30506,30405,30420,10056,7059,40965,5398,869543,83491,823190,\n",
    "         48392,2810,48392,3498210,483902,859032,12890,538920,86954,54309,6504,9840,\n",
    "         219805,548,2981,432890,5438908,219094,5843902,60854,979,12890,2108,4093]\n",
    "train_size = 0.7\n",
    "dataset = 'haberman'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64d04633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    225\n",
       "1     81\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a2341bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(y,yt):\n",
    "    le = LabelEncoder()\n",
    "    ohe = OneHotEncoder()\n",
    "    y_train = le.fit_transform(y)\n",
    "    y_one_hot = ohe.fit_transform(y_train.reshape(-1,1))\n",
    "    \n",
    "    y_test = le.transform(yt)\n",
    "    yt_one_hot = ohe.transform(y_test.reshape(-1,1))\n",
    "    \n",
    "    return y_train,y_test,y_one_hot,yt_one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdd30c5",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f418f618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 21 1\n",
      "10 30 2\n",
      "12 36 3\n",
      "13 39 4\n",
      "15 45 5\n",
      "16 48 6\n",
      "17 51 7\n",
      "17 51 8\n",
      "17 51 9\n",
      "17 51 10\n",
      "17 51 11\n",
      "17 51 12\n",
      "17 51 13\n",
      "17 51 14\n",
      "17 51 15\n",
      "17 51 16\n",
      "17 51 17\n",
      "17 51 18\n",
      "17 51 19\n",
      "17 51 20\n",
      "17 51 21\n",
      "17 51 22\n",
      "17 51 23\n",
      "17 51 24\n",
      "17 51 25\n",
      "17 51 26\n",
      "17 51 27\n",
      "17 51 28\n",
      "17 51 29\n",
      "17 51 30\n",
      "17 51 31\n",
      "17 51 32\n",
      "17 51 33\n",
      "17 51 34\n",
      "17 51 35\n",
      "17 51 36\n",
      "17 51 37\n",
      "17 51 38\n",
      "17 51 39\n",
      "17 51 40\n",
      "17 51 41\n",
      "17 51 42\n",
      "17 51 43\n",
      "17 51 44\n",
      "17 51 45\n",
      "17 51 46\n",
      "17 51 47\n",
      "17 51 48\n",
      "17 51 49\n",
      "17 51 50\n",
      "17 51 51\n",
      "17 51 52\n",
      "17 51 53\n",
      "17 51 54\n",
      "17 51 55\n",
      "17 51 56\n",
      "17 51 57\n",
      "17 51 58\n",
      "17 51 59\n",
      "17 51 60\n",
      "17 51 61\n",
      "17 51 62\n",
      "17 51 63\n",
      "17 51 64\n",
      "17 51 65\n",
      "17 51 66\n",
      "17 51 67\n",
      "17 51 68\n",
      "17 51 69\n",
      "17 51 70\n",
      "17 51 71\n",
      "17 51 72\n",
      "17 51 73\n",
      "17 51 74\n",
      "17 51 75\n",
      "17 51 76\n",
      "17 51 77\n",
      "17 51 78\n",
      "17 51 79\n",
      "17 51 80\n",
      "17 51 81\n",
      "17 51 82\n",
      "17 51 83\n",
      "17 51 84\n",
      "17 51 85\n",
      "17 51 86\n",
      "17 51 87\n",
      "17 51 88\n",
      "17 51 89\n",
      "17 51 90\n",
      "17 51 91\n",
      "17 51 92\n",
      "17 51 93\n",
      "17 51 94\n",
      "17 51 95\n",
      "17 51 96\n",
      "17 51 97\n",
      "17 51 98\n",
      "17 51 99\n",
      "17 51 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.7336448598130841 77.42450541112657 \ttest: 0.7391304347826086 33.082590289709465\n",
      "retrain  2 :\n",
      "\ttrain: 0.7336448598130841 74.2645811368357 \ttest: 0.7391304347826086 31.887017009623428\n",
      "retrain  3 :\n",
      "\ttrain: 0.7336448598130841 72.55778704294832 \ttest: 0.7391304347826086 31.267468537764394\n",
      "retrain  4 :\n",
      "\ttrain: 0.7336448598130841 71.53414423391365 \ttest: 0.7391304347826086 30.923794452927407\n",
      "retrain  5 :\n",
      "\ttrain: 0.7336448598130841 70.84087588196624 \ttest: 0.7391304347826086 30.71887000044517\n",
      "retrain  6 :\n",
      "\ttrain: 0.7476635514018691 70.31801845023278 \ttest: 0.7608695652173914 30.589425194208275\n",
      "retrain  7 :\n",
      "\ttrain: 0.7476635514018691 69.89173561926003 \ttest: 0.7608695652173914 30.504777070758603\n",
      "retrain  8 :\n",
      "\ttrain: 0.7476635514018691 69.52656238839619 \ttest: 0.7608695652173914 30.44885566251797\n",
      "retrain  9 :\n",
      "\ttrain: 0.7616822429906542 69.20436718962418 \ttest: 0.75 30.412457712261226\n",
      "retrain  10 :\n",
      "\ttrain: 0.7616822429906542 68.91505296091204 \ttest: 0.75 30.389845806203823\n",
      "retrain  11 :\n",
      "\ttrain: 0.7663551401869159 68.65239753653674 \ttest: 0.7934782608695652 30.377192097902434\n",
      "retrain  12 :\n",
      "\ttrain: 0.7663551401869159 68.41215994652057 \ttest: 0.7934782608695652 30.371819277919506\n",
      "retrain  13 :\n",
      "\ttrain: 0.7663551401869159 68.19119650274382 \ttest: 0.7934782608695652 30.37179838754767\n",
      "retrain  14 :\n",
      "\ttrain: 0.7663551401869159 67.98703255504644 \ttest: 0.7934782608695652 30.37571533080093\n",
      "retrain  15 :\n",
      "\ttrain: 0.7663551401869159 67.79764310240584 \ttest: 0.7934782608695652 30.382523410728567\n",
      "retrain  16 :\n",
      "\ttrain: 0.7663551401869159 67.62133131038081 \ttest: 0.7934782608695652 30.391443887527767\n",
      "retrain  17 :\n",
      "\ttrain: 0.7663551401869159 67.45665458122704 \ttest: 0.7934782608695652 30.401895885705\n",
      "retrain  18 :\n",
      "\ttrain: 0.7663551401869159 67.30237503343126 \ttest: 0.7934782608695652 30.413445642770824\n",
      "retrain  19 :\n",
      "\ttrain: 0.7663551401869159 67.15742353506067 \ttest: 0.7934782608695652 30.425769201188015\n",
      "retrain  20 :\n",
      "\ttrain: 0.7663551401869159 67.02087201841907 \ttest: 0.7934782608695652 30.438624757069597\n",
      "retrain  21 :\n",
      "\ttrain: 0.7663551401869159 66.89191136539108 \ttest: 0.7934782608695652 30.45183207495235\n",
      "retrain  22 :\n",
      "\ttrain: 0.7663551401869159 66.76983335072865 \ttest: 0.7934782608695652 30.465257122823115\n",
      "retrain  23 :\n",
      "\ttrain: 0.7663551401869159 66.65401571082131 \ttest: 0.7934782608695652 30.478800582074143\n",
      "retrain  24 :\n",
      "\ttrain: 0.7663551401869159 66.54390970412072 \ttest: 0.7934782608695652 30.492389240635955\n",
      "retrain  25 :\n",
      "\ttrain: 0.7663551401869159 66.43902969727614 \ttest: 0.7934782608695652 30.50596953447497\n",
      "retrain  26 :\n",
      "\ttrain: 0.7663551401869159 66.3389444159425 \ttest: 0.7934782608695652 30.519502691947956\n",
      "retrain  27 :\n",
      "\ttrain: 0.7663551401869159 66.24326957170321 \ttest: 0.7934782608695652 30.532961075758493\n",
      "retrain  28 :\n",
      "\ttrain: 0.7663551401869159 66.15166163061718 \ttest: 0.7934782608695652 30.546325421322106\n",
      "retrain  29 :\n",
      "\ttrain: 0.7663551401869159 66.06381253123595 \ttest: 0.7934782608695652 30.559582747538343\n",
      "retrain  30 :\n",
      "\ttrain: 0.7663551401869159 65.97944519398104 \ttest: 0.7934782608695652 30.572724773190714\n",
      "retrain  31 :\n",
      "\ttrain: 0.7663551401869159 65.89830969150566 \ttest: 0.7934782608695652 30.58574671459781\n",
      "retrain  32 :\n",
      "\ttrain: 0.7663551401869159 65.82017997238411 \ttest: 0.7934782608695652 30.598646371563106\n",
      "retrain  33 :\n",
      "\ttrain: 0.7663551401869159 65.7448510491211 \ttest: 0.7934782608695652 30.61142343197771\n",
      "retrain  34 :\n",
      "\ttrain: 0.7663551401869159 65.67213657679261 \ttest: 0.7934782608695652 30.624078942739235\n",
      "retrain  35 :\n",
      "\ttrain: 0.7663551401869159 65.60186676121465 \ttest: 0.7934782608695652 30.636614907531808\n",
      "retrain  36 :\n",
      "\ttrain: 0.7663551401869159 65.53388654588029 \ttest: 0.7934782608695652 30.64903398162136\n",
      "retrain  37 :\n",
      "\ttrain: 0.7663551401869159 65.46805403541114 \ttest: 0.7934782608695652 30.66133924101066\n",
      "retrain  38 :\n",
      "\ttrain: 0.7663551401869159 65.40423912027194 \ttest: 0.7934782608695652 30.673534008696084\n",
      "retrain  39 :\n",
      "\ttrain: 0.7663551401869159 65.34232227326821 \ttest: 0.7934782608695652 30.685621724833588\n",
      "retrain  40 :\n",
      "\ttrain: 0.7663551401869159 65.28219349311091 \ttest: 0.7934782608695652 30.69760585069638\n",
      "retrain  41 :\n",
      "\ttrain: 0.7663551401869159 65.22375137427314 \ttest: 0.7934782608695652 30.709489798639996\n",
      "retrain  42 :\n",
      "\ttrain: 0.7663551401869159 65.16690228562841 \ttest: 0.7934782608695652 30.721276882068874\n",
      "retrain  43 :\n",
      "\ttrain: 0.7663551401869159 65.11155964307238 \ttest: 0.7934782608695652 30.732970280758753\n",
      "retrain  44 :\n",
      "\ttrain: 0.7663551401869159 65.05764326358666 \ttest: 0.7934782608695652 30.744573017933458\n",
      "retrain  45 :\n",
      "\ttrain: 0.7663551401869159 65.00507879008653 \ttest: 0.7934782608695652 30.756087946299427\n",
      "retrain  46 :\n",
      "\ttrain: 0.7663551401869159 64.9537971779697 \ttest: 0.7934782608695652 30.767517740863717\n",
      "retrain  47 :\n",
      "\ttrain: 0.7663551401869159 64.90373423560314 \ttest: 0.7934782608695652 30.778864896843743\n",
      "retrain  48 :\n",
      "\ttrain: 0.7663551401869159 64.85483021209555 \ttest: 0.7934782608695652 30.790131731352574\n",
      "retrain  49 :\n",
      "\ttrain: 0.7663551401869159 64.80702942663811 \ttest: 0.7934782608695652 30.801320387836554\n",
      "retrain  50 :\n",
      "\ttrain: 0.7663551401869159 64.76027993448602 \ttest: 0.7934782608695652 30.8124328424709\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.80925   0.89172   0.84848       157\n",
      "           1    0.58537   0.42105   0.48980        57\n",
      "\n",
      "    accuracy                        0.76636       214\n",
      "   macro avg    0.69731   0.65639   0.66914       214\n",
      "weighted avg    0.74962   0.76636   0.75295       214\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.81013   0.94118   0.87075        68\n",
      "           1    0.69231   0.37500   0.48649        24\n",
      "\n",
      "    accuracy                        0.79348        92\n",
      "   macro avg    0.75122   0.65809   0.67862        92\n",
      "weighted avg    0.77939   0.79348   0.77051        92\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 17\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 51\n",
      "7 21 1\n",
      "12 36 2\n",
      "14 42 3\n",
      "14 42 4\n",
      "14 42 5\n",
      "15 45 6\n",
      "15 45 7\n",
      "16 48 8\n",
      "16 48 9\n",
      "16 48 10\n",
      "16 48 11\n",
      "16 48 12\n",
      "16 48 13\n",
      "16 48 14\n",
      "16 48 15\n",
      "16 48 16\n",
      "16 48 17\n",
      "16 48 18\n",
      "16 48 19\n",
      "16 48 20\n",
      "16 48 21\n",
      "16 48 22\n",
      "16 48 23\n",
      "16 48 24\n",
      "16 48 25\n",
      "16 48 26\n",
      "16 48 27\n",
      "16 48 28\n",
      "16 48 29\n",
      "16 48 30\n",
      "16 48 31\n",
      "16 48 32\n",
      "16 48 33\n",
      "16 48 34\n",
      "16 48 35\n",
      "16 48 36\n",
      "16 48 37\n",
      "16 48 38\n",
      "16 48 39\n",
      "16 48 40\n",
      "16 48 41\n",
      "16 48 42\n",
      "16 48 43\n",
      "16 48 44\n",
      "16 48 45\n",
      "16 48 46\n",
      "16 48 47\n",
      "16 48 48\n",
      "16 48 49\n",
      "16 48 50\n",
      "16 48 51\n",
      "16 48 52\n",
      "16 48 53\n",
      "16 48 54\n",
      "16 48 55\n",
      "16 48 56\n",
      "16 48 57\n",
      "16 48 58\n",
      "16 48 59\n",
      "16 48 60\n",
      "16 48 61\n",
      "16 48 62\n",
      "16 48 63\n",
      "16 48 64\n",
      "16 48 65\n",
      "16 48 66\n",
      "16 48 67\n",
      "16 48 68\n",
      "16 48 69\n",
      "16 48 70\n",
      "16 48 71\n",
      "16 48 72\n",
      "16 48 73\n",
      "16 48 74\n",
      "16 48 75\n",
      "16 48 76\n",
      "16 48 77\n",
      "16 48 78\n",
      "16 48 79\n",
      "16 48 80\n",
      "16 48 81\n",
      "16 48 82\n",
      "16 48 83\n",
      "16 48 84\n",
      "16 48 85\n",
      "16 48 86\n",
      "16 48 87\n",
      "16 48 88\n",
      "16 48 89\n",
      "16 48 90\n",
      "16 48 91\n",
      "16 48 92\n",
      "16 48 93\n",
      "16 48 94\n",
      "16 48 95\n",
      "16 48 96\n",
      "16 48 97\n",
      "16 48 98\n",
      "16 48 99\n",
      "16 48 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.7336448598130841 77.50495581062219 \ttest: 0.7391304347826086 32.95555003090986\n",
      "retrain  2 :\n",
      "\ttrain: 0.7336448598130841 74.2651331231683 \ttest: 0.7391304347826086 31.603563441821983\n",
      "retrain  3 :\n",
      "\ttrain: 0.7336448598130841 72.46613124393578 \ttest: 0.7391304347826086 30.851680306652256\n",
      "retrain  4 :\n",
      "\ttrain: 0.7336448598130841 71.37613253359584 \ttest: 0.7391304347826086 30.409392307681763\n",
      "retrain  5 :\n",
      "\ttrain: 0.7429906542056075 70.64272040836912 \ttest: 0.75 30.1322167933709\n",
      "retrain  6 :\n",
      "\ttrain: 0.7616822429906542 70.09865685823654 \ttest: 0.782608695652174 29.947727000865253\n",
      "retrain  7 :\n",
      "\ttrain: 0.7616822429906542 69.66353667018583 \ttest: 0.782608695652174 29.818407101777133\n",
      "retrain  8 :\n",
      "\ttrain: 0.7710280373831776 69.29738495657398 \ttest: 0.782608695652174 29.723859629223067\n",
      "retrain  9 :\n",
      "\ttrain: 0.7710280373831776 68.97926066000139 \ttest: 0.782608695652174 29.65235668620955\n",
      "retrain  10 :\n",
      "\ttrain: 0.7710280373831776 68.6973886585058 \ttest: 0.782608695652174 29.596764700701584\n",
      "retrain  11 :\n",
      "\ttrain: 0.7710280373831776 68.44455912440438 \ttest: 0.782608695652174 29.552517239465466\n",
      "retrain  12 :\n",
      "\ttrain: 0.7710280373831776 68.21594628855671 \ttest: 0.782608695652174 29.516563870988215\n",
      "retrain  13 :\n",
      "\ttrain: 0.7710280373831776 68.00805073715571 \ttest: 0.782608695652174 29.486797600596596\n",
      "retrain  14 :\n",
      "\ttrain: 0.7710280373831776 67.81817047661093 \ttest: 0.782608695652174 29.461725843283524\n",
      "retrain  15 :\n",
      "\ttrain: 0.7757009345794392 67.64412479550892 \ttest: 0.782608695652174 29.440271018505637\n",
      "retrain  16 :\n",
      "\ttrain: 0.7757009345794392 67.4841014382124 \ttest: 0.782608695652174 29.42164372396818\n",
      "retrain  17 :\n",
      "\ttrain: 0.7757009345794392 67.33656563608976 \ttest: 0.782608695652174 29.40525875739683\n",
      "retrain  18 :\n",
      "\ttrain: 0.7757009345794392 67.20020144102372 \ttest: 0.782608695652174 29.39067774508657\n",
      "retrain  19 :\n",
      "\ttrain: 0.7757009345794392 67.07387089211451 \ttest: 0.782608695652174 29.37756903611435\n",
      "retrain  20 :\n",
      "\ttrain: 0.7757009345794392 66.95658374480968 \ttest: 0.782608695652174 29.36567920396857\n",
      "retrain  21 :\n",
      "\ttrain: 0.7757009345794392 66.84747396444827 \ttest: 0.782608695652174 29.354812561692896\n",
      "retrain  22 :\n",
      "\ttrain: 0.7757009345794392 66.74578088889587 \ttest: 0.782608695652174 29.34481631547117\n",
      "retrain  23 :\n",
      "\ttrain: 0.7663551401869159 66.65083382106532 \ttest: 0.782608695652174 29.335569738181263\n",
      "retrain  24 :\n",
      "\ttrain: 0.7663551401869159 66.56203925951155 \ttest: 0.782608695652174 29.32697623517082\n",
      "retrain  25 :\n",
      "\ttrain: 0.7663551401869159 66.4788702223087 \ttest: 0.782608695652174 29.31895750416664\n",
      "retrain  26 :\n",
      "\ttrain: 0.7616822429906542 66.40085726570544 \ttest: 0.782608695652174 29.311449218550965\n",
      "retrain  27 :\n",
      "\ttrain: 0.7616822429906542 66.3275808926642 \ttest: 0.782608695652174 29.304397822899908\n",
      "retrain  28 :\n",
      "\ttrain: 0.7616822429906542 66.25866511084703 \ttest: 0.782608695652174 29.297758143222033\n",
      "retrain  29 :\n",
      "\ttrain: 0.7616822429906542 66.19377194673528 \ttest: 0.782608695652174 29.291491595749054\n",
      "retrain  30 :\n",
      "\ttrain: 0.7616822429906542 66.13259675855264 \ttest: 0.782608695652174 29.285564836826374\n",
      "retrain  31 :\n",
      "\ttrain: 0.7616822429906542 66.07486421893697 \ttest: 0.782608695652174 29.279948738926098\n",
      "retrain  32 :\n",
      "\ttrain: 0.7616822429906542 66.02032486093705 \ttest: 0.782608695652174 29.274617608625018\n",
      "retrain  33 :\n",
      "\ttrain: 0.7616822429906542 65.96875209922729 \ttest: 0.782608695652174 29.269548584801328\n",
      "retrain  34 :\n",
      "\ttrain: 0.7616822429906542 65.91993965336421 \ttest: 0.782608695652174 29.26472117163227\n",
      "retrain  35 :\n",
      "\ttrain: 0.7616822429906542 65.8736993121397 \ttest: 0.782608695652174 29.26011687289357\n",
      "retrain  36 :\n",
      "\ttrain: 0.7616822429906542 65.82985898813831 \ttest: 0.782608695652174 29.255718902778877\n",
      "retrain  37 :\n",
      "\ttrain: 0.7663551401869159 65.78826101989131 \ttest: 0.782608695652174 29.25151195484663\n",
      "retrain  38 :\n",
      "\ttrain: 0.7663551401869159 65.74876068586777 \ttest: 0.782608695652174 29.247482015395114\n",
      "retrain  39 :\n",
      "\ttrain: 0.7663551401869159 65.71122490021163 \ttest: 0.782608695652174 29.243616211023557\n",
      "retrain  40 :\n",
      "\ttrain: 0.7663551401869159 65.67553106484206 \ttest: 0.782608695652174 29.23990268268954\n",
      "retrain  41 :\n",
      "\ttrain: 0.7663551401869159 65.64156605644884 \ttest: 0.782608695652174 29.236330480463796\n",
      "retrain  42 :\n",
      "\ttrain: 0.7663551401869159 65.60922533018073 \ttest: 0.782608695652174 29.232889474588266\n",
      "retrain  43 :\n",
      "\ttrain: 0.7663551401869159 65.57841212455267 \ttest: 0.782608695652174 29.22957027949068\n",
      "retrain  44 :\n",
      "\ttrain: 0.7663551401869159 65.54903675438455 \ttest: 0.782608695652174 29.22636418819244\n",
      "retrain  45 :\n",
      "\ttrain: 0.7663551401869159 65.52101598050245 \ttest: 0.782608695652174 29.223263115135335\n",
      "retrain  46 :\n",
      "\ttrain: 0.7663551401869159 65.49427244654993 \ttest: 0.782608695652174 29.220259545896145\n",
      "retrain  47 :\n",
      "\ttrain: 0.7663551401869159 65.46873417461822 \ttest: 0.782608695652174 29.21734649259477\n",
      "retrain  48 :\n",
      "\ttrain: 0.7663551401869159 65.44433411255771 \ttest: 0.782608695652174 29.214517454056715\n",
      "retrain  49 :\n",
      "\ttrain: 0.7663551401869159 65.42100972680885 \ttest: 0.782608695652174 29.211766379986425\n",
      "retrain  50 :\n",
      "\ttrain: 0.7663551401869159 65.39870263542133 \ttest: 0.782608695652174 29.20908763855808\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.79888   0.91083   0.85119       157\n",
      "           1    0.60000   0.36842   0.45652        57\n",
      "\n",
      "    accuracy                        0.76636       214\n",
      "   macro avg    0.69944   0.63962   0.65386       214\n",
      "weighted avg    0.74591   0.76636   0.74607       214\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.78571   0.97059   0.86842        68\n",
      "           1    0.75000   0.25000   0.37500        24\n",
      "\n",
      "    accuracy                        0.78261        92\n",
      "   macro avg    0.76786   0.61029   0.62171        92\n",
      "weighted avg    0.77640   0.78261   0.73970        92\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 16\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 48\n",
      "8 24 1\n",
      "11 33 2\n",
      "13 39 3\n",
      "14 42 4\n",
      "14 42 5\n",
      "14 42 6\n",
      "14 42 7\n",
      "14 42 8\n",
      "14 42 9\n",
      "15 45 10\n",
      "15 45 11\n",
      "15 45 12\n",
      "15 45 13\n",
      "15 45 14\n",
      "15 45 15\n",
      "15 45 16\n",
      "15 45 17\n",
      "15 45 18\n",
      "15 45 19\n",
      "15 45 20\n",
      "15 45 21\n",
      "15 45 22\n",
      "15 45 23\n",
      "15 45 24\n",
      "15 45 25\n",
      "15 45 26\n",
      "15 45 27\n",
      "15 45 28\n",
      "15 45 29\n",
      "15 45 30\n",
      "15 45 31\n",
      "15 45 32\n",
      "15 45 33\n",
      "15 45 34\n",
      "15 45 35\n",
      "15 45 36\n",
      "15 45 37\n",
      "15 45 38\n",
      "15 45 39\n",
      "15 45 40\n",
      "15 45 41\n",
      "15 45 42\n",
      "15 45 43\n",
      "15 45 44\n",
      "15 45 45\n",
      "15 45 46\n",
      "15 45 47\n",
      "15 45 48\n",
      "15 45 49\n",
      "15 45 50\n",
      "15 45 51\n",
      "15 45 52\n",
      "15 45 53\n",
      "15 45 54\n",
      "15 45 55\n",
      "15 45 56\n",
      "15 45 57\n",
      "15 45 58\n",
      "15 45 59\n",
      "15 45 60\n",
      "15 45 61\n",
      "15 45 62\n",
      "15 45 63\n",
      "15 45 64\n",
      "15 45 65\n",
      "15 45 66\n",
      "15 45 67\n",
      "15 45 68\n",
      "15 45 69\n",
      "15 45 70\n",
      "15 45 71\n",
      "15 45 72\n",
      "15 45 73\n",
      "15 45 74\n",
      "15 45 75\n",
      "15 45 76\n",
      "15 45 77\n",
      "15 45 78\n",
      "15 45 79\n",
      "15 45 80\n",
      "15 45 81\n",
      "15 45 82\n",
      "15 45 83\n",
      "15 45 84\n",
      "15 45 85\n",
      "15 45 86\n",
      "15 45 87\n",
      "15 45 88\n",
      "15 45 89\n",
      "15 45 90\n",
      "15 45 91\n",
      "15 45 92\n",
      "15 45 93\n",
      "15 45 94\n",
      "15 45 95\n",
      "15 45 96\n",
      "15 45 97\n",
      "15 45 98\n",
      "15 45 99\n",
      "15 45 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.7336448598130841 78.07448012822132 \ttest: 0.7391304347826086 32.955215782318575\n",
      "retrain  2 :\n",
      "\ttrain: 0.7336448598130841 74.8486441489932 \ttest: 0.7391304347826086 31.524757395873984\n",
      "retrain  3 :\n",
      "\ttrain: 0.7336448598130841 72.92411236729122 \ttest: 0.7391304347826086 30.717345607029706\n",
      "retrain  4 :\n",
      "\ttrain: 0.7336448598130841 71.71058910518414 \ttest: 0.7391304347826086 30.259916445582746\n",
      "retrain  5 :\n",
      "\ttrain: 0.7429906542056075 70.88863563284643 \ttest: 0.7717391304347826 30.000437114657906\n",
      "retrain  6 :\n",
      "\ttrain: 0.7429906542056075 70.28925909021999 \ttest: 0.7717391304347826 29.85525427881026\n",
      "retrain  7 :\n",
      "\ttrain: 0.7897196261682243 69.8226639155713 \ttest: 0.7608695652173914 29.777869925235347\n",
      "retrain  8 :\n",
      "\ttrain: 0.7897196261682243 69.44009261696064 \ttest: 0.7608695652173914 29.741829705225072\n",
      "retrain  9 :\n",
      "\ttrain: 0.7897196261682243 69.11417416006292 \ttest: 0.7608695652173914 29.73162686001923\n",
      "retrain  10 :\n",
      "\ttrain: 0.7897196261682243 68.82888381340382 \ttest: 0.7608695652173914 29.73787640671793\n",
      "retrain  11 :\n",
      "\ttrain: 0.7897196261682243 68.57437364249171 \ttest: 0.7608695652173914 29.754719581661398\n",
      "retrain  12 :\n",
      "\ttrain: 0.7897196261682243 68.34426733310852 \ttest: 0.7608695652173914 29.778395716989046\n",
      "retrain  13 :\n",
      "\ttrain: 0.7897196261682243 68.13421369571844 \ttest: 0.7608695652173914 29.806433889011117\n",
      "retrain  14 :\n",
      "\ttrain: 0.7897196261682243 67.94109289710103 \ttest: 0.7391304347826086 29.83718067885259\n",
      "retrain  15 :\n",
      "\ttrain: 0.7897196261682243 67.762567614592 \ttest: 0.7391304347826086 29.869515071557608\n",
      "retrain  16 :\n",
      "\ttrain: 0.7897196261682243 67.59682049273582 \ttest: 0.7282608695652174 29.90267071392304\n",
      "retrain  17 :\n",
      "\ttrain: 0.7990654205607477 67.44239478162686 \ttest: 0.7282608695652174 29.936121773921343\n",
      "retrain  18 :\n",
      "\ttrain: 0.7990654205607477 67.29809376995905 \ttest: 0.7282608695652174 29.969507730002555\n",
      "retrain  19 :\n",
      "\ttrain: 0.7990654205607477 67.16291479848687 \ttest: 0.7282608695652174 30.002582747883686\n",
      "retrain  20 :\n",
      "\ttrain: 0.7990654205607477 67.0360043198425 \ttest: 0.7282608695652174 30.035181033922683\n",
      "retrain  21 :\n",
      "\ttrain: 0.7990654205607477 66.91662622987033 \ttest: 0.7282608695652174 30.06719282583271\n",
      "retrain  22 :\n",
      "\ttrain: 0.7990654205607477 66.80413886662427 \ttest: 0.7282608695652174 30.098547607777853\n",
      "retrain  23 :\n",
      "\ttrain: 0.7990654205607477 66.69797786114492 \ttest: 0.7282608695652174 30.12920230820631\n",
      "retrain  24 :\n",
      "\ttrain: 0.7990654205607477 66.59764305972931 \ttest: 0.7282608695652174 30.15913297397\n",
      "retrain  25 :\n",
      "\ttrain: 0.7990654205607477 66.50268835517917 \ttest: 0.7282608695652174 30.18832888951102\n",
      "retrain  26 :\n",
      "\ttrain: 0.7990654205607477 66.41271364469567 \ttest: 0.7282608695652174 30.216788425109172\n",
      "retrain  27 :\n",
      "\ttrain: 0.7990654205607477 66.32735837351609 \ttest: 0.7282608695652174 30.244516111790986\n",
      "retrain  28 :\n",
      "\ttrain: 0.7990654205607477 66.24629628140599 \ttest: 0.7282608695652174 30.27152058773875\n",
      "retrain  29 :\n",
      "\ttrain: 0.7990654205607477 66.16923107545252 \ttest: 0.7282608695652174 30.297813163857406\n",
      "retrain  30 :\n",
      "\ttrain: 0.7990654205607477 66.09589282594118 \ttest: 0.7282608695652174 30.323406828648917\n",
      "retrain  31 :\n",
      "\ttrain: 0.7990654205607477 66.02603493375624 \ttest: 0.7282608695652174 30.348315564004345\n",
      "retrain  32 :\n",
      "\ttrain: 0.7990654205607477 65.95943155479266 \ttest: 0.7282608695652174 30.37255388022468\n",
      "retrain  33 :\n",
      "\ttrain: 0.7990654205607477 65.89587539384121 \ttest: 0.7282608695652174 30.39613650483508\n",
      "retrain  34 :\n",
      "\ttrain: 0.7990654205607477 65.83517580030176 \ttest: 0.7282608695652174 30.419078178569343\n",
      "retrain  35 :\n",
      "\ttrain: 0.7990654205607477 65.77715711291705 \ttest: 0.7282608695652174 30.44139352539056\n",
      "retrain  36 :\n",
      "\ttrain: 0.7990654205607477 65.72165721189657 \ttest: 0.7282608695652174 30.463096973085065\n",
      "retrain  37 :\n",
      "\ttrain: 0.7990654205607477 65.66852624529498 \ttest: 0.7282608695652174 30.48420270789384\n",
      "retrain  38 :\n",
      "\ttrain: 0.7990654205607477 65.61762550302672 \ttest: 0.7282608695652174 30.504724651599794\n",
      "retrain  39 :\n",
      "\ttrain: 0.7990654205607477 65.56882641693316 \ttest: 0.7282608695652174 30.524676453023474\n",
      "retrain  40 :\n",
      "\ttrain: 0.7990654205607477 65.52200966924754 \ttest: 0.7282608695652174 30.544071488393836\n",
      "retrain  41 :\n",
      "\ttrain: 0.7990654205607477 65.47706439488731 \ttest: 0.7282608695652174 30.56292286684078\n",
      "retrain  42 :\n",
      "\ttrain: 0.7990654205607477 65.43388746544915 \ttest: 0.7282608695652174 30.581243438510597\n",
      "retrain  43 :\n",
      "\ttrain: 0.7990654205607477 65.3923828447351 \ttest: 0.7282608695652174 30.59904580368282\n",
      "retrain  44 :\n",
      "\ttrain: 0.7990654205607477 65.35246100721079 \ttest: 0.7282608695652174 30.61634232187559\n",
      "retrain  45 :\n",
      "\ttrain: 0.7990654205607477 65.31403841207398 \ttest: 0.7282608695652174 30.633145120343734\n",
      "retrain  46 :\n",
      "\ttrain: 0.7990654205607477 65.2770370266573 \ttest: 0.7282608695652174 30.649466101655104\n",
      "retrain  47 :\n",
      "\ttrain: 0.8037383177570093 65.24138389375042 \ttest: 0.7282608695652174 30.66531695021659\n",
      "retrain  48 :\n",
      "\ttrain: 0.8037383177570093 65.20701073814553 \ttest: 0.7282608695652174 30.68070913774031\n",
      "retrain  49 :\n",
      "\ttrain: 0.8037383177570093 65.17385360830865 \ttest: 0.7282608695652174 30.695653927713074\n",
      "retrain  50 :\n",
      "\ttrain: 0.8084112149532711 65.14185254958774 \ttest: 0.7282608695652174 30.71016237897335\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.83333   0.92357   0.87613       157\n",
      "           1    0.70000   0.49123   0.57732        57\n",
      "\n",
      "    accuracy                        0.80841       214\n",
      "   macro avg    0.76667   0.70740   0.72673       214\n",
      "weighted avg    0.79782   0.80841   0.79654       214\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.77215   0.89706   0.82993        68\n",
      "           1    0.46154   0.25000   0.32432        24\n",
      "\n",
      "    accuracy                        0.72826        92\n",
      "   macro avg    0.61685   0.57353   0.57713        92\n",
      "weighted avg    0.69112   0.72826   0.69803        92\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 15\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 45\n",
      "9 27 1\n",
      "11 33 2\n",
      "13 39 3\n",
      "14 42 4\n",
      "14 42 5\n",
      "17 51 6\n",
      "17 51 7\n",
      "17 51 8\n",
      "17 51 9\n",
      "17 51 10\n",
      "17 51 11\n",
      "17 51 12\n",
      "17 51 13\n",
      "17 51 14\n",
      "17 51 15\n",
      "17 51 16\n",
      "17 51 17\n",
      "17 51 18\n",
      "17 51 19\n",
      "17 51 20\n",
      "17 51 21\n",
      "17 51 22\n",
      "17 51 23\n",
      "17 51 24\n",
      "17 51 25\n",
      "17 51 26\n",
      "17 51 27\n",
      "17 51 28\n",
      "17 51 29\n",
      "17 51 30\n",
      "17 51 31\n",
      "17 51 32\n",
      "17 51 33\n",
      "17 51 34\n",
      "17 51 35\n",
      "17 51 36\n",
      "17 51 37\n",
      "17 51 38\n",
      "17 51 39\n",
      "17 51 40\n",
      "17 51 41\n",
      "17 51 42\n",
      "17 51 43\n",
      "17 51 44\n",
      "17 51 45\n",
      "17 51 46\n",
      "17 51 47\n",
      "17 51 48\n",
      "17 51 49\n",
      "17 51 50\n",
      "17 51 51\n",
      "17 51 52\n",
      "17 51 53\n",
      "17 51 54\n",
      "17 51 55\n",
      "17 51 56\n",
      "17 51 57\n",
      "17 51 58\n",
      "17 51 59\n",
      "17 51 60\n",
      "17 51 61\n",
      "17 51 62\n",
      "17 51 63\n",
      "17 51 64\n",
      "17 51 65\n",
      "17 51 66\n",
      "17 51 67\n",
      "17 51 68\n",
      "17 51 69\n",
      "17 51 70\n",
      "17 51 71\n",
      "17 51 72\n",
      "17 51 73\n",
      "17 51 74\n",
      "17 51 75\n",
      "17 51 76\n",
      "17 51 77\n",
      "17 51 78\n",
      "17 51 79\n",
      "17 51 80\n",
      "17 51 81\n",
      "17 51 82\n",
      "17 51 83\n",
      "17 51 84\n",
      "17 51 85\n",
      "17 51 86\n",
      "17 51 87\n",
      "17 51 88\n",
      "17 51 89\n",
      "17 51 90\n",
      "17 51 91\n",
      "17 51 92\n",
      "17 51 93\n",
      "17 51 94\n",
      "17 51 95\n",
      "17 51 96\n",
      "17 51 97\n",
      "17 51 98\n",
      "17 51 99\n",
      "17 51 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.7336448598130841 76.67744751791571 \ttest: 0.7391304347826086 33.172471399041996\n",
      "retrain  2 :\n",
      "\ttrain: 0.7336448598130841 72.72207422294413 \ttest: 0.7391304347826086 31.999328168339076\n",
      "retrain  3 :\n",
      "\ttrain: 0.7336448598130841 70.43897992779414 \ttest: 0.7391304347826086 31.417949730122043\n",
      "retrain  4 :\n",
      "\ttrain: 0.780373831775701 69.0539808732243 \ttest: 0.717391304347826 31.139023471174742\n",
      "retrain  5 :\n",
      "\ttrain: 0.780373831775701 68.15091999841029 \ttest: 0.75 31.01448978148208\n",
      "retrain  6 :\n",
      "\ttrain: 0.780373831775701 67.51411498939311 \ttest: 0.75 30.96997925835043\n",
      "retrain  7 :\n",
      "\ttrain: 0.7850467289719626 67.0316722953274 \ttest: 0.75 30.96793165298126\n",
      "retrain  8 :\n",
      "\ttrain: 0.780373831775701 66.64428919123398 \ttest: 0.75 30.98900466553231\n",
      "retrain  9 :\n",
      "\ttrain: 0.780373831775701 66.31947798610625 \ttest: 0.75 31.022959433112224\n",
      "retrain  10 :\n",
      "\ttrain: 0.780373831775701 66.03868521720776 \ttest: 0.75 31.06419240650046\n",
      "retrain  11 :\n",
      "\ttrain: 0.7850467289719626 65.79078485512227 \ttest: 0.75 31.109518053665433\n",
      "retrain  12 :\n",
      "\ttrain: 0.7897196261682243 65.56873074865304 \ttest: 0.75 31.157049061867482\n",
      "retrain  13 :\n",
      "\ttrain: 0.7897196261682243 65.36779705495644 \ttest: 0.75 31.205619127183997\n",
      "retrain  14 :\n",
      "\ttrain: 0.7897196261682243 65.18463137271712 \ttest: 0.75 31.254478417539094\n",
      "retrain  15 :\n",
      "\ttrain: 0.7897196261682243 65.01673182982117 \ttest: 0.75 31.303128471805504\n",
      "retrain  16 :\n",
      "\ttrain: 0.7897196261682243 64.86214969985764 \ttest: 0.75 31.351229745633184\n",
      "retrain  17 :\n",
      "\ttrain: 0.7897196261682243 64.71931447352253 \ttest: 0.75 31.398547814315407\n",
      "retrain  18 :\n",
      "\ttrain: 0.7850467289719626 64.58692692436134 \ttest: 0.75 31.444920670897197\n",
      "retrain  19 :\n",
      "\ttrain: 0.7850467289719626 64.46389090220848 \ttest: 0.75 31.490237896583565\n",
      "retrain  20 :\n",
      "\ttrain: 0.7850467289719626 64.34926784434916 \ttest: 0.75 31.534426766816086\n",
      "retrain  21 :\n",
      "\ttrain: 0.7850467289719626 64.24224507190773 \ttest: 0.75 31.577442587715147\n",
      "retrain  22 :\n",
      "\ttrain: 0.7850467289719626 64.14211277328806 \ttest: 0.75 31.619261735702167\n",
      "retrain  23 :\n",
      "\ttrain: 0.7850467289719626 64.0482466867619 \ttest: 0.75 31.659876506015234\n",
      "retrain  24 :\n",
      "\ttrain: 0.7850467289719626 63.960094676595666 \ttest: 0.75 31.699291223510528\n",
      "retrain  25 :\n",
      "\ttrain: 0.7850467289719626 63.87716607340666 \ttest: 0.75 31.737519265752034\n",
      "retrain  26 :\n",
      "\ttrain: 0.7850467289719626 63.79902304586351 \ttest: 0.75 31.774580763693756\n",
      "retrain  27 :\n",
      "\ttrain: 0.7850467289719626 63.72527350988447 \ttest: 0.75 31.810500815847398\n",
      "retrain  28 :\n",
      "\ttrain: 0.7850467289719626 63.65556523028904 \ttest: 0.75 31.845308097112202\n",
      "retrain  29 :\n",
      "\ttrain: 0.7850467289719626 63.589580865719725 \ttest: 0.75 31.87903377387496\n",
      "retrain  30 :\n",
      "\ttrain: 0.7850467289719626 63.5270337716214 \ttest: 0.75 31.911710658312558\n",
      "retrain  31 :\n",
      "\ttrain: 0.7850467289719626 63.4676644202438 \ttest: 0.75 31.943372550300158\n",
      "retrain  32 :\n",
      "\ttrain: 0.7850467289719626 63.41123732812256 \ttest: 0.75 31.974053726854603\n",
      "retrain  33 :\n",
      "\ttrain: 0.7850467289719626 63.35753840458 \ttest: 0.75 32.00378854779797\n",
      "retrain  34 :\n",
      "\ttrain: 0.7850467289719626 63.3063726521184 \ttest: 0.75 32.03261115306533\n",
      "retrain  35 :\n",
      "\ttrain: 0.7850467289719626 63.25756216285041 \ttest: 0.75 32.060555232315444\n",
      "retrain  36 :\n",
      "\ttrain: 0.7850467289719626 63.2109443654398 \ttest: 0.75 32.08765385159202\n",
      "retrain  37 :\n",
      "\ttrain: 0.7850467289719626 63.16637048516816 \ttest: 0.75 32.11393932499074\n",
      "retrain  38 :\n",
      "\ttrain: 0.7850467289719626 63.123704186232274 \ttest: 0.75 32.139443121808625\n",
      "retrain  39 :\n",
      "\ttrain: 0.7850467289719626 63.08282037059138 \ttest: 0.75 32.164195801639025\n",
      "retrain  40 :\n",
      "\ttrain: 0.7850467289719626 63.043604111906 \ttest: 0.75 32.18822697144189\n",
      "retrain  41 :\n",
      "\ttrain: 0.7850467289719626 63.00594970655007 \ttest: 0.75 32.21156525985651\n",
      "retrain  42 :\n",
      "\ttrain: 0.7850467289719626 62.9697598264947 \ttest: 0.7608695652173914 32.23423830500149\n",
      "retrain  43 :\n",
      "\ttrain: 0.7850467289719626 62.93494476118193 \ttest: 0.7608695652173914 32.256272752780625\n",
      "retrain  44 :\n",
      "\ttrain: 0.7850467289719626 62.90142173742338 \ttest: 0.7608695652173914 32.277694263326126\n",
      "retrain  45 :\n",
      "\ttrain: 0.7850467289719626 62.869114307951676 \ttest: 0.7608695652173914 32.29852752369649\n",
      "retrain  46 :\n",
      "\ttrain: 0.7850467289719626 62.837951800579596 \ttest: 0.7608695652173914 32.31879626533211\n",
      "retrain  47 :\n",
      "\ttrain: 0.7850467289719626 62.80786882103329 \ttest: 0.7608695652173914 32.338523285077976\n",
      "retrain  48 :\n",
      "\ttrain: 0.7850467289719626 62.77880480346019 \ttest: 0.7608695652173914 32.3577304688272\n",
      "retrain  49 :\n",
      "\ttrain: 0.7850467289719626 62.75070360340002 \ttest: 0.7608695652173914 32.376438817032856\n",
      "retrain  50 :\n",
      "\ttrain: 0.7850467289719626 62.72351312867498 \ttest: 0.7608695652173914 32.39466847149093\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.80663   0.92994   0.86391       157\n",
      "           1    0.66667   0.38596   0.48889        57\n",
      "\n",
      "    accuracy                        0.78505       214\n",
      "   macro avg    0.73665   0.65795   0.67640       214\n",
      "weighted avg    0.76935   0.78505   0.76402       214\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.78049   0.94118   0.85333        68\n",
      "           1    0.60000   0.25000   0.35294        24\n",
      "\n",
      "    accuracy                        0.76087        92\n",
      "   macro avg    0.69024   0.59559   0.60314        92\n",
      "weighted avg    0.73340   0.76087   0.72280        92\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 17\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 51\n",
      "9 27 1\n",
      "10 30 2\n",
      "12 36 3\n",
      "13 39 4\n",
      "13 39 5\n",
      "14 42 6\n",
      "15 45 7\n",
      "15 45 8\n",
      "16 48 9\n",
      "16 48 10\n",
      "16 48 11\n",
      "16 48 12\n",
      "16 48 13\n",
      "16 48 14\n",
      "16 48 15\n",
      "16 48 16\n",
      "16 48 17\n",
      "16 48 18\n",
      "16 48 19\n",
      "16 48 20\n",
      "16 48 21\n",
      "16 48 22\n",
      "16 48 23\n",
      "16 48 24\n",
      "16 48 25\n",
      "16 48 26\n",
      "16 48 27\n",
      "16 48 28\n",
      "16 48 29\n",
      "16 48 30\n",
      "16 48 31\n",
      "16 48 32\n",
      "16 48 33\n",
      "16 48 34\n",
      "16 48 35\n",
      "16 48 36\n",
      "16 48 37\n",
      "16 48 38\n",
      "16 48 39\n",
      "16 48 40\n",
      "16 48 41\n",
      "16 48 42\n",
      "16 48 43\n",
      "16 48 44\n",
      "16 48 45\n",
      "16 48 46\n",
      "16 48 47\n",
      "16 48 48\n",
      "16 48 49\n",
      "16 48 50\n",
      "16 48 51\n",
      "16 48 52\n",
      "16 48 53\n",
      "16 48 54\n",
      "16 48 55\n",
      "16 48 56\n",
      "16 48 57\n",
      "16 48 58\n",
      "16 48 59\n",
      "16 48 60\n",
      "16 48 61\n",
      "16 48 62\n",
      "16 48 63\n",
      "16 48 64\n",
      "16 48 65\n",
      "16 48 66\n",
      "16 48 67\n",
      "16 48 68\n",
      "16 48 69\n",
      "16 48 70\n",
      "16 48 71\n",
      "16 48 72\n",
      "16 48 73\n",
      "16 48 74\n",
      "16 48 75\n",
      "16 48 76\n",
      "16 48 77\n",
      "16 48 78\n",
      "16 48 79\n",
      "16 48 80\n",
      "16 48 81\n",
      "16 48 82\n",
      "16 48 83\n",
      "16 48 84\n",
      "16 48 85\n",
      "16 48 86\n",
      "16 48 87\n",
      "16 48 88\n",
      "16 48 89\n",
      "16 48 90\n",
      "16 48 91\n",
      "16 48 92\n",
      "16 48 93\n",
      "16 48 94\n",
      "16 48 95\n",
      "16 48 96\n",
      "16 48 97\n",
      "16 48 98\n",
      "16 48 99\n",
      "16 48 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.7336448598130841 77.94996167769571 \ttest: 0.7391304347826086 32.93740315523772\n",
      "retrain  2 :\n",
      "\ttrain: 0.7336448598130841 74.69839959463141 \ttest: 0.7391304347826086 31.454992744320577\n",
      "retrain  3 :\n",
      "\ttrain: 0.7336448598130841 72.83928164385615 \ttest: 0.7391304347826086 30.58656324005203\n",
      "retrain  4 :\n",
      "\ttrain: 0.7336448598130841 71.7460597715899 \ttest: 0.7391304347826086 30.060365057833863\n",
      "retrain  5 :\n",
      "\ttrain: 0.7710280373831776 71.07055147851028 \ttest: 0.7391304347826086 29.724911469105045\n",
      "retrain  6 :\n",
      "\ttrain: 0.7757009345794392 70.62639190080712 \ttest: 0.7608695652173914 29.498455225259814\n",
      "retrain  7 :\n",
      "\ttrain: 0.7757009345794392 70.31445701670604 \ttest: 0.7608695652173914 29.336844352604544\n",
      "retrain  8 :\n",
      "\ttrain: 0.7710280373831776 70.08140891381962 \ttest: 0.7717391304347826 29.215751381219192\n",
      "retrain  9 :\n",
      "\ttrain: 0.7710280373831776 69.89788308769161 \ttest: 0.7934782608695652 29.12134007582387\n",
      "retrain  10 :\n",
      "\ttrain: 0.7663551401869159 69.7471988102337 \ttest: 0.7934782608695652 29.045422774972444\n",
      "retrain  11 :\n",
      "\ttrain: 0.7663551401869159 69.6195091541075 \ttest: 0.7934782608695652 28.982932569037608\n",
      "retrain  12 :\n",
      "\ttrain: 0.7663551401869159 69.50873930311069 \ttest: 0.7934782608695652 28.93058322247931\n",
      "retrain  13 :\n",
      "\ttrain: 0.7663551401869159 69.41095952602018 \ttest: 0.7934782608695652 28.886143271005277\n",
      "retrain  14 :\n",
      "\ttrain: 0.7663551401869159 69.32350355612914 \ttest: 0.7934782608695652 28.8480322207935\n",
      "retrain  15 :\n",
      "\ttrain: 0.7663551401869159 69.24447942250168 \ttest: 0.7934782608695652 28.81508879543939\n",
      "retrain  16 :\n",
      "\ttrain: 0.7663551401869159 69.17249026034418 \ttest: 0.7934782608695652 28.786433131441363\n",
      "retrain  17 :\n",
      "\ttrain: 0.7663551401869159 69.10646964853981 \ttest: 0.7934782608695652 28.761381629131172\n",
      "retrain  18 :\n",
      "\ttrain: 0.7616822429906542 69.045580857841 \ttest: 0.7717391304347826 28.739392220438972\n",
      "retrain  19 :\n",
      "\ttrain: 0.7616822429906542 68.98915274050165 \ttest: 0.7717391304347826 28.720027815002616\n",
      "retrain  20 :\n",
      "\ttrain: 0.7616822429906542 68.93663729362828 \ttest: 0.7717391304347826 28.702931016034903\n",
      "retrain  21 :\n",
      "\ttrain: 0.7616822429906542 68.88758049647953 \ttest: 0.7717391304347826 28.687806089349877\n",
      "retrain  22 :\n",
      "\ttrain: 0.7616822429906542 68.84160158291941 \ttest: 0.7717391304347826 28.674405771623434\n",
      "retrain  23 :\n",
      "\ttrain: 0.7616822429906542 68.7983778763423 \ttest: 0.7717391304347826 28.662521414640526\n",
      "retrain  24 :\n",
      "\ttrain: 0.7616822429906542 68.75763342374188 \ttest: 0.7717391304347826 28.651975495050095\n",
      "retrain  25 :\n",
      "\ttrain: 0.7616822429906542 68.71913030775114 \ttest: 0.7717391304347826 28.642615841195195\n",
      "retrain  26 :\n",
      "\ttrain: 0.7616822429906542 68.6826618982639 \ttest: 0.7717391304347826 28.63431113016562\n",
      "retrain  27 :\n",
      "\ttrain: 0.7616822429906542 68.6480475409165 \ttest: 0.7717391304347826 28.626947338899697\n",
      "retrain  28 :\n",
      "\ttrain: 0.7616822429906542 68.61512832980391 \ttest: 0.7717391304347826 28.620424920730624\n",
      "retrain  29 :\n",
      "\ttrain: 0.7616822429906542 68.58376371066689 \ttest: 0.7717391304347826 28.614656539207658\n",
      "retrain  30 :\n",
      "\ttrain: 0.7616822429906542 68.55382872799868 \ttest: 0.7717391304347826 28.609565233783975\n",
      "retrain  31 :\n",
      "\ttrain: 0.7616822429906542 68.52521177652505 \ttest: 0.7717391304347826 28.605082922835525\n",
      "retrain  32 :\n",
      "\ttrain: 0.7616822429906542 68.49781275119355 \ttest: 0.7717391304347826 28.60114917212227\n",
      "retrain  33 :\n",
      "\ttrain: 0.7616822429906542 68.47154151443608 \ttest: 0.7717391304347826 28.597710173622353\n",
      "retrain  34 :\n",
      "\ttrain: 0.7616822429906542 68.4463166177778 \ttest: 0.7717391304347826 28.59471789228123\n",
      "retrain  35 :\n",
      "\ttrain: 0.7616822429906542 68.42206422865715 \ttest: 0.7717391304347826 28.59212934774626\n",
      "retrain  36 :\n",
      "\ttrain: 0.7616822429906542 68.39871722382642 \ttest: 0.7717391304347826 28.589906005400834\n",
      "retrain  37 :\n",
      "\ttrain: 0.7616822429906542 68.37621441877357 \ttest: 0.7717391304347826 28.588013256548308\n",
      "retrain  38 :\n",
      "\ttrain: 0.7616822429906542 68.35449990885425 \ttest: 0.7717391304347826 28.58641997184671\n",
      "retrain  39 :\n",
      "\ttrain: 0.7616822429906542 68.33352250269164 \ttest: 0.7717391304347826 28.5850981153744\n",
      "retrain  40 :\n",
      "\ttrain: 0.7616822429906542 68.31323523221619 \ttest: 0.7717391304347826 28.58402240924709\n",
      "retrain  41 :\n",
      "\ttrain: 0.7616822429906542 68.29359492672162 \ttest: 0.7717391304347826 28.58317004068393\n",
      "retrain  42 :\n",
      "\ttrain: 0.7616822429906542 68.27456184069094 \ttest: 0.7717391304347826 28.58252040496605\n",
      "retrain  43 :\n",
      "\ttrain: 0.7616822429906542 68.2560993270352 \ttest: 0.7717391304347826 28.58205487894595\n",
      "retrain  44 :\n",
      "\ttrain: 0.7616822429906542 68.23817354889708 \ttest: 0.7717391304347826 28.58175662072556\n",
      "retrain  45 :\n",
      "\ttrain: 0.7663551401869159 68.22075322437878 \ttest: 0.7608695652173914 28.58161039188265\n",
      "retrain  46 :\n",
      "\ttrain: 0.7663551401869159 68.20380939952811 \ttest: 0.7608695652173914 28.581602399234203\n",
      "retrain  47 :\n",
      "\ttrain: 0.7663551401869159 68.18731524570165 \ttest: 0.7608695652173914 28.581720153614462\n",
      "retrain  48 :\n",
      "\ttrain: 0.7663551401869159 68.17124587806306 \ttest: 0.7608695652173914 28.58195234354067\n",
      "retrain  49 :\n",
      "\ttrain: 0.7663551401869159 68.15557819249273 \ttest: 0.7608695652173914 28.582288721961863\n",
      "retrain  50 :\n",
      "\ttrain: 0.7663551401869159 68.1402907186115 \ttest: 0.7608695652173914 28.582720004549383\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.80925   0.89172   0.84848       157\n",
      "           1    0.58537   0.42105   0.48980        57\n",
      "\n",
      "    accuracy                        0.76636       214\n",
      "   macro avg    0.69731   0.65639   0.66914       214\n",
      "weighted avg    0.74962   0.76636   0.75295       214\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.81081   0.88235   0.84507        68\n",
      "           1    0.55556   0.41667   0.47619        24\n",
      "\n",
      "    accuracy                        0.76087        92\n",
      "   macro avg    0.68318   0.64951   0.66063        92\n",
      "weighted avg    0.74422   0.76087   0.74884        92\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 16\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 48\n",
      "8 24 1\n",
      "11 33 2\n",
      "11 33 3\n",
      "13 39 4\n",
      "15 45 5\n",
      "17 51 6\n",
      "17 51 7\n",
      "17 51 8\n",
      "17 51 9\n",
      "17 51 10\n",
      "17 51 11\n",
      "17 51 12\n",
      "17 51 13\n",
      "17 51 14\n",
      "17 51 15\n",
      "17 51 16\n",
      "17 51 17\n",
      "17 51 18\n",
      "17 51 19\n",
      "17 51 20\n",
      "17 51 21\n",
      "17 51 22\n",
      "17 51 23\n",
      "17 51 24\n",
      "17 51 25\n",
      "17 51 26\n",
      "17 51 27\n",
      "17 51 28\n",
      "17 51 29\n",
      "17 51 30\n",
      "17 51 31\n",
      "17 51 32\n",
      "17 51 33\n",
      "17 51 34\n",
      "17 51 35\n",
      "17 51 36\n",
      "17 51 37\n",
      "17 51 38\n",
      "17 51 39\n",
      "17 51 40\n",
      "17 51 41\n",
      "17 51 42\n",
      "17 51 43\n",
      "17 51 44\n",
      "17 51 45\n",
      "17 51 46\n",
      "17 51 47\n",
      "17 51 48\n",
      "17 51 49\n",
      "17 51 50\n",
      "17 51 51\n",
      "17 51 52\n",
      "17 51 53\n",
      "17 51 54\n",
      "17 51 55\n",
      "17 51 56\n",
      "17 51 57\n",
      "17 51 58\n",
      "17 51 59\n",
      "17 51 60\n",
      "17 51 61\n",
      "17 51 62\n",
      "17 51 63\n",
      "17 51 64\n",
      "17 51 65\n",
      "17 51 66\n",
      "17 51 67\n",
      "17 51 68\n",
      "17 51 69\n",
      "17 51 70\n",
      "17 51 71\n",
      "17 51 72\n",
      "17 51 73\n",
      "17 51 74\n",
      "17 51 75\n",
      "17 51 76\n",
      "17 51 77\n",
      "17 51 78\n",
      "17 51 79\n",
      "17 51 80\n",
      "17 51 81\n",
      "17 51 82\n",
      "17 51 83\n",
      "17 51 84\n",
      "17 51 85\n",
      "17 51 86\n",
      "17 51 87\n",
      "17 51 88\n",
      "17 51 89\n",
      "17 51 90\n",
      "17 51 91\n",
      "17 51 92\n",
      "17 51 93\n",
      "17 51 94\n",
      "17 51 95\n",
      "17 51 96\n",
      "17 51 97\n",
      "17 51 98\n",
      "17 51 99\n",
      "17 51 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.7336448598130841 73.78872471243156 \ttest: 0.7391304347826086 34.85580320832224\n",
      "retrain  2 :\n",
      "\ttrain: 0.7336448598130841 69.15908457263467 \ttest: 0.7391304347826086 35.14806940480015\n",
      "retrain  3 :\n",
      "\ttrain: 0.7336448598130841 66.96734048438947 \ttest: 0.7391304347826086 35.65342834019947\n",
      "retrain  4 :\n",
      "\ttrain: 0.7663551401869159 65.87062270817047 \ttest: 0.782608695652174 36.11622110694109\n",
      "retrain  5 :\n",
      "\ttrain: 0.7757009345794392 65.27038249945974 \ttest: 0.7717391304347826 36.47391728668069\n",
      "retrain  6 :\n",
      "\ttrain: 0.7710280373831776 64.9035575758565 \ttest: 0.7717391304347826 36.730885818341164\n",
      "retrain  7 :\n",
      "\ttrain: 0.7710280373831776 64.65256551037214 \ttest: 0.7717391304347826 36.90864558728677\n",
      "retrain  8 :\n",
      "\ttrain: 0.7850467289719626 64.46323273255845 \ttest: 0.7391304347826086 37.029043581803194\n",
      "retrain  9 :\n",
      "\ttrain: 0.7850467289719626 64.30963123771798 \ttest: 0.7391304347826086 37.1097288461559\n",
      "retrain  10 :\n",
      "\ttrain: 0.7850467289719626 64.17876733896917 \ttest: 0.7282608695652174 37.163762107169816\n",
      "retrain  11 :\n",
      "\ttrain: 0.7850467289719626 64.06375128858858 \ttest: 0.7282608695652174 37.2003926895563\n",
      "retrain  12 :\n",
      "\ttrain: 0.7850467289719626 63.960670655472775 \ttest: 0.7282608695652174 37.22599842427242\n",
      "retrain  13 :\n",
      "\ttrain: 0.7897196261682243 63.867122271729386 \ttest: 0.717391304347826 37.24489183687554\n",
      "retrain  14 :\n",
      "\ttrain: 0.7897196261682243 63.781505076034605 \ttest: 0.717391304347826 37.259938161767664\n",
      "retrain  15 :\n",
      "\ttrain: 0.7897196261682243 63.70266986864097 \ttest: 0.717391304347826 37.273005429914335\n",
      "retrain  16 :\n",
      "\ttrain: 0.794392523364486 63.629740004014835 \ttest: 0.717391304347826 37.28528334358906\n",
      "retrain  17 :\n",
      "\ttrain: 0.794392523364486 63.5620156996849 \ttest: 0.7282608695652174 37.29750543347115\n",
      "retrain  18 :\n",
      "\ttrain: 0.794392523364486 63.4989202367878 \ttest: 0.7282608695652174 37.31010206773339\n",
      "retrain  19 :\n",
      "\ttrain: 0.794392523364486 63.4399677801202 \ttest: 0.7282608695652174 37.32330490150356\n",
      "retrain  20 :\n",
      "\ttrain: 0.794392523364486 63.38474279110983 \ttest: 0.7282608695652174 37.337217617204935\n",
      "retrain  21 :\n",
      "\ttrain: 0.794392523364486 63.33288596702164 \ttest: 0.7282608695652174 37.35186345618469\n",
      "retrain  22 :\n",
      "\ttrain: 0.794392523364486 63.284084073820374 \ttest: 0.7282608695652174 37.367216874240206\n",
      "retrain  23 :\n",
      "\ttrain: 0.794392523364486 63.23806225367137 \ttest: 0.7282608695652174 37.383224398679175\n",
      "retrain  24 :\n",
      "\ttrain: 0.794392523364486 63.19457800547602 \ttest: 0.7282608695652174 37.399818181599585\n",
      "retrain  25 :\n",
      "\ttrain: 0.794392523364486 63.15341635962699 \ttest: 0.7282608695652174 37.41692464296828\n",
      "retrain  26 :\n",
      "\ttrain: 0.794392523364486 63.11438594316848 \ttest: 0.7282608695652174 37.43446983597342\n",
      "retrain  27 :\n",
      "\ttrain: 0.794392523364486 63.07731573091693 \ttest: 0.7282608695652174 37.45238264348912\n",
      "retrain  28 :\n",
      "\ttrain: 0.794392523364486 63.04205233768269 \ttest: 0.7282608695652174 37.470596555562324\n",
      "retrain  29 :\n",
      "\ttrain: 0.794392523364486 63.00845774460534 \ttest: 0.7282608695652174 37.48905053259159\n",
      "retrain  30 :\n",
      "\ttrain: 0.794392523364486 62.9764073780747 \ttest: 0.7282608695652174 37.50768929181645\n",
      "retrain  31 :\n",
      "\ttrain: 0.794392523364486 62.94578847768271 \ttest: 0.7282608695652174 37.52646324130504\n",
      "retrain  32 :\n",
      "\ttrain: 0.794392523364486 62.91649870284513 \ttest: 0.7282608695652174 37.545328208880306\n",
      "retrain  33 :\n",
      "\ttrain: 0.794392523364486 62.88844493770928 \ttest: 0.7282608695652174 37.564245061714544\n",
      "retrain  34 :\n",
      "\ttrain: 0.794392523364486 62.86154226167274 \ttest: 0.7282608695652174 37.583179277660506\n",
      "retrain  35 :\n",
      "\ttrain: 0.794392523364486 62.835713058887535 \ttest: 0.7282608695652174 37.60210050630407\n",
      "retrain  36 :\n",
      "\ttrain: 0.794392523364486 62.81088624492693 \ttest: 0.7282608695652174 37.62098214248039\n",
      "retrain  37 :\n",
      "\ttrain: 0.794392523364486 62.78699659263673 \ttest: 0.7282608695652174 37.639800925040426\n",
      "retrain  38 :\n",
      "\ttrain: 0.794392523364486 62.7639841422931 \ttest: 0.7282608695652174 37.65853656725036\n",
      "retrain  39 :\n",
      "\ttrain: 0.794392523364486 62.741793683701474 \ttest: 0.7282608695652174 37.67717142117387\n",
      "retrain  40 :\n",
      "\ttrain: 0.794392523364486 62.72037429991942 \ttest: 0.7282608695652174 37.69569017592355\n",
      "retrain  41 :\n",
      "\ttrain: 0.794392523364486 62.69967896396029 \ttest: 0.7282608695652174 37.71407958823601\n",
      "retrain  42 :\n",
      "\ttrain: 0.794392523364486 62.679664181211976 \ttest: 0.7282608695652174 37.73232824305957\n",
      "retrain  43 :\n",
      "\ttrain: 0.794392523364486 62.660289671439656 \ttest: 0.7282608695652174 37.75042634150252\n",
      "retrain  44 :\n",
      "\ttrain: 0.794392523364486 62.641518085180635 \ttest: 0.7282608695652174 37.76836551341119\n",
      "retrain  45 :\n",
      "\ttrain: 0.794392523364486 62.623314750120535 \ttest: 0.7282608695652174 37.78613865192515\n",
      "retrain  46 :\n",
      "\ttrain: 0.794392523364486 62.605647443689456 \ttest: 0.7282608695652174 37.80373976752158\n",
      "retrain  47 :\n",
      "\ttrain: 0.794392523364486 62.5884861886612 \ttest: 0.7282608695652174 37.821163859269134\n",
      "retrain  48 :\n",
      "\ttrain: 0.794392523364486 62.57180306899454 \ttest: 0.7282608695652174 37.83840680123434\n",
      "retrain  49 :\n",
      "\ttrain: 0.794392523364486 62.5555720635393 \ttest: 0.7282608695652174 37.85546524220524\n",
      "retrain  50 :\n",
      "\ttrain: 0.794392523364486 62.5397688955545 \ttest: 0.7282608695652174 37.872336517107215\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.85535   0.86624   0.86076       157\n",
      "           1    0.61818   0.59649   0.60714        57\n",
      "\n",
      "    accuracy                        0.79439       214\n",
      "   macro avg    0.73676   0.73137   0.73395       214\n",
      "weighted avg    0.79218   0.79439   0.79321       214\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.78667   0.86765   0.82517        68\n",
      "           1    0.47059   0.33333   0.39024        24\n",
      "\n",
      "    accuracy                        0.72826        92\n",
      "   macro avg    0.62863   0.60049   0.60771        92\n",
      "weighted avg    0.70421   0.72826   0.71171        92\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 17\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 51\n",
      "8 24 1\n",
      "11 33 2\n",
      "14 42 3\n",
      "16 48 4\n",
      "17 51 5\n",
      "17 51 6\n",
      "17 51 7\n",
      "17 51 8\n",
      "17 51 9\n",
      "17 51 10\n",
      "17 51 11\n",
      "17 51 12\n",
      "17 51 13\n",
      "17 51 14\n",
      "17 51 15\n",
      "17 51 16\n",
      "17 51 17\n",
      "17 51 18\n",
      "17 51 19\n",
      "17 51 20\n",
      "17 51 21\n",
      "17 51 22\n",
      "17 51 23\n",
      "17 51 24\n",
      "17 51 25\n",
      "17 51 26\n",
      "17 51 27\n",
      "17 51 28\n",
      "17 51 29\n",
      "17 51 30\n",
      "17 51 31\n",
      "17 51 32\n",
      "17 51 33\n",
      "17 51 34\n",
      "17 51 35\n",
      "17 51 36\n",
      "17 51 37\n",
      "17 51 38\n",
      "17 51 39\n",
      "17 51 40\n",
      "17 51 41\n",
      "17 51 42\n",
      "17 51 43\n",
      "17 51 44\n",
      "17 51 45\n",
      "17 51 46\n",
      "17 51 47\n",
      "17 51 48\n",
      "17 51 49\n",
      "17 51 50\n",
      "17 51 51\n",
      "17 51 52\n",
      "17 51 53\n",
      "17 51 54\n",
      "17 51 55\n",
      "17 51 56\n",
      "17 51 57\n",
      "17 51 58\n",
      "17 51 59\n",
      "17 51 60\n",
      "17 51 61\n",
      "17 51 62\n",
      "17 51 63\n",
      "17 51 64\n",
      "17 51 65\n",
      "17 51 66\n",
      "17 51 67\n",
      "17 51 68\n",
      "17 51 69\n",
      "17 51 70\n",
      "17 51 71\n",
      "17 51 72\n",
      "17 51 73\n",
      "17 51 74\n",
      "17 51 75\n",
      "17 51 76\n",
      "17 51 77\n",
      "17 51 78\n",
      "17 51 79\n",
      "17 51 80\n",
      "17 51 81\n",
      "17 51 82\n",
      "17 51 83\n",
      "17 51 84\n",
      "17 51 85\n",
      "17 51 86\n",
      "17 51 87\n",
      "17 51 88\n",
      "17 51 89\n",
      "17 51 90\n",
      "17 51 91\n",
      "17 51 92\n",
      "17 51 93\n",
      "17 51 94\n",
      "17 51 95\n",
      "17 51 96\n",
      "17 51 97\n",
      "17 51 98\n",
      "17 51 99\n",
      "17 51 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.7336448598130841 77.34082914947217 \ttest: 0.7391304347826086 32.99894356681643\n",
      "retrain  2 :\n",
      "\ttrain: 0.7336448598130841 73.76624838302344 \ttest: 0.7391304347826086 31.752785217106787\n",
      "retrain  3 :\n",
      "\ttrain: 0.7336448598130841 71.5763561550961 \ttest: 0.7391304347826086 31.13896649694964\n",
      "retrain  4 :\n",
      "\ttrain: 0.7476635514018691 70.09875532451775 \ttest: 0.75 30.849770445064642\n",
      "retrain  5 :\n",
      "\ttrain: 0.7429906542056075 69.00302001296846 \ttest: 0.75 30.733384855530634\n",
      "retrain  6 :\n",
      "\ttrain: 0.7429906542056075 68.12773079805169 \ttest: 0.75 30.71451006063464\n",
      "retrain  7 :\n",
      "\ttrain: 0.7897196261682243 67.39211540551669 \ttest: 0.75 30.754233782953506\n",
      "retrain  8 :\n",
      "\ttrain: 0.794392523364486 66.75368334128565 \ttest: 0.7391304347826086 30.831114563433836\n",
      "retrain  9 :\n",
      "\ttrain: 0.794392523364486 66.18840353260445 \ttest: 0.7391304347826086 30.932431798177085\n",
      "retrain  10 :\n",
      "\ttrain: 0.794392523364486 65.68144173811712 \ttest: 0.7391304347826086 31.050088206750964\n",
      "retrain  11 :\n",
      "\ttrain: 0.794392523364486 65.22278277947024 \ttest: 0.7391304347826086 31.178624395531905\n",
      "retrain  12 :\n",
      "\ttrain: 0.7897196261682243 64.80511753714683 \ttest: 0.7391304347826086 31.314204753720972\n",
      "retrain  13 :\n",
      "\ttrain: 0.7897196261682243 64.42278933964643 \ttest: 0.7391304347826086 31.454062843792677\n",
      "retrain  14 :\n",
      "\ttrain: 0.7897196261682243 64.07124255441565 \ttest: 0.7391304347826086 31.596173860576513\n",
      "retrain  15 :\n",
      "\ttrain: 0.794392523364486 63.74671392553343 \ttest: 0.7391304347826086 31.739046261727616\n",
      "retrain  16 :\n",
      "\ttrain: 0.7990654205607477 63.4460448355388 \ttest: 0.7391304347826086 31.881580740527994\n",
      "retrain  17 :\n",
      "\ttrain: 0.7990654205607477 63.166556686515925 \ttest: 0.7391304347826086 32.02297036587033\n",
      "retrain  18 :\n",
      "\ttrain: 0.7990654205607477 62.90596152305661 \ttest: 0.7391304347826086 32.162627748179716\n",
      "retrain  19 :\n",
      "\ttrain: 0.7990654205607477 62.662294076100814 \ttest: 0.7391304347826086 32.3001309593339\n",
      "retrain  20 :\n",
      "\ttrain: 0.7990654205607477 62.433858052585535 \ttest: 0.7391304347826086 32.43518296777915\n",
      "retrain  21 :\n",
      "\ttrain: 0.7990654205607477 62.21918267833301 \ttest: 0.7391304347826086 32.56758104171811\n",
      "retrain  22 :\n",
      "\ttrain: 0.7990654205607477 62.01698706469774 \ttest: 0.7391304347826086 32.69719360060907\n",
      "retrain  23 :\n",
      "\ttrain: 0.7990654205607477 61.82615077355159 \ttest: 0.7391304347826086 32.82394267024033\n",
      "retrain  24 :\n",
      "\ttrain: 0.7990654205607477 61.645689400316805 \ttest: 0.7391304347826086 32.947790567835504\n",
      "retrain  25 :\n",
      "\ttrain: 0.8037383177570093 61.47473426624493 \ttest: 0.7391304347826086 33.06872978581367\n",
      "retrain  26 :\n",
      "\ttrain: 0.8037383177570093 61.31251549458526 \ttest: 0.7391304347826086 33.186775296922306\n",
      "retrain  27 :\n",
      "\ttrain: 0.8037383177570093 61.158347880382465 \ttest: 0.7391304347826086 33.30195869421736\n",
      "retrain  28 :\n",
      "\ttrain: 0.8037383177570093 61.011619069147265 \ttest: 0.7391304347826086 33.41432372317797\n",
      "retrain  29 :\n",
      "\ttrain: 0.8037383177570093 60.87177964485486 \ttest: 0.7391304347826086 33.52392287174826\n",
      "retrain  30 :\n",
      "\ttrain: 0.8037383177570093 60.73833479768061 \ttest: 0.7391304347826086 33.630814765908504\n",
      "retrain  31 :\n",
      "\ttrain: 0.8037383177570093 60.61083729968037 \ttest: 0.7391304347826086 33.735062179993776\n",
      "retrain  32 :\n",
      "\ttrain: 0.8037383177570093 60.488881564438714 \ttest: 0.7391304347826086 33.83673051734588\n",
      "retrain  33 :\n",
      "\ttrain: 0.8037383177570093 60.372098606226515 \ttest: 0.7282608695652174 33.93588665176698\n",
      "retrain  34 :\n",
      "\ttrain: 0.8037383177570093 60.260151746811836 \ttest: 0.7282608695652174 34.03259804649386\n",
      "retrain  35 :\n",
      "\ttrain: 0.8037383177570093 60.15273294491455 \ttest: 0.7282608695652174 34.12693208718666\n",
      "retrain  36 :\n",
      "\ttrain: 0.8037383177570093 60.049559645366585 \ttest: 0.7282608695652174 34.21895558034828\n",
      "retrain  37 :\n",
      "\ttrain: 0.8037383177570093 59.95037206316298 \ttest: 0.7282608695652174 34.30873437987587\n",
      "retrain  38 :\n",
      "\ttrain: 0.8037383177570093 59.854930832457214 \ttest: 0.7282608695652174 34.396333113006534\n",
      "retrain  39 :\n",
      "\ttrain: 0.8037383177570093 59.76301496274668 \ttest: 0.7282608695652174 34.481814983433225\n",
      "retrain  40 :\n",
      "\ttrain: 0.8037383177570093 59.67442005449123 \ttest: 0.7282608695652174 34.565241634342804\n",
      "retrain  41 :\n",
      "\ttrain: 0.8037383177570093 59.58895673460485 \ttest: 0.7282608695652174 34.646673057943936\n",
      "retrain  42 :\n",
      "\ttrain: 0.8037383177570093 59.506449278986274 \ttest: 0.7282608695652174 34.726167540991135\n",
      "retrain  43 :\n",
      "\ttrain: 0.8037383177570093 59.42673439477497 \ttest: 0.7282608695652174 34.80378163808393\n",
      "retrain  44 :\n",
      "\ttrain: 0.8037383177570093 59.34966013955522 \ttest: 0.7282608695652174 34.87957016628553\n",
      "retrain  45 :\n",
      "\ttrain: 0.8037383177570093 59.275084958462585 \ttest: 0.7282608695652174 34.9535862159823\n",
      "retrain  46 :\n",
      "\ttrain: 0.8037383177570093 59.20287682322037 \ttest: 0.7282608695652174 35.02588117398385\n",
      "retrain  47 :\n",
      "\ttrain: 0.8037383177570093 59.13291245966822 \ttest: 0.7282608695652174 35.096504755711436\n",
      "retrain  48 :\n",
      "\ttrain: 0.8037383177570093 59.065076652440766 \ttest: 0.7282608695652174 35.16550504399106\n",
      "retrain  49 :\n",
      "\ttrain: 0.8037383177570093 58.99926161718692 \ttest: 0.7282608695652174 35.23292853249731\n",
      "retrain  50 :\n",
      "\ttrain: 0.8037383177570093 58.93536643216065 \ttest: 0.7282608695652174 35.29882017231371\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.82123   0.93631   0.87500       157\n",
      "           1    0.71429   0.43860   0.54348        57\n",
      "\n",
      "    accuracy                        0.80374       214\n",
      "   macro avg    0.76776   0.68745   0.70924       214\n",
      "weighted avg    0.79274   0.80374   0.78670       214\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.77922   0.88235   0.82759        68\n",
      "           1    0.46667   0.29167   0.35897        24\n",
      "\n",
      "    accuracy                        0.72826        92\n",
      "   macro avg    0.62294   0.58701   0.59328        92\n",
      "weighted avg    0.69768   0.72826   0.70534        92\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 17\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 51\n",
      "9 27 1\n",
      "12 36 2\n",
      "14 42 3\n",
      "16 48 4\n",
      "16 48 5\n",
      "16 48 6\n",
      "16 48 7\n",
      "16 48 8\n",
      "16 48 9\n",
      "16 48 10\n",
      "16 48 11\n",
      "16 48 12\n",
      "17 51 13\n",
      "17 51 14\n",
      "17 51 15\n",
      "17 51 16\n",
      "17 51 17\n",
      "18 54 18\n",
      "18 54 19\n",
      "18 54 20\n",
      "18 54 21\n",
      "18 54 22\n",
      "18 54 23\n",
      "18 54 24\n",
      "18 54 25\n",
      "18 54 26\n",
      "18 54 27\n",
      "18 54 28\n",
      "18 54 29\n",
      "18 54 30\n",
      "18 54 31\n",
      "18 54 32\n",
      "18 54 33\n",
      "18 54 34\n",
      "18 54 35\n",
      "18 54 36\n",
      "18 54 37\n",
      "18 54 38\n",
      "18 54 39\n",
      "18 54 40\n",
      "18 54 41\n",
      "18 54 42\n",
      "18 54 43\n",
      "18 54 44\n",
      "18 54 45\n",
      "18 54 46\n",
      "18 54 47\n",
      "18 54 48\n",
      "18 54 49\n",
      "18 54 50\n",
      "18 54 51\n",
      "18 54 52\n",
      "18 54 53\n",
      "18 54 54\n",
      "18 54 55\n",
      "18 54 56\n",
      "18 54 57\n",
      "18 54 58\n",
      "18 54 59\n",
      "18 54 60\n",
      "18 54 61\n",
      "18 54 62\n",
      "18 54 63\n",
      "18 54 64\n",
      "18 54 65\n",
      "18 54 66\n",
      "18 54 67\n",
      "18 54 68\n",
      "18 54 69\n",
      "18 54 70\n",
      "18 54 71\n",
      "18 54 72\n",
      "18 54 73\n",
      "18 54 74\n",
      "18 54 75\n",
      "18 54 76\n",
      "18 54 77\n",
      "18 54 78\n",
      "18 54 79\n",
      "18 54 80\n",
      "18 54 81\n",
      "18 54 82\n",
      "18 54 83\n",
      "18 54 84\n",
      "18 54 85\n",
      "18 54 86\n",
      "18 54 87\n",
      "18 54 88\n",
      "18 54 89\n",
      "18 54 90\n",
      "18 54 91\n",
      "18 54 92\n",
      "18 54 93\n",
      "18 54 94\n",
      "18 54 95\n",
      "18 54 96\n",
      "18 54 97\n",
      "18 54 98\n",
      "18 54 99\n",
      "18 54 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.7336448598130841 76.86537628467553 \ttest: 0.7391304347826086 32.5065189615776\n",
      "retrain  2 :\n",
      "\ttrain: 0.7336448598130841 73.36304194146553 \ttest: 0.7391304347826086 30.95519784377624\n",
      "retrain  3 :\n",
      "\ttrain: 0.7336448598130841 71.45378189869551 \ttest: 0.7391304347826086 30.11837185415724\n",
      "retrain  4 :\n",
      "\ttrain: 0.7429906542056075 70.31152801820832 \ttest: 0.7391304347826086 29.639045655596384\n",
      "retrain  5 :\n",
      "\ttrain: 0.780373831775701 69.5505643468437 \ttest: 0.782608695652174 29.344526062805656\n",
      "retrain  6 :\n",
      "\ttrain: 0.780373831775701 68.99192413804346 \ttest: 0.7608695652173914 29.15095886683053\n",
      "retrain  7 :\n",
      "\ttrain: 0.7710280373831776 68.55011078699532 \ttest: 0.782608695652174 29.016238150914177\n",
      "retrain  8 :\n",
      "\ttrain: 0.7663551401869159 68.18214960706399 \ttest: 0.7934782608695652 28.918163718114748\n",
      "retrain  9 :\n",
      "\ttrain: 0.7663551401869159 67.86497530375658 \ttest: 0.7934782608695652 28.844357257367264\n",
      "retrain  10 :\n",
      "\ttrain: 0.7663551401869159 67.58524771406084 \ttest: 0.7934782608695652 28.787505397450886\n",
      "retrain  11 :\n",
      "\ttrain: 0.7616822429906542 67.33463559329576 \ttest: 0.782608695652174 28.743038722639938\n",
      "retrain  12 :\n",
      "\ttrain: 0.7663551401869159 67.10755211722994 \ttest: 0.782608695652174 28.7079528941239\n",
      "retrain  13 :\n",
      "\ttrain: 0.7663551401869159 66.90001876580186 \ttest: 0.782608695652174 28.680182744502183\n",
      "retrain  14 :\n",
      "\ttrain: 0.7663551401869159 66.70906499175499 \ttest: 0.782608695652174 28.658254069916914\n",
      "retrain  15 :\n",
      "\ttrain: 0.7710280373831776 66.53239185383599 \ttest: 0.7934782608695652 28.641080581583644\n",
      "retrain  16 :\n",
      "\ttrain: 0.7710280373831776 66.36817152160768 \ttest: 0.7934782608695652 28.62784005619058\n",
      "retrain  17 :\n",
      "\ttrain: 0.7710280373831776 66.21492037435394 \ttest: 0.7934782608695652 28.617895645511133\n",
      "retrain  18 :\n",
      "\ttrain: 0.7710280373831776 66.0714142677025 \ttest: 0.7934782608695652 28.610744073399236\n",
      "retrain  19 :\n",
      "\ttrain: 0.7710280373831776 65.93662939283392 \ttest: 0.7934782608695652 28.60598049688044\n",
      "retrain  20 :\n",
      "\ttrain: 0.7710280373831776 65.80969953270127 \ttest: 0.7934782608695652 28.603274067583257\n",
      "retrain  21 :\n",
      "\ttrain: 0.7710280373831776 65.68988432980495 \ttest: 0.7934782608695652 28.602350573562582\n",
      "retrain  22 :\n",
      "\ttrain: 0.7850467289719626 65.57654523800632 \ttest: 0.7717391304347826 28.602979884165222\n",
      "retrain  23 :\n",
      "\ttrain: 0.7850467289719626 65.46912699961108 \ttest: 0.7717391304347826 28.604966720490452\n",
      "retrain  24 :\n",
      "\ttrain: 0.7850467289719626 65.36714318802635 \ttest: 0.7717391304347826 28.608143768164346\n",
      "retrain  25 :\n",
      "\ttrain: 0.7850467289719626 65.27016479560866 \ttest: 0.7717391304347826 28.612366464267478\n",
      "retrain  26 :\n",
      "\ttrain: 0.7850467289719626 65.17781113470777 \ttest: 0.7717391304347826 28.617508996617683\n",
      "retrain  27 :\n",
      "\ttrain: 0.7850467289719626 65.08974251620721 \ttest: 0.7717391304347826 28.6234611917103\n",
      "retrain  28 :\n",
      "\ttrain: 0.7850467289719626 65.00565430738436 \ttest: 0.7717391304347826 28.630126061668918\n",
      "retrain  29 :\n",
      "\ttrain: 0.7850467289719626 64.92527206944587 \ttest: 0.7717391304347826 28.637417845525732\n",
      "retrain  30 :\n",
      "\ttrain: 0.7850467289719626 64.84834754693507 \ttest: 0.7717391304347826 28.64526042555856\n",
      "retrain  31 :\n",
      "\ttrain: 0.7850467289719626 64.77465533431531 \ttest: 0.7717391304347826 28.653586031470795\n",
      "retrain  32 :\n",
      "\ttrain: 0.7850467289719626 64.70399008472765 \ttest: 0.7717391304347826 28.662334168040985\n",
      "retrain  33 :\n",
      "\ttrain: 0.7850467289719626 64.63616415587012 \ttest: 0.7717391304347826 28.671450718277065\n",
      "retrain  34 :\n",
      "\ttrain: 0.7850467289719626 64.57100561071857 \ttest: 0.7717391304347826 28.680887185993356\n",
      "retrain  35 :\n",
      "\ttrain: 0.7850467289719626 64.50835650824816 \ttest: 0.7717391304347826 28.690600050402224\n",
      "retrain  36 :\n",
      "\ttrain: 0.7850467289719626 64.4480714327537 \ttest: 0.7717391304347826 28.700550211694193\n",
      "retrain  37 :\n",
      "\ttrain: 0.7850467289719626 64.39001622078318 \ttest: 0.7717391304347826 28.7107025113131\n",
      "retrain  38 :\n",
      "\ttrain: 0.7850467289719626 64.33406685281575 \ttest: 0.7717391304347826 28.72102531417254\n",
      "retrain  39 :\n",
      "\ttrain: 0.7850467289719626 64.28010848317447 \ttest: 0.7717391304347826 28.731490142727885\n",
      "retrain  40 :\n",
      "\ttrain: 0.7850467289719626 64.228034586669 \ttest: 0.7717391304347826 28.742071354848182\n",
      "retrain  41 :\n",
      "\ttrain: 0.7850467289719626 64.17774620442341 \ttest: 0.7717391304347826 28.752745858988444\n",
      "retrain  42 :\n",
      "\ttrain: 0.7850467289719626 64.12915127449061 \ttest: 0.7717391304347826 28.76349286136787\n",
      "retrain  43 :\n",
      "\ttrain: 0.7850467289719626 64.08216403536838 \ttest: 0.7717391304347826 28.774293640799897\n",
      "retrain  44 :\n",
      "\ttrain: 0.7850467289719626 64.03670449254851 \ttest: 0.7717391304347826 28.785131347561094\n",
      "retrain  45 :\n",
      "\ttrain: 0.7850467289719626 63.992697939856285 \ttest: 0.7608695652173914 28.795990823274693\n",
      "retrain  46 :\n",
      "\ttrain: 0.7850467289719626 63.950074528655115 \ttest: 0.7608695652173914 28.80685843925683\n",
      "retrain  47 :\n",
      "\ttrain: 0.7850467289719626 63.908768879064105 \ttest: 0.7608695652173914 28.817721951155665\n",
      "retrain  48 :\n",
      "\ttrain: 0.7850467289719626 63.868719728214145 \ttest: 0.7608695652173914 28.828570368025197\n",
      "retrain  49 :\n",
      "\ttrain: 0.7850467289719626 63.82986961129123 \ttest: 0.7608695652173914 28.839393834232084\n",
      "retrain  50 :\n",
      "\ttrain: 0.794392523364486 63.79216457171296 \ttest: 0.7717391304347826 28.85018352280653\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.81215   0.93631   0.86982       157\n",
      "           1    0.69697   0.40351   0.51111        57\n",
      "\n",
      "    accuracy                        0.79439       214\n",
      "   macro avg    0.75456   0.66991   0.69047       214\n",
      "weighted avg    0.78147   0.79439   0.77428       214\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.79012   0.94118   0.85906        68\n",
      "           1    0.63636   0.29167   0.40000        24\n",
      "\n",
      "    accuracy                        0.77174        92\n",
      "   macro avg    0.71324   0.61642   0.62953        92\n",
      "weighted avg    0.75001   0.77174   0.73931        92\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 18\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 54\n",
      "6 18 1\n",
      "11 33 2\n",
      "13 39 3\n",
      "14 42 4\n",
      "14 42 5\n",
      "15 45 6\n",
      "16 48 7\n",
      "16 48 8\n",
      "16 48 9\n",
      "16 48 10\n",
      "16 48 11\n",
      "16 48 12\n",
      "16 48 13\n",
      "17 51 14\n",
      "17 51 15\n",
      "17 51 16\n",
      "17 51 17\n",
      "17 51 18\n",
      "17 51 19\n",
      "17 51 20\n",
      "17 51 21\n",
      "17 51 22\n",
      "17 51 23\n",
      "17 51 24\n",
      "17 51 25\n",
      "17 51 26\n",
      "17 51 27\n",
      "17 51 28\n",
      "17 51 29\n",
      "17 51 30\n",
      "17 51 31\n",
      "17 51 32\n",
      "17 51 33\n",
      "17 51 34\n",
      "17 51 35\n",
      "17 51 36\n",
      "17 51 37\n",
      "17 51 38\n",
      "17 51 39\n",
      "17 51 40\n",
      "17 51 41\n",
      "17 51 42\n",
      "17 51 43\n",
      "17 51 44\n",
      "17 51 45\n",
      "17 51 46\n",
      "17 51 47\n",
      "17 51 48\n",
      "17 51 49\n",
      "17 51 50\n",
      "17 51 51\n",
      "17 51 52\n",
      "17 51 53\n",
      "17 51 54\n",
      "17 51 55\n",
      "17 51 56\n",
      "17 51 57\n",
      "17 51 58\n",
      "17 51 59\n",
      "17 51 60\n",
      "17 51 61\n",
      "17 51 62\n",
      "17 51 63\n",
      "17 51 64\n",
      "17 51 65\n",
      "17 51 66\n",
      "17 51 67\n",
      "17 51 68\n",
      "17 51 69\n",
      "17 51 70\n",
      "17 51 71\n",
      "17 51 72\n",
      "17 51 73\n",
      "17 51 74\n",
      "17 51 75\n",
      "17 51 76\n",
      "17 51 77\n",
      "17 51 78\n",
      "17 51 79\n",
      "17 51 80\n",
      "17 51 81\n",
      "17 51 82\n",
      "17 51 83\n",
      "17 51 84\n",
      "17 51 85\n",
      "17 51 86\n",
      "17 51 87\n",
      "17 51 88\n",
      "17 51 89\n",
      "17 51 90\n",
      "17 51 91\n",
      "17 51 92\n",
      "17 51 93\n",
      "17 51 94\n",
      "17 51 95\n",
      "17 51 96\n",
      "17 51 97\n",
      "17 51 98\n",
      "17 51 99\n",
      "17 51 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.7336448598130841 77.74058069148779 \ttest: 0.7391304347826086 32.78844300471805\n",
      "retrain  2 :\n",
      "\ttrain: 0.7336448598130841 74.74730582941754 \ttest: 0.7391304347826086 31.365860790338978\n",
      "retrain  3 :\n",
      "\ttrain: 0.7336448598130841 73.19520487080052 \ttest: 0.7391304347826086 30.57826008333314\n",
      "retrain  4 :\n",
      "\ttrain: 0.7336448598130841 72.33945756241827 \ttest: 0.7391304347826086 30.09945000836922\n",
      "retrain  5 :\n",
      "\ttrain: 0.7336448598130841 71.82201449122937 \ttest: 0.7391304347826086 29.774554365658076\n",
      "retrain  6 :\n",
      "\ttrain: 0.7429906542056075 71.47450936715505 \ttest: 0.7717391304347826 29.53182421138051\n",
      "retrain  7 :\n",
      "\ttrain: 0.7429906542056075 71.21740277513909 \ttest: 0.7717391304347826 29.337558329492676\n",
      "retrain  8 :\n",
      "\ttrain: 0.7570093457943925 71.01232741412637 \ttest: 0.7934782608695652 29.175201787421848\n",
      "retrain  9 :\n",
      "\ttrain: 0.7616822429906542 70.84012601387303 \ttest: 0.8043478260869565 29.035988692023828\n",
      "retrain  10 :\n",
      "\ttrain: 0.7570093457943925 70.69073870848763 \ttest: 0.8152173913043478 28.91478650958742\n",
      "retrain  11 :\n",
      "\ttrain: 0.7570093457943925 70.55850670172185 \ttest: 0.8152173913043478 28.808242436142336\n",
      "retrain  12 :\n",
      "\ttrain: 0.7570093457943925 70.43996501934564 \ttest: 0.8152173913043478 28.71394545917198\n",
      "retrain  13 :\n",
      "\ttrain: 0.7570093457943925 70.3327904641895 \ttest: 0.8152173913043478 28.63003736656612\n",
      "retrain  14 :\n",
      "\ttrain: 0.7570093457943925 70.23529131238783 \ttest: 0.8152173913043478 28.555023032670768\n",
      "retrain  15 :\n",
      "\ttrain: 0.7570093457943925 70.14615361627028 \ttest: 0.8152173913043478 28.487669998639888\n",
      "retrain  16 :\n",
      "\ttrain: 0.7570093457943925 70.06431033162451 \ttest: 0.8152173913043478 28.42694899944417\n",
      "retrain  17 :\n",
      "\ttrain: 0.7570093457943925 69.9888700166941 \ttest: 0.8152173913043478 28.37199424578054\n",
      "retrain  18 :\n",
      "\ttrain: 0.7570093457943925 69.91907500272258 \ttest: 0.8152173913043478 28.32207415780084\n",
      "retrain  19 :\n",
      "\ttrain: 0.7570093457943925 69.85427461652478 \ttest: 0.8152173913043478 28.27656839334342\n",
      "retrain  20 :\n",
      "\ttrain: 0.7570093457943925 69.79390648348217 \ttest: 0.8152173913043478 28.234949208409578\n",
      "retrain  21 :\n",
      "\ttrain: 0.7570093457943925 69.73748248753029 \ttest: 0.8152173913043478 28.196766113218914\n",
      "retrain  22 :\n",
      "\ttrain: 0.7570093457943925 69.68457766034314 \ttest: 0.8152173913043478 28.16163318044611\n",
      "retrain  23 :\n",
      "\ttrain: 0.7570093457943925 69.63482108667495 \ttest: 0.8152173913043478 28.12921853983544\n",
      "retrain  24 :\n",
      "\ttrain: 0.7570093457943925 69.58788830879323 \ttest: 0.8152173913043478 28.09923568695504\n",
      "retrain  25 :\n",
      "\ttrain: 0.7570093457943925 69.54349490986942 \ttest: 0.8152173913043478 28.071436295450304\n",
      "retrain  26 :\n",
      "\ttrain: 0.7570093457943925 69.50139105837877 \ttest: 0.8152173913043478 28.045604270835064\n",
      "retrain  27 :\n",
      "\ttrain: 0.7570093457943925 69.46135685233443 \ttest: 0.8152173913043478 28.02155082577517\n",
      "retrain  28 :\n",
      "\ttrain: 0.7570093457943925 69.42319833679423 \ttest: 0.8152173913043478 27.99911039357984\n",
      "retrain  29 :\n",
      "\ttrain: 0.7570093457943925 69.38674409145278 \ttest: 0.8152173913043478 27.978137228542096\n",
      "retrain  30 :\n",
      "\ttrain: 0.7570093457943925 69.35184230240796 \ttest: 0.8152173913043478 27.958502569019164\n",
      "retrain  31 :\n",
      "\ttrain: 0.7570093457943925 69.31835824580797 \ttest: 0.8152173913043478 27.940092262010914\n",
      "retrain  32 :\n",
      "\ttrain: 0.7570093457943925 69.28617212224958 \ttest: 0.8152173913043478 27.922804766914087\n",
      "retrain  33 :\n",
      "\ttrain: 0.7570093457943925 69.25517719013605 \ttest: 0.8152173913043478 27.906549471616522\n",
      "retrain  34 :\n",
      "\ttrain: 0.7570093457943925 69.22527815408849 \ttest: 0.8152173913043478 27.891245266672918\n",
      "retrain  35 :\n",
      "\ttrain: 0.7570093457943925 69.19638977118225 \ttest: 0.8152173913043478 27.87681933346663\n",
      "retrain  36 :\n",
      "\ttrain: 0.7570093457943925 69.16843564343868 \ttest: 0.8152173913043478 27.86320611044949\n",
      "retrain  37 :\n",
      "\ttrain: 0.7570093457943925 69.14134716979353 \ttest: 0.8152173913043478 27.85034640814004\n",
      "retrain  38 :\n",
      "\ttrain: 0.7570093457943925 69.11506263481577 \ttest: 0.8152173913043478 27.83818664886315\n",
      "retrain  39 :\n",
      "\ttrain: 0.7570093457943925 69.08952641487477 \ttest: 0.8152173913043478 27.826678211487692\n",
      "retrain  40 :\n",
      "\ttrain: 0.7570093457943925 69.06468828534727 \ttest: 0.8152173913043478 27.815776864871154\n",
      "retrain  41 :\n",
      "\ttrain: 0.7570093457943925 69.04050281489725 \ttest: 0.8152173913043478 27.80544227651628\n",
      "retrain  42 :\n",
      "\ttrain: 0.7570093457943925 69.01692883492636 \ttest: 0.8152173913043478 27.795637585217914\n",
      "retrain  43 :\n",
      "\ttrain: 0.7570093457943925 68.99392897403534 \ttest: 0.8152173913043478 27.78632902833217\n",
      "retrain  44 :\n",
      "\ttrain: 0.7570093457943925 68.97146924881216 \ttest: 0.8152173913043478 27.777485615818772\n",
      "retrain  45 :\n",
      "\ttrain: 0.7570093457943925 68.94951870351052 \ttest: 0.8152173913043478 27.769078844455393\n",
      "retrain  46 :\n",
      "\ttrain: 0.7570093457943925 68.92804909224118 \ttest: 0.8152173913043478 27.761082446653703\n",
      "retrain  47 :\n",
      "\ttrain: 0.7570093457943925 68.9070345981961 \ttest: 0.8152173913043478 27.753472169160375\n",
      "retrain  48 :\n",
      "\ttrain: 0.7616822429906542 68.88645158518898 \ttest: 0.8043478260869565 27.746225577636928\n",
      "retrain  49 :\n",
      "\ttrain: 0.7616822429906542 68.86627837744548 \ttest: 0.8043478260869565 27.73932188370505\n",
      "retrain  50 :\n",
      "\ttrain: 0.7616822429906542 68.84649506413058 \ttest: 0.8043478260869565 27.73274179154114\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.80114   0.89809   0.84685       157\n",
      "           1    0.57895   0.38596   0.46316        57\n",
      "\n",
      "    accuracy                        0.76168       214\n",
      "   macro avg    0.69004   0.64203   0.65500       214\n",
      "weighted avg    0.74196   0.76168   0.74465       214\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.82895   0.92647   0.87500        68\n",
      "           1    0.68750   0.45833   0.55000        24\n",
      "\n",
      "    accuracy                        0.80435        92\n",
      "   macro avg    0.75822   0.69240   0.71250        92\n",
      "weighted avg    0.79205   0.80435   0.79022        92\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 17\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 51\n",
      "6 18 1\n",
      "10 30 2\n",
      "14 42 3\n",
      "14 42 4\n",
      "15 45 5\n",
      "16 48 6\n",
      "16 48 7\n",
      "17 51 8\n",
      "17 51 9\n",
      "17 51 10\n",
      "17 51 11\n",
      "17 51 12\n",
      "17 51 13\n",
      "17 51 14\n",
      "17 51 15\n",
      "17 51 16\n",
      "17 51 17\n",
      "17 51 18\n",
      "17 51 19\n",
      "17 51 20\n",
      "17 51 21\n",
      "17 51 22\n",
      "17 51 23\n",
      "17 51 24\n",
      "17 51 25\n",
      "17 51 26\n",
      "17 51 27\n",
      "17 51 28\n",
      "17 51 29\n",
      "17 51 30\n",
      "17 51 31\n",
      "17 51 32\n",
      "17 51 33\n",
      "17 51 34\n",
      "17 51 35\n",
      "17 51 36\n",
      "17 51 37\n",
      "17 51 38\n",
      "17 51 39\n",
      "17 51 40\n",
      "17 51 41\n",
      "17 51 42\n",
      "17 51 43\n",
      "17 51 44\n",
      "17 51 45\n",
      "17 51 46\n",
      "17 51 47\n",
      "17 51 48\n",
      "17 51 49\n",
      "17 51 50\n",
      "17 51 51\n",
      "17 51 52\n",
      "17 51 53\n",
      "17 51 54\n",
      "17 51 55\n",
      "17 51 56\n",
      "17 51 57\n",
      "17 51 58\n",
      "17 51 59\n",
      "17 51 60\n",
      "17 51 61\n",
      "17 51 62\n",
      "17 51 63\n",
      "17 51 64\n",
      "17 51 65\n",
      "17 51 66\n",
      "17 51 67\n",
      "17 51 68\n",
      "17 51 69\n",
      "17 51 70\n",
      "17 51 71\n",
      "17 51 72\n",
      "17 51 73\n",
      "17 51 74\n",
      "17 51 75\n",
      "17 51 76\n",
      "17 51 77\n",
      "17 51 78\n",
      "17 51 79\n",
      "17 51 80\n",
      "17 51 81\n",
      "17 51 82\n",
      "17 51 83\n",
      "17 51 84\n",
      "17 51 85\n",
      "17 51 86\n",
      "17 51 87\n",
      "17 51 88\n",
      "17 51 89\n",
      "17 51 90\n",
      "17 51 91\n",
      "17 51 92\n",
      "17 51 93\n",
      "17 51 94\n",
      "17 51 95\n",
      "17 51 96\n",
      "17 51 97\n",
      "17 51 98\n",
      "17 51 99\n",
      "17 51 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.7336448598130841 76.55865110243494 \ttest: 0.7391304347826086 33.603786891996776\n",
      "retrain  2 :\n",
      "\ttrain: 0.7336448598130841 73.15422714749872 \ttest: 0.7391304347826086 32.853254884669134\n",
      "retrain  3 :\n",
      "\ttrain: 0.7336448598130841 71.37996668368073 \ttest: 0.7391304347826086 32.55893079844337\n",
      "retrain  4 :\n",
      "\ttrain: 0.7336448598130841 70.3237611523027 \ttest: 0.7391304347826086 32.443108750424834\n",
      "retrain  5 :\n",
      "\ttrain: 0.7476635514018691 69.59426509488459 \ttest: 0.7391304347826086 32.396018094110154\n",
      "retrain  6 :\n",
      "\ttrain: 0.7663551401869159 69.02405378548369 \ttest: 0.7608695652173914 32.37540055510042\n",
      "retrain  7 :\n",
      "\ttrain: 0.7663551401869159 68.54010302996254 \ttest: 0.782608695652174 32.365407363765115\n",
      "retrain  8 :\n",
      "\ttrain: 0.7663551401869159 68.10944602117462 \ttest: 0.7717391304347826 32.360353177149406\n",
      "retrain  9 :\n",
      "\ttrain: 0.7757009345794392 67.71640037927658 \ttest: 0.7608695652173914 32.35836225339445\n",
      "retrain  10 :\n",
      "\ttrain: 0.7757009345794392 67.3528962132452 \ttest: 0.7608695652173914 32.35890169081667\n",
      "retrain  11 :\n",
      "\ttrain: 0.7757009345794392 67.01429930486921 \ttest: 0.7608695652173914 32.36184447114823\n",
      "retrain  12 :\n",
      "\ttrain: 0.7710280373831776 66.69757991344588 \ttest: 0.7608695652173914 32.36713435057653\n",
      "retrain  13 :\n",
      "\ttrain: 0.7710280373831776 66.40049982294458 \ttest: 0.7608695652173914 32.374683746148406\n",
      "retrain  14 :\n",
      "\ttrain: 0.7710280373831776 66.12124710682197 \ttest: 0.7608695652173914 32.38435730061052\n",
      "retrain  15 :\n",
      "\ttrain: 0.7710280373831776 65.858269261342 \ttest: 0.7608695652173914 32.39598290868277\n",
      "retrain  16 :\n",
      "\ttrain: 0.7710280373831776 65.6101944633487 \ttest: 0.7608695652173914 32.4093681269473\n",
      "retrain  17 :\n",
      "\ttrain: 0.7710280373831776 65.37579194094322 \ttest: 0.7608695652173914 32.424314460333136\n",
      "retrain  18 :\n",
      "\ttrain: 0.7710280373831776 65.15394968669143 \ttest: 0.7608695652173914 32.440627708617725\n",
      "retrain  19 :\n",
      "\ttrain: 0.7710280373831776 64.94365991627319 \ttest: 0.7608695652173914 32.45812459910535\n",
      "retrain  20 :\n",
      "\ttrain: 0.7710280373831776 64.7440081040465 \ttest: 0.7608695652173914 32.476636511837654\n",
      "retrain  21 :\n",
      "\ttrain: 0.7710280373831776 64.5541638249594 \ttest: 0.7608695652173914 32.496011134175184\n",
      "retrain  22 :\n",
      "\ttrain: 0.7710280373831776 64.3733726717584 \ttest: 0.7608695652173914 32.51611273684439\n",
      "retrain  23 :\n",
      "\ttrain: 0.7710280373831776 64.20094895282456 \ttest: 0.7608695652173914 32.53682158975727\n",
      "retrain  24 :\n",
      "\ttrain: 0.7710280373831776 64.03626904956789 \ttest: 0.7608695652173914 32.55803288374018\n",
      "retrain  25 :\n",
      "\ttrain: 0.7710280373831776 63.87876537511317 \ttest: 0.7608695652173914 32.57965540595616\n",
      "retrain  26 :\n",
      "\ttrain: 0.7710280373831776 63.72792089471897 \ttest: 0.7608695652173914 32.601610130291114\n",
      "retrain  27 :\n",
      "\ttrain: 0.7710280373831776 63.583264171378744 \ttest: 0.7608695652173914 32.62382882317201\n",
      "retrain  28 :\n",
      "\ttrain: 0.7710280373831776 63.44436489881984 \ttest: 0.7608695652173914 32.646252723783334\n",
      "retrain  29 :\n",
      "\ttrain: 0.7710280373831776 63.31082988281627 \ttest: 0.7608695652173914 32.66883133004489\n",
      "retrain  30 :\n",
      "\ttrain: 0.794392523364486 63.182299431548714 \ttest: 0.7391304347826086 32.691521303839664\n",
      "retrain  31 :\n",
      "\ttrain: 0.794392523364486 63.05844411673608 \ttest: 0.7391304347826086 32.71428549778048\n",
      "retrain  32 :\n",
      "\ttrain: 0.794392523364486 62.93896186914226 \ttest: 0.7391304347826086 32.73709209909847\n",
      "retrain  33 :\n",
      "\ttrain: 0.794392523364486 62.82357537449485 \ttest: 0.7391304347826086 32.759913882505884\n",
      "retrain  34 :\n",
      "\ttrain: 0.794392523364486 62.71202973856558 \ttest: 0.7391304347826086 32.782727562083124\n",
      "retrain  35 :\n",
      "\ttrain: 0.794392523364486 62.60409039295355 \ttest: 0.7391304347826086 32.80551323165679\n",
      "retrain  36 :\n",
      "\ttrain: 0.794392523364486 62.49954121585088 \ttest: 0.7391304347826086 32.82825388329411\n",
      "retrain  37 :\n",
      "\ttrain: 0.794392523364486 62.398182844671474 \ttest: 0.7391304347826086 32.850934994126845\n",
      "retrain  38 :\n",
      "\ttrain: 0.794392523364486 62.29983115984652 \ttest: 0.7391304347826086 32.87354417252631\n",
      "retrain  39 :\n",
      "\ttrain: 0.794392523364486 62.20431592130968 \ttest: 0.7391304347826086 32.89607085555335\n",
      "retrain  40 :\n",
      "\ttrain: 0.794392523364486 62.11147954121162 \ttest: 0.7391304347826086 32.91850605051899\n",
      "retrain  41 :\n",
      "\ttrain: 0.794392523364486 62.02117597821794 \ttest: 0.7391304347826086 32.9408421143671\n",
      "retrain  42 :\n",
      "\ttrain: 0.794392523364486 61.933269740371365 \ttest: 0.7391304347826086 32.963072565402385\n",
      "retrain  43 :\n",
      "\ttrain: 0.794392523364486 61.84763498495063 \ttest: 0.7391304347826086 32.98519192262388\n",
      "retrain  44 :\n",
      "\ttrain: 0.7990654205607477 61.7641547050501 \ttest: 0.7391304347826086 33.007195568580904\n",
      "retrain  45 :\n",
      "\ttrain: 0.7990654205607477 61.682719993751235 \ttest: 0.7391304347826086 33.02907963224828\n",
      "retrain  46 :\n",
      "\ttrain: 0.7990654205607477 61.60322937777468 \ttest: 0.7391304347826086 33.05084088892399\n",
      "retrain  47 :\n",
      "\ttrain: 0.7990654205607477 61.52558821340379 \ttest: 0.7391304347826086 33.072476674591876\n",
      "retrain  48 :\n",
      "\ttrain: 0.7990654205607477 61.44970813826763 \ttest: 0.7391304347826086 33.09398481257149\n",
      "retrain  49 :\n",
      "\ttrain: 0.7990654205607477 61.37550657327989 \ttest: 0.7391304347826086 33.115363550603476\n",
      "retrain  50 :\n",
      "\ttrain: 0.7990654205607477 61.302906269654834 \ttest: 0.7391304347826086 33.136611506797905\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.82022   0.92994   0.87164       157\n",
      "           1    0.69444   0.43860   0.53763        57\n",
      "\n",
      "    accuracy                        0.79907       214\n",
      "   macro avg    0.75733   0.68427   0.70464       214\n",
      "weighted avg    0.78672   0.79907   0.78268       214\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.77500   0.91176   0.83784        68\n",
      "           1    0.50000   0.25000   0.33333        24\n",
      "\n",
      "    accuracy                        0.73913        92\n",
      "   macro avg    0.63750   0.58088   0.58559        92\n",
      "weighted avg    0.70326   0.73913   0.70623        92\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 17\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 51\n",
      "9 27 1\n",
      "13 39 2\n",
      "16 48 3\n",
      "16 48 4\n",
      "16 48 5\n",
      "16 48 6\n",
      "16 48 7\n",
      "16 48 8\n",
      "16 48 9\n",
      "16 48 10\n",
      "16 48 11\n",
      "16 48 12\n",
      "16 48 13\n",
      "17 51 14\n",
      "17 51 15\n",
      "17 51 16\n",
      "17 51 17\n",
      "17 51 18\n",
      "17 51 19\n",
      "17 51 20\n",
      "17 51 21\n",
      "17 51 22\n",
      "17 51 23\n",
      "17 51 24\n",
      "17 51 25\n",
      "17 51 26\n",
      "17 51 27\n",
      "17 51 28\n",
      "17 51 29\n",
      "17 51 30\n",
      "17 51 31\n",
      "17 51 32\n",
      "17 51 33\n",
      "17 51 34\n",
      "17 51 35\n",
      "17 51 36\n",
      "17 51 37\n",
      "17 51 38\n",
      "17 51 39\n",
      "17 51 40\n",
      "17 51 41\n",
      "17 51 42\n",
      "17 51 43\n",
      "17 51 44\n",
      "17 51 45\n",
      "17 51 46\n",
      "17 51 47\n",
      "17 51 48\n",
      "17 51 49\n",
      "17 51 50\n",
      "17 51 51\n",
      "17 51 52\n",
      "17 51 53\n",
      "17 51 54\n",
      "17 51 55\n",
      "17 51 56\n",
      "17 51 57\n",
      "17 51 58\n",
      "17 51 59\n",
      "17 51 60\n",
      "17 51 61\n",
      "17 51 62\n",
      "17 51 63\n",
      "17 51 64\n",
      "17 51 65\n",
      "17 51 66\n",
      "17 51 67\n",
      "17 51 68\n",
      "17 51 69\n",
      "17 51 70\n",
      "17 51 71\n",
      "17 51 72\n",
      "17 51 73\n",
      "17 51 74\n",
      "17 51 75\n",
      "17 51 76\n",
      "17 51 77\n",
      "17 51 78\n",
      "17 51 79\n",
      "17 51 80\n",
      "17 51 81\n",
      "17 51 82\n",
      "17 51 83\n",
      "17 51 84\n",
      "17 51 85\n",
      "17 51 86\n",
      "17 51 87\n",
      "17 51 88\n",
      "17 51 89\n",
      "17 51 90\n",
      "17 51 91\n",
      "17 51 92\n",
      "17 51 93\n",
      "17 51 94\n",
      "17 51 95\n",
      "17 51 96\n",
      "17 51 97\n",
      "17 51 98\n",
      "17 51 99\n",
      "17 51 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.7336448598130841 76.86361079890074 \ttest: 0.7391304347826086 33.04393119890847\n",
      "retrain  2 :\n",
      "\ttrain: 0.7336448598130841 73.21890541770046 \ttest: 0.7391304347826086 31.806055090738596\n",
      "retrain  3 :\n",
      "\ttrain: 0.7336448598130841 71.23152511861825 \ttest: 0.7391304347826086 31.16775271199644\n",
      "retrain  4 :\n",
      "\ttrain: 0.7757009345794392 70.08762940988862 \ttest: 0.7282608695652174 30.825557379655802\n",
      "retrain  5 :\n",
      "\ttrain: 0.7850467289719626 69.37180483629658 \ttest: 0.7282608695652174 30.631713923125844\n",
      "retrain  6 :\n",
      "\ttrain: 0.7850467289719626 68.88036401294985 \ttest: 0.7608695652173914 30.515117546090025\n",
      "retrain  7 :\n",
      "\ttrain: 0.7850467289719626 68.5134573365078 \ttest: 0.75 30.440946407005008\n",
      "retrain  8 :\n",
      "\ttrain: 0.7850467289719626 68.22097650983422 \ttest: 0.75 30.391515233506723\n",
      "retrain  9 :\n",
      "\ttrain: 0.7850467289719626 67.97674862601943 \ttest: 0.75 30.357390390559523\n",
      "retrain  10 :\n",
      "\ttrain: 0.7850467289719626 67.76634074998752 \ttest: 0.75 30.333244012991496\n",
      "retrain  11 :\n",
      "\ttrain: 0.7850467289719626 67.58125063602603 \ttest: 0.75 30.31588163829539\n",
      "retrain  12 :\n",
      "\ttrain: 0.7850467289719626 67.4160937510396 \ttest: 0.75 30.30327674426538\n",
      "retrain  13 :\n",
      "\ttrain: 0.7850467289719626 67.26721008435561 \ttest: 0.75 30.294080335750362\n",
      "retrain  14 :\n",
      "\ttrain: 0.7850467289719626 67.13195342446434 \ttest: 0.75 30.287360133911307\n",
      "retrain  15 :\n",
      "\ttrain: 0.7850467289719626 67.00831454500101 \ttest: 0.75 30.282454209905566\n",
      "retrain  16 :\n",
      "\ttrain: 0.7850467289719626 66.89471143188428 \ttest: 0.75 30.278883938089887\n",
      "retrain  17 :\n",
      "\ttrain: 0.7850467289719626 66.78986552758222 \ttest: 0.75 30.2762992113943\n",
      "retrain  18 :\n",
      "\ttrain: 0.7850467289719626 66.69272398229124 \ttest: 0.75 30.27444220096811\n",
      "retrain  19 :\n",
      "\ttrain: 0.7850467289719626 66.60240772278149 \ttest: 0.75 30.27312240960125\n",
      "retrain  20 :\n",
      "\ttrain: 0.7850467289719626 66.51817485288363 \ttest: 0.75 30.272198986879005\n",
      "retrain  21 :\n",
      "\ttrain: 0.7850467289719626 66.43939372695975 \ttest: 0.75 30.27156793249258\n",
      "retrain  22 :\n",
      "\ttrain: 0.7850467289719626 66.3655224918961 \ttest: 0.75 30.27115270814148\n",
      "retrain  23 :\n",
      "\ttrain: 0.7850467289719626 66.296093178323 \ttest: 0.75 30.270897287144923\n",
      "retrain  24 :\n",
      "\ttrain: 0.7850467289719626 66.23069912175112 \ttest: 0.75 30.270760977693623\n",
      "retrain  25 :\n",
      "\ttrain: 0.7850467289719626 66.16898489473624 \ttest: 0.75 30.270714551379108\n",
      "retrain  26 :\n",
      "\ttrain: 0.7850467289719626 66.11063817343297 \ttest: 0.75 30.270737339579576\n",
      "retrain  27 :\n",
      "\ttrain: 0.7850467289719626 66.05538311713264 \ttest: 0.75 30.270815051174054\n",
      "retrain  28 :\n",
      "\ttrain: 0.7850467289719626 66.00297494428355 \ttest: 0.75 30.27093812981435\n",
      "retrain  29 :\n",
      "\ttrain: 0.7850467289719626 65.9531954626002 \ttest: 0.75 30.27110051593023\n",
      "retrain  30 :\n",
      "\ttrain: 0.7850467289719626 65.90584936504828 \ttest: 0.75 30.271298713056165\n",
      "retrain  31 :\n",
      "\ttrain: 0.7850467289719626 65.86076114410639 \ttest: 0.75 30.271531083471057\n",
      "retrain  32 :\n",
      "\ttrain: 0.7850467289719626 65.81777250769488 \ttest: 0.75 30.27179731697907\n",
      "retrain  33 :\n",
      "\ttrain: 0.7850467289719626 65.77674020410299 \ttest: 0.75 30.272098030669916\n",
      "retrain  34 :\n",
      "\ttrain: 0.7850467289719626 65.73753418190739 \ttest: 0.75 30.272434467942546\n",
      "retrain  35 :\n",
      "\ttrain: 0.7850467289719626 65.70003602551895 \ttest: 0.75 30.272808272879253\n",
      "retrain  36 :\n",
      "\ttrain: 0.7850467289719626 65.66413761854588 \ttest: 0.75 30.273221321899175\n",
      "retrain  37 :\n",
      "\ttrain: 0.7850467289719626 65.62973999631137 \ttest: 0.75 30.27367559900192\n",
      "retrain  38 :\n",
      "\ttrain: 0.7850467289719626 65.59675235614333 \ttest: 0.75 30.274173104207144\n",
      "retrain  39 :\n",
      "\ttrain: 0.7850467289719626 65.5650911998608 \ttest: 0.75 30.27471578727894\n",
      "retrain  40 :\n",
      "\ttrain: 0.7850467289719626 65.53467958753572 \ttest: 0.75 30.275305500700192\n",
      "retrain  41 :\n",
      "\ttrain: 0.7850467289719626 65.50544648534495 \ttest: 0.75 30.275943967283638\n",
      "retrain  42 :\n",
      "\ttrain: 0.7850467289719626 65.47732619334315 \ttest: 0.75 30.27663275888616\n",
      "retrain  43 :\n",
      "\ttrain: 0.7850467289719626 65.4502578414238 \ttest: 0.75 30.277373283515644\n",
      "retrain  44 :\n",
      "\ttrain: 0.7850467289719626 65.42418494371505 \ttest: 0.75 30.278166778747742\n",
      "retrain  45 :\n",
      "\ttrain: 0.7850467289719626 65.39905500326812 \ttest: 0.75 30.27901430985148\n",
      "retrain  46 :\n",
      "\ttrain: 0.7850467289719626 65.37481916021372 \ttest: 0.75 30.279916771391797\n",
      "retrain  47 :\n",
      "\ttrain: 0.7850467289719626 65.35143187764078 \ttest: 0.75 30.280874891361638\n",
      "retrain  48 :\n",
      "\ttrain: 0.7850467289719626 65.32885066034154 \ttest: 0.75 30.281889237115273\n",
      "retrain  49 :\n",
      "\ttrain: 0.7850467289719626 65.30703580230116 \ttest: 0.75 30.28296022254424\n",
      "retrain  50 :\n",
      "\ttrain: 0.7850467289719626 65.28595015941795 \ttest: 0.75 30.28408811606819\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.81006   0.92357   0.86310       157\n",
      "           1    0.65714   0.40351   0.50000        57\n",
      "\n",
      "    accuracy                        0.78505       214\n",
      "   macro avg    0.73360   0.66354   0.68155       214\n",
      "weighted avg    0.76933   0.78505   0.76638       214\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.77108   0.94118   0.84768        68\n",
      "           1    0.55556   0.20833   0.30303        24\n",
      "\n",
      "    accuracy                        0.75000        92\n",
      "   macro avg    0.66332   0.57475   0.57536        92\n",
      "weighted avg    0.71486   0.75000   0.70560        92\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 17\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 51\n",
      "8 24 1\n",
      "12 36 2\n",
      "13 39 3\n",
      "15 45 4\n",
      "16 48 5\n",
      "16 48 6\n",
      "16 48 7\n",
      "16 48 8\n",
      "17 51 9\n",
      "17 51 10\n",
      "17 51 11\n",
      "17 51 12\n",
      "17 51 13\n",
      "17 51 14\n",
      "18 54 15\n",
      "18 54 16\n",
      "18 54 17\n",
      "18 54 18\n",
      "18 54 19\n",
      "18 54 20\n",
      "18 54 21\n",
      "18 54 22\n",
      "18 54 23\n",
      "18 54 24\n",
      "18 54 25\n",
      "18 54 26\n",
      "18 54 27\n",
      "18 54 28\n",
      "18 54 29\n",
      "18 54 30\n",
      "18 54 31\n",
      "18 54 32\n",
      "18 54 33\n",
      "18 54 34\n",
      "18 54 35\n",
      "18 54 36\n",
      "18 54 37\n",
      "18 54 38\n",
      "18 54 39\n",
      "18 54 40\n",
      "18 54 41\n",
      "18 54 42\n",
      "18 54 43\n",
      "18 54 44\n",
      "18 54 45\n",
      "18 54 46\n",
      "18 54 47\n",
      "18 54 48\n",
      "18 54 49\n",
      "18 54 50\n",
      "18 54 51\n",
      "18 54 52\n",
      "18 54 53\n",
      "18 54 54\n",
      "18 54 55\n",
      "18 54 56\n",
      "18 54 57\n",
      "18 54 58\n",
      "18 54 59\n",
      "18 54 60\n",
      "18 54 61\n",
      "18 54 62\n",
      "18 54 63\n",
      "18 54 64\n",
      "18 54 65\n",
      "18 54 66\n",
      "18 54 67\n",
      "18 54 68\n",
      "18 54 69\n",
      "18 54 70\n",
      "18 54 71\n",
      "18 54 72\n",
      "18 54 73\n",
      "18 54 74\n",
      "18 54 75\n",
      "18 54 76\n",
      "18 54 77\n",
      "18 54 78\n",
      "18 54 79\n",
      "18 54 80\n",
      "18 54 81\n",
      "18 54 82\n",
      "18 54 83\n",
      "18 54 84\n",
      "18 54 85\n",
      "18 54 86\n",
      "18 54 87\n",
      "18 54 88\n",
      "18 54 89\n",
      "18 54 90\n",
      "18 54 91\n",
      "18 54 92\n",
      "18 54 93\n",
      "18 54 94\n",
      "18 54 95\n",
      "18 54 96\n",
      "18 54 97\n",
      "18 54 98\n",
      "18 54 99\n",
      "18 54 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.7336448598130841 77.19651203385767 \ttest: 0.7391304347826086 32.6784113232309\n",
      "retrain  2 :\n",
      "\ttrain: 0.7336448598130841 73.7862975738544 \ttest: 0.7391304347826086 31.352650142158055\n",
      "retrain  3 :\n",
      "\ttrain: 0.7336448598130841 71.89141594048948 \ttest: 0.7391304347826086 30.745337011273357\n",
      "retrain  4 :\n",
      "\ttrain: 0.7336448598130841 70.74784691505533 \ttest: 0.7391304347826086 30.47269496069714\n",
      "retrain  5 :\n",
      "\ttrain: 0.7663551401869159 69.9903440865565 \ttest: 0.7391304347826086 30.356862453383705\n",
      "retrain  6 :\n",
      "\ttrain: 0.7757009345794392 69.44472614180387 \ttest: 0.7391304347826086 30.316863303887207\n",
      "retrain  7 :\n",
      "\ttrain: 0.7850467289719626 69.02507495479541 \ttest: 0.75 30.31510415814507\n",
      "retrain  8 :\n",
      "\ttrain: 0.7850467289719626 68.68658466371761 \ttest: 0.75 30.33344826128662\n",
      "retrain  9 :\n",
      "\ttrain: 0.7850467289719626 68.40423386752721 \ttest: 0.7608695652173914 30.36271405180599\n",
      "retrain  10 :\n",
      "\ttrain: 0.7850467289719626 68.16298937482273 \ttest: 0.7608695652173914 30.398004904660496\n",
      "retrain  11 :\n",
      "\ttrain: 0.7850467289719626 67.95316541665754 \ttest: 0.7608695652173914 30.43657228910692\n",
      "retrain  12 :\n",
      "\ttrain: 0.7850467289719626 67.76813166224382 \ttest: 0.7608695652173914 30.476800945091888\n",
      "retrain  13 :\n",
      "\ttrain: 0.7850467289719626 67.60312252616288 \ttest: 0.7608695652173914 30.517705480717208\n",
      "retrain  14 :\n",
      "\ttrain: 0.7850467289719626 67.45458199228275 \ttest: 0.75 30.558668386932016\n",
      "retrain  15 :\n",
      "\ttrain: 0.7850467289719626 67.31978051076462 \ttest: 0.75 30.599296692797193\n",
      "retrain  16 :\n",
      "\ttrain: 0.7850467289719626 67.19657731509119 \ttest: 0.75 30.63933958446622\n",
      "retrain  17 :\n",
      "\ttrain: 0.7850467289719626 67.08326489760356 \ttest: 0.75 30.678638870075787\n",
      "retrain  18 :\n",
      "\ttrain: 0.7850467289719626 66.9784625976908 \ttest: 0.75 30.717098004073172\n",
      "retrain  19 :\n",
      "\ttrain: 0.7850467289719626 66.88104114918264 \ttest: 0.75 30.754662080894153\n",
      "retrain  20 :\n",
      "\ttrain: 0.780373831775701 66.79006767036606 \ttest: 0.7282608695652174 30.791304576648624\n",
      "retrain  21 :\n",
      "\ttrain: 0.780373831775701 66.70476467887872 \ttest: 0.7282608695652174 30.827018384845374\n",
      "retrain  22 :\n",
      "\ttrain: 0.7757009345794392 66.62447902553944 \ttest: 0.7282608695652174 30.861809661044443\n",
      "retrain  23 :\n",
      "\ttrain: 0.7757009345794392 66.54865801239919 \ttest: 0.7282608695652174 30.89569354596229\n",
      "retrain  24 :\n",
      "\ttrain: 0.7757009345794392 66.47683081310353 \ttest: 0.7282608695652174 30.92869116708896\n",
      "retrain  25 :\n",
      "\ttrain: 0.7757009345794392 66.40859386659582 \ttest: 0.7282608695652174 30.96082752291938\n",
      "retrain  26 :\n",
      "\ttrain: 0.7757009345794392 66.3435992863329 \ttest: 0.7282608695652174 30.99212998363171\n",
      "retrain  27 :\n",
      "\ttrain: 0.7757009345794392 66.28154558331711 \ttest: 0.7282608695652174 31.022627226533388\n",
      "retrain  28 :\n",
      "\ttrain: 0.7757009345794392 66.22217018193945 \ttest: 0.7282608695652174 31.052348480691244\n",
      "retrain  29 :\n",
      "\ttrain: 0.7757009345794392 66.16524333734021 \ttest: 0.7282608695652174 31.081322992995926\n",
      "retrain  30 :\n",
      "\ttrain: 0.7757009345794392 66.11056315744648 \ttest: 0.7282608695652174 31.109579653760964\n",
      "retrain  31 :\n",
      "\ttrain: 0.7757009345794392 66.05795150244185 \ttest: 0.7282608695652174 31.137146737816632\n",
      "retrain  32 :\n",
      "\ttrain: 0.7757009345794392 66.00725058624244 \ttest: 0.7282608695652174 31.16405172951993\n",
      "retrain  33 :\n",
      "\ttrain: 0.7757009345794392 65.95832014348807 \ttest: 0.7282608695652174 31.190321208875012\n",
      "retrain  34 :\n",
      "\ttrain: 0.7757009345794392 65.91103505506567 \ttest: 0.7282608695652174 31.215980782186527\n",
      "retrain  35 :\n",
      "\ttrain: 0.7757009345794392 65.86528334771855 \ttest: 0.7282608695652174 31.241055045125105\n",
      "retrain  36 :\n",
      "\ttrain: 0.7757009345794392 65.82096450063926 \ttest: 0.7282608695652174 31.26556756929708\n",
      "retrain  37 :\n",
      "\ttrain: 0.7757009345794392 65.77798800538534 \ttest: 0.7282608695652174 31.289540905743532\n",
      "retrain  38 :\n",
      "\ttrain: 0.7757009345794392 65.73627213594389 \ttest: 0.7282608695652174 31.312996600499105\n",
      "retrain  39 :\n",
      "\ttrain: 0.7757009345794392 65.6957428940079 \ttest: 0.7282608695652174 31.335955218594904\n",
      "retrain  40 :\n",
      "\ttrain: 0.7757009345794392 65.65633310103438 \ttest: 0.7282608695652174 31.35843637381778\n",
      "retrain  41 :\n",
      "\ttrain: 0.7757009345794392 65.61798161382718 \ttest: 0.7282608695652174 31.38045876222789\n",
      "retrain  42 :\n",
      "\ttrain: 0.7757009345794392 65.58063264452312 \ttest: 0.7282608695652174 31.402040197951305\n",
      "retrain  43 :\n",
      "\ttrain: 0.7757009345794392 65.54423516918227 \ttest: 0.7282608695652174 31.423197650150914\n",
      "retrain  44 :\n",
      "\ttrain: 0.7757009345794392 65.50874241186999 \ttest: 0.7282608695652174 31.443947280368917\n",
      "retrain  45 :\n",
      "\ttrain: 0.7757009345794392 65.4741113932969 \ttest: 0.7282608695652174 31.464304479653\n",
      "retrain  46 :\n",
      "\ttrain: 0.780373831775701 65.44030253486345 \ttest: 0.7282608695652174 31.484283905043636\n",
      "retrain  47 :\n",
      "\ttrain: 0.780373831775701 65.40727931041276 \ttest: 0.7282608695652174 31.503899515124505\n",
      "retrain  48 :\n",
      "\ttrain: 0.780373831775701 65.37500793919659 \ttest: 0.7282608695652174 31.523164604431997\n",
      "retrain  49 :\n",
      "\ttrain: 0.780373831775701 65.3434571145516 \ttest: 0.7282608695652174 31.54209183659089\n",
      "retrain  50 :\n",
      "\ttrain: 0.780373831775701 65.31259776360739 \ttest: 0.7282608695652174 31.560693276096337\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.82353   0.89172   0.85627       157\n",
      "           1    0.61364   0.47368   0.53465        57\n",
      "\n",
      "    accuracy                        0.78037       214\n",
      "   macro avg    0.71858   0.68270   0.69546       214\n",
      "weighted avg    0.76762   0.78037   0.77061       214\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.83077   0.79412   0.81203        68\n",
      "           1    0.48148   0.54167   0.50980        24\n",
      "\n",
      "    accuracy                        0.72826        92\n",
      "   macro avg    0.65613   0.66789   0.66092        92\n",
      "weighted avg    0.73965   0.72826   0.73319        92\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 18\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 54\n",
      "7 21 1\n",
      "12 36 2\n",
      "15 45 3\n",
      "16 48 4\n",
      "16 48 5\n",
      "16 48 6\n",
      "16 48 7\n",
      "16 48 8\n",
      "16 48 9\n",
      "16 48 10\n",
      "16 48 11\n",
      "16 48 12\n",
      "16 48 13\n",
      "16 48 14\n",
      "16 48 15\n",
      "16 48 16\n",
      "16 48 17\n",
      "16 48 18\n",
      "16 48 19\n",
      "16 48 20\n",
      "16 48 21\n",
      "16 48 22\n",
      "16 48 23\n",
      "16 48 24\n",
      "16 48 25\n",
      "16 48 26\n",
      "16 48 27\n",
      "16 48 28\n",
      "16 48 29\n",
      "16 48 30\n",
      "16 48 31\n",
      "16 48 32\n",
      "16 48 33\n",
      "16 48 34\n",
      "16 48 35\n",
      "16 48 36\n",
      "16 48 37\n",
      "16 48 38\n",
      "16 48 39\n",
      "16 48 40\n",
      "16 48 41\n",
      "16 48 42\n",
      "16 48 43\n",
      "16 48 44\n",
      "16 48 45\n",
      "16 48 46\n",
      "16 48 47\n",
      "16 48 48\n",
      "16 48 49\n",
      "16 48 50\n",
      "16 48 51\n",
      "16 48 52\n",
      "16 48 53\n",
      "16 48 54\n",
      "16 48 55\n",
      "16 48 56\n",
      "16 48 57\n",
      "16 48 58\n",
      "16 48 59\n",
      "16 48 60\n",
      "16 48 61\n",
      "16 48 62\n",
      "16 48 63\n",
      "16 48 64\n",
      "16 48 65\n",
      "16 48 66\n",
      "16 48 67\n",
      "16 48 68\n",
      "16 48 69\n",
      "16 48 70\n",
      "16 48 71\n",
      "16 48 72\n",
      "16 48 73\n",
      "16 48 74\n",
      "16 48 75\n",
      "16 48 76\n",
      "16 48 77\n",
      "16 48 78\n",
      "16 48 79\n",
      "16 48 80\n",
      "16 48 81\n",
      "16 48 82\n",
      "16 48 83\n",
      "16 48 84\n",
      "16 48 85\n",
      "16 48 86\n",
      "16 48 87\n",
      "16 48 88\n",
      "16 48 89\n",
      "16 48 90\n",
      "16 48 91\n",
      "16 48 92\n",
      "16 48 93\n",
      "16 48 94\n",
      "16 48 95\n",
      "16 48 96\n",
      "16 48 97\n",
      "16 48 98\n",
      "16 48 99\n",
      "16 48 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.7336448598130841 78.05924576015337 \ttest: 0.7391304347826086 32.771096234151116\n",
      "retrain  2 :\n",
      "\ttrain: 0.7336448598130841 75.06659972995269 \ttest: 0.7391304347826086 31.3445065379582\n",
      "retrain  3 :\n",
      "\ttrain: 0.7336448598130841 73.41765221194223 \ttest: 0.7391304347826086 30.590361043162996\n",
      "retrain  4 :\n",
      "\ttrain: 0.7336448598130841 72.44640543267514 \ttest: 0.7391304347826086 30.177911553781946\n",
      "retrain  5 :\n",
      "\ttrain: 0.7757009345794392 71.81768079584236 \ttest: 0.75 29.940120182484577\n",
      "retrain  6 :\n",
      "\ttrain: 0.7757009345794392 71.36805881186322 \ttest: 0.75 29.79465604777568\n",
      "retrain  7 :\n",
      "\ttrain: 0.7757009345794392 71.01797404303326 \ttest: 0.7391304347826086 29.700609636202216\n",
      "retrain  8 :\n",
      "\ttrain: 0.7850467289719626 70.72794154407666 \ttest: 0.75 29.63706795182745\n",
      "retrain  9 :\n",
      "\ttrain: 0.780373831775701 70.47763703224936 \ttest: 0.7608695652173914 29.59287566645297\n",
      "retrain  10 :\n",
      "\ttrain: 0.780373831775701 70.25601117782341 \ttest: 0.7608695652173914 29.561758532054615\n",
      "retrain  11 :\n",
      "\ttrain: 0.780373831775701 70.05660774100677 \ttest: 0.7608695652173914 29.539971933935036\n",
      "retrain  12 :\n",
      "\ttrain: 0.780373831775701 69.87532570583738 \ttest: 0.7608695652173914 29.52514192478162\n",
      "retrain  13 :\n",
      "\ttrain: 0.780373831775701 69.70933356004757 \ttest: 0.7608695652173914 29.51567667306262\n",
      "retrain  14 :\n",
      "\ttrain: 0.780373831775701 69.55653072335852 \ttest: 0.7608695652173914 29.51045606260863\n",
      "retrain  15 :\n",
      "\ttrain: 0.780373831775701 69.41527145702813 \ttest: 0.7608695652173914 29.508660394211628\n",
      "retrain  16 :\n",
      "\ttrain: 0.780373831775701 69.28421648952158 \ttest: 0.7608695652173914 29.509670920506046\n",
      "retrain  17 :\n",
      "\ttrain: 0.780373831775701 69.16224810572938 \ttest: 0.7608695652173914 29.513008974566127\n",
      "retrain  18 :\n",
      "\ttrain: 0.780373831775701 69.04841778894581 \ttest: 0.7608695652173914 29.518296817799275\n",
      "retrain  19 :\n",
      "\ttrain: 0.780373831775701 68.94191135018819 \ttest: 0.7608695652173914 29.52523134266773\n",
      "retrain  20 :\n",
      "\ttrain: 0.780373831775701 68.84202405212356 \ttest: 0.7608695652173914 29.533565775303693\n",
      "retrain  21 :\n",
      "\ttrain: 0.780373831775701 68.74814188180625 \ttest: 0.7608695652173914 29.543096589353567\n",
      "retrain  22 :\n",
      "\ttrain: 0.780373831775701 68.65972690417149 \ttest: 0.7608695652173914 29.55365394715273\n",
      "retrain  23 :\n",
      "\ttrain: 0.780373831775701 68.57630551230744 \ttest: 0.7608695652173914 29.565094601649832\n",
      "retrain  24 :\n",
      "\ttrain: 0.780373831775701 68.49745884452477 \ttest: 0.7608695652173914 29.57729655469585\n",
      "retrain  25 :\n",
      "\ttrain: 0.780373831775701 68.42281488285593 \ttest: 0.7608695652173914 29.590154990541667\n",
      "retrain  26 :\n",
      "\ttrain: 0.780373831775701 68.35204188820617 \ttest: 0.7608695652173914 29.60357914730956\n",
      "retrain  27 :\n",
      "\ttrain: 0.780373831775701 68.28484291453307 \ttest: 0.7608695652173914 29.617489885563735\n",
      "retrain  28 :\n",
      "\ttrain: 0.780373831775701 68.22095120271902 \ttest: 0.7608695652173914 29.631817779545884\n",
      "retrain  29 :\n",
      "\ttrain: 0.780373831775701 68.16012629639772 \ttest: 0.7608695652173914 29.64650160345547\n",
      "retrain  30 :\n",
      "\ttrain: 0.780373831775701 68.10215075316185 \ttest: 0.7608695652173914 29.661487118655035\n",
      "retrain  31 :\n",
      "\ttrain: 0.780373831775701 68.0468273487057 \ttest: 0.7608695652173914 29.67672609191862\n",
      "retrain  32 :\n",
      "\ttrain: 0.780373831775701 67.99397669051947 \ttest: 0.7608695652173914 29.692175492519524\n",
      "retrain  33 :\n",
      "\ttrain: 0.780373831775701 67.94343517300076 \ttest: 0.7608695652173914 29.707796828926494\n",
      "retrain  34 :\n",
      "\ttrain: 0.780373831775701 67.89505321813664 \ttest: 0.75 29.723555595446847\n",
      "retrain  35 :\n",
      "\ttrain: 0.780373831775701 67.84869375585569 \ttest: 0.75 29.739420806246976\n",
      "retrain  36 :\n",
      "\ttrain: 0.780373831775701 67.80423090622503 \ttest: 0.75 29.75536459946081\n",
      "retrain  37 :\n",
      "\ttrain: 0.780373831775701 67.76154883223921 \ttest: 0.75 29.771361898046884\n",
      "retrain  38 :\n",
      "\ttrain: 0.780373831775701 67.72054073730712 \ttest: 0.75 29.787390117024152\n",
      "retrain  39 :\n",
      "\ttrain: 0.780373831775701 67.68110798592228 \ttest: 0.75 29.80342890896182\n",
      "retrain  40 :\n",
      "\ttrain: 0.780373831775701 67.64315932958766 \ttest: 0.75 29.81945994130548\n",
      "retrain  41 :\n",
      "\ttrain: 0.780373831775701 67.60661022300806 \ttest: 0.75 29.835466700427393\n",
      "retrain  42 :\n",
      "\ttrain: 0.780373831775701 67.57138221798328 \ttest: 0.75 29.851434318294906\n",
      "retrain  43 :\n",
      "\ttrain: 0.780373831775701 67.53740242443051 \ttest: 0.75 29.867349418430464\n",
      "retrain  44 :\n",
      "\ttrain: 0.780373831775701 67.50460302961292 \ttest: 0.75 29.883199978445973\n",
      "retrain  45 :\n",
      "\ttrain: 0.780373831775701 67.47292086801835 \ttest: 0.75 29.898975206913253\n",
      "retrain  46 :\n",
      "\ttrain: 0.780373831775701 67.44229703546762 \ttest: 0.75 29.91466543271239\n",
      "retrain  47 :\n",
      "\ttrain: 0.780373831775701 67.41267654197817 \ttest: 0.75 29.930262005302886\n",
      "retrain  48 :\n",
      "\ttrain: 0.780373831775701 67.38400799869945 \ttest: 0.75 29.945757204606878\n",
      "retrain  49 :\n",
      "\ttrain: 0.780373831775701 67.35624333490006 \ttest: 0.75 29.96114415939143\n",
      "retrain  50 :\n",
      "\ttrain: 0.780373831775701 67.32933754154305 \ttest: 0.75 29.976416773198714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.79891   0.93631   0.86217       157\n",
      "           1    0.66667   0.35088   0.45977        57\n",
      "\n",
      "    accuracy                        0.78037       214\n",
      "   macro avg    0.73279   0.64359   0.66097       214\n",
      "weighted avg    0.76369   0.78037   0.75499       214\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.78481   0.91176   0.84354        68\n",
      "           1    0.53846   0.29167   0.37838        24\n",
      "\n",
      "    accuracy                        0.75000        92\n",
      "   macro avg    0.66164   0.60172   0.61096        92\n",
      "weighted avg    0.72055   0.75000   0.72219        92\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 16\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 48\n",
      "8 24 1\n",
      "12 36 2\n",
      "14 42 3\n",
      "15 45 4\n",
      "15 45 5\n",
      "15 45 6\n",
      "16 48 7\n",
      "16 48 8\n",
      "16 48 9\n",
      "16 48 10\n",
      "16 48 11\n",
      "16 48 12\n",
      "16 48 13\n",
      "16 48 14\n",
      "16 48 15\n",
      "16 48 16\n",
      "16 48 17\n",
      "16 48 18\n",
      "16 48 19\n",
      "16 48 20\n",
      "16 48 21\n",
      "16 48 22\n",
      "16 48 23\n",
      "16 48 24\n",
      "16 48 25\n",
      "16 48 26\n",
      "16 48 27\n",
      "16 48 28\n",
      "16 48 29\n",
      "16 48 30\n",
      "16 48 31\n",
      "16 48 32\n",
      "16 48 33\n",
      "16 48 34\n",
      "16 48 35\n",
      "16 48 36\n",
      "16 48 37\n",
      "16 48 38\n",
      "16 48 39\n",
      "16 48 40\n",
      "16 48 41\n",
      "16 48 42\n",
      "16 48 43\n",
      "16 48 44\n",
      "16 48 45\n",
      "16 48 46\n",
      "16 48 47\n",
      "16 48 48\n",
      "16 48 49\n",
      "16 48 50\n",
      "16 48 51\n",
      "16 48 52\n",
      "16 48 53\n",
      "16 48 54\n",
      "16 48 55\n",
      "16 48 56\n",
      "16 48 57\n",
      "16 48 58\n",
      "16 48 59\n",
      "16 48 60\n",
      "16 48 61\n",
      "16 48 62\n",
      "16 48 63\n",
      "16 48 64\n",
      "16 48 65\n",
      "16 48 66\n",
      "16 48 67\n",
      "16 48 68\n",
      "16 48 69\n",
      "16 48 70\n",
      "16 48 71\n",
      "16 48 72\n",
      "16 48 73\n",
      "16 48 74\n",
      "16 48 75\n",
      "16 48 76\n",
      "16 48 77\n",
      "16 48 78\n",
      "16 48 79\n",
      "16 48 80\n",
      "16 48 81\n",
      "16 48 82\n",
      "16 48 83\n",
      "16 48 84\n",
      "16 48 85\n",
      "16 48 86\n",
      "16 48 87\n",
      "16 48 88\n",
      "16 48 89\n",
      "16 48 90\n",
      "16 48 91\n",
      "16 48 92\n",
      "16 48 93\n",
      "16 48 94\n",
      "16 48 95\n",
      "16 48 96\n",
      "16 48 97\n",
      "16 48 98\n",
      "16 48 99\n",
      "16 48 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.7336448598130841 78.45129907327318 \ttest: 0.7391304347826086 32.82251997744605\n",
      "retrain  2 :\n",
      "\ttrain: 0.7336448598130841 75.39356440516012 \ttest: 0.7391304347826086 31.296994345023965\n",
      "retrain  3 :\n",
      "\ttrain: 0.7336448598130841 73.60996938745734 \ttest: 0.7391304347826086 30.43532994998468\n",
      "retrain  4 :\n",
      "\ttrain: 0.7570093457943925 72.55162475760406 \ttest: 0.7391304347826086 29.946175724388258\n",
      "retrain  5 :\n",
      "\ttrain: 0.7757009345794392 71.89230628202246 \ttest: 0.7717391304347826 29.660755740162585\n",
      "retrain  6 :\n",
      "\ttrain: 0.7710280373831776 71.45264718665206 \ttest: 0.7717391304347826 29.486840888322497\n",
      "retrain  7 :\n",
      "\ttrain: 0.7710280373831776 71.13708529676799 \ttest: 0.7717391304347826 29.37502239265114\n",
      "retrain  8 :\n",
      "\ttrain: 0.7710280373831776 70.89486131426267 \ttest: 0.7717391304347826 29.29874626809113\n",
      "retrain  9 :\n",
      "\ttrain: 0.7757009345794392 70.69861603442916 \ttest: 0.782608695652174 29.24351230636947\n",
      "retrain  10 :\n",
      "\ttrain: 0.7757009345794392 70.53317628461562 \ttest: 0.782608695652174 29.20121101953085\n",
      "retrain  11 :\n",
      "\ttrain: 0.7757009345794392 70.3897696081356 \ttest: 0.782608695652174 29.167170428535467\n",
      "retrain  12 :\n",
      "\ttrain: 0.7757009345794392 70.26304484551119 \ttest: 0.782608695652174 29.138605933624945\n",
      "retrain  13 :\n",
      "\ttrain: 0.7757009345794392 70.14952944708358 \ttest: 0.782608695652174 29.113796180899705\n",
      "retrain  14 :\n",
      "\ttrain: 0.7757009345794392 70.04682212996283 \ttest: 0.782608695652174 29.091637311347437\n",
      "retrain  15 :\n",
      "\ttrain: 0.7757009345794392 69.95316332859551 \ttest: 0.782608695652174 29.071396665165338\n",
      "retrain  16 :\n",
      "\ttrain: 0.7757009345794392 69.86720103659582 \ttest: 0.782608695652174 29.052573137792386\n",
      "retrain  17 :\n",
      "\ttrain: 0.7757009345794392 69.78785870617267 \ttest: 0.782608695652174 29.03481556488377\n",
      "retrain  18 :\n",
      "\ttrain: 0.7757009345794392 69.71425724009868 \ttest: 0.782608695652174 29.01787335467134\n",
      "retrain  19 :\n",
      "\ttrain: 0.7757009345794392 69.64566628240925 \ttest: 0.782608695652174 29.00156550286368\n",
      "retrain  20 :\n",
      "\ttrain: 0.7757009345794392 69.58147188387031 \ttest: 0.782608695652174 28.985760405705765\n",
      "retrain  21 :\n",
      "\ttrain: 0.7757009345794392 69.52115371961034 \ttest: 0.782608695652174 28.970362235222233\n",
      "retrain  22 :\n",
      "\ttrain: 0.7757009345794392 69.46426818669035 \ttest: 0.782608695652174 28.95530145044968\n",
      "retrain  23 :\n",
      "\ttrain: 0.7757009345794392 69.4104353471044 \ttest: 0.782608695652174 28.94052801312361\n",
      "retrain  24 :\n",
      "\ttrain: 0.7757009345794392 69.35932854235026 \ttest: 0.782608695652174 28.926006434336784\n",
      "retrain  25 :\n",
      "\ttrain: 0.7757009345794392 69.31066596592441 \ttest: 0.782608695652174 28.911712099729712\n",
      "retrain  26 :\n",
      "\ttrain: 0.7757009345794392 69.26420373288461 \ttest: 0.782608695652174 28.897628511010506\n",
      "retrain  27 :\n",
      "\ttrain: 0.7757009345794392 69.21973012998038 \ttest: 0.782608695652174 28.8837451981383\n",
      "retrain  28 :\n",
      "\ttrain: 0.7757009345794392 69.17706081663712 \ttest: 0.782608695652174 28.870056130459762\n",
      "retrain  29 :\n",
      "\ttrain: 0.7757009345794392 69.13603480252146 \ttest: 0.782608695652174 28.856558503702846\n",
      "retrain  30 :\n",
      "\ttrain: 0.7757009345794392 69.09651106513901 \ttest: 0.782608695652174 28.843251812758574\n",
      "retrain  31 :\n",
      "\ttrain: 0.7757009345794392 69.05836569809698 \ttest: 0.782608695652174 28.830137143280098\n",
      "retrain  32 :\n",
      "\ttrain: 0.7757009345794392 69.02148950117422 \ttest: 0.782608695652174 28.817216631681237\n",
      "retrain  33 :\n",
      "\ttrain: 0.7757009345794392 68.9857859393436 \ttest: 0.782608695652174 28.80449305521466\n",
      "retrain  34 :\n",
      "\ttrain: 0.7757009345794392 68.95116941066215 \ttest: 0.782608695652174 28.791969522788648\n",
      "retrain  35 :\n",
      "\ttrain: 0.7757009345794392 68.91756377328261 \ttest: 0.782608695652174 28.779649243926364\n",
      "retrain  36 :\n",
      "\ttrain: 0.7757009345794392 68.88490109028461 \ttest: 0.782608695652174 28.7675353583846\n",
      "retrain  37 :\n",
      "\ttrain: 0.7757009345794392 68.85312055795815 \ttest: 0.782608695652174 28.75563081285397\n",
      "retrain  38 :\n",
      "\ttrain: 0.7757009345794392 68.82216758888843 \ttest: 0.782608695652174 28.743938274162065\n",
      "retrain  39 :\n",
      "\ttrain: 0.7757009345794392 68.79199302591209 \ttest: 0.782608695652174 28.732460070716193\n",
      "retrain  40 :\n",
      "\ttrain: 0.7757009345794392 68.76255246692311 \ttest: 0.782608695652174 28.7211981557169\n",
      "retrain  41 :\n",
      "\ttrain: 0.7757009345794392 68.73380568374651 \ttest: 0.782608695652174 28.71015408706948\n",
      "retrain  42 :\n",
      "\ttrain: 0.7757009345794392 68.70571612098777 \ttest: 0.782608695652174 28.69932902001023\n",
      "retrain  43 :\n",
      "\ttrain: 0.7757009345794392 68.67825046300297 \ttest: 0.782608695652174 28.688723709317212\n",
      "retrain  44 :\n",
      "\ttrain: 0.7757009345794392 68.65137825899812 \ttest: 0.782608695652174 28.678338518645383\n",
      "retrain  45 :\n",
      "\ttrain: 0.7757009345794392 68.62507159782155 \ttest: 0.782608695652174 28.668173435053014\n",
      "retrain  46 :\n",
      "\ttrain: 0.7757009345794392 68.59930482531239 \ttest: 0.782608695652174 28.658228087202712\n",
      "retrain  47 :\n",
      "\ttrain: 0.7757009345794392 68.57405429815765 \ttest: 0.782608695652174 28.648501766049552\n",
      "retrain  48 :\n",
      "\ttrain: 0.7757009345794392 68.54929816912343 \ttest: 0.782608695652174 28.638993447089675\n",
      "retrain  49 :\n",
      "\ttrain: 0.7757009345794392 68.52501619929335 \ttest: 0.782608695652174 28.62970181344985\n",
      "retrain  50 :\n",
      "\ttrain: 0.7757009345794392 68.5011895935945 \ttest: 0.782608695652174 28.620625279263272\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.80110   0.92357   0.85799       157\n",
      "           1    0.63636   0.36842   0.46667        57\n",
      "\n",
      "    accuracy                        0.77570       214\n",
      "   macro avg    0.71873   0.64599   0.66233       214\n",
      "weighted avg    0.75723   0.77570   0.75376       214\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.81579   0.91176   0.86111        68\n",
      "           1    0.62500   0.41667   0.50000        24\n",
      "\n",
      "    accuracy                        0.78261        92\n",
      "   macro avg    0.72039   0.66422   0.68056        92\n",
      "weighted avg    0.76602   0.78261   0.76691        92\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 16\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 48\n",
      "5 15 1\n",
      "9 27 2\n",
      "11 33 3\n",
      "14 42 4\n",
      "15 45 5\n",
      "16 48 6\n",
      "17 51 7\n",
      "17 51 8\n",
      "17 51 9\n",
      "17 51 10\n",
      "17 51 11\n",
      "17 51 12\n",
      "17 51 13\n",
      "17 51 14\n",
      "17 51 15\n",
      "17 51 16\n",
      "17 51 17\n",
      "17 51 18\n",
      "17 51 19\n",
      "17 51 20\n",
      "17 51 21\n",
      "17 51 22\n",
      "17 51 23\n",
      "17 51 24\n",
      "17 51 25\n",
      "17 51 26\n",
      "17 51 27\n",
      "17 51 28\n",
      "17 51 29\n",
      "17 51 30\n",
      "17 51 31\n",
      "17 51 32\n",
      "17 51 33\n",
      "17 51 34\n",
      "17 51 35\n",
      "17 51 36\n",
      "17 51 37\n",
      "17 51 38\n",
      "17 51 39\n",
      "17 51 40\n",
      "17 51 41\n",
      "17 51 42\n",
      "17 51 43\n",
      "17 51 44\n",
      "17 51 45\n",
      "17 51 46\n",
      "17 51 47\n",
      "17 51 48\n",
      "17 51 49\n",
      "17 51 50\n",
      "17 51 51\n",
      "17 51 52\n",
      "17 51 53\n",
      "17 51 54\n",
      "17 51 55\n",
      "17 51 56\n",
      "17 51 57\n",
      "17 51 58\n",
      "17 51 59\n",
      "17 51 60\n",
      "17 51 61\n",
      "17 51 62\n",
      "17 51 63\n",
      "17 51 64\n",
      "17 51 65\n",
      "17 51 66\n",
      "17 51 67\n",
      "17 51 68\n",
      "17 51 69\n",
      "17 51 70\n",
      "17 51 71\n",
      "17 51 72\n",
      "17 51 73\n",
      "17 51 74\n",
      "17 51 75\n",
      "17 51 76\n",
      "17 51 77\n",
      "17 51 78\n",
      "17 51 79\n",
      "17 51 80\n",
      "17 51 81\n",
      "17 51 82\n",
      "17 51 83\n",
      "17 51 84\n",
      "17 51 85\n",
      "17 51 86\n",
      "17 51 87\n",
      "17 51 88\n",
      "17 51 89\n",
      "17 51 90\n",
      "17 51 91\n",
      "17 51 92\n",
      "17 51 93\n",
      "17 51 94\n",
      "17 51 95\n",
      "17 51 96\n",
      "17 51 97\n",
      "17 51 98\n",
      "17 51 99\n",
      "17 51 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.7336448598130841 77.19534300681183 \ttest: 0.7391304347826086 33.06391861543705\n",
      "retrain  2 :\n",
      "\ttrain: 0.7336448598130841 73.64894210060415 \ttest: 0.7391304347826086 31.797997033434008\n",
      "retrain  3 :\n",
      "\ttrain: 0.7336448598130841 71.63268619406706 \ttest: 0.7391304347826086 31.12702138171489\n",
      "retrain  4 :\n",
      "\ttrain: 0.7336448598130841 70.41536660016641 \ttest: 0.7391304347826086 30.75980580592882\n",
      "retrain  5 :\n",
      "\ttrain: 0.7616822429906542 69.62508643793845 \ttest: 0.7608695652173914 30.54973343576293\n",
      "retrain  6 :\n",
      "\ttrain: 0.7710280373831776 69.07343051195093 \ttest: 0.7934782608695652 30.423278071121835\n",
      "retrain  7 :\n",
      "\ttrain: 0.7663551401869159 68.6627119042702 \ttest: 0.7934782608695652 30.34297691503687\n",
      "retrain  8 :\n",
      "\ttrain: 0.7663551401869159 68.34040562797183 \ttest: 0.7934782608695652 30.289236449582702\n",
      "retrain  9 :\n",
      "\ttrain: 0.7710280373831776 68.07701191353436 \ttest: 0.782608695652174 30.251478038763793\n",
      "retrain  10 :\n",
      "\ttrain: 0.7663551401869159 67.85514834106026 \ttest: 0.782608695652174 30.223783232446976\n",
      "retrain  11 :\n",
      "\ttrain: 0.7663551401869159 67.66404215097393 \ttest: 0.782608695652174 30.20271097302119\n",
      "retrain  12 :\n",
      "\ttrain: 0.7663551401869159 67.49666901966994 \ttest: 0.782608695652174 30.186178567141773\n",
      "retrain  13 :\n",
      "\ttrain: 0.7663551401869159 67.34822075003679 \ttest: 0.782608695652174 30.17287380755201\n",
      "retrain  14 :\n",
      "\ttrain: 0.7663551401869159 67.21525777399626 \ttest: 0.782608695652174 30.161937837943263\n",
      "retrain  15 :\n",
      "\ttrain: 0.7663551401869159 67.09522397287795 \ttest: 0.782608695652174 30.152788993472953\n",
      "retrain  16 :\n",
      "\ttrain: 0.7663551401869159 66.98615846287437 \ttest: 0.782608695652174 30.14502171566558\n",
      "retrain  17 :\n",
      "\ttrain: 0.7616822429906542 66.88651757777819 \ttest: 0.782608695652174 30.138346447936364\n",
      "retrain  18 :\n",
      "\ttrain: 0.7663551401869159 66.79506045311875 \ttest: 0.7934782608695652 30.13255253614348\n",
      "retrain  19 :\n",
      "\ttrain: 0.7663551401869159 66.71077257826494 \ttest: 0.7934782608695652 30.127484459487512\n",
      "retrain  20 :\n",
      "\ttrain: 0.7663551401869159 66.63281284168774 \ttest: 0.7934782608695652 30.123026060644648\n",
      "retrain  21 :\n",
      "\ttrain: 0.7663551401869159 66.56047565657425 \ttest: 0.7934782608695652 30.11908975573742\n",
      "retrain  22 :\n",
      "\ttrain: 0.7663551401869159 66.4931631202059 \ttest: 0.7934782608695652 30.115608959236305\n",
      "retrain  23 :\n",
      "\ttrain: 0.7663551401869159 66.43036407599746 \ttest: 0.7934782608695652 30.11253265560861\n",
      "retrain  24 :\n",
      "\ttrain: 0.7663551401869159 66.3716380673563 \ttest: 0.7934782608695652 30.109821447309432\n",
      "retrain  25 :\n",
      "\ttrain: 0.7663551401869159 66.31660284780973 \ttest: 0.7934782608695652 30.107444643170155\n",
      "retrain  26 :\n",
      "\ttrain: 0.7663551401869159 66.26492453222907 \ttest: 0.7934782608695652 30.105378094353416\n",
      "retrain  27 :\n",
      "\ttrain: 0.7663551401869159 66.21630974439465 \ttest: 0.7934782608695652 30.103602575596703\n",
      "retrain  28 :\n",
      "\ttrain: 0.7757009345794392 66.17049929570638 \ttest: 0.782608695652174 30.10210256877491\n",
      "retrain  29 :\n",
      "\ttrain: 0.7757009345794392 66.1272630526266 \ttest: 0.782608695652174 30.100865345880244\n",
      "retrain  30 :\n",
      "\ttrain: 0.7757009345794392 66.086395736611 \ttest: 0.782608695652174 30.099880276308912\n",
      "retrain  31 :\n",
      "\ttrain: 0.7757009345794392 66.04771346211976 \ttest: 0.782608695652174 30.099138303035875\n",
      "retrain  32 :\n",
      "\ttrain: 0.7757009345794392 66.01105086351734 \ttest: 0.782608695652174 30.098631546446754\n",
      "retrain  33 :\n",
      "\ttrain: 0.780373831775701 65.9762586952485 \ttest: 0.782608695652174 30.098353004951512\n",
      "retrain  34 :\n",
      "\ttrain: 0.780373831775701 65.94320181494044 \ttest: 0.782608695652174 30.0982963291389\n",
      "retrain  35 :\n",
      "\ttrain: 0.780373831775701 65.91175747829467 \ttest: 0.782608695652174 30.098455651902537\n",
      "retrain  36 :\n",
      "\ttrain: 0.780373831775701 65.88181388937963 \ttest: 0.782608695652174 30.098825461209664\n",
      "retrain  37 :\n",
      "\ttrain: 0.780373831775701 65.8532689613451 \ttest: 0.782608695652174 30.09940050537073\n",
      "retrain  38 :\n",
      "\ttrain: 0.780373831775701 65.82602925147219 \ttest: 0.782608695652174 30.10017572307253\n",
      "retrain  39 :\n",
      "\ttrain: 0.780373831775701 65.80000904144589 \ttest: 0.782608695652174 30.101146192260263\n",
      "retrain  40 :\n",
      "\ttrain: 0.780373831775701 65.77512953923772 \ttest: 0.782608695652174 30.102307093339128\n",
      "retrain  41 :\n",
      "\ttrain: 0.780373831775701 65.75131818335008 \ttest: 0.782608695652174 30.10365368322251\n",
      "retrain  42 :\n",
      "\ttrain: 0.780373831775701 65.72850803365236 \ttest: 0.782608695652174 30.105181277561755\n",
      "retrain  43 :\n",
      "\ttrain: 0.780373831775701 65.70663723582602 \ttest: 0.782608695652174 30.106885239111698\n",
      "retrain  44 :\n",
      "\ttrain: 0.780373831775701 65.68564854867961 \ttest: 0.782608695652174 30.108760970661926\n",
      "retrain  45 :\n",
      "\ttrain: 0.780373831775701 65.66548892540906 \ttest: 0.782608695652174 30.11080391132973\n",
      "retrain  46 :\n",
      "\ttrain: 0.780373831775701 65.64610914135221 \ttest: 0.782608695652174 30.11300953529303\n",
      "retrain  47 :\n",
      "\ttrain: 0.780373831775701 65.62746346198827 \ttest: 0.782608695652174 30.11537335225924\n",
      "retrain  48 :\n",
      "\ttrain: 0.780373831775701 65.60950934591818 \ttest: 0.782608695652174 30.11789090913401\n",
      "retrain  49 :\n",
      "\ttrain: 0.780373831775701 65.59220717837184 \ttest: 0.782608695652174 30.120557792483986\n",
      "retrain  50 :\n",
      "\ttrain: 0.780373831775701 65.57552003145705 \ttest: 0.782608695652174 30.123369631487584\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.80899   0.91720   0.85970       157\n",
      "           1    0.63889   0.40351   0.49462        57\n",
      "\n",
      "    accuracy                        0.78037       214\n",
      "   macro avg    0.72394   0.66035   0.67716       214\n",
      "weighted avg    0.76368   0.78037   0.76246       214\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.80769   0.92647   0.86301        68\n",
      "           1    0.64286   0.37500   0.47368        24\n",
      "\n",
      "    accuracy                        0.78261        92\n",
      "   macro avg    0.72527   0.65074   0.66835        92\n",
      "weighted avg    0.76469   0.78261   0.76145        92\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 17\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 51\n",
      "5 15 1\n",
      "11 33 2\n",
      "12 36 3\n",
      "13 39 4\n",
      "15 45 5\n",
      "15 45 6\n",
      "15 45 7\n",
      "15 45 8\n",
      "16 48 9\n",
      "16 48 10\n",
      "16 48 11\n",
      "16 48 12\n",
      "16 48 13\n",
      "16 48 14\n",
      "16 48 15\n",
      "16 48 16\n",
      "16 48 17\n",
      "16 48 18\n",
      "16 48 19\n",
      "16 48 20\n",
      "16 48 21\n",
      "16 48 22\n",
      "16 48 23\n",
      "16 48 24\n",
      "16 48 25\n",
      "16 48 26\n",
      "16 48 27\n",
      "16 48 28\n",
      "16 48 29\n",
      "16 48 30\n",
      "16 48 31\n",
      "16 48 32\n",
      "16 48 33\n",
      "16 48 34\n",
      "16 48 35\n",
      "16 48 36\n",
      "16 48 37\n",
      "16 48 38\n",
      "16 48 39\n",
      "16 48 40\n",
      "16 48 41\n",
      "16 48 42\n",
      "16 48 43\n",
      "16 48 44\n",
      "16 48 45\n",
      "16 48 46\n",
      "16 48 47\n",
      "16 48 48\n",
      "16 48 49\n",
      "16 48 50\n",
      "16 48 51\n",
      "16 48 52\n",
      "16 48 53\n",
      "16 48 54\n",
      "16 48 55\n",
      "16 48 56\n",
      "16 48 57\n",
      "16 48 58\n",
      "16 48 59\n",
      "16 48 60\n",
      "16 48 61\n",
      "16 48 62\n",
      "16 48 63\n",
      "16 48 64\n",
      "16 48 65\n",
      "16 48 66\n",
      "16 48 67\n",
      "16 48 68\n",
      "16 48 69\n",
      "16 48 70\n",
      "16 48 71\n",
      "16 48 72\n",
      "16 48 73\n",
      "16 48 74\n",
      "16 48 75\n",
      "16 48 76\n",
      "16 48 77\n",
      "16 48 78\n",
      "16 48 79\n",
      "16 48 80\n",
      "16 48 81\n",
      "16 48 82\n",
      "16 48 83\n",
      "16 48 84\n",
      "16 48 85\n",
      "16 48 86\n",
      "16 48 87\n",
      "16 48 88\n",
      "16 48 89\n",
      "16 48 90\n",
      "16 48 91\n",
      "16 48 92\n",
      "16 48 93\n",
      "16 48 94\n",
      "16 48 95\n",
      "16 48 96\n",
      "16 48 97\n",
      "16 48 98\n",
      "16 48 99\n",
      "16 48 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.7336448598130841 78.45149923730717 \ttest: 0.7391304347826086 32.824074672603984\n",
      "retrain  2 :\n",
      "\ttrain: 0.7336448598130841 75.39423756030439 \ttest: 0.7391304347826086 31.300847070242362\n",
      "retrain  3 :\n",
      "\ttrain: 0.7336448598130841 73.6112694431058 \ttest: 0.7391304347826086 30.441519821353314\n",
      "retrain  4 :\n",
      "\ttrain: 0.7570093457943925 72.55360639831632 \ttest: 0.7391304347826086 29.9544479063545\n",
      "retrain  5 :\n",
      "\ttrain: 0.7757009345794392 71.89497510857905 \ttest: 0.7717391304347826 29.670785031506753\n",
      "retrain  6 :\n",
      "\ttrain: 0.7710280373831776 71.45598868718764 \ttest: 0.7717391304347826 29.498320027986285\n",
      "retrain  7 :\n",
      "\ttrain: 0.7710280373831776 71.14107780432101 \ttest: 0.7717391304347826 29.3876876125365\n",
      "retrain  8 :\n",
      "\ttrain: 0.7710280373831776 70.8994813920985 \ttest: 0.7717391304347826 29.31237927154851\n",
      "retrain  9 :\n",
      "\ttrain: 0.7757009345794392 70.70384068318758 \ttest: 0.782608695652174 29.2579348724085\n",
      "retrain  10 :\n",
      "\ttrain: 0.7757009345794392 70.53898383933426 \ttest: 0.782608695652174 29.216278143153442\n",
      "retrain  11 :\n",
      "\ttrain: 0.7757009345794392 70.39614007765653 \ttest: 0.782608695652174 29.18276393710347\n",
      "retrain  12 :\n",
      "\ttrain: 0.7757009345794392 70.26996000002376 \ttest: 0.782608695652174 29.15462909071254\n",
      "retrain  13 :\n",
      "\ttrain: 0.7757009345794392 70.15697278463664 \ttest: 0.782608695652174 29.130169302942164\n",
      "retrain  14 :\n",
      "\ttrain: 0.7757009345794392 70.05477878283656 \ttest: 0.782608695652174 29.108294273738974\n",
      "retrain  15 :\n",
      "\ttrain: 0.7757009345794392 69.96161994071173 \ttest: 0.782608695652174 29.088282144145815\n",
      "retrain  16 :\n",
      "\ttrain: 0.7757009345794392 69.87614562926892 \ttest: 0.782608695652174 29.06964044393094\n",
      "retrain  17 :\n",
      "\ttrain: 0.7757009345794392 69.7972805422726 \ttest: 0.782608695652174 29.05202494493821\n",
      "retrain  18 :\n",
      "\ttrain: 0.7757009345794392 69.72414669255116 \ttest: 0.782608695652174 29.03519066090916\n",
      "retrain  19 :\n",
      "\ttrain: 0.7757009345794392 69.65601471042015 \ttest: 0.782608695652174 29.01896114907903\n",
      "retrain  20 :\n",
      "\ttrain: 0.7757009345794392 69.592271518652 \ttest: 0.782608695652174 29.003208546187427\n",
      "retrain  21 :\n",
      "\ttrain: 0.7757009345794392 69.53239756035626 \ttest: 0.782608695652174 28.98784011681592\n",
      "retrain  22 :\n",
      "\ttrain: 0.7757009345794392 69.47594990688543 \ttest: 0.782608695652174 28.972788898957962\n",
      "retrain  23 :\n",
      "\ttrain: 0.7757009345794392 69.42254921084768 \ttest: 0.782608695652174 28.958007024038885\n",
      "retrain  24 :\n",
      "\ttrain: 0.7757009345794392 69.37186933012 \ttest: 0.782608695652174 28.943460844739313\n",
      "retrain  25 :\n",
      "\ttrain: 0.7757009345794392 69.32362890908102 \ttest: 0.782608695652174 28.92912732348759\n",
      "retrain  26 :\n",
      "\ttrain: 0.7757009345794392 69.27758445614523 \ttest: 0.782608695652174 28.914991323515263\n",
      "retrain  27 :\n",
      "\ttrain: 0.7757009345794392 69.233524601087 \ttest: 0.782608695652174 28.901043559962694\n",
      "retrain  28 :\n",
      "\ttrain: 0.7757009345794392 69.1912653024591 \ttest: 0.782608695652174 28.88727904174589\n",
      "retrain  29 :\n",
      "\ttrain: 0.7757009345794392 69.15064583087297 \ttest: 0.782608695652174 28.873695882945313\n",
      "retrain  30 :\n",
      "\ttrain: 0.7757009345794392 69.11152539164208 \ttest: 0.782608695652174 28.86029439507079\n",
      "retrain  31 :\n",
      "\ttrain: 0.7757009345794392 69.07378027747696 \ttest: 0.782608695652174 28.847076394322713\n",
      "retrain  32 :\n",
      "\ttrain: 0.7757009345794392 69.03730146243322 \ttest: 0.782608695652174 28.834044674268675\n",
      "retrain  33 :\n",
      "\ttrain: 0.7757009345794392 69.00199256431401 \ttest: 0.782608695652174 28.82120260625878\n",
      "retrain  34 :\n",
      "\ttrain: 0.7757009345794392 68.9677681154977 \ttest: 0.782608695652174 28.808553838733623\n",
      "retrain  35 :\n",
      "\ttrain: 0.7757009345794392 68.93455209249542 \ttest: 0.782608695652174 28.796102073211053\n",
      "retrain  36 :\n",
      "\ttrain: 0.7757009345794392 68.90227666298391 \ttest: 0.782608695652174 28.783850899764484\n",
      "retrain  37 :\n",
      "\ttrain: 0.7757009345794392 68.87088111598952 \ttest: 0.782608695652174 28.771803678645007\n",
      "retrain  38 :\n",
      "\ttrain: 0.7757009345794392 68.84031094661056 \ttest: 0.782608695652174 28.759963457648162\n",
      "retrain  39 :\n",
      "\ttrain: 0.7757009345794392 68.81051707138278 \ttest: 0.782608695652174 28.748332917103134\n",
      "retrain  40 :\n",
      "\ttrain: 0.7757009345794392 68.78145515429657 \ttest: 0.782608695652174 28.736914336126713\n",
      "retrain  41 :\n",
      "\ttrain: 0.7757009345794392 68.75308502671095 \ttest: 0.782608695652174 28.725709575157303\n",
      "retrain  42 :\n",
      "\ttrain: 0.7757009345794392 68.72537018709546 \ttest: 0.782608695652174 28.714720070856274\n",
      "retrain  43 :\n",
      "\ttrain: 0.7757009345794392 68.69827736876596 \ttest: 0.782608695652174 28.703946840303036\n",
      "retrain  44 :\n",
      "\ttrain: 0.7757009345794392 68.67177616564007 \ttest: 0.782608695652174 28.693390492069362\n",
      "retrain  45 :\n",
      "\ttrain: 0.7757009345794392 68.64583870759202 \ttest: 0.782608695652174 28.68305124227725\n",
      "retrain  46 :\n",
      "\ttrain: 0.7757009345794392 68.62043937828298 \ttest: 0.782608695652174 28.6729289341542\n",
      "retrain  47 :\n",
      "\ttrain: 0.7757009345794392 68.59555456943124 \ttest: 0.782608695652174 28.66302305992361\n",
      "retrain  48 :\n",
      "\ttrain: 0.7757009345794392 68.5711624663971 \ttest: 0.782608695652174 28.653332784124636\n",
      "retrain  49 :\n",
      "\ttrain: 0.7757009345794392 68.54724286072472 \ttest: 0.782608695652174 28.64385696765968\n",
      "retrain  50 :\n",
      "\ttrain: 0.7757009345794392 68.52377698592827 \ttest: 0.782608695652174 28.6345941920292\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.80110   0.92357   0.85799       157\n",
      "           1    0.63636   0.36842   0.46667        57\n",
      "\n",
      "    accuracy                        0.77570       214\n",
      "   macro avg    0.71873   0.64599   0.66233       214\n",
      "weighted avg    0.75723   0.77570   0.75376       214\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.81579   0.91176   0.86111        68\n",
      "           1    0.62500   0.41667   0.50000        24\n",
      "\n",
      "    accuracy                        0.78261        92\n",
      "   macro avg    0.72039   0.66422   0.68056        92\n",
      "weighted avg    0.76602   0.78261   0.76691        92\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 16\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 48\n",
      "7 21 1\n",
      "11 33 2\n",
      "15 45 3\n",
      "15 45 4\n",
      "15 45 5\n",
      "15 45 6\n",
      "15 45 7\n",
      "15 45 8\n",
      "15 45 9\n",
      "15 45 10\n",
      "15 45 11\n",
      "15 45 12\n",
      "15 45 13\n",
      "15 45 14\n",
      "15 45 15\n",
      "15 45 16\n",
      "15 45 17\n",
      "15 45 18\n",
      "15 45 19\n",
      "15 45 20\n",
      "15 45 21\n",
      "15 45 22\n",
      "15 45 23\n",
      "15 45 24\n",
      "15 45 25\n",
      "15 45 26\n",
      "15 45 27\n",
      "15 45 28\n",
      "15 45 29\n",
      "15 45 30\n",
      "15 45 31\n",
      "15 45 32\n",
      "15 45 33\n",
      "15 45 34\n",
      "15 45 35\n",
      "15 45 36\n",
      "15 45 37\n",
      "15 45 38\n",
      "15 45 39\n",
      "15 45 40\n",
      "15 45 41\n",
      "15 45 42\n",
      "15 45 43\n",
      "15 45 44\n",
      "15 45 45\n",
      "15 45 46\n",
      "15 45 47\n",
      "15 45 48\n",
      "15 45 49\n",
      "15 45 50\n",
      "15 45 51\n",
      "15 45 52\n",
      "15 45 53\n",
      "15 45 54\n",
      "15 45 55\n",
      "15 45 56\n",
      "15 45 57\n",
      "15 45 58\n",
      "15 45 59\n",
      "15 45 60\n",
      "15 45 61\n",
      "15 45 62\n",
      "15 45 63\n",
      "15 45 64\n",
      "15 45 65\n",
      "15 45 66\n",
      "15 45 67\n",
      "15 45 68\n",
      "15 45 69\n",
      "15 45 70\n",
      "15 45 71\n",
      "15 45 72\n",
      "15 45 73\n",
      "15 45 74\n",
      "15 45 75\n",
      "15 45 76\n",
      "15 45 77\n",
      "15 45 78\n",
      "15 45 79\n",
      "15 45 80\n",
      "15 45 81\n",
      "15 45 82\n",
      "15 45 83\n",
      "15 45 84\n",
      "15 45 85\n",
      "15 45 86\n",
      "15 45 87\n",
      "15 45 88\n",
      "15 45 89\n",
      "15 45 90\n",
      "15 45 91\n",
      "15 45 92\n",
      "15 45 93\n",
      "15 45 94\n",
      "15 45 95\n",
      "15 45 96\n",
      "15 45 97\n",
      "15 45 98\n",
      "15 45 99\n",
      "15 45 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.7336448598130841 77.85804709919351 \ttest: 0.7391304347826086 33.056444372451736\n",
      "retrain  2 :\n",
      "\ttrain: 0.7336448598130841 74.43426017306778 \ttest: 0.7391304347826086 31.704186333024143\n",
      "retrain  3 :\n",
      "\ttrain: 0.7336448598130841 72.43990726445651 \ttest: 0.7391304347826086 30.979587769972298\n",
      "retrain  4 :\n",
      "\ttrain: 0.780373831775701 71.26779426256245 \ttest: 0.7608695652173914 30.600169176741645\n",
      "retrain  5 :\n",
      "\ttrain: 0.7757009345794392 70.55212933426944 \ttest: 0.7608695652173914 30.401833476717567\n",
      "retrain  6 :\n",
      "\ttrain: 0.7710280373831776 70.08785190174416 \ttest: 0.782608695652174 30.295982298029973\n",
      "retrain  7 :\n",
      "\ttrain: 0.7663551401869159 69.76359380086022 \ttest: 0.782608695652174 30.236652994881062\n",
      "retrain  8 :\n",
      "\ttrain: 0.7663551401869159 69.51939376485431 \ttest: 0.782608695652174 30.20055297145803\n",
      "retrain  9 :\n",
      "\ttrain: 0.7663551401869159 69.32286442243975 \ttest: 0.7717391304347826 30.176101453007686\n",
      "retrain  10 :\n",
      "\ttrain: 0.7663551401869159 69.15633009600066 \ttest: 0.7717391304347826 30.157666594989593\n",
      "retrain  11 :\n",
      "\ttrain: 0.7663551401869159 69.00998234180628 \ttest: 0.7717391304347826 30.142590771856472\n",
      "retrain  12 :\n",
      "\ttrain: 0.7663551401869159 68.87824388051622 \ttest: 0.7717391304347826 30.129671326404882\n",
      "retrain  13 :\n",
      "\ttrain: 0.7663551401869159 68.75783077478175 \ttest: 0.7717391304347826 30.118393086455175\n",
      "retrain  14 :\n",
      "\ttrain: 0.7663551401869159 68.64671472701218 \ttest: 0.7717391304347826 30.10854706555772\n",
      "retrain  15 :\n",
      "\ttrain: 0.7663551401869159 68.54356455233786 \ttest: 0.7717391304347826 30.100046270821554\n",
      "retrain  16 :\n",
      "\ttrain: 0.7663551401869159 68.44744399253258 \ttest: 0.7717391304347826 30.09284097107295\n",
      "retrain  17 :\n",
      "\ttrain: 0.7663551401869159 68.3576472729213 \ttest: 0.7717391304347826 30.086883141338422\n",
      "retrain  18 :\n",
      "\ttrain: 0.7663551401869159 68.27360894820555 \ttest: 0.7717391304347826 30.082114373363304\n",
      "retrain  19 :\n",
      "\ttrain: 0.7663551401869159 68.19485393719259 \ttest: 0.7717391304347826 30.078464290134384\n",
      "retrain  20 :\n",
      "\ttrain: 0.7663551401869159 68.1209693603156 \ttest: 0.7717391304347826 30.07585309054575\n",
      "retrain  21 :\n",
      "\ttrain: 0.7663551401869159 68.05158824418146 \ttest: 0.7717391304347826 30.07419522333808\n",
      "retrain  22 :\n",
      "\ttrain: 0.7663551401869159 67.98637971677121 \ttest: 0.7717391304347826 30.073402886596277\n",
      "retrain  23 :\n",
      "\ttrain: 0.7663551401869159 67.9250427821331 \ttest: 0.7717391304347826 30.073388877883495\n",
      "retrain  24 :\n",
      "\ttrain: 0.7663551401869159 67.86730209762558 \ttest: 0.7717391304347826 30.074068704295357\n",
      "retrain  25 :\n",
      "\ttrain: 0.7663551401869159 67.81290489882069 \ttest: 0.7717391304347826 30.075362022997442\n",
      "retrain  26 :\n",
      "\ttrain: 0.7663551401869159 67.76161860755133 \ttest: 0.7717391304347826 30.077193536163296\n",
      "retrain  27 :\n",
      "\ttrain: 0.7663551401869159 67.7132288692622 \ttest: 0.7717391304347826 30.079493468453343\n",
      "retrain  28 :\n",
      "\ttrain: 0.7663551401869159 67.66753787926643 \ttest: 0.7717391304347826 30.082197739601\n",
      "retrain  29 :\n",
      "\ttrain: 0.7663551401869159 67.62436291845889 \ttest: 0.7717391304347826 30.08524792335369\n",
      "retrain  30 :\n",
      "\ttrain: 0.7663551401869159 67.58353505175066 \ttest: 0.7717391304347826 30.088591063214288\n",
      "retrain  31 :\n",
      "\ttrain: 0.7663551401869159 67.54489796008362 \ttest: 0.7717391304347826 30.092179397542186\n",
      "retrain  32 :\n",
      "\ttrain: 0.7663551401869159 67.50830688643464 \ttest: 0.7717391304347826 30.09597003217552\n",
      "retrain  33 :\n",
      "\ttrain: 0.7663551401869159 67.47362768151548 \ttest: 0.7717391304347826 30.099924587605617\n",
      "retrain  34 :\n",
      "\ttrain: 0.7663551401869159 67.44073593793831 \ttest: 0.7717391304347826 30.10400883936541\n",
      "retrain  35 :\n",
      "\ttrain: 0.7663551401869159 67.4095162035122 \ttest: 0.7717391304347826 30.108192364130577\n",
      "retrain  36 :\n",
      "\ttrain: 0.7663551401869159 67.37986126562032 \ttest: 0.7717391304347826 30.112448199571894\n",
      "retrain  37 :\n",
      "\ttrain: 0.7663551401869159 67.35167149958414 \ttest: 0.7717391304347826 30.116752522819958\n",
      "retrain  38 :\n",
      "\ttrain: 0.7663551401869159 67.32485427469506 \ttest: 0.7717391304347826 30.12108435017757\n",
      "retrain  39 :\n",
      "\ttrain: 0.7663551401869159 67.29932341225596 \ttest: 0.7717391304347826 30.125425259183118\n",
      "retrain  40 :\n",
      "\ttrain: 0.7663551401869159 67.27499869056001 \ttest: 0.7717391304347826 30.129759133099\n",
      "retrain  41 :\n",
      "\ttrain: 0.7663551401869159 67.25180539225822 \ttest: 0.7717391304347826 30.134071927227815\n",
      "retrain  42 :\n",
      "\ttrain: 0.7663551401869159 67.22967389003935 \ttest: 0.7717391304347826 30.138351456041626\n",
      "retrain  43 :\n",
      "\ttrain: 0.7663551401869159 67.20853926697127 \ttest: 0.7717391304347826 30.142587199869194\n",
      "retrain  44 :\n",
      "\ttrain: 0.7663551401869159 67.18834096823487 \ttest: 0.7717391304347826 30.146770129767074\n",
      "retrain  45 :\n",
      "\ttrain: 0.7663551401869159 67.16902248132344 \ttest: 0.7717391304347826 30.150892549164396\n",
      "retrain  46 :\n",
      "\ttrain: 0.7663551401869159 67.15053104208677 \ttest: 0.7717391304347826 30.154947950888786\n",
      "retrain  47 :\n",
      "\ttrain: 0.7663551401869159 67.1328173642705 \ttest: 0.7717391304347826 30.158930888233172\n",
      "retrain  48 :\n",
      "\ttrain: 0.7663551401869159 67.11583539044369 \ttest: 0.7717391304347826 30.162836858796172\n",
      "retrain  49 :\n",
      "\ttrain: 0.7663551401869159 67.09954206242244 \ttest: 0.7717391304347826 30.16666219991259\n",
      "retrain  50 :\n",
      "\ttrain: 0.7663551401869159 67.0838971094874 \ttest: 0.7717391304347826 30.17040399457928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.78919   0.92994   0.85380       157\n",
      "           1    0.62069   0.31579   0.41860        57\n",
      "\n",
      "    accuracy                        0.76636       214\n",
      "   macro avg    0.70494   0.62286   0.63620       214\n",
      "weighted avg    0.74431   0.76636   0.73788       214\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.80519   0.91176   0.85517        68\n",
      "           1    0.60000   0.37500   0.46154        24\n",
      "\n",
      "    accuracy                        0.77174        92\n",
      "   macro avg    0.70260   0.64338   0.65836        92\n",
      "weighted avg    0.75167   0.77174   0.75249        92\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 15\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 45\n",
      "5 15 1\n",
      "9 27 2\n",
      "13 39 3\n",
      "15 45 4\n",
      "15 45 5\n",
      "15 45 6\n",
      "15 45 7\n",
      "15 45 8\n",
      "15 45 9\n",
      "15 45 10\n",
      "15 45 11\n",
      "15 45 12\n",
      "15 45 13\n",
      "15 45 14\n",
      "15 45 15\n",
      "15 45 16\n",
      "15 45 17\n",
      "15 45 18\n",
      "16 48 19\n",
      "16 48 20\n",
      "16 48 21\n",
      "16 48 22\n",
      "16 48 23\n",
      "16 48 24\n",
      "16 48 25\n",
      "16 48 26\n",
      "16 48 27\n",
      "16 48 28\n",
      "16 48 29\n",
      "16 48 30\n",
      "16 48 31\n",
      "16 48 32\n",
      "16 48 33\n",
      "16 48 34\n",
      "16 48 35\n",
      "16 48 36\n",
      "16 48 37\n",
      "16 48 38\n",
      "16 48 39\n",
      "16 48 40\n",
      "16 48 41\n",
      "16 48 42\n",
      "16 48 43\n",
      "16 48 44\n",
      "16 48 45\n",
      "16 48 46\n",
      "16 48 47\n",
      "16 48 48\n",
      "16 48 49\n",
      "16 48 50\n",
      "16 48 51\n",
      "16 48 52\n",
      "16 48 53\n",
      "16 48 54\n",
      "16 48 55\n",
      "16 48 56\n",
      "16 48 57\n",
      "16 48 58\n",
      "16 48 59\n",
      "16 48 60\n",
      "16 48 61\n",
      "16 48 62\n",
      "16 48 63\n",
      "16 48 64\n",
      "16 48 65\n",
      "16 48 66\n",
      "16 48 67\n",
      "16 48 68\n",
      "16 48 69\n",
      "16 48 70\n",
      "16 48 71\n",
      "16 48 72\n",
      "16 48 73\n",
      "16 48 74\n",
      "16 48 75\n",
      "16 48 76\n",
      "16 48 77\n",
      "16 48 78\n",
      "16 48 79\n",
      "16 48 80\n",
      "16 48 81\n",
      "16 48 82\n",
      "16 48 83\n",
      "16 48 84\n",
      "16 48 85\n",
      "16 48 86\n",
      "16 48 87\n",
      "16 48 88\n",
      "16 48 89\n",
      "16 48 90\n",
      "16 48 91\n",
      "16 48 92\n",
      "16 48 93\n",
      "16 48 94\n",
      "16 48 95\n",
      "16 48 96\n",
      "16 48 97\n",
      "16 48 98\n",
      "16 48 99\n",
      "16 48 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.7336448598130841 75.8387505511432 \ttest: 0.7391304347826086 33.794372620475826\n",
      "retrain  2 :\n",
      "\ttrain: 0.7336448598130841 71.8246910163517 \ttest: 0.7391304347826086 33.215333270147816\n",
      "retrain  3 :\n",
      "\ttrain: 0.7336448598130841 69.66055173958696 \ttest: 0.7391304347826086 33.07774412613858\n",
      "retrain  4 :\n",
      "\ttrain: 0.7429906542056075 68.39377201788872 \ttest: 0.7391304347826086 33.08953761285895\n",
      "retrain  5 :\n",
      "\ttrain: 0.7757009345794392 67.57605904849449 \ttest: 0.7608695652173914 33.13865590435249\n",
      "retrain  6 :\n",
      "\ttrain: 0.7710280373831776 66.99707945188621 \ttest: 0.7608695652173914 33.18768205829416\n",
      "retrain  7 :\n",
      "\ttrain: 0.7850467289719626 66.55540051547592 \ttest: 0.75 33.227237645125896\n",
      "retrain  8 :\n",
      "\ttrain: 0.7850467289719626 66.19974131977254 \ttest: 0.75 33.257364970332084\n",
      "retrain  9 :\n",
      "\ttrain: 0.7850467289719626 65.90253416426522 \ttest: 0.75 33.28058193547234\n",
      "retrain  10 :\n",
      "\ttrain: 0.7850467289719626 65.64786618894375 \ttest: 0.75 33.29950753797792\n",
      "retrain  11 :\n",
      "\ttrain: 0.7850467289719626 65.42583657205029 \ttest: 0.75 33.31619598667369\n",
      "retrain  12 :\n",
      "\ttrain: 0.7850467289719626 65.22982753261957 \ttest: 0.75 33.33206798158126\n",
      "retrain  13 :\n",
      "\ttrain: 0.7850467289719626 65.05513208496987 \ttest: 0.7391304347826086 33.348020629547065\n",
      "retrain  14 :\n",
      "\ttrain: 0.7850467289719626 64.89823194704839 \ttest: 0.7391304347826086 33.36456629263681\n",
      "retrain  15 :\n",
      "\ttrain: 0.7850467289719626 64.75639717186573 \ttest: 0.7391304347826086 33.38195292119505\n",
      "retrain  16 :\n",
      "\ttrain: 0.7850467289719626 64.62745090632419 \ttest: 0.7391304347826086 33.40025583783352\n",
      "retrain  17 :\n",
      "\ttrain: 0.7850467289719626 64.50962256849911 \ttest: 0.7282608695652174 33.419443404505905\n",
      "retrain  18 :\n",
      "\ttrain: 0.7850467289719626 64.40145073250495 \ttest: 0.7282608695652174 33.439422143980636\n",
      "retrain  19 :\n",
      "\ttrain: 0.7850467289719626 64.30171550583867 \ttest: 0.7282608695652174 33.46006678301108\n",
      "retrain  20 :\n",
      "\ttrain: 0.7850467289719626 64.20938941060771 \ttest: 0.7282608695652174 33.48123965763608\n",
      "retrain  21 :\n",
      "\ttrain: 0.7850467289719626 64.1236005120719 \ttest: 0.7282608695652174 33.502802808178465\n",
      "retrain  22 :\n",
      "\ttrain: 0.7850467289719626 64.04360404555572 \ttest: 0.7282608695652174 33.5246251531224\n",
      "retrain  23 :\n",
      "\ttrain: 0.7850467289719626 63.968760174342215 \ttest: 0.7282608695652174 33.546586413117204\n",
      "retrain  24 :\n",
      "\ttrain: 0.7850467289719626 63.898516307296696 \ttest: 0.7282608695652174 33.5685789333629\n",
      "retrain  25 :\n",
      "\ttrain: 0.7850467289719626 63.83239288682795 \ttest: 0.7282608695652174 33.59050818228169\n",
      "retrain  26 :\n",
      "\ttrain: 0.7850467289719626 63.769971864315124 \ttest: 0.7282608695652174 33.61229244679863\n",
      "retrain  27 :\n",
      "\ttrain: 0.7850467289719626 63.710887284412216 \ttest: 0.7282608695652174 33.63386206764626\n",
      "retrain  28 :\n",
      "\ttrain: 0.7850467289719626 63.65481754140474 \ttest: 0.7282608695652174 33.655158437795095\n",
      "retrain  29 :\n",
      "\ttrain: 0.7850467289719626 63.60147897246972 \ttest: 0.7282608695652174 33.676132905999054\n",
      "retrain  30 :\n",
      "\ttrain: 0.7850467289719626 63.55062052751482 \ttest: 0.7282608695652174 33.69674567324489\n",
      "retrain  31 :\n",
      "\ttrain: 0.7850467289719626 63.50201931142679 \ttest: 0.7282608695652174 33.716964734041454\n",
      "retrain  32 :\n",
      "\ttrain: 0.7850467289719626 63.45547683733028 \ttest: 0.7282608695652174 33.73676489106648\n",
      "retrain  33 :\n",
      "\ttrain: 0.7850467289719626 63.410815862411276 \ttest: 0.7282608695652174 33.75612685664479\n",
      "retrain  34 :\n",
      "\ttrain: 0.7850467289719626 63.367877703475294 \ttest: 0.7282608695652174 33.775036445093335\n",
      "retrain  35 :\n",
      "\ttrain: 0.7850467289719626 63.326519949473024 \ttest: 0.7282608695652174 33.79348385424808\n",
      "retrain  36 :\n",
      "\ttrain: 0.7850467289719626 63.28661450403675 \ttest: 0.7282608695652174 33.8114630312109\n",
      "retrain  37 :\n",
      "\ttrain: 0.7850467289719626 63.24804590360145 \ttest: 0.7282608695652174 33.82897111565848\n",
      "retrain  38 :\n",
      "\ttrain: 0.7850467289719626 63.21070986666658 \ttest: 0.7282608695652174 33.84600795336386\n",
      "retrain  39 :\n",
      "\ttrain: 0.7850467289719626 63.17451203774323 \ttest: 0.7282608695652174 33.86257567250912\n",
      "retrain  40 :\n",
      "\ttrain: 0.7850467289719626 63.13936689595606 \ttest: 0.7282608695652174 33.878678315661745\n",
      "retrain  41 :\n",
      "\ttrain: 0.7850467289719626 63.10519680345622 \ttest: 0.7282608695652174 33.89432152078156\n",
      "retrain  42 :\n",
      "\ttrain: 0.7850467289719626 63.07193117300947 \ttest: 0.7282608695652174 33.9095122452133\n",
      "retrain  43 :\n",
      "\ttrain: 0.7850467289719626 63.03950573754916 \ttest: 0.7282608695652174 33.92425852723679\n",
      "retrain  44 :\n",
      "\ttrain: 0.7850467289719626 63.00786190728583 \ttest: 0.7282608695652174 33.9385692803507\n",
      "retrain  45 :\n",
      "\ttrain: 0.7850467289719626 62.97694620226356 \ttest: 0.7282608695652174 33.95245411603513\n",
      "retrain  46 :\n",
      "\ttrain: 0.7850467289719626 62.94670975014898 \ttest: 0.7282608695652174 33.965923191260956\n",
      "retrain  47 :\n",
      "\ttrain: 0.7850467289719626 62.91710784060511 \ttest: 0.7282608695652174 33.97898707748516\n",
      "retrain  48 :\n",
      "\ttrain: 0.7850467289719626 62.88809952890345 \ttest: 0.7282608695652174 33.991656648291396\n",
      "retrain  49 :\n",
      "\ttrain: 0.7850467289719626 62.85964728251139 \ttest: 0.7282608695652174 34.003942983205455\n",
      "retrain  50 :\n",
      "\ttrain: 0.7850467289719626 62.83171666529812 \ttest: 0.7282608695652174 34.01585728554049\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.81356   0.91720   0.86228       157\n",
      "           1    0.64865   0.42105   0.51064        57\n",
      "\n",
      "    accuracy                        0.78505       214\n",
      "   macro avg    0.73110   0.66913   0.68646       214\n",
      "weighted avg    0.76963   0.78505   0.76862       214\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.81159   0.82353   0.81752        68\n",
      "           1    0.47826   0.45833   0.46809        24\n",
      "\n",
      "    accuracy                        0.72826        92\n",
      "   macro avg    0.64493   0.64093   0.64280        92\n",
      "weighted avg    0.72464   0.72826   0.72636        92\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 16\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 48\n",
      "9 27 1\n",
      "12 36 2\n",
      "13 39 3\n",
      "16 48 4\n",
      "17 51 5\n",
      "17 51 6\n",
      "17 51 7\n",
      "17 51 8\n",
      "17 51 9\n",
      "18 54 10\n",
      "18 54 11\n",
      "18 54 12\n",
      "18 54 13\n",
      "18 54 14\n",
      "18 54 15\n",
      "18 54 16\n",
      "18 54 17\n",
      "18 54 18\n",
      "18 54 19\n",
      "18 54 20\n",
      "18 54 21\n",
      "18 54 22\n",
      "18 54 23\n",
      "18 54 24\n",
      "18 54 25\n",
      "18 54 26\n",
      "18 54 27\n",
      "18 54 28\n",
      "18 54 29\n",
      "18 54 30\n",
      "18 54 31\n",
      "18 54 32\n",
      "18 54 33\n",
      "18 54 34\n",
      "18 54 35\n",
      "18 54 36\n",
      "18 54 37\n",
      "18 54 38\n",
      "18 54 39\n",
      "18 54 40\n",
      "18 54 41\n",
      "18 54 42\n",
      "18 54 43\n",
      "18 54 44\n",
      "18 54 45\n",
      "18 54 46\n",
      "18 54 47\n",
      "18 54 48\n",
      "18 54 49\n",
      "18 54 50\n",
      "18 54 51\n",
      "18 54 52\n",
      "18 54 53\n",
      "18 54 54\n",
      "18 54 55\n",
      "18 54 56\n",
      "18 54 57\n",
      "18 54 58\n",
      "18 54 59\n",
      "18 54 60\n",
      "18 54 61\n",
      "18 54 62\n",
      "18 54 63\n",
      "18 54 64\n",
      "18 54 65\n",
      "18 54 66\n",
      "18 54 67\n",
      "18 54 68\n",
      "18 54 69\n",
      "18 54 70\n",
      "18 54 71\n",
      "18 54 72\n",
      "18 54 73\n",
      "18 54 74\n",
      "18 54 75\n",
      "18 54 76\n",
      "18 54 77\n",
      "18 54 78\n",
      "18 54 79\n",
      "18 54 80\n",
      "18 54 81\n",
      "18 54 82\n",
      "18 54 83\n",
      "18 54 84\n",
      "18 54 85\n",
      "18 54 86\n",
      "18 54 87\n",
      "18 54 88\n",
      "18 54 89\n",
      "18 54 90\n",
      "18 54 91\n",
      "18 54 92\n",
      "18 54 93\n",
      "18 54 94\n",
      "18 54 95\n",
      "18 54 96\n",
      "18 54 97\n",
      "18 54 98\n",
      "18 54 99\n",
      "18 54 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.7336448598130841 77.21341991289755 \ttest: 0.7391304347826086 32.61397167985557\n",
      "retrain  2 :\n",
      "\ttrain: 0.7336448598130841 74.05509459905699 \ttest: 0.7391304347826086 31.25908546146974\n",
      "retrain  3 :\n",
      "\ttrain: 0.7336448598130841 72.27325113367654 \ttest: 0.7391304347826086 30.574042749038718\n",
      "retrain  4 :\n",
      "\ttrain: 0.7383177570093458 71.11053062626509 \ttest: 0.7391304347826086 30.20901699606738\n",
      "retrain  5 :\n",
      "\ttrain: 0.7523364485981309 70.25966711189739 \ttest: 0.7282608695652174 30.01234112998119\n",
      "retrain  6 :\n",
      "\ttrain: 0.7663551401869159 69.58942852225704 \ttest: 0.7282608695652174 29.912927167424748\n",
      "retrain  7 :\n",
      "\ttrain: 0.7663551401869159 69.03860804688762 \ttest: 0.7282608695652174 29.87395145478526\n",
      "retrain  8 :\n",
      "\ttrain: 0.7663551401869159 68.57510192457609 \ttest: 0.7282608695652174 29.8742760545135\n",
      "retrain  9 :\n",
      "\ttrain: 0.780373831775701 68.17971351435816 \ttest: 0.7608695652173914 29.900658014284126\n",
      "retrain  10 :\n",
      "\ttrain: 0.780373831775701 67.8395013200906 \ttest: 0.7608695652173914 29.944261289202196\n",
      "retrain  11 :\n",
      "\ttrain: 0.780373831775701 67.54491773130907 \ttest: 0.7608695652173914 29.9989550671839\n",
      "retrain  12 :\n",
      "\ttrain: 0.7710280373831776 67.28850032637695 \ttest: 0.7608695652173914 30.060395780381533\n",
      "retrain  13 :\n",
      "\ttrain: 0.7710280373831776 67.06421962250576 \ttest: 0.7608695652173914 30.12547975068624\n",
      "retrain  14 :\n",
      "\ttrain: 0.7710280373831776 66.86711548443475 \ttest: 0.7608695652173914 30.191988698453997\n",
      "retrain  15 :\n",
      "\ttrain: 0.7710280373831776 66.69306803519318 \ttest: 0.7608695652173914 30.25834657840835\n",
      "retrain  16 :\n",
      "\ttrain: 0.7710280373831776 66.53863698198192 \ttest: 0.7608695652173914 30.32344686508966\n",
      "retrain  17 :\n",
      "\ttrain: 0.7710280373831776 66.40094004752721 \ttest: 0.7608695652173914 30.386527496709927\n",
      "retrain  18 :\n",
      "\ttrain: 0.7710280373831776 66.2775567170631 \ttest: 0.7608695652173914 30.447079409039752\n",
      "retrain  19 :\n",
      "\ttrain: 0.7710280373831776 66.16645016184529 \ttest: 0.7608695652173914 30.50477927498608\n",
      "retrain  20 :\n",
      "\ttrain: 0.7710280373831776 66.0659031434347 \ttest: 0.7608695652173914 30.55943987991528\n",
      "retrain  21 :\n",
      "\ttrain: 0.7710280373831776 65.97446509372136 \ttest: 0.7608695652173914 30.610973414202206\n",
      "retrain  22 :\n",
      "\ttrain: 0.7663551401869159 65.89090829962075 \ttest: 0.7608695652173914 30.65936425465372\n",
      "retrain  23 :\n",
      "\ttrain: 0.7663551401869159 65.81419156812882 \ttest: 0.7608695652173914 30.70464873265675\n",
      "retrain  24 :\n",
      "\ttrain: 0.7663551401869159 65.74343005840117 \ttest: 0.7608695652173914 30.74690006005832\n",
      "retrain  25 :\n",
      "\ttrain: 0.7663551401869159 65.67787020501058 \ttest: 0.7608695652173914 30.786217074696204\n",
      "retrain  26 :\n",
      "\ttrain: 0.7663551401869159 65.61686884709252 \ttest: 0.7608695652173914 30.822715825398646\n",
      "retrain  27 :\n",
      "\ttrain: 0.7663551401869159 65.55987583421198 \ttest: 0.7608695652173914 30.856523276888446\n",
      "retrain  28 :\n",
      "\ttrain: 0.7663551401869159 65.50641950851596 \ttest: 0.7608695652173914 30.887772604667955\n",
      "retrain  29 :\n",
      "\ttrain: 0.7663551401869159 65.45609456889659 \ttest: 0.7608695652173914 30.916599688006386\n",
      "retrain  30 :\n",
      "\ttrain: 0.7663551401869159 65.4085519102823 \ttest: 0.7608695652173914 30.943140509800564\n",
      "retrain  31 :\n",
      "\ttrain: 0.7663551401869159 65.36349010297282 \ttest: 0.7608695652173914 30.967529245677927\n",
      "retrain  32 :\n",
      "\ttrain: 0.7663551401869159 65.32064823583976 \ttest: 0.7608695652173914 30.98989687874469\n",
      "retrain  33 :\n",
      "\ttrain: 0.7663551401869159 65.27979989550761 \ttest: 0.7608695652173914 31.010370216252404\n",
      "retrain  34 :\n",
      "\ttrain: 0.7663551401869159 65.24074809322225 \ttest: 0.7608695652173914 31.029071214045963\n",
      "retrain  35 :\n",
      "\ttrain: 0.7663551401869159 65.20332098359194 \ttest: 0.7608695652173914 31.04611653675678\n",
      "retrain  36 :\n",
      "\ttrain: 0.7663551401869159 65.16736824605373 \ttest: 0.7608695652173914 31.06161729832177\n",
      "retrain  37 :\n",
      "\ttrain: 0.7663551401869159 65.13275802184342 \ttest: 0.7608695652173914 31.075678939989345\n",
      "retrain  38 :\n",
      "\ttrain: 0.7663551401869159 65.09937431730219 \ttest: 0.7608695652173914 31.088401212562374\n",
      "retrain  39 :\n",
      "\ttrain: 0.7663551401869159 65.06711479924452 \ttest: 0.7608695652173914 31.099878236985457\n",
      "retrain  40 :\n",
      "\ttrain: 0.7663551401869159 65.03588892041671 \ttest: 0.7608695652173914 31.110198623063873\n",
      "retrain  41 :\n",
      "\ttrain: 0.7663551401869159 65.00561632325855 \ttest: 0.7608695652173914 31.11944563051248\n",
      "retrain  42 :\n",
      "\ttrain: 0.7663551401869159 64.97622547862592 \ttest: 0.7608695652173914 31.127697359976022\n",
      "retrain  43 :\n",
      "\ttrain: 0.7663551401869159 64.94765252314518 \ttest: 0.7608695652173914 31.13502696436247\n",
      "retrain  44 :\n",
      "\ttrain: 0.7663551401869159 64.9198402647061 \ttest: 0.7608695652173914 31.14150287295736\n",
      "retrain  45 :\n",
      "\ttrain: 0.7663551401869159 64.89273733046278 \ttest: 0.7608695652173914 31.14718902246656\n",
      "retrain  46 :\n",
      "\ttrain: 0.7663551401869159 64.86629743577114 \ttest: 0.7608695652173914 31.152145090465535\n",
      "retrain  47 :\n",
      "\ttrain: 0.7663551401869159 64.84047875588455 \ttest: 0.7608695652173914 31.15642672778895\n",
      "retrain  48 :\n",
      "\ttrain: 0.7663551401869159 64.81524338506972 \ttest: 0.7608695652173914 31.160085787233474\n",
      "retrain  49 :\n",
      "\ttrain: 0.7663551401869159 64.7905568701864 \ttest: 0.7608695652173914 31.163170546613387\n",
      "retrain  50 :\n",
      "\ttrain: 0.7663551401869159 64.7663878077728 \ttest: 0.7608695652173914 31.165725924738474\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.79888   0.91083   0.85119       157\n",
      "           1    0.60000   0.36842   0.45652        57\n",
      "\n",
      "    accuracy                        0.76636       214\n",
      "   macro avg    0.69944   0.63962   0.65386       214\n",
      "weighted avg    0.74591   0.76636   0.74607       214\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.79487   0.91176   0.84932        68\n",
      "           1    0.57143   0.33333   0.42105        24\n",
      "\n",
      "    accuracy                        0.76087        92\n",
      "   macro avg    0.68315   0.62255   0.63518        92\n",
      "weighted avg    0.73658   0.76087   0.73759        92\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 18\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 54\n",
      "9 27 1\n",
      "12 36 2\n",
      "14 42 3\n",
      "15 45 4\n",
      "15 45 5\n",
      "15 45 6\n",
      "15 45 7\n",
      "15 45 8\n",
      "16 48 9\n",
      "16 48 10\n",
      "16 48 11\n",
      "16 48 12\n",
      "16 48 13\n",
      "16 48 14\n",
      "16 48 15\n",
      "16 48 16\n",
      "16 48 17\n",
      "16 48 18\n",
      "16 48 19\n",
      "16 48 20\n",
      "16 48 21\n",
      "16 48 22\n",
      "16 48 23\n",
      "16 48 24\n",
      "16 48 25\n",
      "16 48 26\n",
      "16 48 27\n",
      "16 48 28\n",
      "16 48 29\n",
      "16 48 30\n",
      "16 48 31\n",
      "16 48 32\n",
      "16 48 33\n",
      "16 48 34\n",
      "16 48 35\n",
      "16 48 36\n",
      "16 48 37\n",
      "16 48 38\n",
      "16 48 39\n",
      "16 48 40\n",
      "16 48 41\n",
      "16 48 42\n",
      "16 48 43\n",
      "16 48 44\n",
      "16 48 45\n",
      "16 48 46\n",
      "16 48 47\n",
      "16 48 48\n",
      "16 48 49\n",
      "16 48 50\n",
      "16 48 51\n",
      "16 48 52\n",
      "16 48 53\n",
      "16 48 54\n",
      "16 48 55\n",
      "16 48 56\n",
      "16 48 57\n",
      "16 48 58\n",
      "16 48 59\n",
      "16 48 60\n",
      "16 48 61\n",
      "16 48 62\n",
      "16 48 63\n",
      "16 48 64\n",
      "16 48 65\n",
      "16 48 66\n",
      "16 48 67\n",
      "16 48 68\n",
      "16 48 69\n",
      "16 48 70\n",
      "16 48 71\n",
      "16 48 72\n",
      "16 48 73\n",
      "16 48 74\n",
      "16 48 75\n",
      "16 48 76\n",
      "16 48 77\n",
      "16 48 78\n",
      "16 48 79\n",
      "16 48 80\n",
      "16 48 81\n",
      "16 48 82\n",
      "16 48 83\n",
      "16 48 84\n",
      "16 48 85\n",
      "16 48 86\n",
      "16 48 87\n",
      "16 48 88\n",
      "16 48 89\n",
      "16 48 90\n",
      "16 48 91\n",
      "16 48 92\n",
      "16 48 93\n",
      "16 48 94\n",
      "16 48 95\n",
      "16 48 96\n",
      "16 48 97\n",
      "16 48 98\n",
      "16 48 99\n",
      "16 48 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.7336448598130841 75.43198733761199 \ttest: 0.7391304347826086 34.199690867025424\n",
      "retrain  2 :\n",
      "\ttrain: 0.7336448598130841 70.64471666775668 \ttest: 0.7391304347826086 33.81697461771181\n",
      "retrain  3 :\n",
      "\ttrain: 0.7336448598130841 67.85339421966229 \ttest: 0.7391304347826086 33.84987433169549\n",
      "retrain  4 :\n",
      "\ttrain: 0.7850467289719626 66.17272701037116 \ttest: 0.75 34.03792746122847\n",
      "retrain  5 :\n",
      "\ttrain: 0.780373831775701 65.10638835347362 \ttest: 0.7391304347826086 34.26105477144882\n",
      "retrain  6 :\n",
      "\ttrain: 0.794392523364486 64.38761627759254 \ttest: 0.7065217391304348 34.470918356552815\n",
      "retrain  7 :\n",
      "\ttrain: 0.794392523364486 63.873386654676395 \ttest: 0.7065217391304348 34.651924862810624\n",
      "retrain  8 :\n",
      "\ttrain: 0.7990654205607477 63.48556492814485 \ttest: 0.7065217391304348 34.802197336249094\n",
      "retrain  9 :\n",
      "\ttrain: 0.8084112149532711 63.18011657476094 \ttest: 0.6956521739130435 34.924946701446174\n",
      "retrain  10 :\n",
      "\ttrain: 0.8084112149532711 62.931231571111695 \ttest: 0.6956521739130435 35.024762038845395\n",
      "retrain  11 :\n",
      "\ttrain: 0.8084112149532711 62.72309140675026 \ttest: 0.6956521739130435 35.10612635596622\n",
      "retrain  12 :\n",
      "\ttrain: 0.8084112149532711 62.54553182665183 \ttest: 0.6956521739130435 35.17290762543933\n",
      "retrain  13 :\n",
      "\ttrain: 0.8084112149532711 62.39170807618843 \ttest: 0.6956521739130435 35.22825904038708\n",
      "retrain  14 :\n",
      "\ttrain: 0.8084112149532711 62.256804962885205 \ttest: 0.6956521739130435 35.27467671338698\n",
      "retrain  15 :\n",
      "\ttrain: 0.8084112149532711 62.13730237301443 \ttest: 0.6956521739130435 35.31410567558679\n",
      "retrain  16 :\n",
      "\ttrain: 0.8084112149532711 62.03054258675741 \ttest: 0.6956521739130435 35.3480492378057\n",
      "retrain  17 :\n",
      "\ttrain: 0.8084112149532711 61.934465702684555 \ttest: 0.6956521739130435 35.37766527200952\n",
      "retrain  18 :\n",
      "\ttrain: 0.8084112149532711 61.84744138753063 \ttest: 0.6956521739130435 35.40384523455397\n",
      "retrain  19 :\n",
      "\ttrain: 0.8084112149532711 61.76815759687638 \ttest: 0.6956521739130435 35.42727668198899\n",
      "retrain  20 :\n",
      "\ttrain: 0.8084112149532711 61.69554417848066 \ttest: 0.6956521739130435 35.44849170546745\n",
      "retrain  21 :\n",
      "\ttrain: 0.8084112149532711 61.62871862656314 \ttest: 0.6956521739130435 35.46790399916872\n",
      "retrain  22 :\n",
      "\ttrain: 0.8084112149532711 61.56694642637517 \ttest: 0.6956521739130435 35.48583702926713\n",
      "retrain  23 :\n",
      "\ttrain: 0.8084112149532711 61.5096113505861 \ttest: 0.6956521739130435 35.502545357992624\n",
      "retrain  24 :\n",
      "\ttrain: 0.8084112149532711 61.45619276263522 \ttest: 0.6956521739130435 35.5182307594352\n",
      "retrain  25 :\n",
      "\ttrain: 0.8084112149532711 61.40624799198747 \ttest: 0.6956521739130435 35.53305439801129\n",
      "retrain  26 :\n",
      "\ttrain: 0.8084112149532711 61.35939846720245 \ttest: 0.6956521739130435 35.54714604144556\n",
      "retrain  27 :\n",
      "\ttrain: 0.8084112149532711 61.315318687195784 \ttest: 0.6956521739130435 35.56061104440849\n",
      "retrain  28 :\n",
      "\ttrain: 0.8084112149532711 61.27372736996189 \ttest: 0.6956521739130435 35.57353565715165\n",
      "retrain  29 :\n",
      "\ttrain: 0.8084112149532711 61.234380293322666 \ttest: 0.6956521739130435 35.585991075124674\n",
      "retrain  30 :\n",
      "\ttrain: 0.8084112149532711 61.19706446439687 \ttest: 0.6956521739130435 35.598036541138725\n",
      "retrain  31 :\n",
      "\ttrain: 0.8084112149532711 61.16159334173618 \ttest: 0.6956521739130435 35.60972173324805\n",
      "retrain  32 :\n",
      "\ttrain: 0.8084112149532711 61.127802897752694 \ttest: 0.6956521739130435 35.621088612856035\n",
      "retrain  33 :\n",
      "\ttrain: 0.8084112149532711 61.09554835637063 \ttest: 0.6956521739130435 35.63217286373026\n",
      "retrain  34 :\n",
      "\ttrain: 0.8084112149532711 61.06470147649941 \ttest: 0.6956521739130435 35.64300501990578\n",
      "retrain  35 :\n",
      "\ttrain: 0.8084112149532711 61.035148279137275 \ttest: 0.6956521739130435 35.65361135605089\n",
      "retrain  36 :\n",
      "\ttrain: 0.8084112149532711 61.006787136883716 \ttest: 0.6956521739130435 35.664014595653455\n",
      "retrain  37 :\n",
      "\ttrain: 0.8084112149532711 60.97952716093491 \ttest: 0.6956521739130435 35.67423447877808\n",
      "retrain  38 :\n",
      "\ttrain: 0.8084112149532711 60.95328683338886 \ttest: 0.6956521739130435 35.68428822096962\n",
      "retrain  39 :\n",
      "\ttrain: 0.8084112149532711 60.92799284273133 \ttest: 0.6956521739130435 35.69419088725891\n",
      "retrain  40 :\n",
      "\ttrain: 0.8084112149532711 60.90357908832712 \ttest: 0.6956521739130435 35.70395569951259\n",
      "retrain  41 :\n",
      "\ttrain: 0.8084112149532711 60.87998582607323 \ttest: 0.6956521739130435 35.71359429107455\n",
      "retrain  42 :\n",
      "\ttrain: 0.8084112149532711 60.85715893243286 \ttest: 0.6956521739130435 35.72311691941241\n",
      "retrain  43 :\n",
      "\ttrain: 0.8084112149532711 60.83504926813671 \ttest: 0.6956521739130435 35.73253264504061\n",
      "retrain  44 :\n",
      "\ttrain: 0.8084112149532711 60.81361212611875 \ttest: 0.6956521739130435 35.74184948314261\n",
      "retrain  45 :\n",
      "\ttrain: 0.8084112149532711 60.79280675090987 \ttest: 0.6956521739130435 35.75107453290963\n",
      "retrain  46 :\n",
      "\ttrain: 0.8084112149532711 60.77259591887346 \ttest: 0.6956521739130435 35.76021408854224\n",
      "retrain  47 :\n",
      "\ttrain: 0.8084112149532711 60.75294557042899 \ttest: 0.6956521739130435 35.7692737350404\n",
      "retrain  48 :\n",
      "\ttrain: 0.8084112149532711 60.73382448685396 \ttest: 0.6956521739130435 35.7782584312766\n",
      "retrain  49 :\n",
      "\ttrain: 0.8084112149532711 60.71520400544002 \ttest: 0.6956521739130435 35.787172582358345\n",
      "retrain  50 :\n",
      "\ttrain: 0.8084112149532711 60.6970577677586 \ttest: 0.6956521739130435 35.79602010290674\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.84118   0.91083   0.87462       157\n",
      "           1    0.68182   0.52632   0.59406        57\n",
      "\n",
      "    accuracy                        0.80841       214\n",
      "   macro avg    0.76150   0.71857   0.73434       214\n",
      "weighted avg    0.79873   0.80841   0.79989       214\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.77027   0.83824   0.80282        68\n",
      "           1    0.38889   0.29167   0.33333        24\n",
      "\n",
      "    accuracy                        0.69565        92\n",
      "   macro avg    0.57958   0.56495   0.56808        92\n",
      "weighted avg    0.67078   0.69565   0.68034        92\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 16\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 48\n",
      "6 18 1\n",
      "9 27 2\n",
      "12 36 3\n",
      "13 39 4\n",
      "13 39 5\n",
      "14 42 6\n",
      "14 42 7\n",
      "14 42 8\n",
      "15 45 9\n",
      "16 48 10\n",
      "16 48 11\n",
      "16 48 12\n",
      "16 48 13\n",
      "16 48 14\n",
      "16 48 15\n",
      "16 48 16\n",
      "16 48 17\n",
      "16 48 18\n",
      "16 48 19\n",
      "16 48 20\n",
      "16 48 21\n",
      "16 48 22\n",
      "16 48 23\n",
      "16 48 24\n",
      "16 48 25\n",
      "16 48 26\n",
      "16 48 27\n",
      "16 48 28\n",
      "16 48 29\n",
      "16 48 30\n",
      "16 48 31\n",
      "16 48 32\n",
      "16 48 33\n",
      "16 48 34\n",
      "16 48 35\n",
      "16 48 36\n",
      "16 48 37\n",
      "16 48 38\n",
      "16 48 39\n",
      "16 48 40\n",
      "16 48 41\n",
      "16 48 42\n",
      "16 48 43\n",
      "16 48 44\n",
      "16 48 45\n",
      "16 48 46\n",
      "16 48 47\n",
      "16 48 48\n",
      "16 48 49\n",
      "16 48 50\n",
      "16 48 51\n",
      "16 48 52\n",
      "16 48 53\n",
      "16 48 54\n",
      "16 48 55\n",
      "16 48 56\n",
      "16 48 57\n",
      "16 48 58\n",
      "16 48 59\n",
      "16 48 60\n",
      "16 48 61\n",
      "16 48 62\n",
      "16 48 63\n",
      "16 48 64\n",
      "16 48 65\n",
      "16 48 66\n",
      "16 48 67\n",
      "16 48 68\n",
      "16 48 69\n",
      "16 48 70\n",
      "16 48 71\n",
      "16 48 72\n",
      "16 48 73\n",
      "16 48 74\n",
      "16 48 75\n",
      "16 48 76\n",
      "16 48 77\n",
      "16 48 78\n",
      "16 48 79\n",
      "16 48 80\n",
      "16 48 81\n",
      "16 48 82\n",
      "16 48 83\n",
      "16 48 84\n",
      "16 48 85\n",
      "16 48 86\n",
      "16 48 87\n",
      "16 48 88\n",
      "16 48 89\n",
      "16 48 90\n",
      "16 48 91\n",
      "16 48 92\n",
      "16 48 93\n",
      "16 48 94\n",
      "16 48 95\n",
      "16 48 96\n",
      "16 48 97\n",
      "16 48 98\n",
      "16 48 99\n",
      "16 48 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.7336448598130841 75.58305291163353 \ttest: 0.7391304347826086 33.77957745911173\n",
      "retrain  2 :\n",
      "\ttrain: 0.7336448598130841 71.3570640389079 \ttest: 0.7391304347826086 33.215517417181985\n",
      "retrain  3 :\n",
      "\ttrain: 0.7336448598130841 68.97208326430783 \ttest: 0.7391304347826086 33.106724332423994\n",
      "retrain  4 :\n",
      "\ttrain: 0.7429906542056075 67.47941696934673 \ttest: 0.75 33.162103899129136\n",
      "retrain  5 :\n",
      "\ttrain: 0.7710280373831776 66.44377217697384 \ttest: 0.7608695652173914 33.2676793705384\n",
      "retrain  6 :\n",
      "\ttrain: 0.780373831775701 65.66283525190194 \ttest: 0.7608695652173914 33.38167876825607\n",
      "retrain  7 :\n",
      "\ttrain: 0.780373831775701 65.03791325347098 \ttest: 0.7608695652173914 33.49024688350957\n",
      "retrain  8 :\n",
      "\ttrain: 0.7757009345794392 64.51734333444321 \ttest: 0.7608695652173914 33.58988264257384\n",
      "retrain  9 :\n",
      "\ttrain: 0.7710280373831776 64.07177873565723 \ttest: 0.7608695652173914 33.6806781114547\n",
      "retrain  10 :\n",
      "\ttrain: 0.7710280373831776 63.68312263715195 \ttest: 0.7608695652173914 33.763780543849826\n",
      "retrain  11 :\n",
      "\ttrain: 0.7757009345794392 63.33936512207051 \ttest: 0.75 33.84048241312591\n",
      "retrain  12 :\n",
      "\ttrain: 0.7757009345794392 63.03204397429941 \ttest: 0.75 33.91193014681356\n",
      "retrain  13 :\n",
      "\ttrain: 0.7757009345794392 62.75491673933786 \ttest: 0.75 33.97906057776016\n",
      "retrain  14 :\n",
      "\ttrain: 0.7757009345794392 62.503218365927815 \ttest: 0.75 34.042614662254564\n",
      "retrain  15 :\n",
      "\ttrain: 0.7757009345794392 62.27321749410963 \ttest: 0.75 34.1031718426772\n",
      "retrain  16 :\n",
      "\ttrain: 0.7757009345794392 62.06193435419099 \ttest: 0.75 34.16118498241089\n",
      "retrain  17 :\n",
      "\ttrain: 0.7757009345794392 61.86695171303269 \ttest: 0.75 34.21700982952713\n",
      "retrain  18 :\n",
      "\ttrain: 0.794392523364486 61.6862827200161 \ttest: 0.7282608695652174 34.27092811622011\n",
      "retrain  19 :\n",
      "\ttrain: 0.794392523364486 61.51827548585253 \ttest: 0.7282608695652174 34.32316508318056\n",
      "retrain  20 :\n",
      "\ttrain: 0.794392523364486 61.361542476156586 \ttest: 0.7282608695652174 34.37390258931641\n",
      "retrain  21 :\n",
      "\ttrain: 0.8037383177570093 61.21490728222451 \ttest: 0.7282608695652174 34.42328888364975\n",
      "retrain  22 :\n",
      "\ttrain: 0.8037383177570093 61.077363900234985 \ttest: 0.7282608695652174 34.471445909643464\n",
      "retrain  23 :\n",
      "\ttrain: 0.8037383177570093 60.948045203816164 \ttest: 0.7282608695652174 34.51847480326326\n",
      "retrain  24 :\n",
      "\ttrain: 0.8037383177570093 60.826198282142514 \ttest: 0.7282608695652174 34.5644600717892\n",
      "retrain  25 :\n",
      "\ttrain: 0.8037383177570093 60.71116497003789 \ttest: 0.7282608695652174 34.60947280621971\n",
      "retrain  26 :\n",
      "\ttrain: 0.8037383177570093 60.60236634528506 \ttest: 0.7282608695652174 34.65357318095403\n",
      "retrain  27 :\n",
      "\ttrain: 0.8037383177570093 60.49929028433534 \ttest: 0.7282608695652174 34.69681242279306\n",
      "retrain  28 :\n",
      "\ttrain: 0.8037383177570093 60.401481394673326 \ttest: 0.7282608695652174 34.73923438017842\n",
      "retrain  29 :\n",
      "\ttrain: 0.8037383177570093 60.30853280777755 \ttest: 0.7282608695652174 34.78087678735039\n",
      "retrain  30 :\n",
      "\ttrain: 0.8037383177570093 60.2200794389708 \ttest: 0.7282608695652174 34.82177229247341\n",
      "retrain  31 :\n",
      "\ttrain: 0.8037383177570093 60.135792411680114 \ttest: 0.7282608695652174 34.86194930062792\n",
      "retrain  32 :\n",
      "\ttrain: 0.8037383177570093 60.05537441219202 \ttest: 0.7282608695652174 34.90143266966667\n",
      "retrain  33 :\n",
      "\ttrain: 0.8037383177570093 59.97855579288653 \ttest: 0.7282608695652174 34.940244287704814\n",
      "retrain  34 :\n",
      "\ttrain: 0.8037383177570093 59.90509128146341 \ttest: 0.7282608695652174 34.978403554351544\n",
      "retrain  35 :\n",
      "\ttrain: 0.8037383177570093 59.83475718396512 \ttest: 0.7282608695652174 35.015927782930106\n",
      "retrain  36 :\n",
      "\ttrain: 0.8037383177570093 59.76734899273971 \ttest: 0.7282608695652174 35.0528325373381\n",
      "retrain  37 :\n",
      "\ttrain: 0.8037383177570093 59.70267932856975 \ttest: 0.7282608695652174 35.08913191450286\n",
      "retrain  38 :\n",
      "\ttrain: 0.8037383177570093 59.64057616027599 \ttest: 0.7282608695652174 35.124838781329906\n",
      "retrain  39 :\n",
      "\ttrain: 0.8037383177570093 59.58088125612977 \ttest: 0.7282608695652174 35.15996497344957\n",
      "retrain  40 :\n",
      "\ttrain: 0.8037383177570093 59.523448830083794 \ttest: 0.7282608695652174 35.19452146181202\n",
      "retrain  41 :\n",
      "\ttrain: 0.8037383177570093 59.468144352691134 \ttest: 0.7282608695652174 35.22851849217876\n",
      "retrain  42 :\n",
      "\ttrain: 0.8037383177570093 59.41484350203528 \ttest: 0.7282608695652174 35.261965701745595\n",
      "retrain  43 :\n",
      "\ttrain: 0.8037383177570093 59.36343123434818 \ttest: 0.7282608695652174 35.29487221646632\n",
      "retrain  44 :\n",
      "\ttrain: 0.8037383177570093 59.31380095748906 \ttest: 0.7282608695652174 35.32724673209395\n",
      "retrain  45 :\n",
      "\ttrain: 0.8037383177570093 59.26585379327457 \ttest: 0.7282608695652174 35.35909758149512\n",
      "retrain  46 :\n",
      "\ttrain: 0.8037383177570093 59.21949791693581 \ttest: 0.7282608695652174 35.39043279040559\n",
      "retrain  47 :\n",
      "\ttrain: 0.8037383177570093 59.174647963836975 \ttest: 0.7282608695652174 35.42126012346678\n",
      "retrain  48 :\n",
      "\ttrain: 0.8037383177570093 59.131224495113074 \ttest: 0.7282608695652174 35.45158712210518\n",
      "retrain  49 :\n",
      "\ttrain: 0.8037383177570093 59.089153515134505 \ttest: 0.7282608695652174 35.48142113557985\n",
      "retrain  50 :\n",
      "\ttrain: 0.8037383177570093 59.048366034740674 \ttest: 0.7282608695652174 35.51076934632176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.83626   0.91083   0.87195       157\n",
      "           1    0.67442   0.50877   0.58000        57\n",
      "\n",
      "    accuracy                        0.80374       214\n",
      "   macro avg    0.75534   0.70980   0.72598       214\n",
      "weighted avg    0.79315   0.80374   0.79419       214\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.77215   0.89706   0.82993        68\n",
      "           1    0.46154   0.25000   0.32432        24\n",
      "\n",
      "    accuracy                        0.72826        92\n",
      "   macro avg    0.61685   0.57353   0.57713        92\n",
      "weighted avg    0.69112   0.72826   0.69803        92\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 16\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 48\n",
      "8 24 1\n",
      "13 39 2\n",
      "16 48 3\n",
      "16 48 4\n",
      "16 48 5\n",
      "17 51 6\n",
      "17 51 7\n",
      "17 51 8\n",
      "17 51 9\n",
      "17 51 10\n",
      "17 51 11\n",
      "17 51 12\n",
      "17 51 13\n",
      "17 51 14\n",
      "18 54 15\n",
      "18 54 16\n",
      "18 54 17\n",
      "18 54 18\n",
      "18 54 19\n",
      "18 54 20\n",
      "18 54 21\n",
      "18 54 22\n",
      "18 54 23\n",
      "18 54 24\n",
      "18 54 25\n",
      "18 54 26\n",
      "18 54 27\n",
      "18 54 28\n",
      "18 54 29\n",
      "18 54 30\n",
      "18 54 31\n",
      "18 54 32\n",
      "18 54 33\n",
      "18 54 34\n",
      "18 54 35\n",
      "18 54 36\n",
      "18 54 37\n",
      "18 54 38\n",
      "18 54 39\n",
      "18 54 40\n",
      "18 54 41\n",
      "18 54 42\n",
      "18 54 43\n",
      "18 54 44\n",
      "18 54 45\n",
      "18 54 46\n",
      "18 54 47\n",
      "18 54 48\n",
      "18 54 49\n",
      "18 54 50\n",
      "18 54 51\n",
      "18 54 52\n",
      "18 54 53\n",
      "18 54 54\n",
      "18 54 55\n",
      "18 54 56\n",
      "18 54 57\n",
      "18 54 58\n",
      "18 54 59\n",
      "18 54 60\n",
      "18 54 61\n",
      "18 54 62\n",
      "18 54 63\n",
      "18 54 64\n",
      "18 54 65\n",
      "18 54 66\n",
      "18 54 67\n",
      "18 54 68\n",
      "18 54 69\n",
      "18 54 70\n",
      "18 54 71\n",
      "18 54 72\n",
      "18 54 73\n",
      "18 54 74\n",
      "18 54 75\n",
      "18 54 76\n",
      "18 54 77\n",
      "18 54 78\n",
      "18 54 79\n",
      "18 54 80\n",
      "18 54 81\n",
      "18 54 82\n",
      "18 54 83\n",
      "18 54 84\n",
      "18 54 85\n",
      "18 54 86\n",
      "18 54 87\n",
      "18 54 88\n",
      "18 54 89\n",
      "18 54 90\n",
      "18 54 91\n",
      "18 54 92\n",
      "18 54 93\n",
      "18 54 94\n",
      "18 54 95\n",
      "18 54 96\n",
      "18 54 97\n",
      "18 54 98\n",
      "18 54 99\n",
      "18 54 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.7336448598130841 75.6280345911226 \ttest: 0.7391304347826086 33.371040577780846\n",
      "retrain  2 :\n",
      "\ttrain: 0.7336448598130841 71.71209857787593 \ttest: 0.7391304347826086 32.525034107517826\n",
      "retrain  3 :\n",
      "\ttrain: 0.7383177570093458 69.60286080095 \ttest: 0.7391304347826086 32.15960439616032\n",
      "retrain  4 :\n",
      "\ttrain: 0.7429906542056075 68.31558363708879 \ttest: 0.75 31.975388842950117\n",
      "retrain  5 :\n",
      "\ttrain: 0.7570093457943925 67.43088954512916 \ttest: 0.7391304347826086 31.862324827099094\n",
      "retrain  6 :\n",
      "\ttrain: 0.7897196261682243 66.7646695589793 \ttest: 0.7608695652173914 31.78014594708329\n",
      "retrain  7 :\n",
      "\ttrain: 0.7897196261682243 66.23097565060114 \ttest: 0.7717391304347826 31.71365415554491\n",
      "retrain  8 :\n",
      "\ttrain: 0.7897196261682243 65.78620008108169 \ttest: 0.7717391304347826 31.656602744715276\n",
      "retrain  9 :\n",
      "\ttrain: 0.7897196261682243 65.40597095649778 \ttest: 0.7717391304347826 31.605986404491485\n",
      "retrain  10 :\n",
      "\ttrain: 0.7850467289719626 65.07526211543546 \ttest: 0.7717391304347826 31.560044927398266\n",
      "retrain  11 :\n",
      "\ttrain: 0.7757009345794392 64.78397178312795 \ttest: 0.7717391304347826 31.517575106224818\n",
      "retrain  12 :\n",
      "\ttrain: 0.7757009345794392 64.5248378766573 \ttest: 0.7717391304347826 31.47769234673092\n",
      "retrain  13 :\n",
      "\ttrain: 0.7757009345794392 64.29238797001392 \ttest: 0.7717391304347826 31.43973944533124\n",
      "retrain  14 :\n",
      "\ttrain: 0.7757009345794392 64.08236676181666 \ttest: 0.7717391304347826 31.403239732114884\n",
      "retrain  15 :\n",
      "\ttrain: 0.7757009345794392 63.89139565977294 \ttest: 0.7717391304347826 31.36786253453703\n",
      "retrain  16 :\n",
      "\ttrain: 0.7757009345794392 63.716752973343155 \ttest: 0.7717391304347826 31.333392808008846\n",
      "retrain  17 :\n",
      "\ttrain: 0.7757009345794392 63.5562220138348 \ttest: 0.7717391304347826 31.2997039304755\n",
      "retrain  18 :\n",
      "\ttrain: 0.7757009345794392 63.40798082928362 \ttest: 0.7717391304347826 31.266734163581816\n",
      "retrain  19 :\n",
      "\ttrain: 0.7757009345794392 63.27051951865121 \ttest: 0.7717391304347826 31.23446714861798\n",
      "retrain  20 :\n",
      "\ttrain: 0.7757009345794392 63.142576950886536 \ttest: 0.7717391304347826 31.2029163859348\n",
      "retrain  21 :\n",
      "\ttrain: 0.7850467289719626 63.02309171622157 \ttest: 0.7608695652173914 31.17211332829539\n",
      "retrain  22 :\n",
      "\ttrain: 0.7850467289719626 62.91116379251074 \ttest: 0.7608695652173914 31.142098558434725\n",
      "retrain  23 :\n",
      "\ttrain: 0.7850467289719626 62.80602440587775 \ttest: 0.7608695652173914 31.112915482383258\n",
      "retrain  24 :\n",
      "\ttrain: 0.7850467289719626 62.707012216381244 \ttest: 0.7608695652173914 31.084606004182056\n",
      "retrain  25 :\n",
      "\ttrain: 0.7850467289719626 62.61355441403971 \ttest: 0.7608695652173914 31.05720771662457\n",
      "retrain  26 :\n",
      "\ttrain: 0.7850467289719626 62.52515164223877 \ttest: 0.7608695652173914 31.03075222243078\n",
      "retrain  27 :\n",
      "\ttrain: 0.7850467289719626 62.441365914129115 \ttest: 0.7608695652173914 31.005264277369506\n",
      "retrain  28 :\n",
      "\ttrain: 0.7850467289719626 62.36181087674441 \ttest: 0.7608695652173914 30.98076151497013\n",
      "retrain  29 :\n",
      "\ttrain: 0.7850467289719626 62.28614392258919 \ttest: 0.7608695652173914 30.957254569489187\n",
      "retrain  30 :\n",
      "\ttrain: 0.7850467289719626 62.214059760098905 \ttest: 0.7608695652173914 30.934747459852005\n",
      "retrain  31 :\n",
      "\ttrain: 0.7850467289719626 62.145285140517856 \ttest: 0.7608695652173914 30.913238133552756\n",
      "retrain  32 :\n",
      "\ttrain: 0.7850467289719626 62.07957450529527 \ttest: 0.7608695652173914 30.892719097510653\n",
      "retrain  33 :\n",
      "\ttrain: 0.7850467289719626 62.01670636957331 \ttest: 0.7608695652173914 30.87317808419463\n",
      "retrain  34 :\n",
      "\ttrain: 0.7850467289719626 61.95648029720005 \ttest: 0.7608695652173914 30.85459871733744\n",
      "retrain  35 :\n",
      "\ttrain: 0.7897196261682243 61.89871435360652 \ttest: 0.7608695652173914 30.836961153439724\n",
      "retrain  36 :\n",
      "\ttrain: 0.7897196261682243 61.8432429468895 \ttest: 0.7608695652173914 30.82024268397555\n",
      "retrain  37 :\n",
      "\ttrain: 0.7897196261682243 61.78991498611709 \ttest: 0.7608695652173914 30.804418289514537\n",
      "retrain  38 :\n",
      "\ttrain: 0.7897196261682243 61.73859230043571 \ttest: 0.7608695652173914 30.78946114146766\n",
      "retrain  39 :\n",
      "\ttrain: 0.7897196261682243 61.689148273936965 \ttest: 0.7608695652173914 30.775343050303007\n",
      "retrain  40 :\n",
      "\ttrain: 0.7897196261682243 61.64146666016091 \ttest: 0.7608695652173914 30.762034861214495\n",
      "retrain  41 :\n",
      "\ttrain: 0.7897196261682243 61.59544054711912 \ttest: 0.7608695652173914 30.749506799627238\n",
      "retrain  42 :\n",
      "\ttrain: 0.7897196261682243 61.550971449246184 \ttest: 0.7608695652173914 30.737728769788234\n",
      "retrain  43 :\n",
      "\ttrain: 0.7897196261682243 61.50796850705759 \ttest: 0.7608695652173914 30.72667061017065\n",
      "retrain  44 :\n",
      "\ttrain: 0.7897196261682243 61.46634777876247 \ttest: 0.7608695652173914 30.716302309627075\n",
      "retrain  45 :\n",
      "\ttrain: 0.7897196261682243 61.42603161084559 \ttest: 0.7608695652173914 30.706594188244225\n",
      "retrain  46 :\n",
      "\ttrain: 0.7850467289719626 61.3869480768482 \ttest: 0.7608695652173914 30.6975170467413\n",
      "retrain  47 :\n",
      "\ttrain: 0.7850467289719626 61.349030475359754 \ttest: 0.7608695652173914 30.68904228806028\n",
      "retrain  48 :\n",
      "\ttrain: 0.7850467289719626 61.31221687967249 \ttest: 0.7608695652173914 30.681142014553288\n",
      "retrain  49 :\n",
      "\ttrain: 0.7850467289719626 61.2764497327227 \ttest: 0.7608695652173914 30.673789103901818\n",
      "retrain  50 :\n",
      "\ttrain: 0.7850467289719626 61.241675481899236 \ttest: 0.7608695652173914 30.6669572666223\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.82081   0.90446   0.86061       157\n",
      "           1    0.63415   0.45614   0.53061        57\n",
      "\n",
      "    accuracy                        0.78505       214\n",
      "   macro avg    0.72748   0.68030   0.69561       214\n",
      "weighted avg    0.77109   0.78505   0.77271       214\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.78750   0.92647   0.85135        68\n",
      "           1    0.58333   0.29167   0.38889        24\n",
      "\n",
      "    accuracy                        0.76087        92\n",
      "   macro avg    0.68542   0.60907   0.62012        92\n",
      "weighted avg    0.73424   0.76087   0.73071        92\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 18\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 54\n",
      "8 24 1\n",
      "10 30 2\n",
      "12 36 3\n",
      "16 48 4\n",
      "16 48 5\n",
      "17 51 6\n",
      "17 51 7\n",
      "17 51 8\n",
      "17 51 9\n",
      "17 51 10\n",
      "17 51 11\n",
      "17 51 12\n",
      "17 51 13\n",
      "17 51 14\n",
      "17 51 15\n",
      "17 51 16\n",
      "17 51 17\n",
      "17 51 18\n",
      "17 51 19\n",
      "17 51 20\n",
      "17 51 21\n",
      "17 51 22\n",
      "17 51 23\n",
      "17 51 24\n",
      "17 51 25\n",
      "17 51 26\n",
      "17 51 27\n",
      "17 51 28\n",
      "17 51 29\n",
      "17 51 30\n",
      "17 51 31\n",
      "17 51 32\n",
      "17 51 33\n",
      "17 51 34\n",
      "17 51 35\n",
      "17 51 36\n",
      "17 51 37\n",
      "17 51 38\n",
      "17 51 39\n",
      "17 51 40\n",
      "17 51 41\n",
      "17 51 42\n",
      "17 51 43\n",
      "17 51 44\n",
      "17 51 45\n",
      "17 51 46\n",
      "17 51 47\n",
      "17 51 48\n",
      "17 51 49\n",
      "17 51 50\n",
      "17 51 51\n",
      "17 51 52\n",
      "17 51 53\n",
      "17 51 54\n",
      "17 51 55\n",
      "17 51 56\n",
      "17 51 57\n",
      "17 51 58\n",
      "17 51 59\n",
      "17 51 60\n",
      "17 51 61\n",
      "17 51 62\n",
      "17 51 63\n",
      "17 51 64\n",
      "17 51 65\n",
      "17 51 66\n",
      "17 51 67\n",
      "17 51 68\n",
      "17 51 69\n",
      "17 51 70\n",
      "17 51 71\n",
      "17 51 72\n",
      "17 51 73\n",
      "17 51 74\n",
      "17 51 75\n",
      "17 51 76\n",
      "17 51 77\n",
      "17 51 78\n",
      "17 51 79\n",
      "17 51 80\n",
      "17 51 81\n",
      "17 51 82\n",
      "17 51 83\n",
      "17 51 84\n",
      "17 51 85\n",
      "17 51 86\n",
      "17 51 87\n",
      "17 51 88\n",
      "17 51 89\n",
      "17 51 90\n",
      "17 51 91\n",
      "17 51 92\n",
      "17 51 93\n",
      "17 51 94\n",
      "17 51 95\n",
      "17 51 96\n",
      "17 51 97\n",
      "17 51 98\n",
      "17 51 99\n",
      "17 51 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.7336448598130841 75.40294154482308 \ttest: 0.7391304347826086 33.425309810311674\n",
      "retrain  2 :\n",
      "\ttrain: 0.7336448598130841 71.44790600028168 \ttest: 0.7391304347826086 32.74860150987409\n",
      "retrain  3 :\n",
      "\ttrain: 0.7336448598130841 69.47077645234123 \ttest: 0.7391304347826086 32.586850920424084\n",
      "retrain  4 :\n",
      "\ttrain: 0.794392523364486 68.39258108359864 \ttest: 0.7391304347826086 32.591519443848384\n",
      "retrain  5 :\n",
      "\ttrain: 0.794392523364486 67.73365123006144 \ttest: 0.75 32.63670253389786\n",
      "retrain  6 :\n",
      "\ttrain: 0.794392523364486 67.28196639998072 \ttest: 0.75 32.682315607000554\n",
      "retrain  7 :\n",
      "\ttrain: 0.7897196261682243 66.94138263427925 \ttest: 0.7608695652173914 32.71877671472444\n",
      "retrain  8 :\n",
      "\ttrain: 0.7850467289719626 66.66636442082162 \ttest: 0.7608695652173914 32.74628164861973\n",
      "retrain  9 :\n",
      "\ttrain: 0.7850467289719626 66.43406973095841 \ttest: 0.7608695652173914 32.76743481818583\n",
      "retrain  10 :\n",
      "\ttrain: 0.7897196261682243 66.2321931481951 \ttest: 0.75 32.784834385965624\n",
      "retrain  11 :\n",
      "\ttrain: 0.794392523364486 66.0535299935865 \ttest: 0.7391304347826086 32.80043860387359\n",
      "retrain  12 :\n",
      "\ttrain: 0.794392523364486 65.89347389733676 \ttest: 0.7391304347826086 32.81553354505437\n",
      "retrain  13 :\n",
      "\ttrain: 0.794392523364486 65.74882803121423 \ttest: 0.7391304347826086 32.8308707777016\n",
      "retrain  14 :\n",
      "\ttrain: 0.794392523364486 65.6172195349036 \ttest: 0.7391304347826086 32.84682445083979\n",
      "retrain  15 :\n",
      "\ttrain: 0.794392523364486 65.49679777246702 \ttest: 0.7391304347826086 32.86352206963489\n",
      "retrain  16 :\n",
      "\ttrain: 0.794392523364486 65.38606968555362 \ttest: 0.7391304347826086 32.88094102844761\n",
      "retrain  17 :\n",
      "\ttrain: 0.794392523364486 65.28380348876792 \ttest: 0.7391304347826086 32.89897522182228\n",
      "retrain  18 :\n",
      "\ttrain: 0.794392523364486 65.18896786301192 \ttest: 0.7391304347826086 32.91747880145523\n",
      "retrain  19 :\n",
      "\ttrain: 0.794392523364486 65.10069060880608 \ttest: 0.7391304347826086 32.93629363337492\n",
      "retrain  20 :\n",
      "\ttrain: 0.794392523364486 65.01822870237876 \ttest: 0.7391304347826086 32.955265626838205\n",
      "retrain  21 :\n",
      "\ttrain: 0.794392523364486 64.94094554585413 \ttest: 0.7391304347826086 32.974253717098264\n",
      "retrain  22 :\n",
      "\ttrain: 0.794392523364486 64.86829309477471 \ttest: 0.7391304347826086 32.99313414775223\n",
      "retrain  23 :\n",
      "\ttrain: 0.794392523364486 64.79979750151658 \ttest: 0.7391304347826086 33.01180184785954\n",
      "retrain  24 :\n",
      "\ttrain: 0.794392523364486 64.73504741436952 \ttest: 0.7391304347826086 33.03017009287824\n",
      "retrain  25 :\n",
      "\ttrain: 0.794392523364486 64.67368434913531 \ttest: 0.7391304347826086 33.0481692197032\n",
      "retrain  26 :\n",
      "\ttrain: 0.7897196261682243 64.6153947135929 \ttest: 0.75 33.06574488313425\n",
      "retrain  27 :\n",
      "\ttrain: 0.7897196261682243 64.55990316884628 \ttest: 0.75 33.08285615329087\n",
      "retrain  28 :\n",
      "\ttrain: 0.7897196261682243 64.50696708200022 \ttest: 0.75 33.099473630841146\n",
      "retrain  29 :\n",
      "\ttrain: 0.7897196261682243 64.45637187532179 \ttest: 0.75 33.115577678156086\n",
      "retrain  30 :\n",
      "\ttrain: 0.7897196261682243 64.40792711518495 \ttest: 0.75 33.1311568149154\n",
      "retrain  31 :\n",
      "\ttrain: 0.7897196261682243 64.36146321366198 \ttest: 0.75 33.146206296258974\n",
      "retrain  32 :\n",
      "\ttrain: 0.7897196261682243 64.31682863899914 \ttest: 0.75 33.16072687356745\n",
      "retrain  33 :\n",
      "\ttrain: 0.7897196261682243 64.27388754993196 \ttest: 0.75 33.17472372788825\n",
      "retrain  34 :\n",
      "\ttrain: 0.7897196261682243 64.23251778390592 \ttest: 0.75 33.18820556094938\n",
      "retrain  35 :\n",
      "\ttrain: 0.7897196261682243 64.19260914153571 \ttest: 0.75 33.201183826694376\n",
      "retrain  36 :\n",
      "\ttrain: 0.7897196261682243 64.15406191963314 \ttest: 0.75 33.213672086083996\n",
      "retrain  37 :\n",
      "\ttrain: 0.7897196261682243 64.1167856533065 \ttest: 0.75 33.22568546874653\n",
      "retrain  38 :\n",
      "\ttrain: 0.7897196261682243 64.08069803433175 \ttest: 0.75 33.237240226420724\n",
      "retrain  39 :\n",
      "\ttrain: 0.7897196261682243 64.04572397849796 \ttest: 0.75 33.24835336471491\n",
      "retrain  40 :\n",
      "\ttrain: 0.7897196261682243 64.0117948191583 \ttest: 0.75 33.259042341320594\n",
      "retrain  41 :\n",
      "\ttrain: 0.7897196261682243 63.97884760795475 \ttest: 0.75 33.26932482036432\n",
      "retrain  42 :\n",
      "\ttrain: 0.7897196261682243 63.94682450677321 \ttest: 0.75 33.27921847400443\n",
      "retrain  43 :\n",
      "\ttrain: 0.7897196261682243 63.91567225754419 \ttest: 0.75 33.28874082365644\n",
      "retrain  44 :\n",
      "\ttrain: 0.7897196261682243 63.88534171862868 \ttest: 0.75 33.29790911435604\n",
      "retrain  45 :\n",
      "\ttrain: 0.7897196261682243 63.85578745829459 \ttest: 0.75 33.3067402167501\n",
      "retrain  46 :\n",
      "\ttrain: 0.7897196261682243 63.826967397261846 \ttest: 0.75 33.31525055205221\n",
      "retrain  47 :\n",
      "\ttrain: 0.7897196261682243 63.7988424935239 \ttest: 0.75 33.32345603602536\n",
      "retrain  48 :\n",
      "\ttrain: 0.7897196261682243 63.7713764636816 \ttest: 0.75 33.33137203867385\n",
      "retrain  49 :\n",
      "\ttrain: 0.7897196261682243 63.74453553588876 \ttest: 0.75 33.33901335685336\n",
      "retrain  50 :\n",
      "\ttrain: 0.7897196261682243 63.718288230232915 \ttest: 0.75 33.34639419745458\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.82558   0.90446   0.86322       157\n",
      "           1    0.64286   0.47368   0.54545        57\n",
      "\n",
      "    accuracy                        0.78972       214\n",
      "   macro avg    0.73422   0.68907   0.70434       214\n",
      "weighted avg    0.77691   0.78972   0.77858       214\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.79221   0.89706   0.84138        68\n",
      "           1    0.53333   0.33333   0.41026        24\n",
      "\n",
      "    accuracy                        0.75000        92\n",
      "   macro avg    0.66277   0.61520   0.62582        92\n",
      "weighted avg    0.72468   0.75000   0.72891        92\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 17\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 51\n",
      "7 21 1\n",
      "11 33 2\n",
      "13 39 3\n",
      "15 45 4\n",
      "16 48 5\n",
      "16 48 6\n",
      "16 48 7\n",
      "17 51 8\n",
      "17 51 9\n",
      "17 51 10\n",
      "17 51 11\n",
      "17 51 12\n",
      "17 51 13\n",
      "17 51 14\n",
      "17 51 15\n",
      "17 51 16\n",
      "17 51 17\n",
      "17 51 18\n",
      "17 51 19\n",
      "17 51 20\n",
      "17 51 21\n",
      "17 51 22\n",
      "17 51 23\n",
      "17 51 24\n",
      "17 51 25\n",
      "17 51 26\n",
      "17 51 27\n",
      "17 51 28\n",
      "17 51 29\n",
      "17 51 30\n",
      "17 51 31\n",
      "17 51 32\n",
      "17 51 33\n",
      "17 51 34\n",
      "17 51 35\n",
      "17 51 36\n",
      "17 51 37\n",
      "17 51 38\n",
      "17 51 39\n",
      "17 51 40\n",
      "17 51 41\n",
      "17 51 42\n",
      "17 51 43\n",
      "17 51 44\n",
      "17 51 45\n",
      "17 51 46\n",
      "17 51 47\n",
      "17 51 48\n",
      "17 51 49\n",
      "17 51 50\n",
      "17 51 51\n",
      "17 51 52\n",
      "17 51 53\n",
      "17 51 54\n",
      "17 51 55\n",
      "17 51 56\n",
      "17 51 57\n",
      "17 51 58\n",
      "17 51 59\n",
      "17 51 60\n",
      "17 51 61\n",
      "17 51 62\n",
      "17 51 63\n",
      "17 51 64\n",
      "17 51 65\n",
      "17 51 66\n",
      "17 51 67\n",
      "17 51 68\n",
      "17 51 69\n",
      "17 51 70\n",
      "17 51 71\n",
      "17 51 72\n",
      "17 51 73\n",
      "17 51 74\n",
      "17 51 75\n",
      "17 51 76\n",
      "17 51 77\n",
      "17 51 78\n",
      "17 51 79\n",
      "17 51 80\n",
      "17 51 81\n",
      "17 51 82\n",
      "17 51 83\n",
      "17 51 84\n",
      "17 51 85\n",
      "17 51 86\n",
      "17 51 87\n",
      "17 51 88\n",
      "17 51 89\n",
      "17 51 90\n",
      "17 51 91\n",
      "17 51 92\n",
      "17 51 93\n",
      "17 51 94\n",
      "17 51 95\n",
      "17 51 96\n",
      "17 51 97\n",
      "17 51 98\n",
      "17 51 99\n",
      "17 51 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.7336448598130841 75.87979185772656 \ttest: 0.7391304347826086 33.053820886296954\n",
      "retrain  2 :\n",
      "\ttrain: 0.7336448598130841 71.70123270794008 \ttest: 0.7391304347826086 31.94064828505135\n",
      "retrain  3 :\n",
      "\ttrain: 0.7429906542056075 69.41962546971169 \ttest: 0.75 31.467823028931488\n",
      "retrain  4 :\n",
      "\ttrain: 0.7757009345794392 68.09555724749835 \ttest: 0.782608695652174 31.27514625738402\n",
      "retrain  5 :\n",
      "\ttrain: 0.7850467289719626 67.25010277524738 \ttest: 0.7282608695652174 31.19492880386965\n",
      "retrain  6 :\n",
      "\ttrain: 0.7897196261682243 66.6503974871669 \ttest: 0.7282608695652174 31.15577444625237\n",
      "retrain  7 :\n",
      "\ttrain: 0.7897196261682243 66.1839275310614 \ttest: 0.7282608695652174 31.129458206230836\n",
      "retrain  8 :\n",
      "\ttrain: 0.7897196261682243 65.79548985776263 \ttest: 0.7282608695652174 31.105974602552536\n",
      "retrain  9 :\n",
      "\ttrain: 0.7897196261682243 65.45719710223395 \ttest: 0.7282608695652174 31.082574429414798\n",
      "retrain  10 :\n",
      "\ttrain: 0.7897196261682243 65.15434353326371 \ttest: 0.7282608695652174 31.059127122444842\n",
      "retrain  11 :\n",
      "\ttrain: 0.7897196261682243 64.878701734092 \ttest: 0.7282608695652174 31.036242420011817\n",
      "retrain  12 :\n",
      "\ttrain: 0.7897196261682243 64.62530562972034 \ttest: 0.7282608695652174 31.014568830974774\n",
      "retrain  13 :\n",
      "\ttrain: 0.7897196261682243 64.39088576064849 \ttest: 0.7282608695652174 30.994578228809445\n",
      "retrain  14 :\n",
      "\ttrain: 0.7897196261682243 64.17309684072758 \ttest: 0.7282608695652174 30.97653879793322\n",
      "retrain  15 :\n",
      "\ttrain: 0.7897196261682243 63.97012945768412 \ttest: 0.7282608695652174 30.960550879869242\n",
      "retrain  16 :\n",
      "\ttrain: 0.7897196261682243 63.78050993850039 \ttest: 0.7282608695652174 30.9465954369959\n",
      "retrain  17 :\n",
      "\ttrain: 0.7897196261682243 63.602993354811204 \ttest: 0.7282608695652174 30.93457710818533\n",
      "retrain  18 :\n",
      "\ttrain: 0.7897196261682243 63.436503232687315 \ttest: 0.7282608695652174 30.924357147240347\n",
      "retrain  19 :\n",
      "\ttrain: 0.7850467289719626 63.28009512647529 \ttest: 0.7282608695652174 30.915776588024702\n",
      "retrain  20 :\n",
      "\ttrain: 0.7850467289719626 63.13293274854901 \ttest: 0.7282608695652174 30.908671534546997\n",
      "retrain  21 :\n",
      "\ttrain: 0.7850467289719626 62.994271008563516 \ttest: 0.7282608695652174 30.902882639982792\n",
      "retrain  22 :\n",
      "\ttrain: 0.7850467289719626 62.86344310455147 \ttest: 0.7282608695652174 30.898260528271422\n",
      "retrain  23 :\n",
      "\ttrain: 0.7850467289719626 62.739850186061915 \ttest: 0.7282608695652174 30.894668500883057\n",
      "retrain  24 :\n",
      "\ttrain: 0.7850467289719626 62.62295279334766 \ttest: 0.7282608695652174 30.891983498440585\n",
      "retrain  25 :\n",
      "\ttrain: 0.7850467289719626 62.51226361882962 \ttest: 0.7282608695652174 30.890095990798535\n",
      "retrain  26 :\n",
      "\ttrain: 0.7850467289719626 62.407341311193875 \ttest: 0.7282608695652174 30.888909249495853\n",
      "retrain  27 :\n",
      "\ttrain: 0.7850467289719626 62.3077851338484 \ttest: 0.7282608695652174 30.88833830007458\n",
      "retrain  28 :\n",
      "\ttrain: 0.7850467289719626 62.21323033997756 \ttest: 0.7282608695652174 30.88830874351058\n",
      "retrain  29 :\n",
      "\ttrain: 0.7850467289719626 62.12334415657833 \ttest: 0.7282608695652174 30.888755562758284\n",
      "retrain  30 :\n",
      "\ttrain: 0.7850467289719626 62.03782228963438 \ttest: 0.7282608695652174 30.889621981839703\n",
      "retrain  31 :\n",
      "\ttrain: 0.7850467289719626 61.956385876833615 \ttest: 0.7282608695652174 30.890858413359226\n",
      "retrain  32 :\n",
      "\ttrain: 0.7850467289719626 61.87877882531775 \ttest: 0.7282608695652174 30.892421510323995\n",
      "retrain  33 :\n",
      "\ttrain: 0.7850467289719626 61.804765481026536 \ttest: 0.7282608695652174 30.89427332586599\n",
      "retrain  34 :\n",
      "\ttrain: 0.7850467289719626 61.73412858384634 \ttest: 0.7282608695652174 30.89638057725862\n",
      "retrain  35 :\n",
      "\ttrain: 0.7850467289719626 61.666667469311356 \ttest: 0.7282608695652174 30.898714006706808\n",
      "retrain  36 :\n",
      "\ttrain: 0.7850467289719626 61.602196483225086 \ttest: 0.7391304347826086 30.901247829561257\n",
      "retrain  37 :\n",
      "\ttrain: 0.7850467289719626 61.54054358040297 \ttest: 0.7391304347826086 30.903959260064624\n",
      "retrain  38 :\n",
      "\ttrain: 0.7850467289719626 61.48154908288824 \ttest: 0.7391304347826086 30.90682810495516\n",
      "retrain  39 :\n",
      "\ttrain: 0.7850467289719626 61.42506457655032 \ttest: 0.7391304347826086 30.909836415891625\n",
      "retrain  40 :\n",
      "\ttrain: 0.7850467289719626 61.37095192801538 \ttest: 0.7391304347826086 30.91296819250593\n",
      "retrain  41 :\n",
      "\ttrain: 0.7850467289719626 61.319082406474024 \ttest: 0.7391304347826086 30.91620912880405\n",
      "retrain  42 :\n",
      "\ttrain: 0.7850467289719626 61.269335897119234 \ttest: 0.7391304347826086 30.919546396540532\n",
      "retrain  43 :\n",
      "\ttrain: 0.7850467289719626 61.22160019484822 \ttest: 0.7391304347826086 30.922968460043645\n",
      "retrain  44 :\n",
      "\ttrain: 0.7850467289719626 61.175770368458835 \ttest: 0.7391304347826086 30.926464917743154\n",
      "retrain  45 :\n",
      "\ttrain: 0.7850467289719626 61.131748186929315 \ttest: 0.7391304347826086 30.93002636634371\n",
      "retrain  46 :\n",
      "\ttrain: 0.7850467289719626 61.089441600523756 \ttest: 0.7391304347826086 30.933644284191953\n",
      "retrain  47 :\n",
      "\ttrain: 0.7850467289719626 61.04876427044776 \ttest: 0.7391304347826086 30.937310930910513\n",
      "retrain  48 :\n",
      "\ttrain: 0.7850467289719626 61.00963514161346 \ttest: 0.7391304347826086 30.941019260822728\n",
      "retrain  49 :\n",
      "\ttrain: 0.7850467289719626 60.97197805378585 \ttest: 0.7391304347826086 30.944762848077296\n",
      "retrain  50 :\n",
      "\ttrain: 0.7850467289719626 60.93572138698983 \ttest: 0.7391304347826086 30.948535821708894\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.81356   0.91720   0.86228       157\n",
      "           1    0.64865   0.42105   0.51064        57\n",
      "\n",
      "    accuracy                        0.78505       214\n",
      "   macro avg    0.73110   0.66913   0.68646       214\n",
      "weighted avg    0.76963   0.78505   0.76862       214\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.79730   0.86765   0.83099        68\n",
      "           1    0.50000   0.37500   0.42857        24\n",
      "\n",
      "    accuracy                        0.73913        92\n",
      "   macro avg    0.64865   0.62132   0.62978        92\n",
      "weighted avg    0.71974   0.73913   0.72601        92\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 17\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 51\n",
      "8 24 1\n",
      "14 42 2\n",
      "16 48 3\n",
      "16 48 4\n",
      "17 51 5\n",
      "17 51 6\n",
      "17 51 7\n",
      "17 51 8\n",
      "17 51 9\n",
      "17 51 10\n",
      "17 51 11\n",
      "17 51 12\n",
      "17 51 13\n",
      "17 51 14\n",
      "17 51 15\n",
      "17 51 16\n",
      "17 51 17\n",
      "17 51 18\n",
      "17 51 19\n",
      "17 51 20\n",
      "17 51 21\n",
      "17 51 22\n",
      "17 51 23\n",
      "17 51 24\n",
      "17 51 25\n",
      "17 51 26\n",
      "17 51 27\n",
      "17 51 28\n",
      "17 51 29\n",
      "17 51 30\n",
      "17 51 31\n",
      "17 51 32\n",
      "17 51 33\n",
      "17 51 34\n",
      "17 51 35\n",
      "17 51 36\n",
      "17 51 37\n",
      "17 51 38\n",
      "17 51 39\n",
      "17 51 40\n",
      "17 51 41\n",
      "17 51 42\n",
      "17 51 43\n",
      "17 51 44\n",
      "17 51 45\n",
      "17 51 46\n",
      "17 51 47\n",
      "17 51 48\n",
      "17 51 49\n",
      "17 51 50\n",
      "17 51 51\n",
      "17 51 52\n",
      "17 51 53\n",
      "17 51 54\n",
      "17 51 55\n",
      "17 51 56\n",
      "17 51 57\n",
      "17 51 58\n",
      "17 51 59\n",
      "17 51 60\n",
      "17 51 61\n",
      "17 51 62\n",
      "17 51 63\n",
      "17 51 64\n",
      "17 51 65\n",
      "17 51 66\n",
      "17 51 67\n",
      "17 51 68\n",
      "17 51 69\n",
      "17 51 70\n",
      "17 51 71\n",
      "17 51 72\n",
      "17 51 73\n",
      "17 51 74\n",
      "17 51 75\n",
      "17 51 76\n",
      "17 51 77\n",
      "17 51 78\n",
      "17 51 79\n",
      "17 51 80\n",
      "17 51 81\n",
      "17 51 82\n",
      "17 51 83\n",
      "17 51 84\n",
      "17 51 85\n",
      "17 51 86\n",
      "17 51 87\n",
      "17 51 88\n",
      "17 51 89\n",
      "17 51 90\n",
      "17 51 91\n",
      "17 51 92\n",
      "17 51 93\n",
      "17 51 94\n",
      "17 51 95\n",
      "17 51 96\n",
      "17 51 97\n",
      "17 51 98\n",
      "17 51 99\n",
      "17 51 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.7336448598130841 76.30505882374464 \ttest: 0.7391304347826086 33.088463929434816\n",
      "retrain  2 :\n",
      "\ttrain: 0.7336448598130841 72.65012407905546 \ttest: 0.7391304347826086 32.05369203416687\n",
      "retrain  3 :\n",
      "\ttrain: 0.7336448598130841 70.74849019501987 \ttest: 0.7391304347826086 31.62505352818739\n",
      "retrain  4 :\n",
      "\ttrain: 0.7897196261682243 69.66880991817726 \ttest: 0.7608695652173914 31.44956263870104\n",
      "retrain  5 :\n",
      "\ttrain: 0.7897196261682243 68.9785571389673 \ttest: 0.75 31.37471153326642\n",
      "retrain  6 :\n",
      "\ttrain: 0.7897196261682243 68.47959440041276 \ttest: 0.7717391304347826 31.337867062109524\n",
      "retrain  7 :\n",
      "\ttrain: 0.7897196261682243 68.08009478117691 \ttest: 0.7717391304347826 31.31436054686423\n",
      "retrain  8 :\n",
      "\ttrain: 0.7710280373831776 67.7364676438752 \ttest: 0.7717391304347826 31.295120122295614\n",
      "retrain  9 :\n",
      "\ttrain: 0.7710280373831776 67.42736500237581 \ttest: 0.7717391304347826 31.277307356572017\n",
      "retrain  10 :\n",
      "\ttrain: 0.7710280373831776 67.14191464535214 \ttest: 0.7717391304347826 31.26043634283961\n",
      "retrain  11 :\n",
      "\ttrain: 0.7710280373831776 66.87428883804613 \ttest: 0.7717391304347826 31.24478854785839\n",
      "retrain  12 :\n",
      "\ttrain: 0.7710280373831776 66.62114613470956 \ttest: 0.7608695652173914 31.230791246025326\n",
      "retrain  13 :\n",
      "\ttrain: 0.7710280373831776 66.380404156249 \ttest: 0.7608695652173914 31.21879851384519\n",
      "retrain  14 :\n",
      "\ttrain: 0.7710280373831776 66.15064117293613 \ttest: 0.7608695652173914 31.209036033097668\n",
      "retrain  15 :\n",
      "\ttrain: 0.7757009345794392 65.93079965816013 \ttest: 0.7608695652173914 31.20160783020721\n",
      "retrain  16 :\n",
      "\ttrain: 0.7757009345794392 65.72003675779021 \ttest: 0.7608695652173914 31.196522140029366\n",
      "retrain  17 :\n",
      "\ttrain: 0.7757009345794392 65.51764699566124 \ttest: 0.7608695652173914 31.193719265326582\n",
      "retrain  18 :\n",
      "\ttrain: 0.7757009345794392 65.32302083887551 \ttest: 0.7608695652173914 31.193095392929784\n",
      "retrain  19 :\n",
      "\ttrain: 0.7757009345794392 65.13562125966516 \ttest: 0.7608695652173914 31.194520964012774\n",
      "retrain  20 :\n",
      "\ttrain: 0.7757009345794392 64.95496947075262 \ttest: 0.7608695652173914 31.1978539822999\n",
      "retrain  21 :\n",
      "\ttrain: 0.7897196261682243 64.78063545646737 \ttest: 0.7391304347826086 31.202949197382473\n",
      "retrain  22 :\n",
      "\ttrain: 0.7897196261682243 64.6122311170656 \ttest: 0.7391304347826086 31.20966414829805\n",
      "retrain  23 :\n",
      "\ttrain: 0.7897196261682243 64.44940492991837 \ttest: 0.7391304347826086 31.217862918517632\n",
      "retrain  24 :\n",
      "\ttrain: 0.7897196261682243 64.29183756886002 \ttest: 0.7391304347826086 31.227418276078893\n",
      "retrain  25 :\n",
      "\ttrain: 0.7897196261682243 64.13923818888287 \ttest: 0.7391304347826086 31.23821270649335\n",
      "retrain  26 :\n",
      "\ttrain: 0.7897196261682243 63.991341214793195 \ttest: 0.7391304347826086 31.250138708768134\n",
      "retrain  27 :\n",
      "\ttrain: 0.7897196261682243 63.847903537580706 \ttest: 0.7391304347826086 31.263098618362\n",
      "retrain  28 :\n",
      "\ttrain: 0.7897196261682243 63.70870205490469 \ttest: 0.7391304347826086 31.277004141302818\n",
      "retrain  29 :\n",
      "\ttrain: 0.7897196261682243 63.57353150898457 \ttest: 0.7391304347826086 31.291775725698987\n",
      "retrain  30 :\n",
      "\ttrain: 0.7897196261682243 63.44220258449756 \ttest: 0.7391304347826086 31.307341855396714\n",
      "retrain  31 :\n",
      "\ttrain: 0.7897196261682243 63.31454023480859 \ttest: 0.7391304347826086 31.323638321307293\n",
      "retrain  32 :\n",
      "\ttrain: 0.7897196261682243 63.19038220887799 \ttest: 0.7391304347826086 31.340607505612518\n",
      "retrain  33 :\n",
      "\ttrain: 0.7897196261682243 63.069577754384085 \ttest: 0.7391304347826086 31.358197700122695\n",
      "retrain  34 :\n",
      "\ttrain: 0.7897196261682243 62.95198647534663 \ttest: 0.7391304347826086 31.37636247064724\n",
      "retrain  35 :\n",
      "\ttrain: 0.7897196261682243 62.837477325003896 \ttest: 0.7391304347826086 31.39506007298764\n",
      "retrain  36 :\n",
      "\ttrain: 0.7897196261682243 62.725927716939474 \ttest: 0.7391304347826086 31.414252922108307\n",
      "retrain  37 :\n",
      "\ttrain: 0.7897196261682243 62.61722273949762 \ttest: 0.7391304347826086 31.433907113493483\n",
      "retrain  38 :\n",
      "\ttrain: 0.7897196261682243 62.51125446037167 \ttest: 0.7391304347826086 31.453991994173833\n",
      "retrain  39 :\n",
      "\ttrain: 0.7897196261682243 62.40792130990837 \ttest: 0.7391304347826086 31.474479780067256\n",
      "retrain  40 :\n",
      "\ttrain: 0.7897196261682243 62.30712753314557 \ttest: 0.75 31.49534521588958\n",
      "retrain  41 :\n",
      "\ttrain: 0.7897196261682243 62.208782701905434 \ttest: 0.75 31.516565273792004\n",
      "retrain  42 :\n",
      "\ttrain: 0.7897196261682243 62.11280127941068 \ttest: 0.75 31.538118886963716\n",
      "retrain  43 :\n",
      "\ttrain: 0.7897196261682243 62.01910223089221 \ttest: 0.75 31.559986714625914\n",
      "retrain  44 :\n",
      "\ttrain: 0.7897196261682243 61.92760867452749 \ttest: 0.75 31.582150935089043\n",
      "retrain  45 :\n",
      "\ttrain: 0.7897196261682243 61.8382475678043 \ttest: 0.75 31.6045950638159\n",
      "retrain  46 :\n",
      "\ttrain: 0.7897196261682243 61.75094942505764 \ttest: 0.75 31.627303793709746\n",
      "retrain  47 :\n",
      "\ttrain: 0.7897196261682243 61.665648062491414 \ttest: 0.75 31.650262855115365\n",
      "retrain  48 :\n",
      "\ttrain: 0.7897196261682243 61.58228036748266 \ttest: 0.75 31.673458893275537\n",
      "retrain  49 :\n",
      "\ttrain: 0.7897196261682243 61.50078608938465 \ttest: 0.75 31.696879361221896\n",
      "retrain  50 :\n",
      "\ttrain: 0.7897196261682243 61.42110764940614 \ttest: 0.75 31.72051242629516\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.81111   0.92994   0.86647       157\n",
      "           1    0.67647   0.40351   0.50549        57\n",
      "\n",
      "    accuracy                        0.78972       214\n",
      "   macro avg    0.74379   0.66672   0.68598       214\n",
      "weighted avg    0.77525   0.78972   0.77032       214\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.80822   0.86765   0.83688        68\n",
      "           1    0.52632   0.41667   0.46512        24\n",
      "\n",
      "    accuracy                        0.75000        92\n",
      "   macro avg    0.66727   0.64216   0.65100        92\n",
      "weighted avg    0.73468   0.75000   0.73990        92\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 17\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 51\n",
      "8 24 1\n",
      "13 39 2\n",
      "14 42 3\n",
      "14 42 4\n",
      "14 42 5\n",
      "14 42 6\n",
      "15 45 7\n",
      "17 51 8\n",
      "17 51 9\n",
      "17 51 10\n",
      "17 51 11\n",
      "17 51 12\n",
      "17 51 13\n",
      "17 51 14\n",
      "17 51 15\n",
      "17 51 16\n",
      "17 51 17\n",
      "17 51 18\n",
      "17 51 19\n",
      "17 51 20\n",
      "17 51 21\n",
      "17 51 22\n",
      "17 51 23\n",
      "17 51 24\n",
      "17 51 25\n",
      "17 51 26\n",
      "17 51 27\n",
      "17 51 28\n",
      "17 51 29\n",
      "17 51 30\n",
      "17 51 31\n",
      "17 51 32\n",
      "17 51 33\n",
      "17 51 34\n",
      "17 51 35\n",
      "17 51 36\n",
      "17 51 37\n",
      "17 51 38\n",
      "17 51 39\n",
      "17 51 40\n",
      "17 51 41\n",
      "17 51 42\n",
      "17 51 43\n",
      "17 51 44\n",
      "17 51 45\n",
      "17 51 46\n",
      "17 51 47\n",
      "17 51 48\n",
      "17 51 49\n",
      "17 51 50\n",
      "17 51 51\n",
      "17 51 52\n",
      "17 51 53\n",
      "17 51 54\n",
      "17 51 55\n",
      "17 51 56\n",
      "17 51 57\n",
      "17 51 58\n",
      "17 51 59\n",
      "17 51 60\n",
      "17 51 61\n",
      "17 51 62\n",
      "17 51 63\n",
      "17 51 64\n",
      "17 51 65\n",
      "17 51 66\n",
      "17 51 67\n",
      "17 51 68\n",
      "17 51 69\n",
      "17 51 70\n",
      "17 51 71\n",
      "17 51 72\n",
      "17 51 73\n",
      "17 51 74\n",
      "17 51 75\n",
      "17 51 76\n",
      "17 51 77\n",
      "17 51 78\n",
      "17 51 79\n",
      "17 51 80\n",
      "17 51 81\n",
      "17 51 82\n",
      "17 51 83\n",
      "17 51 84\n",
      "17 51 85\n",
      "17 51 86\n",
      "17 51 87\n",
      "17 51 88\n",
      "17 51 89\n",
      "17 51 90\n",
      "17 51 91\n",
      "17 51 92\n",
      "17 51 93\n",
      "17 51 94\n",
      "17 51 95\n",
      "17 51 96\n",
      "17 51 97\n",
      "17 51 98\n",
      "17 51 99\n",
      "17 51 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.7336448598130841 77.13919815144156 \ttest: 0.7391304347826086 33.24850480480063\n",
      "retrain  2 :\n",
      "\ttrain: 0.7336448598130841 73.81733900765795 \ttest: 0.7391304347826086 32.1952277774789\n",
      "retrain  3 :\n",
      "\ttrain: 0.7336448598130841 72.05696580040336 \ttest: 0.7391304347826086 31.697356528800167\n",
      "retrain  4 :\n",
      "\ttrain: 0.7336448598130841 71.0478316157969 \ttest: 0.7391304347826086 31.452141303324066\n",
      "retrain  5 :\n",
      "\ttrain: 0.7429906542056075 70.40283316677187 \ttest: 0.7608695652173914 31.321142918023558\n",
      "retrain  6 :\n",
      "\ttrain: 0.7429906542056075 69.94118732981846 \ttest: 0.7608695652173914 31.24309050459553\n",
      "retrain  7 :\n",
      "\ttrain: 0.7710280373831776 69.57809686117173 \ttest: 0.75 31.191172647347138\n",
      "retrain  8 :\n",
      "\ttrain: 0.7710280373831776 69.27290360942581 \ttest: 0.75 31.15363634269579\n",
      "retrain  9 :\n",
      "\ttrain: 0.7710280373831776 69.00536445733826 \ttest: 0.75 31.125238952479428\n",
      "retrain  10 :\n",
      "\ttrain: 0.7710280373831776 68.76481681353096 \ttest: 0.7608695652173914 31.10352585114103\n",
      "retrain  11 :\n",
      "\ttrain: 0.7710280373831776 68.54519311765011 \ttest: 0.7608695652173914 31.087223294731423\n",
      "retrain  12 :\n",
      "\ttrain: 0.7710280373831776 68.34270172950261 \ttest: 0.7608695652173914 31.075554183897673\n",
      "retrain  13 :\n",
      "\ttrain: 0.7710280373831776 68.15473412607824 \ttest: 0.7608695652173914 31.06795397737733\n",
      "retrain  14 :\n",
      "\ttrain: 0.7710280373831776 67.97934115590317 \ttest: 0.7608695652173914 31.063957530396397\n",
      "retrain  15 :\n",
      "\ttrain: 0.7710280373831776 67.81497550053288 \ttest: 0.7608695652173914 31.0631567689427\n",
      "retrain  16 :\n",
      "\ttrain: 0.7710280373831776 67.66035969987972 \ttest: 0.7608695652173914 31.065186114967556\n",
      "retrain  17 :\n",
      "\ttrain: 0.7710280373831776 67.51441407174067 \ttest: 0.7608695652173914 31.069717674180836\n",
      "retrain  18 :\n",
      "\ttrain: 0.7710280373831776 67.3762137546256 \ttest: 0.7608695652173914 31.076459105613544\n",
      "retrain  19 :\n",
      "\ttrain: 0.7710280373831776 67.24496041124173 \ttest: 0.7608695652173914 31.085151698691682\n",
      "retrain  20 :\n",
      "\ttrain: 0.7710280373831776 67.11996175864873 \ttest: 0.7608695652173914 31.095568023781034\n",
      "retrain  21 :\n",
      "\ttrain: 0.7710280373831776 67.00061565527356 \ttest: 0.7608695652173914 31.107509179011583\n",
      "retrain  22 :\n",
      "\ttrain: 0.7710280373831776 66.88639713638952 \ttest: 0.7608695652173914 31.12080183158837\n",
      "retrain  23 :\n",
      "\ttrain: 0.7710280373831776 66.77684756326182 \ttest: 0.7608695652173914 31.135295249853986\n",
      "retrain  24 :\n",
      "\ttrain: 0.7710280373831776 66.67156541302082 \ttest: 0.7608695652173914 31.150858469145273\n",
      "retrain  25 :\n",
      "\ttrain: 0.7710280373831776 66.57019840879656 \ttest: 0.7608695652173914 31.16737767796398\n",
      "retrain  26 :\n",
      "\ttrain: 0.7710280373831776 66.47243677579945 \ttest: 0.7608695652173914 31.184753866199056\n",
      "retrain  27 :\n",
      "\ttrain: 0.7710280373831776 66.37800745608587 \ttest: 0.7608695652173914 31.202900746210616\n",
      "retrain  28 :\n",
      "\ttrain: 0.7710280373831776 66.28666914400608 \ttest: 0.7608695652173914 31.22174293828101\n",
      "retrain  29 :\n",
      "\ttrain: 0.7710280373831776 66.19820802520901 \ttest: 0.7608695652173914 31.241214401137743\n",
      "retrain  30 :\n",
      "\ttrain: 0.7710280373831776 66.11243411863919 \ttest: 0.7608695652173914 31.261257083184297\n",
      "retrain  31 :\n",
      "\ttrain: 0.7710280373831776 66.029178134922 \ttest: 0.7608695652173914 31.281819768625198\n",
      "retrain  32 :\n",
      "\ttrain: 0.7710280373831776 65.94828877661975 \ttest: 0.7608695652173914 31.302857093355836\n",
      "retrain  33 :\n",
      "\ttrain: 0.7710280373831776 65.86963041638249 \ttest: 0.7608695652173914 31.324328707321065\n",
      "retrain  34 :\n",
      "\ttrain: 0.7710280373831776 65.79308109820279 \ttest: 0.75 31.34619856240168\n",
      "retrain  35 :\n",
      "\ttrain: 0.7757009345794392 65.71853081494632 \ttest: 0.75 31.368434307387147\n",
      "retrain  36 :\n",
      "\ttrain: 0.7757009345794392 65.6458800222019 \ttest: 0.75 31.391006774019253\n",
      "retrain  37 :\n",
      "\ttrain: 0.7757009345794392 65.57503835439425 \ttest: 0.75 31.413889540332207\n",
      "retrain  38 :\n",
      "\ttrain: 0.7757009345794392 65.50592351414883 \ttest: 0.75 31.437058559520743\n",
      "retrain  39 :\n",
      "\ttrain: 0.7757009345794392 65.43846031020047 \ttest: 0.75 31.460491844326867\n",
      "retrain  40 :\n",
      "\ttrain: 0.7757009345794392 65.37257982279968 \ttest: 0.75 31.484169198457842\n",
      "retrain  41 :\n",
      "\ttrain: 0.7757009345794392 65.30821867867976 \ttest: 0.75 31.50807198785153\n",
      "retrain  42 :\n",
      "\ttrain: 0.7757009345794392 65.24531842028806 \ttest: 0.75 31.532182945714876\n",
      "retrain  43 :\n",
      "\ttrain: 0.7757009345794392 65.18382495622555 \ttest: 0.75 31.556486006201812\n",
      "retrain  44 :\n",
      "\ttrain: 0.7757009345794392 65.12368808173812 \ttest: 0.75 31.580966162391356\n",
      "retrain  45 :\n",
      "\ttrain: 0.780373831775701 65.06486105971726 \ttest: 0.75 31.605609344897104\n",
      "retrain  46 :\n",
      "\ttrain: 0.780373831775701 65.007300254037 \ttest: 0.75 31.63040231800434\n",
      "retrain  47 :\n",
      "\ttrain: 0.7850467289719626 64.9509648082187 \ttest: 0.75 31.655332590707108\n",
      "retrain  48 :\n",
      "\ttrain: 0.7850467289719626 64.89581636340547 \ttest: 0.75 31.680388340418695\n",
      "retrain  49 :\n",
      "\ttrain: 0.7850467289719626 64.84181881047247 \ttest: 0.75 31.705558347467647\n",
      "retrain  50 :\n",
      "\ttrain: 0.7850467289719626 64.78893807181761 \ttest: 0.75 31.73083193877662\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.82081   0.90446   0.86061       157\n",
      "           1    0.63415   0.45614   0.53061        57\n",
      "\n",
      "    accuracy                        0.78505       214\n",
      "   macro avg    0.72748   0.68030   0.69561       214\n",
      "weighted avg    0.77109   0.78505   0.77271       214\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.77778   0.92647   0.84564        68\n",
      "           1    0.54545   0.25000   0.34286        24\n",
      "\n",
      "    accuracy                        0.75000        92\n",
      "   macro avg    0.66162   0.58824   0.59425        92\n",
      "weighted avg    0.71717   0.75000   0.71448        92\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 17\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 51\n",
      "7 21 1\n",
      "10 30 2\n",
      "13 39 3\n",
      "14 42 4\n",
      "14 42 5\n",
      "15 45 6\n",
      "15 45 7\n",
      "15 45 8\n",
      "16 48 9\n",
      "17 51 10\n",
      "17 51 11\n",
      "17 51 12\n",
      "17 51 13\n",
      "17 51 14\n",
      "17 51 15\n",
      "17 51 16\n",
      "17 51 17\n",
      "17 51 18\n",
      "17 51 19\n",
      "17 51 20\n",
      "17 51 21\n",
      "17 51 22\n",
      "17 51 23\n",
      "17 51 24\n",
      "17 51 25\n",
      "17 51 26\n",
      "17 51 27\n",
      "17 51 28\n",
      "17 51 29\n",
      "17 51 30\n",
      "17 51 31\n",
      "17 51 32\n",
      "17 51 33\n",
      "17 51 34\n",
      "17 51 35\n",
      "17 51 36\n",
      "17 51 37\n",
      "17 51 38\n",
      "17 51 39\n",
      "17 51 40\n",
      "17 51 41\n",
      "17 51 42\n",
      "17 51 43\n",
      "17 51 44\n",
      "17 51 45\n",
      "17 51 46\n",
      "17 51 47\n",
      "17 51 48\n",
      "17 51 49\n",
      "17 51 50\n",
      "17 51 51\n",
      "17 51 52\n",
      "17 51 53\n",
      "17 51 54\n",
      "17 51 55\n",
      "17 51 56\n",
      "17 51 57\n",
      "17 51 58\n",
      "17 51 59\n",
      "17 51 60\n",
      "17 51 61\n",
      "17 51 62\n",
      "17 51 63\n",
      "17 51 64\n",
      "17 51 65\n",
      "17 51 66\n",
      "17 51 67\n",
      "17 51 68\n",
      "17 51 69\n",
      "17 51 70\n",
      "17 51 71\n",
      "17 51 72\n",
      "17 51 73\n",
      "17 51 74\n",
      "17 51 75\n",
      "17 51 76\n",
      "17 51 77\n",
      "17 51 78\n",
      "17 51 79\n",
      "17 51 80\n",
      "17 51 81\n",
      "17 51 82\n",
      "17 51 83\n",
      "17 51 84\n",
      "17 51 85\n",
      "17 51 86\n",
      "17 51 87\n",
      "17 51 88\n",
      "17 51 89\n",
      "17 51 90\n",
      "17 51 91\n",
      "17 51 92\n",
      "17 51 93\n",
      "17 51 94\n",
      "17 51 95\n",
      "17 51 96\n",
      "17 51 97\n",
      "17 51 98\n",
      "17 51 99\n",
      "17 51 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.7336448598130841 76.56102202988824 \ttest: 0.7391304347826086 33.42942735780515\n",
      "retrain  2 :\n",
      "\ttrain: 0.7336448598130841 72.65245965462269 \ttest: 0.7391304347826086 32.58978648785994\n",
      "retrain  3 :\n",
      "\ttrain: 0.7476635514018691 70.51712473056855 \ttest: 0.7391304347826086 32.31655915239901\n",
      "retrain  4 :\n",
      "\ttrain: 0.7897196261682243 69.3065678911405 \ttest: 0.7282608695652174 32.27273865248978\n",
      "retrain  5 :\n",
      "\ttrain: 0.7850467289719626 68.56324510792533 \ttest: 0.7391304347826086 32.30436457568244\n",
      "retrain  6 :\n",
      "\ttrain: 0.780373831775701 68.05817746114408 \ttest: 0.7391304347826086 32.34915361037086\n",
      "retrain  7 :\n",
      "\ttrain: 0.780373831775701 67.67938275321413 \ttest: 0.7391304347826086 32.38552167640886\n",
      "retrain  8 :\n",
      "\ttrain: 0.7850467289719626 67.37192190327976 \ttest: 0.7282608695652174 32.40850877067347\n",
      "retrain  9 :\n",
      "\ttrain: 0.7897196261682243 67.10833810599209 \ttest: 0.717391304347826 32.419250475924656\n",
      "retrain  10 :\n",
      "\ttrain: 0.7897196261682243 66.87445756011142 \ttest: 0.7282608695652174 32.42061117051648\n",
      "retrain  11 :\n",
      "\ttrain: 0.7897196261682243 66.66259446355869 \ttest: 0.7282608695652174 32.415502145327665\n",
      "retrain  12 :\n",
      "\ttrain: 0.7897196261682243 66.46828527519494 \ttest: 0.7282608695652174 32.406332620494055\n",
      "retrain  13 :\n",
      "\ttrain: 0.7897196261682243 66.28870778318581 \ttest: 0.7282608695652174 32.39491520990004\n",
      "retrain  14 :\n",
      "\ttrain: 0.7897196261682243 66.12190868072827 \ttest: 0.7282608695652174 32.382534623805086\n",
      "retrain  15 :\n",
      "\ttrain: 0.794392523364486 65.96642135081657 \ttest: 0.7282608695652174 32.370058838279746\n",
      "retrain  16 :\n",
      "\ttrain: 0.7990654205607477 65.82107302864708 \ttest: 0.7282608695652174 32.35804630271703\n",
      "retrain  17 :\n",
      "\ttrain: 0.7990654205607477 65.68488444623569 \ttest: 0.7282608695652174 32.34683444376963\n",
      "retrain  18 :\n",
      "\ttrain: 0.7990654205607477 65.55701503940509 \ttest: 0.7282608695652174 32.33660752983986\n",
      "retrain  19 :\n",
      "\ttrain: 0.7990654205607477 65.43673093267321 \ttest: 0.7282608695652174 32.32744653398373\n",
      "retrain  20 :\n",
      "\ttrain: 0.7990654205607477 65.32338460367336 \ttest: 0.7282608695652174 32.31936475148428\n",
      "retrain  21 :\n",
      "\ttrain: 0.7990654205607477 65.2164007929166 \ttest: 0.7282608695652174 32.31233271362399\n",
      "retrain  22 :\n",
      "\ttrain: 0.7990654205607477 65.11526597026963 \ttest: 0.7282608695652174 32.30629530874869\n",
      "retrain  23 :\n",
      "\ttrain: 0.7990654205607477 65.01952000037123 \ttest: 0.7282608695652174 32.30118334915815\n",
      "retrain  24 :\n",
      "\ttrain: 0.7990654205607477 64.92874929533664 \ttest: 0.7282608695652174 32.29692124065021\n",
      "retrain  25 :\n",
      "\ttrain: 0.7990654205607477 64.84258105870144 \ttest: 0.7282608695652174 32.29343195171104\n",
      "retrain  26 :\n",
      "\ttrain: 0.7990654205607477 64.76067838112846 \ttest: 0.7282608695652174 32.29064013299171\n",
      "retrain  27 :\n",
      "\ttrain: 0.794392523364486 64.6827360286438 \ttest: 0.7391304347826086 32.28847398432392\n",
      "retrain  28 :\n",
      "\ttrain: 0.794392523364486 64.608476807741 \ttest: 0.7391304347826086 32.28686628463137\n",
      "retrain  29 :\n",
      "\ttrain: 0.794392523364486 64.5376484174863 \ttest: 0.7391304347826086 32.28575487121084\n",
      "retrain  30 :\n",
      "\ttrain: 0.794392523364486 64.4700207156936 \ttest: 0.7391304347826086 32.28508276440722\n",
      "retrain  31 :\n",
      "\ttrain: 0.794392523364486 64.4053833385148 \ttest: 0.7391304347826086 32.28479807069934\n",
      "retrain  32 :\n",
      "\ttrain: 0.794392523364486 64.343543622374 \ttest: 0.7391304347826086 32.284853753597375\n",
      "retrain  33 :\n",
      "\ttrain: 0.794392523364486 64.28432478500955 \ttest: 0.7391304347826086 32.28520733173441\n",
      "retrain  34 :\n",
      "\ttrain: 0.794392523364486 64.22756432894644 \ttest: 0.7391304347826086 32.285820542994365\n",
      "retrain  35 :\n",
      "\ttrain: 0.794392523364486 64.173112636268 \ttest: 0.7391304347826086 32.28665899955351\n",
      "retrain  36 :\n",
      "\ttrain: 0.794392523364486 64.12083172825953 \ttest: 0.7391304347826086 32.28769184928778\n",
      "retrain  37 :\n",
      "\ttrain: 0.794392523364486 64.07059416748264 \ttest: 0.7391304347826086 32.28889145269637\n",
      "retrain  38 :\n",
      "\ttrain: 0.794392523364486 64.02228208321264 \ttest: 0.7391304347826086 32.290233080326885\n",
      "retrain  39 :\n",
      "\ttrain: 0.794392523364486 63.97578630401918 \ttest: 0.7391304347826086 32.29169463297967\n",
      "retrain  40 :\n",
      "\ttrain: 0.794392523364486 63.93100558367199 \ttest: 0.7391304347826086 32.293256385245016\n",
      "retrain  41 :\n",
      "\ttrain: 0.794392523364486 63.887845908577724 \ttest: 0.7391304347826086 32.29490075186692\n",
      "retrain  42 :\n",
      "\ttrain: 0.794392523364486 63.84621987665705 \ttest: 0.7391304347826086 32.29661207580703\n",
      "retrain  43 :\n",
      "\ttrain: 0.794392523364486 63.8060461390076 \ttest: 0.7391304347826086 32.298376436552125\n",
      "retrain  44 :\n",
      "\ttrain: 0.794392523364486 63.76724889690886 \ttest: 0.7391304347826086 32.30018147706536\n",
      "retrain  45 :\n",
      "\ttrain: 0.794392523364486 63.7297574477478 \ttest: 0.75 32.30201624775633\n",
      "retrain  46 :\n",
      "\ttrain: 0.794392523364486 63.69350577430887 \ttest: 0.75 32.30387106589143\n",
      "retrain  47 :\n",
      "\ttrain: 0.794392523364486 63.65843217260607 \ttest: 0.75 32.30573738895335\n",
      "retrain  48 :\n",
      "\ttrain: 0.794392523364486 63.62447891405803 \ttest: 0.75 32.30760770056703\n",
      "retrain  49 :\n",
      "\ttrain: 0.794392523364486 63.591591938338865 \ttest: 0.75 32.309475407726204\n",
      "retrain  50 :\n",
      "\ttrain: 0.794392523364486 63.559720573692225 \ttest: 0.7391304347826086 32.31133474817123\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.81215   0.93631   0.86982       157\n",
      "           1    0.69697   0.40351   0.51111        57\n",
      "\n",
      "    accuracy                        0.79439       214\n",
      "   macro avg    0.75456   0.66991   0.69047       214\n",
      "weighted avg    0.78147   0.79439   0.77428       214\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.78947   0.88235   0.83333        68\n",
      "           1    0.50000   0.33333   0.40000        24\n",
      "\n",
      "    accuracy                        0.73913        92\n",
      "   macro avg    0.64474   0.60784   0.61667        92\n",
      "weighted avg    0.71396   0.73913   0.72029        92\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 17\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 51\n",
      "8 24 1\n",
      "10 30 2\n",
      "10 30 3\n",
      "12 36 4\n",
      "14 42 5\n",
      "15 45 6\n",
      "16 48 7\n",
      "16 48 8\n",
      "17 51 9\n",
      "17 51 10\n",
      "17 51 11\n",
      "17 51 12\n",
      "17 51 13\n",
      "17 51 14\n",
      "17 51 15\n",
      "17 51 16\n",
      "17 51 17\n",
      "17 51 18\n",
      "17 51 19\n",
      "17 51 20\n",
      "17 51 21\n",
      "17 51 22\n",
      "17 51 23\n",
      "17 51 24\n",
      "17 51 25\n",
      "17 51 26\n",
      "17 51 27\n",
      "17 51 28\n",
      "17 51 29\n",
      "17 51 30\n",
      "17 51 31\n",
      "17 51 32\n",
      "17 51 33\n",
      "17 51 34\n",
      "17 51 35\n",
      "17 51 36\n",
      "17 51 37\n",
      "17 51 38\n",
      "17 51 39\n",
      "17 51 40\n",
      "17 51 41\n",
      "17 51 42\n",
      "17 51 43\n",
      "17 51 44\n",
      "17 51 45\n",
      "17 51 46\n",
      "17 51 47\n",
      "17 51 48\n",
      "17 51 49\n",
      "17 51 50\n",
      "17 51 51\n",
      "17 51 52\n",
      "17 51 53\n",
      "17 51 54\n",
      "17 51 55\n",
      "17 51 56\n",
      "17 51 57\n",
      "17 51 58\n",
      "17 51 59\n",
      "17 51 60\n",
      "17 51 61\n",
      "17 51 62\n",
      "17 51 63\n",
      "17 51 64\n",
      "17 51 65\n",
      "17 51 66\n",
      "17 51 67\n",
      "17 51 68\n",
      "17 51 69\n",
      "17 51 70\n",
      "17 51 71\n",
      "17 51 72\n",
      "17 51 73\n",
      "17 51 74\n",
      "17 51 75\n",
      "17 51 76\n",
      "17 51 77\n",
      "17 51 78\n",
      "17 51 79\n",
      "17 51 80\n",
      "17 51 81\n",
      "17 51 82\n",
      "17 51 83\n",
      "17 51 84\n",
      "17 51 85\n",
      "17 51 86\n",
      "17 51 87\n",
      "17 51 88\n",
      "17 51 89\n",
      "17 51 90\n",
      "17 51 91\n",
      "17 51 92\n",
      "17 51 93\n",
      "17 51 94\n",
      "17 51 95\n",
      "17 51 96\n",
      "17 51 97\n",
      "17 51 98\n",
      "17 51 99\n",
      "17 51 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.7336448598130841 76.22084349718389 \ttest: 0.7391304347826086 33.60146652026732\n",
      "retrain  2 :\n",
      "\ttrain: 0.7336448598130841 72.13126264679443 \ttest: 0.7391304347826086 32.786920575885944\n",
      "retrain  3 :\n",
      "\ttrain: 0.7336448598130841 69.88775471024627 \ttest: 0.7391304347826086 32.48517289926744\n",
      "retrain  4 :\n",
      "\ttrain: 0.7757009345794392 68.5987454931787 \ttest: 0.7282608695652174 32.40827136274568\n",
      "retrain  5 :\n",
      "\ttrain: 0.7850467289719626 67.79303375905056 \ttest: 0.7282608695652174 32.421564226328876\n",
      "retrain  6 :\n",
      "\ttrain: 0.7850467289719626 67.23685040942303 \ttest: 0.7282608695652174 32.46737821617379\n",
      "retrain  7 :\n",
      "\ttrain: 0.7850467289719626 66.81595824422195 \ttest: 0.7282608695652174 32.52296522537954\n",
      "retrain  8 :\n",
      "\ttrain: 0.7850467289719626 66.47396319948359 \ttest: 0.7282608695652174 32.58041389116589\n",
      "retrain  9 :\n",
      "\ttrain: 0.7897196261682243 66.18225609412323 \ttest: 0.7282608695652174 32.63768885017396\n",
      "retrain  10 :\n",
      "\ttrain: 0.7897196261682243 65.92567085212693 \ttest: 0.7282608695652174 32.69481487628961\n",
      "retrain  11 :\n",
      "\ttrain: 0.7897196261682243 65.69565370184661 \ttest: 0.7282608695652174 32.75234167253808\n",
      "retrain  12 :\n",
      "\ttrain: 0.7897196261682243 65.48698950298717 \ttest: 0.7282608695652174 32.810787315909394\n",
      "retrain  13 :\n",
      "\ttrain: 0.7897196261682243 65.29621562359085 \ttest: 0.7282608695652174 32.870483009423324\n",
      "retrain  14 :\n",
      "\ttrain: 0.7897196261682243 65.12084098253811 \ttest: 0.7282608695652174 32.931568952570004\n",
      "retrain  15 :\n",
      "\ttrain: 0.7897196261682243 64.95895223476177 \ttest: 0.7282608695652174 32.99403678932185\n",
      "retrain  16 :\n",
      "\ttrain: 0.7897196261682243 64.80900801773666 \ttest: 0.7282608695652174 33.057777867809385\n",
      "retrain  17 :\n",
      "\ttrain: 0.7897196261682243 64.66972590164468 \ttest: 0.7282608695652174 33.12262365870371\n",
      "retrain  18 :\n",
      "\ttrain: 0.7897196261682243 64.54001606388965 \ttest: 0.7282608695652174 33.18837557527742\n",
      "retrain  19 :\n",
      "\ttrain: 0.7897196261682243 64.41893931917394 \ttest: 0.7282608695652174 33.25482533255246\n",
      "retrain  20 :\n",
      "\ttrain: 0.7897196261682243 64.30567847503124 \ttest: 0.7282608695652174 33.32176799126327\n",
      "retrain  21 :\n",
      "\ttrain: 0.7897196261682243 64.19951745671429 \ttest: 0.7282608695652174 33.389009755536044\n",
      "retrain  22 :\n",
      "\ttrain: 0.7897196261682243 64.09982530865624 \ttest: 0.7282608695652174 33.45637218959513\n",
      "retrain  23 :\n",
      "\ttrain: 0.794392523364486 64.00604349208776 \ttest: 0.7282608695652174 33.523694085182\n",
      "retrain  24 :\n",
      "\ttrain: 0.794392523364486 63.91767555877263 \ttest: 0.7282608695652174 33.59083184651122\n",
      "retrain  25 :\n",
      "\ttrain: 0.794392523364486 63.83427862439318 \ttest: 0.7282608695652174 33.65765898236665\n",
      "retrain  26 :\n",
      "\ttrain: 0.794392523364486 63.75545625285707 \ttest: 0.7282608695652174 33.724065095653785\n",
      "retrain  27 :\n",
      "\ttrain: 0.794392523364486 63.68085247225972 \ttest: 0.7282608695652174 33.78995462236219\n",
      "retrain  28 :\n",
      "\ttrain: 0.794392523364486 63.610146712008195 \ttest: 0.7282608695652174 33.85524547816428\n",
      "retrain  29 :\n",
      "\ttrain: 0.794392523364486 63.54304949712552 \ttest: 0.7282608695652174 33.919867708612074\n",
      "retrain  30 :\n",
      "\ttrain: 0.794392523364486 63.47929876923894 \ttest: 0.7282608695652174 33.98376219825421\n",
      "retrain  31 :\n",
      "\ttrain: 0.794392523364486 63.418656729008525 \ttest: 0.7282608695652174 34.046879467952095\n",
      "retrain  32 :\n",
      "\ttrain: 0.794392523364486 63.36090711439745 \ttest: 0.7282608695652174 34.10917857333695\n",
      "retrain  33 :\n",
      "\ttrain: 0.794392523364486 63.30585284476821 \ttest: 0.7282608695652174 34.17062610738837\n",
      "retrain  34 :\n",
      "\ttrain: 0.794392523364486 63.253313973295306 \ttest: 0.7282608695652174 34.23119530428378\n",
      "retrain  35 :\n",
      "\ttrain: 0.794392523364486 63.203125900291084 \ttest: 0.7282608695652174 34.29086523847655\n",
      "retrain  36 :\n",
      "\ttrain: 0.794392523364486 63.155137808244405 \ttest: 0.7282608695652174 34.34962011142464\n",
      "retrain  37 :\n",
      "\ttrain: 0.794392523364486 63.109211286048954 \ttest: 0.7282608695652174 34.4074486178684\n",
      "retrain  38 :\n",
      "\ttrain: 0.794392523364486 63.06521911534579 \ttest: 0.7282608695652174 34.464343383632524\n",
      "retrain  39 :\n",
      "\ttrain: 0.794392523364486 63.02304419636068 \ttest: 0.7282608695652174 34.520300467338224\n",
      "retrain  40 :\n",
      "\ttrain: 0.794392523364486 62.98257859426734 \ttest: 0.7282608695652174 34.57531891899036\n",
      "retrain  41 :\n",
      "\ttrain: 0.794392523364486 62.94372269010794 \ttest: 0.7282608695652174 34.62940038905081\n",
      "retrain  42 :\n",
      "\ttrain: 0.794392523364486 62.90638442277385 \ttest: 0.7282608695652174 34.68254878226139\n",
      "retrain  43 :\n",
      "\ttrain: 0.794392523364486 62.87047861059071 \ttest: 0.7282608695652174 34.73476995110362\n",
      "retrain  44 :\n",
      "\ttrain: 0.794392523364486 62.83592634274519 \ttest: 0.7282608695652174 34.786071424361054\n",
      "retrain  45 :\n",
      "\ttrain: 0.794392523364486 62.8026544321977 \ttest: 0.7282608695652174 34.83646216677495\n",
      "retrain  46 :\n",
      "\ttrain: 0.794392523364486 62.77059492290053 \ttest: 0.7282608695652174 34.88595236625416\n",
      "retrain  47 :\n",
      "\ttrain: 0.794392523364486 62.73968464512549 \ttest: 0.7282608695652174 34.9345532455176\n",
      "retrain  48 :\n",
      "\ttrain: 0.794392523364486 62.709864813533024 \ttest: 0.7282608695652174 34.98227689541591\n",
      "retrain  49 :\n",
      "\ttrain: 0.794392523364486 62.68108066331419 \ttest: 0.7282608695652174 35.02913612750297\n",
      "retrain  50 :\n",
      "\ttrain: 0.794392523364486 62.65328112033027 \ttest: 0.7282608695652174 35.075144343711926\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.82286   0.91720   0.86747       157\n",
      "           1    0.66667   0.45614   0.54167        57\n",
      "\n",
      "    accuracy                        0.79439       214\n",
      "   macro avg    0.74476   0.68667   0.70457       214\n",
      "weighted avg    0.78126   0.79439   0.78069       214\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.77215   0.89706   0.82993        68\n",
      "           1    0.46154   0.25000   0.32432        24\n",
      "\n",
      "    accuracy                        0.72826        92\n",
      "   macro avg    0.61685   0.57353   0.57713        92\n",
      "weighted avg    0.69112   0.72826   0.69803        92\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 17\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 51\n",
      "9 27 1\n",
      "13 39 2\n",
      "14 42 3\n",
      "14 42 4\n",
      "16 48 5\n",
      "16 48 6\n",
      "16 48 7\n",
      "16 48 8\n",
      "16 48 9\n",
      "16 48 10\n",
      "16 48 11\n",
      "16 48 12\n",
      "16 48 13\n",
      "16 48 14\n",
      "16 48 15\n",
      "16 48 16\n",
      "16 48 17\n",
      "16 48 18\n",
      "16 48 19\n",
      "16 48 20\n",
      "16 48 21\n",
      "16 48 22\n",
      "16 48 23\n",
      "16 48 24\n",
      "16 48 25\n",
      "16 48 26\n",
      "16 48 27\n",
      "16 48 28\n",
      "16 48 29\n",
      "16 48 30\n",
      "16 48 31\n",
      "16 48 32\n",
      "16 48 33\n",
      "16 48 34\n",
      "16 48 35\n",
      "16 48 36\n",
      "16 48 37\n",
      "16 48 38\n",
      "16 48 39\n",
      "16 48 40\n",
      "16 48 41\n",
      "16 48 42\n",
      "16 48 43\n",
      "16 48 44\n",
      "16 48 45\n",
      "16 48 46\n",
      "16 48 47\n",
      "16 48 48\n",
      "16 48 49\n",
      "16 48 50\n",
      "16 48 51\n",
      "16 48 52\n",
      "16 48 53\n",
      "16 48 54\n",
      "16 48 55\n",
      "16 48 56\n",
      "16 48 57\n",
      "16 48 58\n",
      "16 48 59\n",
      "16 48 60\n",
      "16 48 61\n",
      "16 48 62\n",
      "16 48 63\n",
      "16 48 64\n",
      "16 48 65\n",
      "16 48 66\n",
      "16 48 67\n",
      "16 48 68\n",
      "16 48 69\n",
      "16 48 70\n",
      "16 48 71\n",
      "16 48 72\n",
      "16 48 73\n",
      "16 48 74\n",
      "16 48 75\n",
      "16 48 76\n",
      "16 48 77\n",
      "16 48 78\n",
      "16 48 79\n",
      "16 48 80\n",
      "16 48 81\n",
      "16 48 82\n",
      "16 48 83\n",
      "16 48 84\n",
      "16 48 85\n",
      "16 48 86\n",
      "16 48 87\n",
      "16 48 88\n",
      "16 48 89\n",
      "16 48 90\n",
      "16 48 91\n",
      "16 48 92\n",
      "16 48 93\n",
      "16 48 94\n",
      "16 48 95\n",
      "16 48 96\n",
      "16 48 97\n",
      "16 48 98\n",
      "16 48 99\n",
      "16 48 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.7336448598130841 77.49922508637178 \ttest: 0.7391304347826086 33.11783498657424\n",
      "retrain  2 :\n",
      "\ttrain: 0.7336448598130841 74.25743078528099 \ttest: 0.7391304347826086 31.915438109325326\n",
      "retrain  3 :\n",
      "\ttrain: 0.7336448598130841 72.46172870454453 \ttest: 0.7391304347826086 31.278173642683992\n",
      "retrain  4 :\n",
      "\ttrain: 0.7336448598130841 71.38503610900958 \ttest: 0.7391304347826086 30.91240377486426\n",
      "retrain  5 :\n",
      "\ttrain: 0.7383177570093458 70.67402565204442 \ttest: 0.7391304347826086 30.67910142373502\n",
      "retrain  6 :\n",
      "\ttrain: 0.7616822429906542 70.15826923586121 \ttest: 0.7391304347826086 30.513388580957205\n",
      "retrain  7 :\n",
      "\ttrain: 0.7616822429906542 69.75422207623008 \ttest: 0.7391304347826086 30.38477978998736\n",
      "retrain  8 :\n",
      "\ttrain: 0.7616822429906542 69.41957419067461 \ttest: 0.7391304347826086 30.278618394747443\n",
      "retrain  9 :\n",
      "\ttrain: 0.7570093457943925 69.13188512584051 \ttest: 0.7934782608695652 30.187574316146115\n",
      "retrain  10 :\n",
      "\ttrain: 0.7570093457943925 68.87852732351601 \ttest: 0.7934782608695652 30.10775234465119\n",
      "retrain  11 :\n",
      "\ttrain: 0.7616822429906542 68.6518784776572 \ttest: 0.7934782608695652 30.036899017277296\n",
      "retrain  12 :\n",
      "\ttrain: 0.7616822429906542 68.44697599984468 \ttest: 0.7934782608695652 29.973569463113616\n",
      "retrain  13 :\n",
      "\ttrain: 0.7616822429906542 68.26034486649645 \ttest: 0.7934782608695652 29.916736829094816\n",
      "retrain  14 :\n",
      "\ttrain: 0.7616822429906542 68.08939468455739 \ttest: 0.7934782608695652 29.865607087867204\n",
      "retrain  15 :\n",
      "\ttrain: 0.7616822429906542 67.93209816063832 \ttest: 0.7934782608695652 29.819529509575595\n",
      "retrain  16 :\n",
      "\ttrain: 0.7616822429906542 67.78681165473097 \ttest: 0.7934782608695652 29.777951752165354\n",
      "retrain  17 :\n",
      "\ttrain: 0.7616822429906542 67.65216932434404 \ttest: 0.7934782608695652 29.740395792491494\n",
      "retrain  18 :\n",
      "\ttrain: 0.7616822429906542 67.52701664181731 \ttest: 0.7934782608695652 29.706443663083945\n",
      "retrain  19 :\n",
      "\ttrain: 0.7616822429906542 67.41036587646249 \ttest: 0.7934782608695652 29.675727914909345\n",
      "retrain  20 :\n",
      "\ttrain: 0.7616822429906542 67.30136447990904 \ttest: 0.7934782608695652 29.64792449329816\n",
      "retrain  21 :\n",
      "\ttrain: 0.7616822429906542 67.19927151331807 \ttest: 0.7934782608695652 29.622746983386577\n",
      "retrain  22 :\n",
      "\ttrain: 0.7616822429906542 67.10343940308343 \ttest: 0.7934782608695652 29.599941751945487\n",
      "retrain  23 :\n",
      "\ttrain: 0.7616822429906542 67.01329943364495 \ttest: 0.7934782608695652 29.579283761717107\n",
      "retrain  24 :\n",
      "\ttrain: 0.7616822429906542 66.92834998933293 \ttest: 0.7934782608695652 29.56057293938902\n",
      "retrain  25 :\n",
      "\ttrain: 0.7616822429906542 66.84814689431542 \ttest: 0.7934782608695652 29.543631020961804\n",
      "retrain  26 :\n",
      "\ttrain: 0.7616822429906542 66.77229539750418 \ttest: 0.7934782608695652 29.52829881544046\n",
      "retrain  27 :\n",
      "\ttrain: 0.7616822429906542 66.70044347196546 \ttest: 0.7934782608695652 29.51443383551736\n",
      "retrain  28 :\n",
      "\ttrain: 0.7616822429906542 66.63227617902251 \ttest: 0.7934782608695652 29.501908248720675\n",
      "retrain  29 :\n",
      "\ttrain: 0.7616822429906542 66.56751090316791 \ttest: 0.7934782608695652 29.490607106719605\n",
      "retrain  30 :\n",
      "\ttrain: 0.7616822429906542 66.5058933044858 \ttest: 0.7934782608695652 29.480426814741353\n",
      "retrain  31 :\n",
      "\ttrain: 0.7616822429906542 66.44719386577427 \ttest: 0.7934782608695652 29.47127380737536\n",
      "retrain  32 :\n",
      "\ttrain: 0.7616822429906542 66.39120493505497 \ttest: 0.7934782608695652 29.463063401263863\n",
      "retrain  33 :\n",
      "\ttrain: 0.7616822429906542 66.33773818259158 \ttest: 0.7934782608695652 29.455718799149935\n",
      "retrain  34 :\n",
      "\ttrain: 0.7616822429906542 66.28662240618296 \ttest: 0.7934782608695652 29.44917022337287\n",
      "retrain  35 :\n",
      "\ttrain: 0.7616822429906542 66.23770163023521 \ttest: 0.7934782608695652 29.443354160118233\n",
      "retrain  36 :\n",
      "\ttrain: 0.7616822429906542 66.19083345358672 \ttest: 0.7934782608695652 29.43821269853718\n",
      "retrain  37 :\n",
      "\ttrain: 0.7663551401869159 66.14588760874085 \ttest: 0.8043478260869565 29.43369295126726\n",
      "retrain  38 :\n",
      "\ttrain: 0.7663551401869159 66.10274470141675 \ttest: 0.8043478260869565 29.429746544947612\n",
      "retrain  39 :\n",
      "\ttrain: 0.7663551401869159 66.06129510444327 \ttest: 0.8043478260869565 29.426329171066612\n",
      "retrain  40 :\n",
      "\ttrain: 0.7663551401869159 66.02143798421764 \ttest: 0.8043478260869565 29.423400188951327\n",
      "retrain  41 :\n",
      "\ttrain: 0.7663551401869159 65.98308044140623 \ttest: 0.8043478260869565 29.420922273944157\n",
      "retrain  42 :\n",
      "\ttrain: 0.7663551401869159 65.94613675041813 \ttest: 0.8043478260869565 29.418861104850563\n",
      "retrain  43 :\n",
      "\ttrain: 0.7663551401869159 65.91052768454796 \ttest: 0.8043478260869565 29.417185085612886\n",
      "retrain  44 :\n",
      "\ttrain: 0.7663551401869159 65.87617991565078 \ttest: 0.8043478260869565 29.415865096896905\n",
      "retrain  45 :\n",
      "\ttrain: 0.7663551401869159 65.84302547885227 \ttest: 0.8043478260869565 29.414874273893467\n",
      "retrain  46 :\n",
      "\ttrain: 0.7663551401869159 65.81100129416973 \ttest: 0.8043478260869565 29.41418780715567\n",
      "retrain  47 :\n",
      "\ttrain: 0.7663551401869159 65.78004873807217 \ttest: 0.8043478260869565 29.41378276373028\n",
      "retrain  48 :\n",
      "\ttrain: 0.7663551401869159 65.75011325897768 \ttest: 0.8043478260869565 29.413637926212434\n",
      "retrain  49 :\n",
      "\ttrain: 0.7663551401869159 65.72114403150636 \ttest: 0.8043478260869565 29.413733647667673\n",
      "retrain  50 :\n",
      "\ttrain: 0.7663551401869159 65.69309364500162 \ttest: 0.8043478260869565 29.414051720632862\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.80925   0.89172   0.84848       157\n",
      "           1    0.58537   0.42105   0.48980        57\n",
      "\n",
      "    accuracy                        0.76636       214\n",
      "   macro avg    0.69731   0.65639   0.66914       214\n",
      "weighted avg    0.74962   0.76636   0.75295       214\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.83784   0.91176   0.87324        68\n",
      "           1    0.66667   0.50000   0.57143        24\n",
      "\n",
      "    accuracy                        0.80435        92\n",
      "   macro avg    0.75225   0.70588   0.72233        92\n",
      "weighted avg    0.79318   0.80435   0.79451        92\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 16\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 48\n",
      "9 27 1\n",
      "12 36 2\n",
      "14 42 3\n",
      "14 42 4\n",
      "14 42 5\n",
      "15 45 6\n",
      "16 48 7\n",
      "16 48 8\n",
      "16 48 9\n",
      "16 48 10\n",
      "16 48 11\n",
      "16 48 12\n",
      "16 48 13\n",
      "16 48 14\n",
      "16 48 15\n",
      "16 48 16\n",
      "16 48 17\n",
      "16 48 18\n",
      "16 48 19\n",
      "16 48 20\n",
      "16 48 21\n",
      "16 48 22\n",
      "16 48 23\n",
      "16 48 24\n",
      "16 48 25\n",
      "16 48 26\n",
      "16 48 27\n",
      "16 48 28\n",
      "16 48 29\n",
      "16 48 30\n",
      "16 48 31\n",
      "16 48 32\n",
      "16 48 33\n",
      "16 48 34\n",
      "16 48 35\n",
      "16 48 36\n",
      "16 48 37\n",
      "16 48 38\n",
      "16 48 39\n",
      "16 48 40\n",
      "16 48 41\n",
      "16 48 42\n",
      "16 48 43\n",
      "16 48 44\n",
      "16 48 45\n",
      "16 48 46\n",
      "16 48 47\n",
      "16 48 48\n",
      "16 48 49\n",
      "16 48 50\n",
      "16 48 51\n",
      "16 48 52\n",
      "16 48 53\n",
      "16 48 54\n",
      "16 48 55\n",
      "16 48 56\n",
      "16 48 57\n",
      "16 48 58\n",
      "16 48 59\n",
      "16 48 60\n",
      "16 48 61\n",
      "16 48 62\n",
      "16 48 63\n",
      "16 48 64\n",
      "16 48 65\n",
      "16 48 66\n",
      "16 48 67\n",
      "16 48 68\n",
      "16 48 69\n",
      "16 48 70\n",
      "16 48 71\n",
      "16 48 72\n",
      "16 48 73\n",
      "16 48 74\n",
      "16 48 75\n",
      "16 48 76\n",
      "16 48 77\n",
      "16 48 78\n",
      "16 48 79\n",
      "16 48 80\n",
      "16 48 81\n",
      "16 48 82\n",
      "16 48 83\n",
      "16 48 84\n",
      "16 48 85\n",
      "16 48 86\n",
      "16 48 87\n",
      "16 48 88\n",
      "16 48 89\n",
      "16 48 90\n",
      "16 48 91\n",
      "16 48 92\n",
      "16 48 93\n",
      "16 48 94\n",
      "16 48 95\n",
      "16 48 96\n",
      "16 48 97\n",
      "16 48 98\n",
      "16 48 99\n",
      "16 48 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.7336448598130841 77.59793122128403 \ttest: 0.7391304347826086 32.89838142216894\n",
      "retrain  2 :\n",
      "\ttrain: 0.7336448598130841 74.1504798197852 \ttest: 0.7391304347826086 31.51830407668063\n",
      "retrain  3 :\n",
      "\ttrain: 0.7336448598130841 72.16777124542436 \ttest: 0.7391304347826086 30.797154518474724\n",
      "retrain  4 :\n",
      "\ttrain: 0.7570093457943925 70.96660238044082 \ttest: 0.7391304347826086 30.4262239551999\n",
      "retrain  5 :\n",
      "\ttrain: 0.7710280373831776 70.17646226748093 \ttest: 0.7717391304347826 30.241688493085665\n",
      "retrain  6 :\n",
      "\ttrain: 0.7710280373831776 69.60802318763882 \ttest: 0.7717391304347826 30.159341860912548\n",
      "retrain  7 :\n",
      "\ttrain: 0.7663551401869159 69.16593373429082 \ttest: 0.7717391304347826 30.135629679868778\n",
      "retrain  8 :\n",
      "\ttrain: 0.7663551401869159 68.80155956364324 \ttest: 0.7717391304347826 30.147290650007214\n",
      "retrain  9 :\n",
      "\ttrain: 0.7663551401869159 68.4892680476723 \ttest: 0.7717391304347826 30.181276988393115\n",
      "retrain  10 :\n",
      "\ttrain: 0.7663551401869159 68.21483943498879 \ttest: 0.7717391304347826 30.229830799814827\n",
      "retrain  11 :\n",
      "\ttrain: 0.7663551401869159 67.9698319233521 \ttest: 0.7717391304347826 30.28805866075933\n",
      "retrain  12 :\n",
      "\ttrain: 0.7663551401869159 67.7488258760621 \ttest: 0.7717391304347826 30.352707840013913\n",
      "retrain  13 :\n",
      "\ttrain: 0.7663551401869159 67.5480580500067 \ttest: 0.7717391304347826 30.421524879749853\n",
      "retrain  14 :\n",
      "\ttrain: 0.7663551401869159 67.36473022061962 \ttest: 0.7717391304347826 30.492901872840086\n",
      "retrain  15 :\n",
      "\ttrain: 0.7663551401869159 67.19664811535692 \ttest: 0.7717391304347826 30.565669376707113\n",
      "retrain  16 :\n",
      "\ttrain: 0.7663551401869159 67.04202446839909 \ttest: 0.7717391304347826 30.63896744256789\n",
      "retrain  17 :\n",
      "\ttrain: 0.7663551401869159 66.89936535669398 \ttest: 0.7717391304347826 30.71216064387548\n",
      "retrain  18 :\n",
      "\ttrain: 0.7663551401869159 66.76740009082974 \ttest: 0.7717391304347826 30.78477947831025\n",
      "retrain  19 :\n",
      "\ttrain: 0.7710280373831776 66.64503485104237 \ttest: 0.7717391304347826 30.85647857032179\n",
      "retrain  20 :\n",
      "\ttrain: 0.7710280373831776 66.53131997989672 \ttest: 0.7717391304347826 30.92700615189488\n",
      "retrain  21 :\n",
      "\ttrain: 0.7710280373831776 66.42542563785649 \ttest: 0.7717391304347826 30.99618142650415\n",
      "retrain  22 :\n",
      "\ttrain: 0.7710280373831776 66.32662292844091 \ttest: 0.7717391304347826 31.063877602917977\n",
      "retrain  23 :\n",
      "\ttrain: 0.7710280373831776 66.234268827669 \ttest: 0.7717391304347826 31.130009085529373\n",
      "retrain  24 :\n",
      "\ttrain: 0.7710280373831776 66.14779390004658 \ttest: 0.7717391304347826 31.194521749944833\n",
      "retrain  25 :\n",
      "\ttrain: 0.7710280373831776 66.0666921390104 \ttest: 0.7717391304347826 31.257385527560032\n",
      "retrain  26 :\n",
      "\ttrain: 0.7710280373831776 65.99051247527241 \ttest: 0.7717391304347826 31.318588728169125\n",
      "retrain  27 :\n",
      "\ttrain: 0.7710280373831776 65.91885162236458 \ttest: 0.7717391304347826 31.378133676743065\n",
      "retrain  28 :\n",
      "\ttrain: 0.7710280373831776 65.85134801047573 \ttest: 0.7717391304347826 31.436033347836272\n",
      "retrain  29 :\n",
      "\ttrain: 0.7710280373831776 65.78767661583133 \ttest: 0.7717391304347826 31.49230876025669\n",
      "retrain  30 :\n",
      "\ttrain: 0.7710280373831776 65.72754453324879 \ttest: 0.7717391304347826 31.546986953420934\n",
      "retrain  31 :\n",
      "\ttrain: 0.7710280373831776 65.67068716960563 \ttest: 0.7717391304347826 31.60009941063004\n",
      "retrain  32 :\n",
      "\ttrain: 0.7710280373831776 65.61686495901456 \ttest: 0.7717391304347826 31.65168082723956\n",
      "retrain  33 :\n",
      "\ttrain: 0.7710280373831776 65.56586051850792 \ttest: 0.7717391304347826 31.701768146209346\n",
      "retrain  34 :\n",
      "\ttrain: 0.7710280373831776 65.51747617730491 \ttest: 0.7717391304347826 31.750399801909225\n",
      "retrain  35 :\n",
      "\ttrain: 0.7710280373831776 65.47153182416963 \ttest: 0.7717391304347826 31.79761512688795\n",
      "retrain  36 :\n",
      "\ttrain: 0.7710280373831776 65.42786302660737 \ttest: 0.7717391304347826 31.843453886744793\n",
      "retrain  37 :\n",
      "\ttrain: 0.7710280373831776 65.38631938316743 \ttest: 0.7717391304347826 31.88795591613696\n",
      "retrain  38 :\n",
      "\ttrain: 0.7710280373831776 65.3467630762782 \ttest: 0.7717391304347826 31.931160834953776\n",
      "retrain  39 :\n",
      "\ttrain: 0.7710280373831776 65.3090675981104 \ttest: 0.7717391304347826 31.973107828264485\n",
      "retrain  40 :\n",
      "\ttrain: 0.7710280373831776 65.27311662615978 \ttest: 0.7717391304347826 32.01383547715563\n",
      "retrain  41 :\n",
      "\ttrain: 0.7710280373831776 65.23880302872652 \ttest: 0.7717391304347826 32.05338163027852\n",
      "retrain  42 :\n",
      "\ttrain: 0.7710280373831776 65.20602798337931 \ttest: 0.7717391304347826 32.091783308023274\n",
      "retrain  43 :\n",
      "\ttrain: 0.7757009345794392 65.17470019393201 \ttest: 0.7717391304347826 32.12907663286984\n",
      "retrain  44 :\n",
      "\ttrain: 0.7757009345794392 65.14473519351138 \ttest: 0.7717391304347826 32.16529678074704\n",
      "retrain  45 :\n",
      "\ttrain: 0.7757009345794392 65.11605472302844 \ttest: 0.7717391304347826 32.200477949240536\n",
      "retrain  46 :\n",
      "\ttrain: 0.7757009345794392 65.08858617583157 \ttest: 0.7717391304347826 32.234653339291135\n",
      "retrain  47 :\n",
      "\ttrain: 0.7757009345794392 65.06226210056721 \ttest: 0.7717391304347826 32.26785514766328\n",
      "retrain  48 :\n",
      "\ttrain: 0.7757009345794392 65.03701975533627 \ttest: 0.7717391304347826 32.3001145679748\n",
      "retrain  49 :\n",
      "\ttrain: 0.7757009345794392 65.01280070714154 \ttest: 0.7717391304347826 32.33146179849058\n",
      "retrain  50 :\n",
      "\ttrain: 0.7757009345794392 64.98955047139958 \ttest: 0.7717391304347826 32.3619260552161\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.80447   0.91720   0.85714       157\n",
      "           1    0.62857   0.38596   0.47826        57\n",
      "\n",
      "    accuracy                        0.77570       214\n",
      "   macro avg    0.71652   0.65158   0.66770       214\n",
      "weighted avg    0.75762   0.77570   0.75623       214\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.79012   0.94118   0.85906        68\n",
      "           1    0.63636   0.29167   0.40000        24\n",
      "\n",
      "    accuracy                        0.77174        92\n",
      "   macro avg    0.71324   0.61642   0.62953        92\n",
      "weighted avg    0.75001   0.77174   0.73931        92\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 16\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 48\n"
     ]
    }
   ],
   "source": [
    "def fit_trees():\n",
    "    learning_rate=0.1\n",
    "    max_depth=1\n",
    "    bins=8\n",
    "    lam=100\n",
    "\n",
    "    gtgp = GTGP(learning_rate=learning_rate,max_depth=max_depth,bins=bins,lam=lam)\n",
    "\n",
    "    total_size=10\n",
    "    elite_size = 10\n",
    "    epoch= 100\n",
    "    gp_epoch= 1\n",
    "    verbose = 1\n",
    "    tolerance=0.001\n",
    "\n",
    "    gtgp.fit(X_train,y_train,total_size=total_size,elite_size = elite_size,epoch=epoch,gp_epoch=gp_epoch,tolerance=tolerance,verbose=verbose)\n",
    "\n",
    "    retrain_epoch= 10\n",
    "    alpha=0\n",
    "    beta=1\n",
    "    gammer=0\n",
    "\n",
    "    verbose=1\n",
    "    gtgp.lam = 10\n",
    "    gtgp.retrain_estimators(X_test,y_test,retrain_epoch=retrain_epoch,alpha=alpha,beta=beta,gammer=gammer,verbose=verbose)\n",
    "\n",
    "    return gtgp\n",
    "\n",
    "for i in range(30):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size,stratify=y, random_state=seeds[i])\n",
    "    y_train,y_test,y_train_one_hot,y_test_one_hot = to_one_hot(y_train,y_test)\n",
    "    gtgp = fit_trees()\n",
    "\n",
    "    print(classification_report(y_train,np.argmax(gtgp.train_p,axis=1),digits=5))\n",
    "    print(classification_report(y_test,np.argmax(gtgp.test_p,axis=1),digits=5))\n",
    "\n",
    "    num_trees,depth,num_nodes = gtgp.print_model()\n",
    "\n",
    "    train_acc = accuracy_score(y_train,np.argmax(gtgp.train_p,axis=1))\n",
    "    test_acc = accuracy_score(y_test,np.argmax(gtgp.test_p,axis=1))\n",
    "    # train_f1 = f1_score(y_train,np.argmax(gtgp.train_p,axis=1),average='macro')\n",
    "    # test_f1 = f1_score(y_test,np.argmax(gtgp.test_p,axis=1),average='macro')\n",
    "\n",
    "    # train_f1 = roc_auc_score(gtgp.y_one_hot.toarray(),(gtgp.train_p.T/np.sum(gtgp.train_p,axis=1)).T)\n",
    "    # test_f1 = roc_auc_score(y_test_one_hot.toarray(),(gtgp.test_p.T/np.sum(gtgp.test_p,axis=1)).T)\n",
    "\n",
    "    train_f1 = roc_auc_score(gtgp.y_one_hot.toarray(),gtgp.train_p)\n",
    "    test_f1 = roc_auc_score(y_test_one_hot.toarray(),gtgp.test_p)\n",
    "\n",
    "\n",
    "    with open('./benchmark/'+dataset+'.csv','a') as f:\n",
    "        s = str(train_acc)+\",\"+str(test_acc)+\",\"+str(train_f1)+\",\"+str(test_f1)+\",\"+str(num_trees)+\",\"+str(depth)+\",\"+str(num_nodes)+\"\\n\"\n",
    "        f.writelines(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662e91a5",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ed15d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "661630ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./benchmark_DC/'+dataset+'.csv','w') as f:\n",
    "    for i in range(30):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size,stratify=y, random_state=seeds[i])\n",
    "        clf = DecisionTreeClassifier(max_depth=2)\n",
    "        clf.fit(X_train,y_train)\n",
    "        y_train,y_test,y_train_one_hot,y_test_one_hot = to_one_hot(y_train,y_test)\n",
    "\n",
    "        num_trees = 1\n",
    "        depth = clf.tree_.max_depth\n",
    "        num_nodes = clf.tree_.node_count\n",
    "\n",
    "        train_acc = accuracy_score(y_train,clf.predict(X_train))\n",
    "        test_acc = accuracy_score(y_test,clf.predict(X_test))\n",
    "        train_f1 = f1_score(y_train,clf.predict(X_train),average='macro')\n",
    "        test_f1 = f1_score(y_test,clf.predict(X_test),average='macro')\n",
    "\n",
    "        train_roc = roc_auc_score(y_train_one_hot.toarray(),clf.predict_proba(X_train))\n",
    "        test_roc = roc_auc_score(y_test_one_hot.toarray(),clf.predict_proba(X_test))\n",
    "\n",
    "        s = str(train_acc)+\",\"+str(test_acc)+\",\"+str(train_f1)+\",\"+str(test_f1)+\",\"+str(num_trees)+\",\"+str(depth)+\",\"+str(num_nodes)+\"\\n\"\n",
    "        f.writelines(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63afbae1",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "28fa8541",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "acfdd7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./benchmark_xgb/'+dataset+'.csv','w') as f:\n",
    "    for i in range(30):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size,stratify=y, random_state=seeds[i])\n",
    "        y_train,y_test,y_train_one_hot,y_test_one_hot = to_one_hot(y_train,y_test)\n",
    "        # xgb = xgboost.XGBClassifier(n_estimators=100,max_depth=6)\n",
    "        # xgb = xgboost.XGBClassifier(min_child_weight=0,max_depth=4)\n",
    "        xgb = xgboost.XGBClassifier(n_estimators=10,max_depth=1)\n",
    "        xgb.fit(X_train,y_train)\n",
    "\n",
    "        import json\n",
    "\n",
    "        def item_generator(json_input, lookup_key):\n",
    "            if isinstance(json_input, dict):\n",
    "                for k, v in json_input.items():\n",
    "                    if k == lookup_key:\n",
    "                        yield v\n",
    "                    else:\n",
    "                        yield from item_generator(v, lookup_key)\n",
    "            elif isinstance(json_input, list):\n",
    "                for item in json_input:\n",
    "                    yield from item_generator(item, lookup_key)\n",
    "\n",
    "        def tree_depth(json_text):\n",
    "            json_input = json.loads(json_text)\n",
    "            depths = list(item_generator(json_input, 'depth'))\n",
    "            return max(depths) + 1 if len(depths) != 0 else 1\n",
    "\n",
    "        train_acc = accuracy_score(y_train,xgb.predict(X_train))\n",
    "        test_acc = accuracy_score(y_test,xgb.predict(X_test))\n",
    "\n",
    "        # train_f1 = f1_score(y_train,xgb.predict(X_train),average='macro')\n",
    "        # test_f1 = f1_score(y_test,xgb.predict(X_test),average='macro')\n",
    "        train_f1 = roc_auc_score(y_train_one_hot.toarray(),xgb.predict_proba(X_train))\n",
    "        test_f1 = roc_auc_score(y_test_one_hot.toarray(),xgb.predict_proba(X_test))\n",
    "\n",
    "        booster = xgb.get_booster()\n",
    "\n",
    "        tree_df = booster.trees_to_dataframe()\n",
    "        depths = [tree_depth(x) for x in booster.get_dump(dump_format = \"json\")]\n",
    "        num_trees = len(depths)\n",
    "        depth = np.average(depths)\n",
    "        num_nodes = len(tree_df)\n",
    "\n",
    "        s = str(train_acc)+\",\"+str(test_acc)+\",\"+str(train_f1)+\",\"+str(test_f1)+\",\"+str(num_trees)+\",\"+str(depth)+\",\"+str(num_nodes)+\"\\n\"\n",
    "        f.writelines(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc363f99",
   "metadata": {},
   "source": [
    "# GDBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6e6d3435",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ef69c1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./benchmark_GBDT/'+dataset+'.csv','w') as f:\n",
    "    for i in range(30):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size,stratify=y, random_state=seeds[i])\n",
    "        y_train,y_test,y_train_one_hot,y_test_one_hot = to_one_hot(y_train,y_test)\n",
    "        # clf = GradientBoostingClassifier(n_estimators=1000)\n",
    "        clf = GradientBoostingClassifier(n_estimators=10,max_depth=2)\n",
    "        clf.fit(X_train,y_train)\n",
    "\n",
    "        train_acc = accuracy_score(y_train,clf.predict(X_train))\n",
    "        test_acc = accuracy_score(y_test,clf.predict(X_test))\n",
    "        # train_f1 = f1_score(y_train,clf.predict(X_train),average='macro')\n",
    "        # test_f1 = f1_score(y_test,clf.predict(X_test),average='macro')\n",
    "        train_f1 = roc_auc_score(y_train_one_hot.toarray(),clf.predict_proba(X_train))\n",
    "        test_f1 = roc_auc_score(y_test_one_hot.toarray(),clf.predict_proba(X_test))\n",
    "\n",
    "\n",
    "        num_trees = len([ est for ests in clf.estimators_ for est in ests])\n",
    "        depth = np.average([ max(1,est.tree_.max_depth) for ests in clf.estimators_ for est in ests])\n",
    "        num_nodes = sum([ est.tree_.node_count for ests in clf.estimators_ for est in ests])\n",
    "\n",
    "        s = str(train_acc)+\",\"+str(test_acc)+\",\"+str(train_f1)+\",\"+str(test_f1)+\",\"+str(num_trees)+\",\"+str(depth)+\",\"+str(num_nodes)+\"\\n\"\n",
    "        f.writelines(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0ef54f",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8623bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3edfc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./benchmark_RF/'+dataset+'.csv','w') as f:\n",
    "    for i in range(30):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size,stratify=y, random_state=seeds[i])\n",
    "        y_train,y_test,y_train_one_hot,y_test_one_hot = to_one_hot(y_train,y_test)\n",
    "        # rfc = RandomForestClassifier(n_estimators=100)\n",
    "        rfc = RandomForestClassifier(n_estimators=10,max_depth=3)\n",
    "        rfc.fit(X_train,y_train)\n",
    "\n",
    "        train_acc = accuracy_score(y_train,rfc.predict(X_train))\n",
    "        test_acc = accuracy_score(y_test,rfc.predict(X_test))\n",
    "        # train_f1 = f1_score(y_train,rfc.predict(X_train),average='macro')\n",
    "        # test_f1 = f1_score(y_test,rfc.predict(X_test),average='macro')\n",
    "        \n",
    "        train_f1 = roc_auc_score(y_train_one_hot.toarray(),rfc.predict_proba(X_train))\n",
    "        test_f1 = roc_auc_score(y_test_one_hot.toarray(),rfc.predict_proba(X_test))\n",
    "\n",
    "        num_trees = len(rfc.estimators_)\n",
    "        depth = np.average([est.tree_.max_depth for est in rfc.estimators_])\n",
    "        num_nodes = sum([est.tree_.node_count for est in rfc.estimators_])\n",
    "\n",
    "        s = str(train_acc)+\",\"+str(test_acc)+\",\"+str(train_f1)+\",\"+str(test_f1)+\",\"+str(num_trees)+\",\"+str(depth)+\",\"+str(num_nodes)+\"\\n\"\n",
    "        f.writelines(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51ae26b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BStackGP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc-autonumbering": true,
  "toc-showcode": true,
  "toc-showmarkdowntxt": true,
  "vscode": {
   "interpreter": {
    "hash": "598cefc26d6e5a65b2978c65314d0610ea9dfe34c7d989c4b6d2528d500ccb7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
