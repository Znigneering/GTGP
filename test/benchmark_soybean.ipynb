{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a8bc990-ebc5-46bd-bab4-f4091ce5b834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../script/\")\n",
    "\n",
    "import Functions\n",
    "from Engine import Engine\n",
    "from GTGP import GTGP\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report,accuracy_score,confusion_matrix,f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import importlib\n",
    "from time import time\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbad47da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.utils import shuffle\n",
    "def plot_roc_curve(true_y, y_prob):\n",
    "    \"\"\"\n",
    "    plots the roc curve based of the probabilities\n",
    "    \"\"\"\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(true_y, y_prob)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    print(roc_auc_score(true_y,prob[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c114de92",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "feedaa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/soybean.tsv\",delimiter='\\t')\n",
    "X = df.iloc[:,:-1].to_numpy().astype(\"float\")\n",
    "y = df.iloc[:,-1].to_numpy().astype(\"int\")\n",
    "\n",
    "seeds = [10086, 200,500,30506,30405,30420,10056,7059,40965,5398,869543,83491,823190,\n",
    "         48392,2810,48392,3498210,483902,859032,12890,538920,86954,54309,6504,9840,\n",
    "         219805,548,2981,432890,5438908,219094,5843902,60854,979,12890,2108,4093]\n",
    "train_size = 0.7\n",
    "dataset = 'soybean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6c17d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(675, 35)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "961615dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5     92\n",
       "12    91\n",
       "1     91\n",
       "15    88\n",
       "6     44\n",
       "2     44\n",
       "10    20\n",
       "17    20\n",
       "14    20\n",
       "4     20\n",
       "7     20\n",
       "3     20\n",
       "11    20\n",
       "16    20\n",
       "18    20\n",
       "0     16\n",
       "9     15\n",
       "8     14\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a2341bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(y,yt):\n",
    "    le = LabelEncoder()\n",
    "    ohe = OneHotEncoder()\n",
    "    y_train = le.fit_transform(y)\n",
    "    y_one_hot = ohe.fit_transform(y_train.reshape(-1,1))\n",
    "    \n",
    "    y_test = le.transform(yt)\n",
    "    yt_one_hot = ohe.transform(y_test.reshape(-1,1))\n",
    "    \n",
    "    return y_train,y_test,y_one_hot,yt_one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdd30c5",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f418f618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 97 1\n",
      "51 207 2\n",
      "73 293 3\n",
      "90 364 4\n",
      "108 424 5\n",
      "129 501 6\n",
      "149 583 7\n",
      "166 646 8\n",
      "186 738 9\n",
      "207 823 10\n",
      "222 882 11\n",
      "237 941 12\n",
      "255 1013 13\n",
      "275 1091 14\n",
      "295 1167 15\n",
      "315 1245 16\n",
      "322 1274 17\n",
      "335 1325 18\n",
      "352 1404 19\n",
      "369 1481 20\n",
      "382 1526 21\n",
      "398 1582 22\n",
      "412 1638 23\n",
      "425 1697 24\n",
      "433 1727 25\n",
      "448 1784 26\n",
      "465 1843 27\n",
      "480 1914 28\n",
      "493 1971 29\n",
      "504 2016 30\n",
      "516 2062 31\n",
      "533 2127 32\n",
      "550 2206 33\n",
      "568 2280 34\n",
      "581 2339 35\n",
      "592 2380 36\n",
      "609 2451 37\n",
      "624 2518 38\n",
      "633 2561 39\n",
      "646 2616 40\n",
      "657 2663 41\n",
      "668 2714 42\n",
      "680 2766 43\n",
      "690 2806 44\n",
      "700 2844 45\n",
      "717 2907 46\n",
      "728 2962 47\n",
      "742 3024 48\n",
      "748 3046 49\n",
      "763 3115 50\n",
      "771 3155 51\n",
      "784 3202 52\n",
      "794 3244 53\n",
      "805 3307 54\n",
      "814 3336 55\n",
      "825 3383 56\n",
      "836 3434 57\n",
      "850 3496 58\n",
      "861 3545 59\n",
      "871 3593 60\n",
      "881 3621 61\n",
      "892 3674 62\n",
      "900 3702 63\n",
      "910 3746 64\n",
      "919 3789 65\n",
      "926 3822 66\n",
      "936 3868 67\n",
      "947 3921 68\n",
      "957 3961 69\n",
      "965 3995 70\n",
      "970 4014 71\n",
      "980 4052 72\n",
      "990 4102 73\n",
      "1003 4159 74\n",
      "1010 4188 75\n",
      "1017 4219 76\n",
      "1031 4287 77\n",
      "1039 4315 78\n",
      "1051 4375 79\n",
      "1060 4414 80\n",
      "1074 4476 81\n",
      "1083 4515 82\n",
      "1090 4542 83\n",
      "1104 4610 84\n",
      "1113 4655 85\n",
      "1123 4707 86\n",
      "1125 4711 87\n",
      "1132 4742 88\n",
      "1143 4799 89\n",
      "1150 4840 90\n",
      "1163 4893 91\n",
      "1171 4925 92\n",
      "1177 4949 93\n",
      "1188 5014 94\n",
      "1198 5070 95\n",
      "1204 5094 96\n",
      "1215 5141 97\n",
      "1224 5184 98\n",
      "1235 5233 99\n",
      "1240 5254 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.9851694915254238 10.126057859547918 \ttest: 0.9408866995073891 15.359957601276491\n",
      "retrain  2 :\n",
      "\ttrain: 0.9936440677966102 6.784831736476006 \ttest: 0.9458128078817734 15.721854521449618\n",
      "retrain  3 :\n",
      "\ttrain: 0.9978813559322034 5.120162166677448 \ttest: 0.9458128078817734 16.003971334230187\n",
      "retrain  4 :\n",
      "\ttrain: 0.9978813559322034 4.082380454099732 \ttest: 0.9507389162561576 16.195763221515733\n",
      "retrain  5 :\n",
      "\ttrain: 0.9978813559322034 3.3820955563669117 \ttest: 0.9507389162561576 16.328929267877186\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        11\n",
      "           1    0.98462   1.00000   0.99225        64\n",
      "           2    1.00000   1.00000   1.00000        31\n",
      "           3    1.00000   1.00000   1.00000        14\n",
      "           4    1.00000   1.00000   1.00000        14\n",
      "           5    1.00000   1.00000   1.00000        64\n",
      "           6    1.00000   1.00000   1.00000        31\n",
      "           7    1.00000   1.00000   1.00000        14\n",
      "           8    1.00000   1.00000   1.00000        10\n",
      "           9    1.00000   1.00000   1.00000        10\n",
      "          10    1.00000   1.00000   1.00000        14\n",
      "          11    1.00000   1.00000   1.00000        14\n",
      "          12    1.00000   0.98438   0.99213        64\n",
      "          13    1.00000   1.00000   1.00000        14\n",
      "          14    1.00000   1.00000   1.00000        61\n",
      "          15    1.00000   1.00000   1.00000        14\n",
      "          16    1.00000   1.00000   1.00000        14\n",
      "          17    1.00000   1.00000   1.00000        14\n",
      "\n",
      "    accuracy                        0.99788       472\n",
      "   macro avg    0.99915   0.99913   0.99913       472\n",
      "weighted avg    0.99791   0.99788   0.99788       472\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000         5\n",
      "           1    0.78788   0.96296   0.86667        27\n",
      "           2    1.00000   1.00000   1.00000        13\n",
      "           3    1.00000   1.00000   1.00000         6\n",
      "           4    1.00000   1.00000   1.00000         6\n",
      "           5    0.93103   0.96429   0.94737        28\n",
      "           6    1.00000   1.00000   1.00000        13\n",
      "           7    1.00000   1.00000   1.00000         6\n",
      "           8    1.00000   1.00000   1.00000         4\n",
      "           9    1.00000   1.00000   1.00000         5\n",
      "          10    1.00000   1.00000   1.00000         6\n",
      "          11    1.00000   1.00000   1.00000         6\n",
      "          12    0.95455   0.77778   0.85714        27\n",
      "          13    1.00000   0.66667   0.80000         6\n",
      "          14    1.00000   1.00000   1.00000        27\n",
      "          15    1.00000   1.00000   1.00000         6\n",
      "          16    1.00000   1.00000   1.00000         6\n",
      "          17    1.00000   1.00000   1.00000         6\n",
      "\n",
      "    accuracy                        0.95074       203\n",
      "   macro avg    0.98186   0.96509   0.97062       203\n",
      "weighted avg    0.95623   0.95074   0.95009       203\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1240\n",
      "Average of depth: 1.5193548387096774\n",
      "Number of nodes: 5254\n",
      "24 84 1\n",
      "47 169 2\n",
      "66 252 3\n",
      "88 340 4\n",
      "109 423 5\n",
      "131 503 6\n",
      "147 561 7\n",
      "167 637 8\n",
      "181 695 9\n",
      "199 763 10\n",
      "212 822 11\n",
      "228 882 12\n",
      "241 949 13\n",
      "254 1006 14\n",
      "273 1083 15\n",
      "291 1159 16\n",
      "311 1251 17\n",
      "331 1323 18\n",
      "345 1385 19\n",
      "360 1446 20\n",
      "376 1514 21\n",
      "389 1569 22\n",
      "401 1619 23\n",
      "412 1664 24\n",
      "430 1748 25\n",
      "442 1796 26\n",
      "460 1872 27\n",
      "468 1908 28\n",
      "487 1993 29\n",
      "501 2051 30\n",
      "522 2144 31\n",
      "537 2199 32\n",
      "548 2244 33\n",
      "562 2312 34\n",
      "574 2370 35\n",
      "585 2415 36\n",
      "598 2466 37\n",
      "610 2510 38\n",
      "623 2563 39\n",
      "634 2606 40\n",
      "645 2659 41\n",
      "662 2726 42\n",
      "668 2744 43\n",
      "676 2776 44\n",
      "687 2819 45\n",
      "701 2879 46\n",
      "708 2908 47\n",
      "722 2978 48\n",
      "735 3037 49\n",
      "746 3082 50\n",
      "758 3128 51\n",
      "773 3193 52\n",
      "782 3230 53\n",
      "792 3272 54\n",
      "802 3320 55\n",
      "813 3369 56\n",
      "828 3436 57\n",
      "836 3468 58\n",
      "845 3505 59\n",
      "854 3538 60\n",
      "860 3564 61\n",
      "871 3603 62\n",
      "879 3637 63\n",
      "886 3662 64\n",
      "897 3703 65\n",
      "906 3752 66\n",
      "914 3788 67\n",
      "929 3843 68\n",
      "940 3890 69\n",
      "945 3911 70\n",
      "957 3969 71\n",
      "964 4002 72\n",
      "973 4039 73\n",
      "983 4087 74\n",
      "991 4115 75\n",
      "997 4149 76\n",
      "1005 4183 77\n",
      "1011 4211 78\n",
      "1021 4243 79\n",
      "1029 4289 80\n",
      "1036 4320 81\n",
      "1046 4362 82\n",
      "1059 4423 83\n",
      "1067 4457 84\n",
      "1075 4495 85\n",
      "1086 4544 86\n",
      "1095 4581 87\n",
      "1103 4621 88\n",
      "1116 4672 89\n",
      "1127 4721 90\n",
      "1137 4765 91\n",
      "1148 4810 92\n",
      "1154 4832 93\n",
      "1165 4879 94\n",
      "1176 4930 95\n",
      "1186 4980 96\n",
      "1196 5030 97\n",
      "1206 5076 98\n",
      "1217 5133 99\n",
      "1220 5148 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.9851694915254238 9.656216945096622 \ttest: 0.9408866995073891 17.760235893225968\n",
      "retrain  2 :\n",
      "\ttrain: 0.9915254237288136 6.712575833878021 \ttest: 0.9359605911330049 17.522654531728897\n",
      "retrain  3 :\n",
      "\ttrain: 0.9957627118644068 5.236891690209122 \ttest: 0.9359605911330049 17.548932709598624\n",
      "retrain  4 :\n",
      "\ttrain: 0.9957627118644068 4.326603366221811 \ttest: 0.9359605911330049 17.65495187158073\n",
      "retrain  5 :\n",
      "\ttrain: 0.9957627118644068 3.703886546899315 \ttest: 0.9359605911330049 17.786222116570787\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        11\n",
      "           1    0.96970   1.00000   0.98462        64\n",
      "           2    1.00000   1.00000   1.00000        31\n",
      "           3    1.00000   1.00000   1.00000        14\n",
      "           4    1.00000   1.00000   1.00000        14\n",
      "           5    1.00000   1.00000   1.00000        64\n",
      "           6    1.00000   1.00000   1.00000        31\n",
      "           7    1.00000   1.00000   1.00000        14\n",
      "           8    1.00000   1.00000   1.00000        10\n",
      "           9    1.00000   1.00000   1.00000        10\n",
      "          10    1.00000   1.00000   1.00000        14\n",
      "          11    1.00000   1.00000   1.00000        14\n",
      "          12    1.00000   0.96875   0.98413        64\n",
      "          13    1.00000   1.00000   1.00000        14\n",
      "          14    1.00000   1.00000   1.00000        61\n",
      "          15    1.00000   1.00000   1.00000        14\n",
      "          16    1.00000   1.00000   1.00000        14\n",
      "          17    1.00000   1.00000   1.00000        14\n",
      "\n",
      "    accuracy                        0.99576       472\n",
      "   macro avg    0.99832   0.99826   0.99826       472\n",
      "weighted avg    0.99589   0.99576   0.99576       472\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000         5\n",
      "           1    0.78125   0.92593   0.84746        27\n",
      "           2    1.00000   1.00000   1.00000        13\n",
      "           3    1.00000   1.00000   1.00000         6\n",
      "           4    1.00000   1.00000   1.00000         6\n",
      "           5    0.92593   0.89286   0.90909        28\n",
      "           6    1.00000   1.00000   1.00000        13\n",
      "           7    1.00000   1.00000   1.00000         6\n",
      "           8    1.00000   1.00000   1.00000         4\n",
      "           9    1.00000   1.00000   1.00000         5\n",
      "          10    1.00000   1.00000   1.00000         6\n",
      "          11    1.00000   1.00000   1.00000         6\n",
      "          12    0.90909   0.74074   0.81633        27\n",
      "          13    0.71429   0.83333   0.76923         6\n",
      "          14    1.00000   1.00000   1.00000        27\n",
      "          15    1.00000   1.00000   1.00000         6\n",
      "          16    1.00000   1.00000   1.00000         6\n",
      "          17    1.00000   1.00000   1.00000         6\n",
      "\n",
      "    accuracy                        0.93596       203\n",
      "   macro avg    0.96281   0.96627   0.96345       203\n",
      "weighted avg    0.94015   0.93596   0.93592       203\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1220\n",
      "Average of depth: 1.518032786885246\n",
      "Number of nodes: 5148\n",
      "24 92 1\n",
      "47 183 2\n",
      "72 282 3\n",
      "94 374 4\n",
      "112 448 5\n",
      "137 549 6\n",
      "159 631 7\n",
      "181 719 8\n",
      "195 777 9\n",
      "217 867 10\n",
      "239 951 11\n",
      "257 1033 12\n",
      "274 1100 13\n",
      "293 1177 14\n",
      "310 1236 15\n",
      "327 1313 16\n",
      "340 1362 17\n",
      "356 1434 18\n",
      "370 1484 19\n",
      "391 1569 20\n",
      "400 1600 21\n",
      "416 1670 22\n",
      "430 1728 23\n",
      "441 1773 24\n",
      "451 1811 25\n",
      "472 1922 26\n",
      "482 1970 27\n",
      "496 2036 28\n",
      "507 2083 29\n",
      "519 2131 30\n",
      "530 2174 31\n",
      "543 2227 32\n",
      "557 2291 33\n",
      "571 2361 34\n",
      "584 2416 35\n",
      "603 2505 36\n",
      "621 2595 37\n",
      "634 2660 38\n",
      "642 2692 39\n",
      "650 2728 40\n",
      "664 2794 41\n",
      "671 2827 42\n",
      "681 2865 43\n",
      "689 2903 44\n",
      "702 2956 45\n",
      "715 3013 46\n",
      "721 3037 47\n",
      "736 3098 48\n",
      "751 3155 49\n",
      "762 3196 50\n",
      "771 3237 51\n",
      "780 3276 52\n",
      "789 3323 53\n",
      "796 3346 54\n",
      "808 3390 55\n",
      "817 3425 56\n",
      "832 3484 57\n",
      "843 3533 58\n",
      "855 3583 59\n",
      "865 3627 60\n",
      "875 3677 61\n",
      "882 3708 62\n",
      "891 3749 63\n",
      "902 3822 64\n",
      "911 3857 65\n",
      "925 3925 66\n",
      "936 3978 67\n",
      "946 4020 68\n",
      "958 4068 69\n",
      "967 4105 70\n",
      "976 4144 71\n",
      "986 4192 72\n",
      "994 4228 73\n",
      "999 4255 74\n",
      "1012 4314 75\n",
      "1026 4380 76\n",
      "1037 4435 77\n",
      "1044 4472 78\n",
      "1056 4536 79\n",
      "1066 4578 80\n",
      "1077 4631 81\n",
      "1087 4675 82\n",
      "1096 4718 83\n",
      "1107 4751 84\n",
      "1114 4784 85\n",
      "1125 4829 86\n",
      "1136 4892 87\n",
      "1141 4915 88\n",
      "1154 4978 89\n",
      "1157 4989 90\n",
      "1169 5049 91\n",
      "1178 5080 92\n",
      "1188 5128 93\n",
      "1194 5160 94\n",
      "1200 5184 95\n",
      "1208 5218 96\n",
      "1215 5255 97\n",
      "1222 5286 98\n",
      "1231 5319 99\n",
      "1242 5360 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.9936440677966102 7.432493815854779 \ttest: 0.9359605911330049 19.106634763356652\n",
      "retrain  2 :\n",
      "\ttrain: 0.9978813559322034 4.68939758207791 \ttest: 0.9359605911330049 19.395076690907032\n",
      "retrain  3 :\n",
      "\ttrain: 0.9978813559322034 3.381301318518941 \ttest: 0.9408866995073891 19.57265560161403\n",
      "retrain  4 :\n",
      "\ttrain: 0.9978813559322034 2.5877870012632624 \ttest: 0.9408866995073891 19.81693668285536\n",
      "retrain  5 :\n",
      "\ttrain: 0.9978813559322034 2.054748564062487 \ttest: 0.9408866995073891 20.092362635371515\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        11\n",
      "           1    1.00000   0.98438   0.99213        64\n",
      "           2    1.00000   1.00000   1.00000        31\n",
      "           3    1.00000   1.00000   1.00000        14\n",
      "           4    1.00000   1.00000   1.00000        14\n",
      "           5    1.00000   1.00000   1.00000        64\n",
      "           6    1.00000   1.00000   1.00000        31\n",
      "           7    1.00000   1.00000   1.00000        14\n",
      "           8    1.00000   1.00000   1.00000        10\n",
      "           9    1.00000   1.00000   1.00000        10\n",
      "          10    1.00000   1.00000   1.00000        14\n",
      "          11    1.00000   1.00000   1.00000        14\n",
      "          12    0.98462   1.00000   0.99225        64\n",
      "          13    1.00000   1.00000   1.00000        14\n",
      "          14    1.00000   1.00000   1.00000        61\n",
      "          15    1.00000   1.00000   1.00000        14\n",
      "          16    1.00000   1.00000   1.00000        14\n",
      "          17    1.00000   1.00000   1.00000        14\n",
      "\n",
      "    accuracy                        0.99788       472\n",
      "   macro avg    0.99915   0.99913   0.99913       472\n",
      "weighted avg    0.99791   0.99788   0.99788       472\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000         5\n",
      "           1    0.81481   0.81481   0.81481        27\n",
      "           2    1.00000   1.00000   1.00000        13\n",
      "           3    1.00000   1.00000   1.00000         6\n",
      "           4    1.00000   1.00000   1.00000         6\n",
      "           5    0.96429   0.96429   0.96429        28\n",
      "           6    1.00000   1.00000   1.00000        13\n",
      "           7    1.00000   1.00000   1.00000         6\n",
      "           8    1.00000   1.00000   1.00000         4\n",
      "           9    1.00000   1.00000   1.00000         5\n",
      "          10    1.00000   1.00000   1.00000         6\n",
      "          11    1.00000   1.00000   1.00000         6\n",
      "          12    0.81481   0.81481   0.81481        27\n",
      "          13    0.83333   0.83333   0.83333         6\n",
      "          14    1.00000   1.00000   1.00000        27\n",
      "          15    1.00000   1.00000   1.00000         6\n",
      "          16    1.00000   1.00000   1.00000         6\n",
      "          17    1.00000   1.00000   1.00000         6\n",
      "\n",
      "    accuracy                        0.94089       203\n",
      "   macro avg    0.96818   0.96818   0.96818       203\n",
      "weighted avg    0.94089   0.94089   0.94089       203\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1242\n",
      "Average of depth: 1.5499194847020934\n",
      "Number of nodes: 5360\n",
      "27 105 1\n",
      "48 176 2\n",
      "73 275 3\n",
      "93 347 4\n",
      "116 440 5\n",
      "137 517 6\n",
      "161 607 7\n",
      "182 692 8\n",
      "197 753 9\n",
      "213 813 10\n",
      "230 874 11\n",
      "248 932 12\n",
      "257 965 13\n",
      "271 1019 14\n",
      "285 1063 15\n",
      "303 1147 16\n",
      "319 1209 17\n",
      "332 1268 18\n",
      "347 1333 19\n",
      "363 1391 20\n",
      "379 1455 21\n",
      "395 1521 22\n",
      "412 1590 23\n",
      "426 1646 24\n",
      "441 1709 25\n",
      "459 1783 26\n",
      "474 1844 27\n",
      "485 1879 28\n",
      "495 1921 29\n",
      "515 2007 30\n",
      "526 2056 31\n",
      "536 2096 32\n",
      "551 2159 33\n",
      "557 2185 34\n",
      "574 2260 35\n",
      "585 2299 36\n",
      "594 2334 37\n",
      "608 2386 38\n",
      "622 2454 39\n",
      "630 2482 40\n",
      "634 2498 41\n",
      "645 2543 42\n",
      "659 2607 43\n",
      "672 2654 44\n",
      "685 2709 45\n",
      "694 2748 46\n",
      "705 2803 47\n",
      "713 2839 48\n",
      "725 2891 49\n",
      "739 2943 50\n",
      "752 3004 51\n",
      "762 3044 52\n",
      "769 3083 53\n",
      "778 3130 54\n",
      "788 3176 55\n",
      "799 3219 56\n",
      "808 3270 57\n",
      "823 3335 58\n",
      "831 3367 59\n",
      "843 3433 60\n",
      "851 3469 61\n",
      "859 3499 62\n",
      "869 3549 63\n",
      "880 3596 64\n",
      "887 3621 65\n",
      "894 3654 66\n",
      "906 3706 67\n",
      "915 3741 68\n",
      "920 3760 69\n",
      "931 3825 70\n",
      "944 3884 71\n",
      "951 3919 72\n",
      "959 3959 73\n",
      "970 4010 74\n",
      "983 4065 75\n",
      "992 4104 76\n",
      "999 4143 77\n",
      "1005 4167 78\n",
      "1010 4192 79\n",
      "1016 4216 80\n",
      "1019 4227 81\n",
      "1026 4260 82\n",
      "1033 4291 83\n",
      "1048 4360 84\n",
      "1056 4396 85\n",
      "1067 4451 86\n",
      "1077 4511 87\n",
      "1085 4557 88\n",
      "1091 4585 89\n",
      "1100 4620 90\n",
      "1108 4654 91\n",
      "1113 4683 92\n",
      "1118 4712 93\n",
      "1128 4756 94\n",
      "1135 4781 95\n",
      "1144 4824 96\n",
      "1153 4865 97\n",
      "1160 4898 98\n",
      "1163 4915 99\n",
      "1166 4924 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.989406779661017 8.446787262529167 \ttest: 0.9507389162561576 14.737095657667368\n",
      "retrain  2 :\n",
      "\ttrain: 0.9915254237288136 5.441118771679396 \ttest: 0.9507389162561576 15.230930967104555\n",
      "retrain  3 :\n",
      "\ttrain: 0.9957627118644068 4.094633245844861 \ttest: 0.9507389162561576 15.538233995590772\n",
      "retrain  4 :\n",
      "\ttrain: 0.9978813559322034 3.2998385563495294 \ttest: 0.9507389162561576 15.720928779412997\n",
      "retrain  5 :\n",
      "\ttrain: 0.9978813559322034 2.7763753837677285 \ttest: 0.9507389162561576 15.832584433175938\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        11\n",
      "           1    0.98462   1.00000   0.99225        64\n",
      "           2    1.00000   1.00000   1.00000        31\n",
      "           3    1.00000   1.00000   1.00000        14\n",
      "           4    1.00000   1.00000   1.00000        14\n",
      "           5    1.00000   1.00000   1.00000        64\n",
      "           6    1.00000   1.00000   1.00000        31\n",
      "           7    1.00000   1.00000   1.00000        14\n",
      "           8    1.00000   1.00000   1.00000        10\n",
      "           9    1.00000   1.00000   1.00000        10\n",
      "          10    1.00000   1.00000   1.00000        14\n",
      "          11    1.00000   1.00000   1.00000        14\n",
      "          12    1.00000   0.98438   0.99213        64\n",
      "          13    1.00000   1.00000   1.00000        14\n",
      "          14    1.00000   1.00000   1.00000        61\n",
      "          15    1.00000   1.00000   1.00000        14\n",
      "          16    1.00000   1.00000   1.00000        14\n",
      "          17    1.00000   1.00000   1.00000        14\n",
      "\n",
      "    accuracy                        0.99788       472\n",
      "   macro avg    0.99915   0.99913   0.99913       472\n",
      "weighted avg    0.99791   0.99788   0.99788       472\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000         5\n",
      "           1    0.88889   0.88889   0.88889        27\n",
      "           2    1.00000   1.00000   1.00000        13\n",
      "           3    0.85714   1.00000   0.92308         6\n",
      "           4    1.00000   0.83333   0.90909         6\n",
      "           5    0.93103   0.96429   0.94737        28\n",
      "           6    1.00000   1.00000   1.00000        13\n",
      "           7    1.00000   1.00000   1.00000         6\n",
      "           8    1.00000   1.00000   1.00000         4\n",
      "           9    1.00000   1.00000   1.00000         5\n",
      "          10    1.00000   1.00000   1.00000         6\n",
      "          11    1.00000   1.00000   1.00000         6\n",
      "          12    0.85185   0.85185   0.85185        27\n",
      "          13    1.00000   0.83333   0.90909         6\n",
      "          14    1.00000   1.00000   1.00000        27\n",
      "          15    1.00000   1.00000   1.00000         6\n",
      "          16    1.00000   1.00000   1.00000         6\n",
      "          17    1.00000   1.00000   1.00000         6\n",
      "\n",
      "    accuracy                        0.95074       203\n",
      "   macro avg    0.97383   0.96509   0.96830       203\n",
      "weighted avg    0.95178   0.95074   0.95061       203\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1166\n",
      "Average of depth: 1.506861063464837\n",
      "Number of nodes: 4924\n",
      "25 97 1\n",
      "52 200 2\n",
      "68 260 3\n",
      "92 352 4\n",
      "111 431 5\n",
      "130 502 6\n",
      "149 581 7\n",
      "167 659 8\n",
      "183 741 9\n",
      "202 828 10\n",
      "218 892 11\n",
      "236 960 12\n",
      "249 1009 13\n",
      "266 1076 14\n",
      "286 1154 15\n",
      "301 1211 16\n",
      "322 1298 17\n",
      "347 1401 18\n",
      "361 1455 19\n",
      "375 1515 20\n",
      "394 1592 21\n",
      "409 1653 22\n",
      "425 1721 23\n",
      "439 1783 24\n",
      "455 1855 25\n",
      "474 1938 26\n",
      "492 2018 27\n",
      "504 2070 28\n",
      "521 2143 29\n",
      "533 2191 30\n",
      "544 2234 31\n",
      "559 2297 32\n",
      "573 2351 33\n",
      "585 2413 34\n",
      "597 2463 35\n",
      "608 2506 36\n",
      "619 2545 37\n",
      "630 2592 38\n",
      "648 2672 39\n",
      "659 2713 40\n",
      "669 2767 41\n",
      "680 2808 42\n",
      "695 2879 43\n",
      "711 2937 44\n",
      "726 2998 45\n",
      "738 3054 46\n",
      "753 3121 47\n",
      "763 3177 48\n",
      "774 3222 49\n",
      "782 3256 50\n",
      "792 3300 51\n",
      "802 3342 52\n",
      "811 3377 53\n",
      "820 3418 54\n",
      "831 3463 55\n",
      "838 3494 56\n",
      "847 3533 57\n",
      "860 3602 58\n",
      "875 3667 59\n",
      "884 3716 60\n",
      "894 3768 61\n",
      "902 3800 62\n",
      "910 3844 63\n",
      "920 3892 64\n",
      "928 3924 65\n",
      "938 3978 66\n",
      "946 4016 67\n",
      "953 4045 68\n",
      "961 4091 69\n",
      "971 4135 70\n",
      "976 4146 71\n",
      "981 4163 72\n",
      "995 4227 73\n",
      "1003 4267 74\n",
      "1015 4317 75\n",
      "1028 4376 76\n",
      "1035 4401 77\n",
      "1046 4446 78\n",
      "1057 4491 79\n",
      "1065 4531 80\n",
      "1073 4563 81\n",
      "1083 4607 82\n",
      "1095 4657 83\n",
      "1104 4688 84\n",
      "1108 4708 85\n",
      "1118 4738 86\n",
      "1127 4779 87\n",
      "1138 4820 88\n",
      "1151 4879 89\n",
      "1160 4926 90\n",
      "1165 4949 91\n",
      "1177 5009 92\n",
      "1186 5052 93\n",
      "1197 5103 94\n",
      "1208 5156 95\n",
      "1216 5192 96\n",
      "1226 5240 97\n",
      "1234 5282 98\n",
      "1242 5318 99\n",
      "1251 5367 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.9851694915254238 10.469902315466909 \ttest: 0.9261083743842364 19.417256701494285\n",
      "retrain  2 :\n",
      "\ttrain: 0.989406779661017 7.105138619092442 \ttest: 0.9261083743842364 19.24825863990564\n",
      "retrain  3 :\n",
      "\ttrain: 0.9978813559322034 5.161223645310399 \ttest: 0.9359605911330049 19.342800761185476\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 3.887092988437106 \ttest: 0.9359605911330049 19.544573311651618\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 3.0125562736313163 \ttest: 0.9359605911330049 19.779875683009557\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        11\n",
      "           1    1.00000   1.00000   1.00000        64\n",
      "           2    1.00000   1.00000   1.00000        31\n",
      "           3    1.00000   1.00000   1.00000        14\n",
      "           4    1.00000   1.00000   1.00000        14\n",
      "           5    1.00000   1.00000   1.00000        64\n",
      "           6    1.00000   1.00000   1.00000        31\n",
      "           7    1.00000   1.00000   1.00000        14\n",
      "           8    1.00000   1.00000   1.00000        10\n",
      "           9    1.00000   1.00000   1.00000        10\n",
      "          10    1.00000   1.00000   1.00000        14\n",
      "          11    1.00000   1.00000   1.00000        14\n",
      "          12    1.00000   1.00000   1.00000        64\n",
      "          13    1.00000   1.00000   1.00000        14\n",
      "          14    1.00000   1.00000   1.00000        61\n",
      "          15    1.00000   1.00000   1.00000        14\n",
      "          16    1.00000   1.00000   1.00000        14\n",
      "          17    1.00000   1.00000   1.00000        14\n",
      "\n",
      "    accuracy                        1.00000       472\n",
      "   macro avg    1.00000   1.00000   1.00000       472\n",
      "weighted avg    1.00000   1.00000   1.00000       472\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000         5\n",
      "           1    0.86207   0.92593   0.89286        27\n",
      "           2    1.00000   1.00000   1.00000        13\n",
      "           3    0.75000   1.00000   0.85714         6\n",
      "           4    1.00000   0.66667   0.80000         6\n",
      "           5    0.96296   0.92857   0.94545        28\n",
      "           6    1.00000   1.00000   1.00000        13\n",
      "           7    1.00000   1.00000   1.00000         6\n",
      "           8    1.00000   1.00000   1.00000         4\n",
      "           9    1.00000   1.00000   1.00000         5\n",
      "          10    1.00000   1.00000   1.00000         6\n",
      "          11    1.00000   1.00000   1.00000         6\n",
      "          12    0.81481   0.81481   0.81481        27\n",
      "          13    0.80000   0.66667   0.72727         6\n",
      "          14    1.00000   1.00000   1.00000        27\n",
      "          15    1.00000   1.00000   1.00000         6\n",
      "          16    1.00000   1.00000   1.00000         6\n",
      "          17    1.00000   1.00000   1.00000         6\n",
      "\n",
      "    accuracy                        0.93596       203\n",
      "   macro avg    0.95499   0.94459   0.94653       203\n",
      "weighted avg    0.93861   0.93596   0.93540       203\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1251\n",
      "Average of depth: 1.5339728217426059\n",
      "Number of nodes: 5367\n",
      "25 89 1\n",
      "53 203 2\n",
      "77 291 3\n",
      "97 373 4\n",
      "120 462 5\n",
      "141 551 6\n",
      "159 629 7\n",
      "181 715 8\n",
      "200 804 9\n",
      "215 853 10\n",
      "232 920 11\n",
      "247 989 12\n",
      "265 1085 13\n",
      "281 1151 14\n",
      "299 1215 15\n",
      "314 1278 16\n",
      "325 1323 17\n",
      "342 1400 18\n",
      "356 1462 19\n",
      "372 1522 20\n",
      "385 1571 21\n",
      "404 1652 22\n",
      "414 1702 23\n",
      "424 1748 24\n",
      "437 1797 25\n",
      "455 1883 26\n",
      "467 1925 27\n",
      "479 1991 28\n",
      "491 2059 29\n",
      "504 2112 30\n",
      "519 2173 31\n",
      "535 2231 32\n",
      "547 2293 33\n",
      "559 2343 34\n",
      "572 2392 35\n",
      "582 2430 36\n",
      "593 2463 37\n",
      "599 2481 38\n",
      "614 2534 39\n",
      "626 2594 40\n",
      "641 2653 41\n",
      "651 2695 42\n",
      "661 2743 43\n",
      "674 2798 44\n",
      "679 2821 45\n",
      "691 2869 46\n",
      "705 2935 47\n",
      "714 2972 48\n",
      "729 3027 49\n",
      "742 3082 50\n",
      "749 3107 51\n",
      "755 3127 52\n",
      "766 3172 53\n",
      "779 3221 54\n",
      "790 3272 55\n",
      "796 3300 56\n",
      "810 3356 57\n",
      "821 3403 58\n",
      "832 3450 59\n",
      "841 3493 60\n",
      "856 3570 61\n",
      "866 3606 62\n",
      "882 3682 63\n",
      "889 3725 64\n",
      "899 3771 65\n",
      "912 3828 66\n",
      "921 3867 67\n",
      "935 3937 68\n",
      "942 3964 69\n",
      "952 4004 70\n",
      "960 4042 71\n",
      "972 4084 72\n",
      "981 4123 73\n",
      "990 4160 74\n",
      "1001 4205 75\n",
      "1006 4222 76\n",
      "1017 4277 77\n",
      "1028 4326 78\n",
      "1035 4349 79\n",
      "1045 4393 80\n",
      "1054 4442 81\n",
      "1065 4499 82\n",
      "1074 4542 83\n",
      "1083 4583 84\n",
      "1089 4609 85\n",
      "1097 4639 86\n",
      "1105 4685 87\n",
      "1114 4722 88\n",
      "1124 4770 89\n",
      "1132 4818 90\n",
      "1141 4857 91\n",
      "1150 4894 92\n",
      "1160 4936 93\n",
      "1163 4947 94\n",
      "1173 4991 95\n",
      "1181 5033 96\n",
      "1194 5096 97\n",
      "1203 5135 98\n",
      "1213 5187 99\n",
      "1219 5221 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.989406779661017 10.08078804444068 \ttest: 0.9556650246305419 13.14533312197086\n",
      "retrain  2 :\n",
      "\ttrain: 0.9957627118644068 6.418826511588343 \ttest: 0.9556650246305419 13.837388146133526\n",
      "retrain  3 :\n",
      "\ttrain: 0.9957627118644068 4.675582701990314 \ttest: 0.9556650246305419 14.265021700312081\n",
      "retrain  4 :\n",
      "\ttrain: 0.9978813559322034 3.6518443154079128 \ttest: 0.9556650246305419 14.578908990813522\n",
      "retrain  5 :\n",
      "\ttrain: 0.9978813559322034 2.9940470665145402 \ttest: 0.9556650246305419 14.824885592600566\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        11\n",
      "           1    0.98462   1.00000   0.99225        64\n",
      "           2    1.00000   1.00000   1.00000        31\n",
      "           3    1.00000   1.00000   1.00000        14\n",
      "           4    1.00000   1.00000   1.00000        14\n",
      "           5    1.00000   1.00000   1.00000        64\n",
      "           6    1.00000   1.00000   1.00000        31\n",
      "           7    1.00000   1.00000   1.00000        14\n",
      "           8    1.00000   1.00000   1.00000        10\n",
      "           9    1.00000   1.00000   1.00000        10\n",
      "          10    1.00000   1.00000   1.00000        14\n",
      "          11    1.00000   1.00000   1.00000        14\n",
      "          12    1.00000   0.98438   0.99213        64\n",
      "          13    1.00000   1.00000   1.00000        14\n",
      "          14    1.00000   1.00000   1.00000        61\n",
      "          15    1.00000   1.00000   1.00000        14\n",
      "          16    1.00000   1.00000   1.00000        14\n",
      "          17    1.00000   1.00000   1.00000        14\n",
      "\n",
      "    accuracy                        0.99788       472\n",
      "   macro avg    0.99915   0.99913   0.99913       472\n",
      "weighted avg    0.99791   0.99788   0.99788       472\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000         5\n",
      "           1    0.89655   0.96296   0.92857        27\n",
      "           2    1.00000   1.00000   1.00000        13\n",
      "           3    0.85714   1.00000   0.92308         6\n",
      "           4    1.00000   0.83333   0.90909         6\n",
      "           5    0.92857   0.92857   0.92857        28\n",
      "           6    1.00000   1.00000   1.00000        13\n",
      "           7    1.00000   1.00000   1.00000         6\n",
      "           8    1.00000   1.00000   1.00000         4\n",
      "           9    1.00000   1.00000   1.00000         5\n",
      "          10    1.00000   1.00000   1.00000         6\n",
      "          11    1.00000   1.00000   1.00000         6\n",
      "          12    0.92000   0.85185   0.88462        27\n",
      "          13    0.83333   0.83333   0.83333         6\n",
      "          14    1.00000   1.00000   1.00000        27\n",
      "          15    1.00000   1.00000   1.00000         6\n",
      "          16    1.00000   1.00000   1.00000         6\n",
      "          17    1.00000   1.00000   1.00000         6\n",
      "\n",
      "    accuracy                        0.95567       203\n",
      "   macro avg    0.96864   0.96723   0.96707       203\n",
      "weighted avg    0.95660   0.95567   0.95541       203\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1219\n",
      "Average of depth: 1.5340442986054144\n",
      "Number of nodes: 5221\n",
      "27 121 1\n",
      "48 192 2\n",
      "66 266 3\n",
      "85 337 4\n",
      "105 413 5\n",
      "120 470 6\n",
      "139 541 7\n",
      "160 626 8\n",
      "178 690 9\n",
      "194 748 10\n",
      "213 821 11\n",
      "221 849 12\n",
      "233 911 13\n",
      "248 972 14\n",
      "259 1015 15\n",
      "277 1091 16\n",
      "292 1152 17\n",
      "307 1211 18\n",
      "324 1284 19\n",
      "339 1343 20\n",
      "356 1422 21\n",
      "367 1469 22\n",
      "379 1527 23\n",
      "391 1571 24\n",
      "405 1633 25\n",
      "419 1691 26\n",
      "435 1749 27\n",
      "448 1796 28\n",
      "464 1862 29\n",
      "478 1928 30\n",
      "495 2005 31\n",
      "501 2019 32\n",
      "513 2073 33\n",
      "529 2141 34\n",
      "548 2252 35\n",
      "554 2286 36\n",
      "563 2327 37\n",
      "575 2375 38\n",
      "586 2414 39\n",
      "600 2474 40\n",
      "611 2521 41\n",
      "625 2599 42\n",
      "634 2630 43\n",
      "645 2667 44\n",
      "653 2705 45\n",
      "659 2731 46\n",
      "666 2760 47\n",
      "678 2814 48\n",
      "682 2830 49\n",
      "697 2883 50\n",
      "707 2929 51\n",
      "717 2971 52\n",
      "729 3013 53\n",
      "737 3037 54\n",
      "750 3104 55\n",
      "762 3152 56\n",
      "775 3225 57\n",
      "782 3262 58\n",
      "795 3323 59\n",
      "803 3369 60\n",
      "812 3414 61\n",
      "823 3451 62\n",
      "832 3492 63\n",
      "842 3544 64\n",
      "854 3600 65\n",
      "867 3667 66\n",
      "882 3742 67\n",
      "889 3777 68\n",
      "897 3815 69\n",
      "906 3858 70\n",
      "915 3893 71\n",
      "925 3959 72\n",
      "935 4003 73\n",
      "948 4068 74\n",
      "956 4108 75\n",
      "963 4145 76\n",
      "977 4207 77\n",
      "984 4244 78\n",
      "998 4302 79\n",
      "1008 4344 80\n",
      "1018 4380 81\n",
      "1027 4425 82\n",
      "1040 4474 83\n",
      "1045 4485 84\n",
      "1056 4530 85\n",
      "1069 4603 86\n",
      "1074 4624 87\n",
      "1081 4673 88\n",
      "1091 4727 89\n",
      "1096 4748 90\n",
      "1105 4779 91\n",
      "1111 4807 92\n",
      "1118 4846 93\n",
      "1124 4872 94\n",
      "1132 4906 95\n",
      "1140 4938 96\n",
      "1146 4956 97\n",
      "1154 4988 98\n",
      "1162 5030 99\n",
      "1173 5081 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.9957627118644068 7.738461632682451 \ttest: 0.9261083743842364 17.951674959061616\n",
      "retrain  2 :\n",
      "\ttrain: 0.9957627118644068 4.4197070886420775 \ttest: 0.9359605911330049 19.041700120193525\n",
      "retrain  3 :\n",
      "\ttrain: 0.9978813559322034 3.1778802450668153 \ttest: 0.9359605911330049 19.71135199430161\n",
      "retrain  4 :\n",
      "\ttrain: 0.9978813559322034 2.542118427880907 \ttest: 0.9359605911330049 20.15327615812659\n",
      "retrain  5 :\n",
      "\ttrain: 0.9978813559322034 2.1608160073386995 \ttest: 0.9359605911330049 20.469006851758877\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        11\n",
      "           1    0.98462   1.00000   0.99225        64\n",
      "           2    1.00000   1.00000   1.00000        31\n",
      "           3    1.00000   1.00000   1.00000        14\n",
      "           4    1.00000   1.00000   1.00000        14\n",
      "           5    1.00000   1.00000   1.00000        64\n",
      "           6    1.00000   1.00000   1.00000        31\n",
      "           7    1.00000   1.00000   1.00000        14\n",
      "           8    1.00000   1.00000   1.00000        10\n",
      "           9    1.00000   1.00000   1.00000        10\n",
      "          10    1.00000   1.00000   1.00000        14\n",
      "          11    1.00000   1.00000   1.00000        14\n",
      "          12    1.00000   0.98438   0.99213        64\n",
      "          13    1.00000   1.00000   1.00000        14\n",
      "          14    1.00000   1.00000   1.00000        61\n",
      "          15    1.00000   1.00000   1.00000        14\n",
      "          16    1.00000   1.00000   1.00000        14\n",
      "          17    1.00000   1.00000   1.00000        14\n",
      "\n",
      "    accuracy                        0.99788       472\n",
      "   macro avg    0.99915   0.99913   0.99913       472\n",
      "weighted avg    0.99791   0.99788   0.99788       472\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000         5\n",
      "           1    0.87500   0.77778   0.82353        27\n",
      "           2    1.00000   1.00000   1.00000        13\n",
      "           3    0.85714   1.00000   0.92308         6\n",
      "           4    1.00000   0.83333   0.90909         6\n",
      "           5    0.90323   1.00000   0.94915        28\n",
      "           6    1.00000   1.00000   1.00000        13\n",
      "           7    1.00000   1.00000   1.00000         6\n",
      "           8    1.00000   1.00000   1.00000         4\n",
      "           9    1.00000   1.00000   1.00000         5\n",
      "          10    1.00000   1.00000   1.00000         6\n",
      "          11    1.00000   1.00000   1.00000         6\n",
      "          12    0.78571   0.81481   0.80000        27\n",
      "          13    1.00000   0.83333   0.90909         6\n",
      "          14    1.00000   1.00000   1.00000        27\n",
      "          15    1.00000   1.00000   1.00000         6\n",
      "          16    1.00000   1.00000   1.00000         6\n",
      "          17    1.00000   1.00000   1.00000         6\n",
      "\n",
      "    accuracy                        0.93596       203\n",
      "   macro avg    0.96784   0.95885   0.96189       203\n",
      "weighted avg    0.93730   0.93596   0.93527       203\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1173\n",
      "Average of depth: 1.5396419437340154\n",
      "Number of nodes: 5081\n",
      "24 90 1\n",
      "45 165 2\n",
      "70 286 3\n",
      "92 372 4\n",
      "110 440 5\n",
      "132 534 6\n",
      "151 609 7\n",
      "171 691 8\n",
      "190 774 9\n",
      "205 839 10\n",
      "218 884 11\n",
      "230 930 12\n",
      "247 995 13\n",
      "265 1065 14\n",
      "280 1128 15\n",
      "292 1166 16\n",
      "309 1237 17\n",
      "325 1299 18\n",
      "340 1356 19\n",
      "351 1389 20\n",
      "365 1441 21\n",
      "380 1496 22\n",
      "394 1558 23\n",
      "406 1608 24\n",
      "420 1664 25\n",
      "434 1718 26\n",
      "449 1775 27\n",
      "462 1836 28\n",
      "470 1864 29\n",
      "479 1907 30\n",
      "491 1955 31\n",
      "501 2005 32\n",
      "517 2087 33\n",
      "527 2127 34\n",
      "541 2207 35\n",
      "555 2259 36\n",
      "565 2295 37\n",
      "575 2343 38\n",
      "583 2377 39\n",
      "597 2443 40\n",
      "608 2488 41\n",
      "625 2565 42\n",
      "641 2641 43\n",
      "650 2682 44\n",
      "663 2741 45\n",
      "678 2790 46\n",
      "689 2841 47\n",
      "699 2905 48\n",
      "712 2964 49\n",
      "720 2994 50\n",
      "731 3041 51\n",
      "739 3085 52\n",
      "755 3151 53\n",
      "763 3185 54\n",
      "778 3266 55\n",
      "792 3332 56\n",
      "799 3365 57\n",
      "812 3422 58\n",
      "823 3471 59\n",
      "834 3522 60\n",
      "845 3567 61\n",
      "854 3612 62\n",
      "860 3634 63\n",
      "870 3684 64\n",
      "880 3724 65\n",
      "882 3732 66\n",
      "893 3781 67\n",
      "902 3824 68\n",
      "910 3860 69\n",
      "919 3889 70\n",
      "933 3957 71\n",
      "942 4002 72\n",
      "949 4031 73\n",
      "960 4080 74\n",
      "972 4130 75\n",
      "986 4192 76\n",
      "999 4249 77\n",
      "1006 4284 78\n",
      "1017 4333 79\n",
      "1030 4398 80\n",
      "1034 4418 81\n",
      "1048 4482 82\n",
      "1060 4532 83\n",
      "1070 4574 84\n",
      "1078 4610 85\n",
      "1087 4647 86\n",
      "1092 4666 87\n",
      "1099 4703 88\n",
      "1109 4749 89\n",
      "1117 4783 90\n",
      "1123 4813 91\n",
      "1127 4829 92\n",
      "1136 4870 93\n",
      "1145 4909 94\n",
      "1158 4964 95\n",
      "1167 5003 96\n",
      "1171 5027 97\n",
      "1177 5043 98\n",
      "1186 5088 99\n",
      "1201 5161 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.9957627118644068 6.114005940556153 \ttest: 0.9113300492610837 22.21909488153559\n",
      "retrain  2 :\n",
      "\ttrain: 0.9978813559322034 3.402641843246003 \ttest: 0.9211822660098522 22.826803882064958\n",
      "retrain  3 :\n",
      "\ttrain: 0.9978813559322034 2.407891210259459 \ttest: 0.9211822660098522 23.382022191467094\n",
      "retrain  4 :\n",
      "\ttrain: 0.9978813559322034 1.925578499825166 \ttest: 0.9211822660098522 23.818674442057947\n",
      "retrain  5 :\n",
      "\ttrain: 0.9978813559322034 1.6546208717463247 \ttest: 0.9211822660098522 24.16779594750253\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        11\n",
      "           1    1.00000   0.98438   0.99213        64\n",
      "           2    1.00000   1.00000   1.00000        31\n",
      "           3    1.00000   1.00000   1.00000        14\n",
      "           4    1.00000   1.00000   1.00000        14\n",
      "           5    1.00000   1.00000   1.00000        64\n",
      "           6    1.00000   1.00000   1.00000        31\n",
      "           7    1.00000   1.00000   1.00000        14\n",
      "           8    1.00000   1.00000   1.00000        10\n",
      "           9    1.00000   1.00000   1.00000        10\n",
      "          10    1.00000   1.00000   1.00000        14\n",
      "          11    1.00000   1.00000   1.00000        14\n",
      "          12    0.98462   1.00000   0.99225        64\n",
      "          13    1.00000   1.00000   1.00000        14\n",
      "          14    1.00000   1.00000   1.00000        61\n",
      "          15    1.00000   1.00000   1.00000        14\n",
      "          16    1.00000   1.00000   1.00000        14\n",
      "          17    1.00000   1.00000   1.00000        14\n",
      "\n",
      "    accuracy                        0.99788       472\n",
      "   macro avg    0.99915   0.99913   0.99913       472\n",
      "weighted avg    0.99791   0.99788   0.99788       472\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000         5\n",
      "           1    0.84000   0.77778   0.80769        27\n",
      "           2    1.00000   1.00000   1.00000        13\n",
      "           3    0.66667   1.00000   0.80000         6\n",
      "           4    1.00000   0.50000   0.66667         6\n",
      "           5    0.93103   0.96429   0.94737        28\n",
      "           6    1.00000   1.00000   1.00000        13\n",
      "           7    1.00000   1.00000   1.00000         6\n",
      "           8    1.00000   1.00000   1.00000         4\n",
      "           9    1.00000   1.00000   1.00000         5\n",
      "          10    1.00000   1.00000   1.00000         6\n",
      "          11    1.00000   1.00000   1.00000         6\n",
      "          12    0.79310   0.85185   0.82143        27\n",
      "          13    0.80000   0.66667   0.72727         6\n",
      "          14    1.00000   1.00000   1.00000        27\n",
      "          15    1.00000   1.00000   1.00000         6\n",
      "          16    1.00000   1.00000   1.00000         6\n",
      "          17    1.00000   1.00000   1.00000         6\n",
      "\n",
      "    accuracy                        0.92118       203\n",
      "   macro avg    0.94616   0.93114   0.93169       203\n",
      "weighted avg    0.92592   0.92118   0.91959       203\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1201\n",
      "Average of depth: 1.5395503746877601\n",
      "Number of nodes: 5161\n",
      "25 87 1\n",
      "50 188 2\n",
      "77 287 3\n",
      "93 339 4\n",
      "113 419 5\n",
      "134 506 6\n",
      "153 579 7\n",
      "167 643 8\n",
      "185 711 9\n",
      "203 787 10\n",
      "220 848 11\n",
      "230 884 12\n",
      "242 940 13\n",
      "253 983 14\n",
      "275 1077 15\n",
      "294 1164 16\n",
      "311 1221 17\n",
      "325 1289 18\n",
      "337 1347 19\n",
      "350 1406 20\n",
      "364 1462 21\n",
      "382 1536 22\n",
      "393 1569 23\n",
      "408 1630 24\n",
      "422 1698 25\n",
      "430 1726 26\n",
      "448 1800 27\n",
      "465 1885 28\n",
      "479 1959 29\n",
      "492 2010 30\n",
      "505 2065 31\n",
      "515 2121 32\n",
      "526 2168 33\n",
      "546 2266 34\n",
      "562 2332 35\n",
      "574 2386 36\n",
      "585 2437 37\n",
      "599 2487 38\n",
      "612 2544 39\n",
      "627 2595 40\n",
      "645 2669 41\n",
      "659 2721 42\n",
      "669 2767 43\n",
      "675 2787 44\n",
      "684 2822 45\n",
      "694 2854 46\n",
      "709 2921 47\n",
      "719 2971 48\n",
      "729 3017 49\n",
      "739 3063 50\n",
      "751 3137 51\n",
      "758 3168 52\n",
      "770 3226 53\n",
      "780 3270 54\n",
      "794 3342 55\n",
      "806 3388 56\n",
      "822 3454 57\n",
      "832 3506 58\n",
      "843 3551 59\n",
      "859 3627 60\n",
      "869 3669 61\n",
      "879 3717 62\n",
      "888 3764 63\n",
      "898 3816 64\n",
      "905 3843 65\n",
      "917 3895 66\n",
      "932 3958 67\n",
      "941 3999 68\n",
      "952 4044 69\n",
      "962 4088 70\n",
      "972 4142 71\n",
      "984 4202 72\n",
      "996 4248 73\n",
      "1006 4298 74\n",
      "1015 4337 75\n",
      "1022 4378 76\n",
      "1029 4411 77\n",
      "1039 4465 78\n",
      "1049 4501 79\n",
      "1053 4513 80\n",
      "1057 4527 81\n",
      "1065 4567 82\n",
      "1076 4622 83\n",
      "1089 4669 84\n",
      "1101 4725 85\n",
      "1108 4754 86\n",
      "1118 4790 87\n",
      "1127 4829 88\n",
      "1133 4855 89\n",
      "1142 4906 90\n",
      "1153 4959 91\n",
      "1164 5018 92\n",
      "1176 5076 93\n",
      "1187 5135 94\n",
      "1201 5197 95\n",
      "1209 5227 96\n",
      "1222 5286 97\n",
      "1231 5327 98\n",
      "1238 5362 99\n",
      "1245 5391 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.9957627118644068 6.26014478410881 \ttest: 0.916256157635468 26.28438429661901\n",
      "retrain  2 :\n",
      "\ttrain: 0.9957627118644068 3.7009260436995404 \ttest: 0.916256157635468 28.08329592474281\n",
      "retrain  3 :\n",
      "\ttrain: 0.9978813559322034 2.6561598821754067 \ttest: 0.916256157635468 29.106740341560315\n",
      "retrain  4 :\n",
      "\ttrain: 0.9978813559322034 2.110509291329725 \ttest: 0.9113300492610837 29.76791816435534\n",
      "retrain  5 :\n",
      "\ttrain: 0.9978813559322034 1.7905900398050305 \ttest: 0.9113300492610837 30.22657804651745\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        11\n",
      "           1    1.00000   0.98438   0.99213        64\n",
      "           2    1.00000   1.00000   1.00000        31\n",
      "           3    1.00000   1.00000   1.00000        14\n",
      "           4    1.00000   1.00000   1.00000        14\n",
      "           5    1.00000   1.00000   1.00000        64\n",
      "           6    1.00000   1.00000   1.00000        31\n",
      "           7    1.00000   1.00000   1.00000        14\n",
      "           8    1.00000   1.00000   1.00000        10\n",
      "           9    1.00000   1.00000   1.00000        10\n",
      "          10    1.00000   1.00000   1.00000        14\n",
      "          11    1.00000   1.00000   1.00000        14\n",
      "          12    0.98462   1.00000   0.99225        64\n",
      "          13    1.00000   1.00000   1.00000        14\n",
      "          14    1.00000   1.00000   1.00000        61\n",
      "          15    1.00000   1.00000   1.00000        14\n",
      "          16    1.00000   1.00000   1.00000        14\n",
      "          17    1.00000   1.00000   1.00000        14\n",
      "\n",
      "    accuracy                        0.99788       472\n",
      "   macro avg    0.99915   0.99913   0.99913       472\n",
      "weighted avg    0.99791   0.99788   0.99788       472\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000         5\n",
      "           1    0.66667   0.88889   0.76190        27\n",
      "           2    1.00000   1.00000   1.00000        13\n",
      "           3    0.85714   1.00000   0.92308         6\n",
      "           4    1.00000   0.83333   0.90909         6\n",
      "           5    0.96429   0.96429   0.96429        28\n",
      "           6    1.00000   1.00000   1.00000        13\n",
      "           7    1.00000   1.00000   1.00000         6\n",
      "           8    1.00000   1.00000   1.00000         4\n",
      "           9    1.00000   1.00000   1.00000         5\n",
      "          10    1.00000   1.00000   1.00000         6\n",
      "          11    1.00000   1.00000   1.00000         6\n",
      "          12    0.83333   0.55556   0.66667        27\n",
      "          13    0.83333   0.83333   0.83333         6\n",
      "          14    1.00000   1.00000   1.00000        27\n",
      "          15    1.00000   1.00000   1.00000         6\n",
      "          16    1.00000   1.00000   1.00000         6\n",
      "          17    1.00000   1.00000   1.00000         6\n",
      "\n",
      "    accuracy                        0.91133       203\n",
      "   macro avg    0.95304   0.94863   0.94769       203\n",
      "weighted avg    0.91942   0.91133   0.90918       203\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1245\n",
      "Average of depth: 1.557429718875502\n",
      "Number of nodes: 5391\n",
      "27 103 1\n",
      "50 184 2\n",
      "75 295 3\n",
      "96 370 4\n",
      "115 441 5\n",
      "137 541 6\n",
      "149 605 7\n",
      "169 673 8\n",
      "182 732 9\n",
      "197 795 10\n",
      "214 874 11\n",
      "229 933 12\n",
      "245 999 13\n",
      "264 1068 14\n",
      "275 1107 15\n",
      "293 1193 16\n",
      "302 1226 17\n",
      "316 1286 18\n",
      "333 1351 19\n",
      "353 1437 20\n",
      "362 1474 21\n",
      "378 1546 22\n",
      "388 1588 23\n",
      "400 1640 24\n",
      "411 1683 25\n",
      "425 1741 26\n",
      "443 1811 27\n",
      "457 1869 28\n",
      "470 1932 29\n",
      "487 1999 30\n",
      "504 2070 31\n",
      "523 2155 32\n",
      "540 2228 33\n",
      "552 2288 34\n",
      "565 2345 35\n",
      "580 2408 36\n",
      "592 2460 37\n",
      "605 2529 38\n",
      "613 2559 39\n",
      "626 2604 40\n",
      "641 2685 41\n",
      "651 2725 42\n",
      "662 2770 43\n",
      "677 2843 44\n",
      "684 2870 45\n",
      "693 2911 46\n",
      "707 2967 47\n",
      "718 3016 48\n",
      "734 3086 49\n",
      "743 3133 50\n",
      "755 3183 51\n",
      "763 3217 52\n",
      "772 3262 53\n",
      "777 3281 54\n",
      "787 3331 55\n",
      "802 3402 56\n",
      "813 3453 57\n",
      "822 3492 58\n",
      "829 3529 59\n",
      "834 3550 60\n",
      "844 3586 61\n",
      "858 3650 62\n",
      "870 3704 63\n",
      "878 3732 64\n",
      "897 3825 65\n",
      "906 3860 66\n",
      "916 3902 67\n",
      "925 3949 68\n",
      "936 3998 69\n",
      "943 4025 70\n",
      "957 4089 71\n",
      "963 4115 72\n",
      "969 4145 73\n",
      "980 4196 74\n",
      "993 4255 75\n",
      "1002 4290 76\n",
      "1009 4315 77\n",
      "1018 4362 78\n",
      "1024 4386 79\n",
      "1030 4416 80\n",
      "1040 4456 81\n",
      "1047 4485 82\n",
      "1060 4548 83\n",
      "1072 4600 84\n",
      "1078 4628 85\n",
      "1092 4688 86\n",
      "1102 4742 87\n",
      "1111 4783 88\n",
      "1119 4815 89\n",
      "1123 4837 90\n",
      "1131 4875 91\n",
      "1138 4900 92\n",
      "1147 4941 93\n",
      "1152 4958 94\n",
      "1163 5003 95\n",
      "1172 5042 96\n",
      "1179 5083 97\n",
      "1185 5125 98\n",
      "1194 5178 99\n",
      "1203 5223 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.9851694915254238 8.1971756723917 \ttest: 0.9359605911330049 20.089483377528804\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 5.225989674627354 \ttest: 0.9359605911330049 21.260798869546818\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 3.7979729880781483 \ttest: 0.9408866995073891 21.985368028743864\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 2.9147315071184323 \ttest: 0.9408866995073891 22.501473063450163\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 2.3113673033629865 \ttest: 0.9408866995073891 22.9061711508177\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        11\n",
      "           1    1.00000   1.00000   1.00000        64\n",
      "           2    1.00000   1.00000   1.00000        31\n",
      "           3    1.00000   1.00000   1.00000        14\n",
      "           4    1.00000   1.00000   1.00000        14\n",
      "           5    1.00000   1.00000   1.00000        64\n",
      "           6    1.00000   1.00000   1.00000        31\n",
      "           7    1.00000   1.00000   1.00000        14\n",
      "           8    1.00000   1.00000   1.00000        10\n",
      "           9    1.00000   1.00000   1.00000        10\n",
      "          10    1.00000   1.00000   1.00000        14\n",
      "          11    1.00000   1.00000   1.00000        14\n",
      "          12    1.00000   1.00000   1.00000        64\n",
      "          13    1.00000   1.00000   1.00000        14\n",
      "          14    1.00000   1.00000   1.00000        61\n",
      "          15    1.00000   1.00000   1.00000        14\n",
      "          16    1.00000   1.00000   1.00000        14\n",
      "          17    1.00000   1.00000   1.00000        14\n",
      "\n",
      "    accuracy                        1.00000       472\n",
      "   macro avg    1.00000   1.00000   1.00000       472\n",
      "weighted avg    1.00000   1.00000   1.00000       472\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000         5\n",
      "           1    0.87500   0.77778   0.82353        27\n",
      "           2    1.00000   1.00000   1.00000        13\n",
      "           3    1.00000   1.00000   1.00000         6\n",
      "           4    1.00000   1.00000   1.00000         6\n",
      "           5    0.93103   0.96429   0.94737        28\n",
      "           6    1.00000   1.00000   1.00000        13\n",
      "           7    1.00000   1.00000   1.00000         6\n",
      "           8    1.00000   1.00000   1.00000         4\n",
      "           9    1.00000   1.00000   1.00000         5\n",
      "          10    1.00000   1.00000   1.00000         6\n",
      "          11    1.00000   1.00000   1.00000         6\n",
      "          12    0.76667   0.85185   0.80702        27\n",
      "          13    1.00000   0.83333   0.90909         6\n",
      "          14    1.00000   1.00000   1.00000        27\n",
      "          15    1.00000   1.00000   1.00000         6\n",
      "          16    1.00000   1.00000   1.00000         6\n",
      "          17    1.00000   1.00000   1.00000         6\n",
      "\n",
      "    accuracy                        0.94089       203\n",
      "   macro avg    0.97626   0.96818   0.97150       203\n",
      "weighted avg    0.94283   0.94089   0.94091       203\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1203\n",
      "Average of depth: 1.5544472152950957\n",
      "Number of nodes: 5223\n",
      "21 87 1\n",
      "45 191 2\n",
      "68 284 3\n",
      "90 368 4\n",
      "109 433 5\n",
      "128 500 6\n",
      "150 594 7\n",
      "170 680 8\n",
      "188 752 9\n",
      "201 791 10\n",
      "218 868 11\n",
      "237 941 12\n",
      "254 1020 13\n",
      "271 1081 14\n",
      "283 1121 15\n",
      "297 1185 16\n",
      "311 1245 17\n",
      "327 1317 18\n",
      "341 1381 19\n",
      "355 1451 20\n",
      "369 1511 21\n",
      "382 1566 22\n",
      "398 1634 23\n",
      "413 1697 24\n",
      "425 1751 25\n",
      "437 1791 26\n",
      "443 1805 27\n",
      "457 1859 28\n",
      "464 1892 29\n",
      "479 1957 30\n",
      "492 2008 31\n",
      "508 2072 32\n",
      "516 2108 33\n",
      "527 2153 34\n",
      "538 2194 35\n",
      "549 2237 36\n",
      "557 2273 37\n",
      "565 2311 38\n",
      "572 2342 39\n",
      "582 2382 40\n",
      "589 2407 41\n",
      "601 2457 42\n",
      "613 2503 43\n",
      "622 2542 44\n",
      "630 2578 45\n",
      "643 2633 46\n",
      "654 2676 47\n",
      "665 2729 48\n",
      "676 2764 49\n",
      "688 2816 50\n",
      "701 2869 51\n",
      "714 2930 52\n",
      "725 2989 53\n",
      "730 3012 54\n",
      "737 3043 55\n",
      "748 3096 56\n",
      "752 3114 57\n",
      "764 3162 58\n",
      "774 3210 59\n",
      "787 3265 60\n",
      "794 3294 61\n",
      "804 3340 62\n",
      "814 3386 63\n",
      "827 3449 64\n",
      "836 3476 65\n",
      "850 3548 66\n",
      "864 3608 67\n",
      "876 3654 68\n",
      "887 3709 69\n",
      "896 3754 70\n",
      "903 3789 71\n",
      "912 3830 72\n",
      "916 3844 73\n",
      "927 3893 74\n",
      "929 3901 75\n",
      "939 3945 76\n",
      "947 3983 77\n",
      "954 4020 78\n",
      "961 4061 79\n",
      "968 4092 80\n",
      "972 4112 81\n",
      "979 4147 82\n",
      "988 4190 83\n",
      "996 4220 84\n",
      "1003 4257 85\n",
      "1010 4286 86\n",
      "1021 4337 87\n",
      "1032 4384 88\n",
      "1042 4436 89\n",
      "1051 4483 90\n",
      "1060 4532 91\n",
      "1066 4558 92\n",
      "1073 4587 93\n",
      "1084 4644 94\n",
      "1090 4674 95\n",
      "1105 4741 96\n",
      "1109 4759 97\n",
      "1114 4782 98\n",
      "1115 4781 99\n",
      "1121 4805 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.989406779661017 8.208114871067336 \ttest: 0.9408866995073891 16.985641361697247\n",
      "retrain  2 :\n",
      "\ttrain: 0.9957627118644068 5.032460550451228 \ttest: 0.9408866995073891 16.934308868367367\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 3.517190816566371 \ttest: 0.9408866995073891 16.932638210128957\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 2.603015720455382 \ttest: 0.9408866995073891 16.949905404111497\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.9979663586225758 \ttest: 0.9408866995073891 16.97479130285208\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        11\n",
      "           1    1.00000   1.00000   1.00000        64\n",
      "           2    1.00000   1.00000   1.00000        31\n",
      "           3    1.00000   1.00000   1.00000        14\n",
      "           4    1.00000   1.00000   1.00000        14\n",
      "           5    1.00000   1.00000   1.00000        64\n",
      "           6    1.00000   1.00000   1.00000        31\n",
      "           7    1.00000   1.00000   1.00000        14\n",
      "           8    1.00000   1.00000   1.00000        10\n",
      "           9    1.00000   1.00000   1.00000        10\n",
      "          10    1.00000   1.00000   1.00000        14\n",
      "          11    1.00000   1.00000   1.00000        14\n",
      "          12    1.00000   1.00000   1.00000        64\n",
      "          13    1.00000   1.00000   1.00000        14\n",
      "          14    1.00000   1.00000   1.00000        61\n",
      "          15    1.00000   1.00000   1.00000        14\n",
      "          16    1.00000   1.00000   1.00000        14\n",
      "          17    1.00000   1.00000   1.00000        14\n",
      "\n",
      "    accuracy                        1.00000       472\n",
      "   macro avg    1.00000   1.00000   1.00000       472\n",
      "weighted avg    1.00000   1.00000   1.00000       472\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000         5\n",
      "           1    0.86957   0.74074   0.80000        27\n",
      "           2    1.00000   1.00000   1.00000        13\n",
      "           3    0.85714   1.00000   0.92308         6\n",
      "           4    1.00000   0.83333   0.90909         6\n",
      "           5    1.00000   0.96429   0.98182        28\n",
      "           6    1.00000   1.00000   1.00000        13\n",
      "           7    1.00000   1.00000   1.00000         6\n",
      "           8    1.00000   1.00000   1.00000         4\n",
      "           9    1.00000   1.00000   1.00000         5\n",
      "          10    1.00000   1.00000   1.00000         6\n",
      "          11    1.00000   1.00000   1.00000         6\n",
      "          12    0.77419   0.88889   0.82759        27\n",
      "          13    0.85714   1.00000   0.92308         6\n",
      "          14    1.00000   1.00000   1.00000        27\n",
      "          15    1.00000   1.00000   1.00000         6\n",
      "          16    1.00000   1.00000   1.00000         6\n",
      "          17    1.00000   1.00000   1.00000         6\n",
      "\n",
      "    accuracy                        0.94089       203\n",
      "   macro avg    0.96434   0.96818   0.96470       203\n",
      "weighted avg    0.94417   0.94089   0.94073       203\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1121\n",
      "Average of depth: 1.536128456735058\n",
      "Number of nodes: 4805\n",
      "27 103 1\n",
      "49 199 2\n",
      "73 297 3\n",
      "87 357 4\n",
      "101 403 5\n",
      "114 454 6\n",
      "133 541 7\n",
      "155 625 8\n",
      "171 689 9\n",
      "189 769 10\n",
      "207 831 11\n",
      "222 898 12\n",
      "240 982 13\n",
      "259 1077 14\n",
      "278 1162 15\n",
      "299 1259 16\n",
      "310 1300 17\n",
      "323 1351 18\n",
      "340 1418 19\n",
      "355 1477 20\n",
      "373 1561 21\n",
      "389 1633 22\n",
      "403 1697 23\n",
      "421 1781 24\n",
      "438 1854 25\n",
      "457 1943 26\n",
      "464 1964 27\n",
      "476 2012 28\n",
      "488 2058 29\n",
      "501 2117 30\n",
      "510 2160 31\n",
      "524 2222 32\n",
      "541 2301 33\n",
      "555 2357 34\n",
      "572 2442 35\n",
      "577 2465 36\n",
      "590 2524 37\n",
      "600 2556 38\n",
      "609 2601 39\n",
      "622 2656 40\n",
      "633 2703 41\n",
      "639 2725 42\n",
      "648 2760 43\n",
      "661 2815 44\n",
      "674 2874 45\n",
      "686 2922 46\n",
      "698 2982 47\n",
      "707 3017 48\n",
      "726 3102 49\n",
      "735 3151 50\n",
      "746 3206 51\n",
      "758 3258 52\n",
      "770 3306 53\n",
      "779 3343 54\n",
      "789 3379 55\n",
      "805 3447 56\n",
      "814 3492 57\n",
      "823 3539 58\n",
      "832 3576 59\n",
      "840 3616 60\n",
      "851 3669 61\n",
      "865 3751 62\n",
      "875 3793 63\n",
      "888 3856 64\n",
      "901 3909 65\n",
      "913 3963 66\n",
      "923 4013 67\n",
      "931 4053 68\n",
      "935 4073 69\n",
      "945 4113 70\n",
      "955 4155 71\n",
      "961 4181 72\n",
      "970 4226 73\n",
      "979 4265 74\n",
      "989 4313 75\n",
      "1001 4369 76\n",
      "1011 4403 77\n",
      "1022 4454 78\n",
      "1030 4478 79\n",
      "1040 4524 80\n",
      "1052 4570 81\n",
      "1059 4611 82\n",
      "1068 4648 83\n",
      "1078 4686 84\n",
      "1090 4738 85\n",
      "1101 4789 86\n",
      "1114 4842 87\n",
      "1120 4866 88\n",
      "1133 4931 89\n",
      "1149 4987 90\n",
      "1156 5018 91\n",
      "1169 5069 92\n",
      "1181 5123 93\n",
      "1190 5164 94\n",
      "1199 5207 95\n",
      "1209 5255 96\n",
      "1216 5284 97\n",
      "1226 5336 98\n",
      "1236 5382 99\n",
      "1242 5410 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.9872881355932204 9.883108905142866 \ttest: 0.9408866995073891 19.058328952010108\n",
      "retrain  2 :\n",
      "\ttrain: 0.9936440677966102 6.430288499252278 \ttest: 0.9310344827586207 19.048710934070687\n",
      "retrain  3 :\n",
      "\ttrain: 0.9978813559322034 4.787829533549662 \ttest: 0.9359605911330049 19.105920447325158\n",
      "retrain  4 :\n",
      "\ttrain: 0.9978813559322034 3.7638387538122773 \ttest: 0.9408866995073891 19.195558231561645\n",
      "retrain  5 :\n",
      "\ttrain: 0.9978813559322034 3.0537473899608765 \ttest: 0.9408866995073891 19.31611087284844\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        11\n",
      "           1    0.98462   1.00000   0.99225        64\n",
      "           2    1.00000   1.00000   1.00000        31\n",
      "           3    1.00000   1.00000   1.00000        14\n",
      "           4    1.00000   1.00000   1.00000        14\n",
      "           5    1.00000   1.00000   1.00000        64\n",
      "           6    1.00000   1.00000   1.00000        31\n",
      "           7    1.00000   1.00000   1.00000        14\n",
      "           8    1.00000   1.00000   1.00000        10\n",
      "           9    1.00000   1.00000   1.00000        10\n",
      "          10    1.00000   1.00000   1.00000        14\n",
      "          11    1.00000   1.00000   1.00000        14\n",
      "          12    1.00000   0.98438   0.99213        64\n",
      "          13    1.00000   1.00000   1.00000        14\n",
      "          14    1.00000   1.00000   1.00000        61\n",
      "          15    1.00000   1.00000   1.00000        14\n",
      "          16    1.00000   1.00000   1.00000        14\n",
      "          17    1.00000   1.00000   1.00000        14\n",
      "\n",
      "    accuracy                        0.99788       472\n",
      "   macro avg    0.99915   0.99913   0.99913       472\n",
      "weighted avg    0.99791   0.99788   0.99788       472\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000         5\n",
      "           1    0.88889   0.88889   0.88889        27\n",
      "           2    1.00000   1.00000   1.00000        13\n",
      "           3    0.75000   1.00000   0.85714         6\n",
      "           4    1.00000   0.66667   0.80000         6\n",
      "           5    0.90000   0.96429   0.93103        28\n",
      "           6    1.00000   1.00000   1.00000        13\n",
      "           7    1.00000   1.00000   1.00000         6\n",
      "           8    1.00000   1.00000   1.00000         4\n",
      "           9    1.00000   1.00000   1.00000         5\n",
      "          10    1.00000   1.00000   1.00000         6\n",
      "          11    1.00000   1.00000   1.00000         6\n",
      "          12    0.88000   0.81481   0.84615        27\n",
      "          13    0.83333   0.83333   0.83333         6\n",
      "          14    1.00000   1.00000   1.00000        27\n",
      "          15    1.00000   1.00000   1.00000         6\n",
      "          16    1.00000   1.00000   1.00000         6\n",
      "          17    1.00000   1.00000   1.00000         6\n",
      "\n",
      "    accuracy                        0.94089       203\n",
      "   macro avg    0.95846   0.95378   0.95314       203\n",
      "weighted avg    0.94315   0.94089   0.94019       203\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1242\n",
      "Average of depth: 1.57085346215781\n",
      "Number of nodes: 5410\n",
      "26 90 1\n",
      "50 176 2\n",
      "74 274 3\n",
      "92 348 4\n",
      "115 435 5\n",
      "134 508 6\n",
      "157 597 7\n",
      "176 664 8\n",
      "193 741 9\n",
      "215 831 10\n",
      "234 918 11\n",
      "246 958 12\n",
      "259 1007 13\n",
      "279 1091 14\n",
      "293 1149 15\n",
      "310 1216 16\n",
      "322 1266 17\n",
      "337 1327 18\n",
      "351 1387 19\n",
      "364 1434 20\n",
      "380 1508 21\n",
      "390 1546 22\n",
      "403 1607 23\n",
      "418 1662 24\n",
      "438 1750 25\n",
      "451 1795 26\n",
      "466 1858 27\n",
      "475 1895 28\n",
      "488 1954 29\n",
      "500 1996 30\n",
      "513 2049 31\n",
      "528 2106 32\n",
      "541 2153 33\n",
      "556 2222 34\n",
      "570 2280 35\n",
      "581 2323 36\n",
      "591 2363 37\n",
      "606 2428 38\n",
      "620 2482 39\n",
      "630 2530 40\n",
      "644 2578 41\n",
      "654 2624 42\n",
      "667 2675 43\n",
      "677 2717 44\n",
      "685 2745 45\n",
      "695 2785 46\n",
      "704 2826 47\n",
      "722 2900 48\n",
      "734 2964 49\n",
      "750 3028 50\n",
      "758 3058 51\n",
      "764 3086 52\n",
      "782 3168 53\n",
      "790 3204 54\n",
      "799 3243 55\n",
      "809 3285 56\n",
      "819 3335 57\n",
      "827 3375 58\n",
      "836 3410 59\n",
      "845 3453 60\n",
      "858 3498 61\n",
      "870 3542 62\n",
      "883 3605 63\n",
      "889 3631 64\n",
      "897 3669 65\n",
      "906 3712 66\n",
      "912 3738 67\n",
      "919 3767 68\n",
      "930 3820 69\n",
      "937 3841 70\n",
      "947 3883 71\n",
      "953 3911 72\n",
      "963 3955 73\n",
      "972 3998 74\n",
      "976 4014 75\n",
      "985 4057 76\n",
      "991 4085 77\n",
      "999 4117 78\n",
      "1013 4181 79\n",
      "1020 4210 80\n",
      "1029 4253 81\n",
      "1044 4314 82\n",
      "1056 4376 83\n",
      "1065 4423 84\n",
      "1075 4461 85\n",
      "1085 4509 86\n",
      "1094 4542 87\n",
      "1098 4556 88\n",
      "1108 4592 89\n",
      "1115 4625 90\n",
      "1121 4643 91\n",
      "1132 4690 92\n",
      "1140 4734 93\n",
      "1150 4770 94\n",
      "1155 4791 95\n",
      "1162 4824 96\n",
      "1173 4867 97\n",
      "1180 4896 98\n",
      "1190 4944 99\n",
      "1199 4987 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.989406779661017 7.696776474079941 \ttest: 0.9655172413793104 13.678653134029283\n",
      "retrain  2 :\n",
      "\ttrain: 0.9978813559322034 4.644273318998839 \ttest: 0.9605911330049262 13.934689730776483\n",
      "retrain  3 :\n",
      "\ttrain: 0.9978813559322034 3.2989339934920423 \ttest: 0.9605911330049262 14.359071915655019\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 2.5067438442924805 \ttest: 0.9605911330049262 14.72583920222391\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.9815413445623462 \ttest: 0.9556650246305419 15.031430427727221\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        11\n",
      "           1    1.00000   1.00000   1.00000        64\n",
      "           2    1.00000   1.00000   1.00000        31\n",
      "           3    1.00000   1.00000   1.00000        14\n",
      "           4    1.00000   1.00000   1.00000        14\n",
      "           5    1.00000   1.00000   1.00000        64\n",
      "           6    1.00000   1.00000   1.00000        31\n",
      "           7    1.00000   1.00000   1.00000        14\n",
      "           8    1.00000   1.00000   1.00000        10\n",
      "           9    1.00000   1.00000   1.00000        10\n",
      "          10    1.00000   1.00000   1.00000        14\n",
      "          11    1.00000   1.00000   1.00000        14\n",
      "          12    1.00000   1.00000   1.00000        64\n",
      "          13    1.00000   1.00000   1.00000        14\n",
      "          14    1.00000   1.00000   1.00000        61\n",
      "          15    1.00000   1.00000   1.00000        14\n",
      "          16    1.00000   1.00000   1.00000        14\n",
      "          17    1.00000   1.00000   1.00000        14\n",
      "\n",
      "    accuracy                        1.00000       472\n",
      "   macro avg    1.00000   1.00000   1.00000       472\n",
      "weighted avg    1.00000   1.00000   1.00000       472\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000         5\n",
      "           1    0.85185   0.85185   0.85185        27\n",
      "           2    1.00000   1.00000   1.00000        13\n",
      "           3    0.85714   1.00000   0.92308         6\n",
      "           4    1.00000   0.83333   0.90909         6\n",
      "           5    1.00000   1.00000   1.00000        28\n",
      "           6    1.00000   1.00000   1.00000        13\n",
      "           7    1.00000   1.00000   1.00000         6\n",
      "           8    1.00000   1.00000   1.00000         4\n",
      "           9    1.00000   1.00000   1.00000         5\n",
      "          10    1.00000   1.00000   1.00000         6\n",
      "          11    1.00000   1.00000   1.00000         6\n",
      "          12    0.85185   0.85185   0.85185        27\n",
      "          13    1.00000   1.00000   1.00000         6\n",
      "          14    1.00000   1.00000   1.00000        27\n",
      "          15    1.00000   1.00000   1.00000         6\n",
      "          16    1.00000   1.00000   1.00000         6\n",
      "          17    1.00000   1.00000   1.00000         6\n",
      "\n",
      "    accuracy                        0.95567       203\n",
      "   macro avg    0.97560   0.97428   0.97422       203\n",
      "weighted avg    0.95637   0.95567   0.95563       203\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1199\n",
      "Average of depth: 1.4979149291075897\n",
      "Number of nodes: 4987\n",
      "24 98 1\n",
      "47 181 2\n",
      "73 291 3\n",
      "93 373 4\n",
      "112 454 5\n",
      "131 527 6\n",
      "151 605 7\n",
      "169 671 8\n",
      "188 738 9\n",
      "209 833 10\n",
      "226 908 11\n",
      "242 962 12\n",
      "255 1013 13\n",
      "270 1062 14\n",
      "290 1130 15\n",
      "306 1200 16\n",
      "321 1253 17\n",
      "335 1297 18\n",
      "347 1341 19\n",
      "362 1410 20\n",
      "380 1494 21\n",
      "394 1550 22\n",
      "408 1618 23\n",
      "428 1720 24\n",
      "445 1797 25\n",
      "457 1851 26\n",
      "466 1884 27\n",
      "485 1973 28\n",
      "501 2041 29\n",
      "510 2080 30\n",
      "527 2143 31\n",
      "545 2221 32\n",
      "555 2261 33\n",
      "569 2315 34\n",
      "581 2365 35\n",
      "597 2423 36\n",
      "610 2482 37\n",
      "626 2558 38\n",
      "631 2575 39\n",
      "640 2606 40\n",
      "650 2650 41\n",
      "663 2707 42\n",
      "677 2757 43\n",
      "685 2787 44\n",
      "703 2869 45\n",
      "722 2962 46\n",
      "734 3006 47\n",
      "745 3063 48\n",
      "757 3125 49\n",
      "768 3176 50\n",
      "782 3234 51\n",
      "789 3251 52\n",
      "797 3287 53\n",
      "807 3327 54\n",
      "820 3390 55\n",
      "836 3474 56\n",
      "849 3531 57\n",
      "863 3581 58\n",
      "874 3632 59\n",
      "883 3669 60\n",
      "894 3724 61\n",
      "901 3761 62\n",
      "910 3804 63\n",
      "917 3837 64\n",
      "926 3876 65\n",
      "936 3936 66\n",
      "945 3981 67\n",
      "957 4021 68\n",
      "966 4066 69\n",
      "981 4137 70\n",
      "992 4186 71\n",
      "1000 4222 72\n",
      "1008 4256 73\n",
      "1020 4306 74\n",
      "1031 4357 75\n",
      "1042 4406 76\n",
      "1053 4455 77\n",
      "1060 4488 78\n",
      "1073 4553 79\n",
      "1081 4589 80\n",
      "1096 4666 81\n",
      "1103 4699 82\n",
      "1115 4763 83\n",
      "1124 4794 84\n",
      "1133 4835 85\n",
      "1140 4878 86\n",
      "1149 4925 87\n",
      "1159 4965 88\n",
      "1168 5016 89\n",
      "1179 5067 90\n",
      "1186 5096 91\n",
      "1191 5121 92\n",
      "1197 5147 93\n",
      "1205 5183 94\n",
      "1212 5216 95\n",
      "1220 5262 96\n",
      "1232 5308 97\n",
      "1242 5358 98\n",
      "1252 5408 99\n",
      "1259 5443 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.9830508474576272 9.242853532393326 \ttest: 0.9261083743842364 17.793229019533435\n",
      "retrain  2 :\n",
      "\ttrain: 0.989406779661017 6.2884653242310335 \ttest: 0.9310344827586207 17.012956538771622\n",
      "retrain  3 :\n",
      "\ttrain: 0.9978813559322034 4.696207844214211 \ttest: 0.9310344827586207 16.792128696532423\n",
      "retrain  4 :\n",
      "\ttrain: 0.9978813559322034 3.712587069205914 \ttest: 0.9310344827586207 16.752628175331505\n",
      "retrain  5 :\n",
      "\ttrain: 0.9978813559322034 3.064328232679084 \ttest: 0.9310344827586207 16.78462078386628\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        11\n",
      "           1    0.98462   1.00000   0.99225        64\n",
      "           2    1.00000   1.00000   1.00000        31\n",
      "           3    1.00000   1.00000   1.00000        14\n",
      "           4    1.00000   1.00000   1.00000        14\n",
      "           5    1.00000   1.00000   1.00000        64\n",
      "           6    1.00000   1.00000   1.00000        31\n",
      "           7    1.00000   1.00000   1.00000        14\n",
      "           8    1.00000   1.00000   1.00000        10\n",
      "           9    1.00000   1.00000   1.00000        10\n",
      "          10    1.00000   1.00000   1.00000        14\n",
      "          11    1.00000   1.00000   1.00000        14\n",
      "          12    1.00000   0.98438   0.99213        64\n",
      "          13    1.00000   1.00000   1.00000        14\n",
      "          14    1.00000   1.00000   1.00000        61\n",
      "          15    1.00000   1.00000   1.00000        14\n",
      "          16    1.00000   1.00000   1.00000        14\n",
      "          17    1.00000   1.00000   1.00000        14\n",
      "\n",
      "    accuracy                        0.99788       472\n",
      "   macro avg    0.99915   0.99913   0.99913       472\n",
      "weighted avg    0.99791   0.99788   0.99788       472\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000         5\n",
      "           1    0.73529   0.92593   0.81967        27\n",
      "           2    1.00000   1.00000   1.00000        13\n",
      "           3    1.00000   1.00000   1.00000         6\n",
      "           4    1.00000   1.00000   1.00000         6\n",
      "           5    0.96296   0.92857   0.94545        28\n",
      "           6    1.00000   1.00000   1.00000        13\n",
      "           7    1.00000   1.00000   1.00000         6\n",
      "           8    1.00000   1.00000   1.00000         4\n",
      "           9    1.00000   1.00000   1.00000         5\n",
      "          10    1.00000   1.00000   1.00000         6\n",
      "          11    1.00000   1.00000   1.00000         6\n",
      "          12    0.90000   0.66667   0.76596        27\n",
      "          13    0.71429   0.83333   0.76923         6\n",
      "          14    1.00000   1.00000   1.00000        27\n",
      "          15    1.00000   1.00000   1.00000         6\n",
      "          16    1.00000   1.00000   1.00000         6\n",
      "          17    1.00000   1.00000   1.00000         6\n",
      "\n",
      "    accuracy                        0.93103       203\n",
      "   macro avg    0.96181   0.96414   0.96113       203\n",
      "weighted avg    0.93794   0.93103   0.93054       203\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1259\n",
      "Average of depth: 1.552025416997617\n",
      "Number of nodes: 5443\n",
      "26 100 1\n",
      "46 182 2\n",
      "70 290 3\n",
      "93 375 4\n",
      "108 424 5\n",
      "127 509 6\n",
      "147 585 7\n",
      "160 622 8\n",
      "182 702 9\n",
      "202 780 10\n",
      "215 833 11\n",
      "232 898 12\n",
      "248 956 13\n",
      "264 1012 14\n",
      "278 1064 15\n",
      "291 1117 16\n",
      "306 1176 17\n",
      "323 1245 18\n",
      "336 1304 19\n",
      "353 1371 20\n",
      "367 1421 21\n",
      "384 1488 22\n",
      "398 1546 23\n",
      "410 1602 24\n",
      "421 1649 25\n",
      "429 1677 26\n",
      "442 1744 27\n",
      "456 1802 28\n",
      "466 1848 29\n",
      "473 1869 30\n",
      "485 1913 31\n",
      "495 1953 32\n",
      "508 2002 33\n",
      "524 2064 34\n",
      "535 2113 35\n",
      "548 2168 36\n",
      "559 2213 37\n",
      "569 2249 38\n",
      "577 2287 39\n",
      "585 2315 40\n",
      "596 2360 41\n",
      "605 2395 42\n",
      "618 2452 43\n",
      "629 2507 44\n",
      "639 2549 45\n",
      "653 2617 46\n",
      "666 2688 47\n",
      "680 2752 48\n",
      "696 2834 49\n",
      "704 2868 50\n",
      "716 2918 51\n",
      "731 2981 52\n",
      "739 3013 53\n",
      "752 3072 54\n",
      "760 3100 55\n",
      "767 3131 56\n",
      "777 3177 57\n",
      "789 3223 58\n",
      "797 3261 59\n",
      "805 3293 60\n",
      "816 3338 61\n",
      "832 3404 62\n",
      "842 3446 63\n",
      "853 3499 64\n",
      "860 3532 65\n",
      "866 3548 66\n",
      "871 3565 67\n",
      "880 3606 68\n",
      "891 3647 69\n",
      "905 3715 70\n",
      "919 3783 71\n",
      "927 3827 72\n",
      "937 3875 73\n",
      "942 3900 74\n",
      "955 3949 75\n",
      "963 3981 76\n",
      "976 4042 77\n",
      "986 4090 78\n",
      "993 4125 79\n",
      "998 4148 80\n",
      "1002 4168 81\n",
      "1009 4193 82\n",
      "1017 4237 83\n",
      "1021 4249 84\n",
      "1028 4282 85\n",
      "1038 4330 86\n",
      "1046 4362 87\n",
      "1055 4399 88\n",
      "1066 4458 89\n",
      "1074 4502 90\n",
      "1079 4525 91\n",
      "1090 4568 92\n",
      "1095 4589 93\n",
      "1104 4632 94\n",
      "1117 4687 95\n",
      "1119 4693 96\n",
      "1128 4740 97\n",
      "1140 4800 98\n",
      "1147 4835 99\n",
      "1152 4856 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.989406779661017 9.849279789262384 \ttest: 0.9655172413793104 12.383694942832397\n",
      "retrain  2 :\n",
      "\ttrain: 0.9936440677966102 6.227561847553358 \ttest: 0.9655172413793104 13.455954113885289\n",
      "retrain  3 :\n",
      "\ttrain: 0.9978813559322034 4.543122831228885 \ttest: 0.9655172413793104 14.16103781244506\n",
      "retrain  4 :\n",
      "\ttrain: 0.9978813559322034 3.5595292710248216 \ttest: 0.9605911330049262 14.692017121345716\n",
      "retrain  5 :\n",
      "\ttrain: 0.9978813559322034 2.9289085220942064 \ttest: 0.9605911330049262 15.115346368545818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        11\n",
      "           1    0.98462   1.00000   0.99225        64\n",
      "           2    1.00000   1.00000   1.00000        31\n",
      "           3    1.00000   1.00000   1.00000        14\n",
      "           4    1.00000   1.00000   1.00000        14\n",
      "           5    1.00000   1.00000   1.00000        64\n",
      "           6    1.00000   1.00000   1.00000        31\n",
      "           7    1.00000   1.00000   1.00000        14\n",
      "           8    1.00000   1.00000   1.00000        10\n",
      "           9    1.00000   1.00000   1.00000        10\n",
      "          10    1.00000   1.00000   1.00000        14\n",
      "          11    1.00000   1.00000   1.00000        14\n",
      "          12    1.00000   0.98438   0.99213        64\n",
      "          13    1.00000   1.00000   1.00000        14\n",
      "          14    1.00000   1.00000   1.00000        61\n",
      "          15    1.00000   1.00000   1.00000        14\n",
      "          16    1.00000   1.00000   1.00000        14\n",
      "          17    1.00000   1.00000   1.00000        14\n",
      "\n",
      "    accuracy                        0.99788       472\n",
      "   macro avg    0.99915   0.99913   0.99913       472\n",
      "weighted avg    0.99791   0.99788   0.99788       472\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000         5\n",
      "           1    0.86667   0.96296   0.91228        27\n",
      "           2    1.00000   1.00000   1.00000        13\n",
      "           3    0.85714   1.00000   0.92308         6\n",
      "           4    1.00000   0.83333   0.90909         6\n",
      "           5    1.00000   0.92857   0.96296        28\n",
      "           6    1.00000   1.00000   1.00000        13\n",
      "           7    1.00000   1.00000   1.00000         6\n",
      "           8    1.00000   1.00000   1.00000         4\n",
      "           9    1.00000   1.00000   1.00000         5\n",
      "          10    1.00000   1.00000   1.00000         6\n",
      "          11    1.00000   1.00000   1.00000         6\n",
      "          12    0.95833   0.85185   0.90196        27\n",
      "          13    0.75000   1.00000   0.85714         6\n",
      "          14    1.00000   1.00000   1.00000        27\n",
      "          15    1.00000   1.00000   1.00000         6\n",
      "          16    1.00000   1.00000   1.00000         6\n",
      "          17    1.00000   1.00000   1.00000         6\n",
      "\n",
      "    accuracy                        0.96059       203\n",
      "   macro avg    0.96845   0.97648   0.97036       203\n",
      "weighted avg    0.96511   0.96059   0.96100       203\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1152\n",
      "Average of depth: 1.5112847222222223\n",
      "Number of nodes: 4856\n",
      "28 110 1\n",
      "51 201 2\n",
      "76 304 3\n",
      "94 386 4\n",
      "114 452 5\n",
      "134 528 6\n",
      "153 609 7\n",
      "170 678 8\n",
      "189 769 9\n",
      "200 808 10\n",
      "214 854 11\n",
      "233 935 12\n",
      "251 1001 13\n",
      "265 1053 14\n",
      "277 1095 15\n",
      "296 1178 16\n",
      "314 1256 17\n",
      "332 1328 18\n",
      "350 1400 19\n",
      "363 1441 20\n",
      "374 1486 21\n",
      "390 1564 22\n",
      "406 1622 23\n",
      "423 1691 24\n",
      "442 1774 25\n",
      "458 1830 26\n",
      "468 1866 27\n",
      "478 1904 28\n",
      "497 2001 29\n",
      "506 2042 30\n",
      "515 2077 31\n",
      "527 2127 32\n",
      "544 2208 33\n",
      "552 2236 34\n",
      "571 2333 35\n",
      "578 2362 36\n",
      "588 2402 37\n",
      "601 2451 38\n",
      "609 2481 39\n",
      "619 2519 40\n",
      "630 2564 41\n",
      "644 2628 42\n",
      "651 2651 43\n",
      "658 2682 44\n",
      "672 2732 45\n",
      "684 2784 46\n",
      "692 2824 47\n",
      "707 2893 48\n",
      "708 2890 49\n",
      "719 2937 50\n",
      "729 2971 51\n",
      "740 3026 52\n",
      "757 3107 53\n",
      "766 3146 54\n",
      "781 3211 55\n",
      "793 3267 56\n",
      "806 3334 57\n",
      "815 3385 58\n",
      "826 3436 59\n",
      "837 3475 60\n",
      "847 3529 61\n",
      "856 3566 62\n",
      "866 3614 63\n",
      "878 3674 64\n",
      "886 3706 65\n",
      "896 3750 66\n",
      "905 3787 67\n",
      "916 3834 68\n",
      "927 3883 69\n",
      "942 3942 70\n",
      "953 3985 71\n",
      "962 4032 72\n",
      "975 4101 73\n",
      "984 4152 74\n",
      "996 4218 75\n",
      "1006 4266 76\n",
      "1016 4304 77\n",
      "1030 4362 78\n",
      "1039 4407 79\n",
      "1042 4420 80\n",
      "1055 4483 81\n",
      "1058 4502 82\n",
      "1070 4556 83\n",
      "1078 4592 84\n",
      "1091 4647 85\n",
      "1099 4691 86\n",
      "1111 4763 87\n",
      "1118 4800 88\n",
      "1124 4818 89\n",
      "1129 4845 90\n",
      "1138 4882 91\n",
      "1147 4929 92\n",
      "1153 4955 93\n",
      "1161 4989 94\n",
      "1169 5023 95\n",
      "1180 5076 96\n",
      "1183 5091 97\n",
      "1187 5109 98\n",
      "1200 5168 99\n",
      "1209 5213 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.9872881355932204 8.427133422058619 \ttest: 0.9310344827586207 17.856614646639187\n",
      "retrain  2 :\n",
      "\ttrain: 0.9957627118644068 5.400588400138857 \ttest: 0.9310344827586207 17.99262725065976\n",
      "retrain  3 :\n",
      "\ttrain: 0.9978813559322034 3.9452543869378163 \ttest: 0.9310344827586207 18.39135859566034\n",
      "retrain  4 :\n",
      "\ttrain: 0.9978813559322034 3.116510770307675 \ttest: 0.9261083743842364 18.809721849755945\n",
      "retrain  5 :\n",
      "\ttrain: 0.9978813559322034 2.597358703015368 \ttest: 0.9310344827586207 19.194718954278006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        11\n",
      "           1    0.98462   1.00000   0.99225        64\n",
      "           2    1.00000   1.00000   1.00000        31\n",
      "           3    1.00000   1.00000   1.00000        14\n",
      "           4    1.00000   1.00000   1.00000        14\n",
      "           5    1.00000   1.00000   1.00000        64\n",
      "           6    1.00000   1.00000   1.00000        31\n",
      "           7    1.00000   1.00000   1.00000        14\n",
      "           8    1.00000   1.00000   1.00000        10\n",
      "           9    1.00000   1.00000   1.00000        10\n",
      "          10    1.00000   1.00000   1.00000        14\n",
      "          11    1.00000   1.00000   1.00000        14\n",
      "          12    1.00000   0.98438   0.99213        64\n",
      "          13    1.00000   1.00000   1.00000        14\n",
      "          14    1.00000   1.00000   1.00000        61\n",
      "          15    1.00000   1.00000   1.00000        14\n",
      "          16    1.00000   1.00000   1.00000        14\n",
      "          17    1.00000   1.00000   1.00000        14\n",
      "\n",
      "    accuracy                        0.99788       472\n",
      "   macro avg    0.99915   0.99913   0.99913       472\n",
      "weighted avg    0.99791   0.99788   0.99788       472\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000         5\n",
      "           1    0.71429   0.92593   0.80645        27\n",
      "           2    1.00000   1.00000   1.00000        13\n",
      "           3    1.00000   1.00000   1.00000         6\n",
      "           4    1.00000   1.00000   1.00000         6\n",
      "           5    0.96296   0.92857   0.94545        28\n",
      "           6    1.00000   1.00000   1.00000        13\n",
      "           7    1.00000   1.00000   1.00000         6\n",
      "           8    1.00000   1.00000   1.00000         4\n",
      "           9    1.00000   1.00000   1.00000         5\n",
      "          10    1.00000   1.00000   1.00000         6\n",
      "          11    1.00000   1.00000   1.00000         6\n",
      "          12    0.90000   0.66667   0.76596        27\n",
      "          13    0.83333   0.83333   0.83333         6\n",
      "          14    1.00000   1.00000   1.00000        27\n",
      "          15    1.00000   1.00000   1.00000         6\n",
      "          16    1.00000   1.00000   1.00000         6\n",
      "          17    1.00000   1.00000   1.00000         6\n",
      "\n",
      "    accuracy                        0.93103       203\n",
      "   macro avg    0.96725   0.96414   0.96396       203\n",
      "weighted avg    0.93866   0.93103   0.93068       203\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1209\n",
      "Average of depth: 1.5351530190239868\n",
      "Number of nodes: 5213\n",
      "25 97 1\n",
      "46 190 2\n",
      "69 291 3\n",
      "91 383 4\n",
      "114 480 5\n",
      "134 556 6\n",
      "156 642 7\n",
      "173 705 8\n",
      "190 770 9\n",
      "208 838 10\n",
      "221 887 11\n",
      "234 934 12\n",
      "248 992 13\n",
      "264 1062 14\n",
      "281 1139 15\n",
      "297 1207 16\n",
      "316 1276 17\n",
      "330 1334 18\n",
      "341 1391 19\n",
      "354 1456 20\n",
      "370 1514 21\n",
      "386 1584 22\n",
      "402 1642 23\n",
      "414 1690 24\n",
      "426 1746 25\n",
      "440 1806 26\n",
      "454 1866 27\n",
      "468 1926 28\n",
      "477 1961 29\n",
      "488 2008 30\n",
      "502 2058 31\n",
      "510 2088 32\n",
      "524 2140 33\n",
      "534 2172 34\n",
      "547 2231 35\n",
      "561 2297 36\n",
      "568 2332 37\n",
      "580 2382 38\n",
      "591 2423 39\n",
      "601 2459 40\n",
      "612 2518 41\n",
      "624 2562 42\n",
      "630 2590 43\n",
      "640 2640 44\n",
      "649 2677 45\n",
      "667 2751 46\n",
      "678 2788 47\n",
      "691 2843 48\n",
      "705 2907 49\n",
      "719 2965 50\n",
      "735 3031 51\n",
      "739 3049 52\n",
      "747 3081 53\n",
      "761 3133 54\n",
      "767 3157 55\n",
      "774 3182 56\n",
      "786 3226 57\n",
      "793 3253 58\n",
      "807 3311 59\n",
      "816 3356 60\n",
      "828 3404 61\n",
      "841 3455 62\n",
      "857 3521 63\n",
      "865 3559 64\n",
      "877 3607 65\n",
      "890 3670 66\n",
      "898 3702 67\n",
      "907 3743 68\n",
      "916 3786 69\n",
      "928 3840 70\n",
      "937 3879 71\n",
      "949 3923 72\n",
      "956 3970 73\n",
      "966 4014 74\n",
      "974 4056 75\n",
      "982 4100 76\n",
      "990 4130 77\n",
      "997 4167 78\n",
      "1004 4204 79\n",
      "1013 4241 80\n",
      "1023 4295 81\n",
      "1033 4333 82\n",
      "1042 4372 83\n",
      "1047 4397 84\n",
      "1057 4445 85\n",
      "1071 4515 86\n",
      "1078 4540 87\n",
      "1089 4587 88\n",
      "1100 4636 89\n",
      "1111 4681 90\n",
      "1119 4709 91\n",
      "1134 4776 92\n",
      "1144 4824 93\n",
      "1151 4857 94\n",
      "1157 4879 95\n",
      "1171 4947 96\n",
      "1184 5008 97\n",
      "1189 5023 98\n",
      "1201 5077 99\n",
      "1208 5112 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.9978813559322034 6.731310994044161 \ttest: 0.9211822660098522 20.22315104223233\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 3.4839977237857975 \ttest: 0.9310344827586207 22.127466842611998\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 2.1609219082379636 \ttest: 0.9261083743842364 23.385078363186466\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 1.4701078275931228 \ttest: 0.9261083743842364 24.296122881789735\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.0624001480007068 \ttest: 0.9261083743842364 24.994077990351194\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        11\n",
      "           1    1.00000   1.00000   1.00000        64\n",
      "           2    1.00000   1.00000   1.00000        31\n",
      "           3    1.00000   1.00000   1.00000        14\n",
      "           4    1.00000   1.00000   1.00000        14\n",
      "           5    1.00000   1.00000   1.00000        64\n",
      "           6    1.00000   1.00000   1.00000        31\n",
      "           7    1.00000   1.00000   1.00000        14\n",
      "           8    1.00000   1.00000   1.00000        10\n",
      "           9    1.00000   1.00000   1.00000        10\n",
      "          10    1.00000   1.00000   1.00000        14\n",
      "          11    1.00000   1.00000   1.00000        14\n",
      "          12    1.00000   1.00000   1.00000        64\n",
      "          13    1.00000   1.00000   1.00000        14\n",
      "          14    1.00000   1.00000   1.00000        61\n",
      "          15    1.00000   1.00000   1.00000        14\n",
      "          16    1.00000   1.00000   1.00000        14\n",
      "          17    1.00000   1.00000   1.00000        14\n",
      "\n",
      "    accuracy                        1.00000       472\n",
      "   macro avg    1.00000   1.00000   1.00000       472\n",
      "weighted avg    1.00000   1.00000   1.00000       472\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000         5\n",
      "           1    0.80769   0.77778   0.79245        27\n",
      "           2    1.00000   1.00000   1.00000        13\n",
      "           3    0.85714   1.00000   0.92308         6\n",
      "           4    1.00000   0.83333   0.90909         6\n",
      "           5    1.00000   0.85714   0.92308        28\n",
      "           6    1.00000   1.00000   1.00000        13\n",
      "           7    1.00000   1.00000   1.00000         6\n",
      "           8    1.00000   1.00000   1.00000         4\n",
      "           9    1.00000   1.00000   1.00000         5\n",
      "          10    1.00000   1.00000   1.00000         6\n",
      "          11    1.00000   1.00000   1.00000         6\n",
      "          12    0.75000   0.88889   0.81356        27\n",
      "          13    0.83333   0.83333   0.83333         6\n",
      "          14    1.00000   1.00000   1.00000        27\n",
      "          15    1.00000   1.00000   1.00000         6\n",
      "          16    1.00000   1.00000   1.00000         6\n",
      "          17    1.00000   1.00000   1.00000         6\n",
      "\n",
      "    accuracy                        0.92611       203\n",
      "   macro avg    0.95823   0.95503   0.95526       203\n",
      "weighted avg    0.93202   0.92611   0.92710       203\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1208\n",
      "Average of depth: 1.5182119205298013\n",
      "Number of nodes: 5112\n",
      "26 92 1\n",
      "51 181 2\n",
      "72 262 3\n",
      "93 349 4\n",
      "109 405 5\n",
      "121 451 6\n",
      "141 527 7\n",
      "161 627 8\n",
      "179 691 9\n",
      "196 754 10\n",
      "211 811 11\n",
      "225 865 12\n",
      "235 901 13\n",
      "250 958 14\n",
      "267 1019 15\n",
      "283 1089 16\n",
      "303 1171 17\n",
      "320 1246 18\n",
      "336 1314 19\n",
      "348 1358 20\n",
      "362 1412 21\n",
      "375 1465 22\n",
      "391 1525 23\n",
      "404 1582 24\n",
      "418 1636 25\n",
      "432 1696 26\n",
      "446 1762 27\n",
      "456 1798 28\n",
      "471 1883 29\n",
      "485 1941 30\n",
      "498 1998 31\n",
      "512 2048 32\n",
      "523 2099 33\n",
      "536 2156 34\n",
      "541 2179 35\n",
      "556 2242 36\n",
      "572 2308 37\n",
      "583 2355 38\n",
      "599 2431 39\n",
      "609 2475 40\n",
      "618 2508 41\n",
      "631 2565 42\n",
      "638 2594 43\n",
      "656 2672 44\n",
      "667 2725 45\n",
      "675 2757 46\n",
      "685 2799 47\n",
      "695 2837 48\n",
      "702 2866 49\n",
      "709 2899 50\n",
      "725 2971 51\n",
      "733 2997 52\n",
      "748 3072 53\n",
      "754 3100 54\n",
      "763 3141 55\n",
      "771 3175 56\n",
      "781 3227 57\n",
      "796 3314 58\n",
      "806 3374 59\n",
      "819 3443 60\n",
      "829 3499 61\n",
      "842 3552 62\n",
      "850 3586 63\n",
      "860 3638 64\n",
      "869 3677 65\n",
      "882 3740 66\n",
      "890 3776 67\n",
      "899 3807 68\n",
      "910 3852 69\n",
      "922 3908 70\n",
      "936 3974 71\n",
      "946 4024 72\n",
      "956 4068 73\n",
      "962 4092 74\n",
      "968 4110 75\n",
      "979 4153 76\n",
      "984 4178 77\n",
      "993 4217 78\n",
      "1002 4256 79\n",
      "1011 4305 80\n",
      "1019 4341 81\n",
      "1028 4386 82\n",
      "1038 4430 83\n",
      "1045 4453 84\n",
      "1055 4497 85\n",
      "1062 4518 86\n",
      "1067 4545 87\n",
      "1078 4604 88\n",
      "1088 4660 89\n",
      "1097 4695 90\n",
      "1108 4744 91\n",
      "1120 4808 92\n",
      "1129 4847 93\n",
      "1133 4871 94\n",
      "1138 4892 95\n",
      "1144 4916 96\n",
      "1149 4943 97\n",
      "1155 4975 98\n",
      "1173 5075 99\n",
      "1180 5108 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.9915254237288136 9.234764689054158 \ttest: 0.9605911330049262 14.881192266213176\n",
      "retrain  2 :\n",
      "\ttrain: 0.9957627118644068 5.555615852164393 \ttest: 0.9556650246305419 15.106420559483098\n",
      "retrain  3 :\n",
      "\ttrain: 0.9978813559322034 3.832456284954984 \ttest: 0.9556650246305419 15.358002686356759\n",
      "retrain  4 :\n",
      "\ttrain: 0.9978813559322034 2.8237434025179473 \ttest: 0.9605911330049262 15.570544545229852\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 2.167053064239494 \ttest: 0.9605911330049262 15.754610256012331\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        11\n",
      "           1    1.00000   1.00000   1.00000        64\n",
      "           2    1.00000   1.00000   1.00000        31\n",
      "           3    1.00000   1.00000   1.00000        14\n",
      "           4    1.00000   1.00000   1.00000        14\n",
      "           5    1.00000   1.00000   1.00000        64\n",
      "           6    1.00000   1.00000   1.00000        31\n",
      "           7    1.00000   1.00000   1.00000        14\n",
      "           8    1.00000   1.00000   1.00000        10\n",
      "           9    1.00000   1.00000   1.00000        10\n",
      "          10    1.00000   1.00000   1.00000        14\n",
      "          11    1.00000   1.00000   1.00000        14\n",
      "          12    1.00000   1.00000   1.00000        64\n",
      "          13    1.00000   1.00000   1.00000        14\n",
      "          14    1.00000   1.00000   1.00000        61\n",
      "          15    1.00000   1.00000   1.00000        14\n",
      "          16    1.00000   1.00000   1.00000        14\n",
      "          17    1.00000   1.00000   1.00000        14\n",
      "\n",
      "    accuracy                        1.00000       472\n",
      "   macro avg    1.00000   1.00000   1.00000       472\n",
      "weighted avg    1.00000   1.00000   1.00000       472\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000         5\n",
      "           1    0.92593   0.92593   0.92593        27\n",
      "           2    1.00000   1.00000   1.00000        13\n",
      "           3    0.85714   1.00000   0.92308         6\n",
      "           4    1.00000   0.83333   0.90909         6\n",
      "           5    0.96296   0.92857   0.94545        28\n",
      "           6    1.00000   1.00000   1.00000        13\n",
      "           7    1.00000   1.00000   1.00000         6\n",
      "           8    1.00000   1.00000   1.00000         4\n",
      "           9    1.00000   1.00000   1.00000         5\n",
      "          10    1.00000   1.00000   1.00000         6\n",
      "          11    1.00000   1.00000   1.00000         6\n",
      "          12    0.89286   0.92593   0.90909        27\n",
      "          13    0.83333   0.83333   0.83333         6\n",
      "          14    1.00000   1.00000   1.00000        27\n",
      "          15    1.00000   1.00000   1.00000         6\n",
      "          16    1.00000   1.00000   1.00000         6\n",
      "          17    1.00000   1.00000   1.00000         6\n",
      "\n",
      "    accuracy                        0.96059       203\n",
      "   macro avg    0.97068   0.96928   0.96922       203\n",
      "weighted avg    0.96164   0.96059   0.96065       203\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1180\n",
      "Average of depth: 1.5423728813559323\n",
      "Number of nodes: 5108\n",
      "27 99 1\n",
      "46 180 2\n",
      "72 284 3\n",
      "96 384 4\n",
      "121 479 5\n",
      "139 557 6\n",
      "159 631 7\n",
      "177 713 8\n",
      "196 792 9\n",
      "216 874 10\n",
      "235 957 11\n",
      "255 1035 12\n",
      "278 1136 13\n",
      "296 1206 14\n",
      "315 1285 15\n",
      "331 1353 16\n",
      "344 1400 17\n",
      "360 1464 18\n",
      "373 1517 19\n",
      "393 1609 20\n",
      "410 1670 21\n",
      "427 1741 22\n",
      "441 1793 23\n",
      "456 1854 24\n",
      "471 1909 25\n",
      "485 1967 26\n",
      "498 2022 27\n",
      "513 2091 28\n",
      "528 2158 29\n",
      "547 2235 30\n",
      "558 2278 31\n",
      "567 2305 32\n",
      "577 2355 33\n",
      "587 2393 34\n",
      "592 2410 35\n",
      "607 2479 36\n",
      "622 2548 37\n",
      "635 2609 38\n",
      "647 2655 39\n",
      "656 2692 40\n",
      "668 2734 41\n",
      "677 2781 42\n",
      "691 2837 43\n",
      "698 2862 44\n",
      "712 2924 45\n",
      "728 2998 46\n",
      "739 3045 47\n",
      "753 3101 48\n",
      "761 3125 49\n",
      "777 3187 50\n",
      "790 3248 51\n",
      "801 3293 52\n",
      "813 3341 53\n",
      "821 3371 54\n",
      "836 3440 55\n",
      "849 3507 56\n",
      "862 3560 57\n",
      "874 3610 58\n",
      "886 3670 59\n",
      "895 3707 60\n",
      "905 3755 61\n",
      "914 3790 62\n",
      "923 3847 63\n",
      "931 3889 64\n",
      "948 3974 65\n",
      "955 4003 66\n",
      "960 4024 67\n",
      "974 4086 68\n",
      "989 4167 69\n",
      "998 4204 70\n",
      "1010 4260 71\n",
      "1018 4292 72\n",
      "1027 4339 73\n",
      "1038 4380 74\n",
      "1045 4407 75\n",
      "1055 4453 76\n",
      "1062 4486 77\n",
      "1074 4562 78\n",
      "1084 4608 79\n",
      "1094 4652 80\n",
      "1102 4680 81\n",
      "1115 4735 82\n",
      "1126 4786 83\n",
      "1133 4815 84\n",
      "1143 4865 85\n",
      "1154 4918 86\n",
      "1161 4941 87\n",
      "1170 4988 88\n",
      "1176 5010 89\n",
      "1187 5053 90\n",
      "1195 5079 91\n",
      "1208 5146 92\n",
      "1218 5192 93\n",
      "1228 5252 94\n",
      "1238 5296 95\n",
      "1244 5326 96\n",
      "1256 5388 97\n",
      "1264 5426 98\n",
      "1271 5461 99\n",
      "1279 5503 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.9872881355932204 10.915554956839602 \ttest: 0.9458128078817734 15.909998721575496\n",
      "retrain  2 :\n",
      "\ttrain: 0.9915254237288136 7.626031705420968 \ttest: 0.9408866995073891 16.355193633419532\n",
      "retrain  3 :\n",
      "\ttrain: 0.9936440677966102 5.861739403421279 \ttest: 0.9359605911330049 16.874987487095588\n",
      "retrain  4 :\n",
      "\ttrain: 0.9957627118644068 4.73618144234269 \ttest: 0.9359605911330049 17.341985543389043\n",
      "retrain  5 :\n",
      "\ttrain: 0.9957627118644068 3.9635643578025954 \ttest: 0.9359605911330049 17.73878611704072\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        11\n",
      "           1    0.98438   0.98438   0.98438        64\n",
      "           2    1.00000   1.00000   1.00000        31\n",
      "           3    1.00000   1.00000   1.00000        14\n",
      "           4    1.00000   1.00000   1.00000        14\n",
      "           5    1.00000   1.00000   1.00000        64\n",
      "           6    1.00000   1.00000   1.00000        31\n",
      "           7    1.00000   1.00000   1.00000        14\n",
      "           8    1.00000   1.00000   1.00000        10\n",
      "           9    1.00000   1.00000   1.00000        10\n",
      "          10    1.00000   1.00000   1.00000        14\n",
      "          11    1.00000   1.00000   1.00000        14\n",
      "          12    0.98438   0.98438   0.98438        64\n",
      "          13    1.00000   1.00000   1.00000        14\n",
      "          14    1.00000   1.00000   1.00000        61\n",
      "          15    1.00000   1.00000   1.00000        14\n",
      "          16    1.00000   1.00000   1.00000        14\n",
      "          17    1.00000   1.00000   1.00000        14\n",
      "\n",
      "    accuracy                        0.99576       472\n",
      "   macro avg    0.99826   0.99826   0.99826       472\n",
      "weighted avg    0.99576   0.99576   0.99576       472\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000         5\n",
      "           1    0.85185   0.85185   0.85185        27\n",
      "           2    1.00000   1.00000   1.00000        13\n",
      "           3    0.85714   1.00000   0.92308         6\n",
      "           4    1.00000   0.83333   0.90909         6\n",
      "           5    1.00000   0.89286   0.94340        28\n",
      "           6    1.00000   1.00000   1.00000        13\n",
      "           7    1.00000   1.00000   1.00000         6\n",
      "           8    1.00000   1.00000   1.00000         4\n",
      "           9    1.00000   1.00000   1.00000         5\n",
      "          10    1.00000   1.00000   1.00000         6\n",
      "          11    1.00000   1.00000   1.00000         6\n",
      "          12    0.84615   0.81481   0.83019        27\n",
      "          13    0.60000   1.00000   0.75000         6\n",
      "          14    1.00000   1.00000   1.00000        27\n",
      "          15    1.00000   1.00000   1.00000         6\n",
      "          16    1.00000   1.00000   1.00000         6\n",
      "          17    1.00000   1.00000   1.00000         6\n",
      "\n",
      "    accuracy                        0.93596       203\n",
      "   macro avg    0.95306   0.96627   0.95598       203\n",
      "weighted avg    0.94379   0.93596   0.93755       203\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1279\n",
      "Average of depth: 1.5402658326817826\n",
      "Number of nodes: 5503\n",
      "29 125 1\n",
      "51 209 2\n",
      "78 320 3\n",
      "99 405 4\n",
      "123 507 5\n",
      "145 603 6\n",
      "165 679 7\n",
      "179 729 8\n",
      "195 793 9\n",
      "211 851 10\n",
      "231 929 11\n",
      "254 1026 12\n",
      "274 1108 13\n",
      "289 1163 14\n",
      "304 1216 15\n",
      "321 1277 16\n",
      "335 1337 17\n",
      "346 1382 18\n",
      "365 1457 19\n",
      "377 1495 20\n",
      "393 1565 21\n",
      "411 1635 22\n",
      "427 1713 23\n",
      "439 1761 24\n",
      "452 1814 25\n",
      "469 1887 26\n",
      "481 1931 27\n",
      "498 2000 28\n",
      "507 2037 29\n",
      "521 2101 30\n",
      "533 2143 31\n",
      "545 2201 32\n",
      "555 2235 33\n",
      "564 2276 34\n",
      "583 2367 35\n",
      "596 2418 36\n",
      "611 2491 37\n",
      "619 2529 38\n",
      "631 2573 39\n",
      "642 2618 40\n",
      "655 2681 41\n",
      "667 2729 42\n",
      "677 2773 43\n",
      "694 2836 44\n",
      "706 2896 45\n",
      "716 2942 46\n",
      "726 2982 47\n",
      "738 3036 48\n",
      "748 3078 49\n",
      "755 3121 50\n",
      "762 3144 51\n",
      "771 3177 52\n",
      "783 3225 53\n",
      "792 3264 54\n",
      "799 3291 55\n",
      "806 3324 56\n",
      "817 3369 57\n",
      "829 3425 58\n",
      "839 3469 59\n",
      "852 3528 60\n",
      "862 3572 61\n",
      "870 3596 62\n",
      "880 3638 63\n",
      "890 3682 64\n",
      "900 3736 65\n",
      "910 3778 66\n",
      "922 3828 67\n",
      "935 3883 68\n",
      "949 3953 69\n",
      "955 3977 70\n",
      "963 4017 71\n",
      "976 4078 72\n",
      "985 4117 73\n",
      "989 4125 74\n",
      "994 4150 75\n",
      "1002 4182 76\n",
      "1013 4235 77\n",
      "1025 4289 78\n",
      "1033 4335 79\n",
      "1046 4390 80\n",
      "1061 4453 81\n",
      "1069 4487 82\n",
      "1077 4525 83\n",
      "1085 4569 84\n",
      "1093 4607 85\n",
      "1101 4637 86\n",
      "1110 4678 87\n",
      "1117 4715 88\n",
      "1128 4764 89\n",
      "1138 4816 90\n",
      "1149 4869 91\n",
      "1160 4910 92\n",
      "1166 4942 93\n",
      "1176 4986 94\n",
      "1189 5063 95\n",
      "1198 5104 96\n",
      "1204 5132 97\n",
      "1215 5181 98\n",
      "1221 5203 99\n",
      "1230 5246 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.989406779661017 9.632562232454664 \ttest: 0.9458128078817734 16.62170704849241\n",
      "retrain  2 :\n",
      "\ttrain: 0.9915254237288136 6.587938482545398 \ttest: 0.9408866995073891 16.11420386286674\n",
      "retrain  3 :\n",
      "\ttrain: 0.9915254237288136 5.0615548437823 \ttest: 0.9556650246305419 15.910661221346942\n",
      "retrain  4 :\n",
      "\ttrain: 0.9957627118644068 4.0816182243173404 \ttest: 0.9556650246305419 15.861290050536567\n",
      "retrain  5 :\n",
      "\ttrain: 0.9978813559322034 3.3892562371076416 \ttest: 0.9556650246305419 15.89588272131386\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        11\n",
      "           1    0.98462   1.00000   0.99225        64\n",
      "           2    1.00000   1.00000   1.00000        31\n",
      "           3    1.00000   1.00000   1.00000        14\n",
      "           4    1.00000   1.00000   1.00000        14\n",
      "           5    1.00000   1.00000   1.00000        64\n",
      "           6    1.00000   1.00000   1.00000        31\n",
      "           7    1.00000   1.00000   1.00000        14\n",
      "           8    1.00000   1.00000   1.00000        10\n",
      "           9    1.00000   1.00000   1.00000        10\n",
      "          10    1.00000   1.00000   1.00000        14\n",
      "          11    1.00000   1.00000   1.00000        14\n",
      "          12    1.00000   0.98438   0.99213        64\n",
      "          13    1.00000   1.00000   1.00000        14\n",
      "          14    1.00000   1.00000   1.00000        61\n",
      "          15    1.00000   1.00000   1.00000        14\n",
      "          16    1.00000   1.00000   1.00000        14\n",
      "          17    1.00000   1.00000   1.00000        14\n",
      "\n",
      "    accuracy                        0.99788       472\n",
      "   macro avg    0.99915   0.99913   0.99913       472\n",
      "weighted avg    0.99791   0.99788   0.99788       472\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000         5\n",
      "           1    0.88889   0.88889   0.88889        27\n",
      "           2    1.00000   1.00000   1.00000        13\n",
      "           3    0.85714   1.00000   0.92308         6\n",
      "           4    1.00000   0.83333   0.90909         6\n",
      "           5    0.96429   0.96429   0.96429        28\n",
      "           6    1.00000   1.00000   1.00000        13\n",
      "           7    1.00000   1.00000   1.00000         6\n",
      "           8    1.00000   1.00000   1.00000         4\n",
      "           9    1.00000   1.00000   1.00000         5\n",
      "          10    1.00000   1.00000   1.00000         6\n",
      "          11    1.00000   1.00000   1.00000         6\n",
      "          12    0.88889   0.88889   0.88889        27\n",
      "          13    0.83333   0.83333   0.83333         6\n",
      "          14    1.00000   1.00000   1.00000        27\n",
      "          15    1.00000   1.00000   1.00000         6\n",
      "          16    1.00000   1.00000   1.00000         6\n",
      "          17    1.00000   1.00000   1.00000         6\n",
      "\n",
      "    accuracy                        0.95567       203\n",
      "   macro avg    0.96847   0.96715   0.96709       203\n",
      "weighted avg    0.95637   0.95567   0.95563       203\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1230\n",
      "Average of depth: 1.534959349593496\n",
      "Number of nodes: 5246\n",
      "26 100 1\n",
      "48 186 2\n",
      "73 275 3\n",
      "94 356 4\n",
      "115 443 5\n",
      "137 525 6\n",
      "152 584 7\n",
      "170 648 8\n",
      "187 717 9\n",
      "207 813 10\n",
      "225 879 11\n",
      "243 949 12\n",
      "255 1001 13\n",
      "270 1056 14\n",
      "286 1120 15\n",
      "299 1177 16\n",
      "318 1250 17\n",
      "335 1321 18\n",
      "351 1385 19\n",
      "362 1426 20\n",
      "378 1492 21\n",
      "390 1542 22\n",
      "404 1596 23\n",
      "413 1639 24\n",
      "428 1710 25\n",
      "441 1759 26\n",
      "452 1806 27\n",
      "468 1872 28\n",
      "482 1938 29\n",
      "496 2004 30\n",
      "510 2066 31\n",
      "526 2136 32\n",
      "540 2188 33\n",
      "552 2234 34\n",
      "563 2283 35\n",
      "577 2353 36\n",
      "585 2377 37\n",
      "601 2455 38\n",
      "616 2520 39\n",
      "625 2553 40\n",
      "637 2611 41\n",
      "650 2678 42\n",
      "659 2729 43\n",
      "667 2765 44\n",
      "676 2814 45\n",
      "686 2866 46\n",
      "700 2936 47\n",
      "709 2981 48\n",
      "722 3042 49\n",
      "732 3082 50\n",
      "743 3123 51\n",
      "751 3145 52\n",
      "763 3199 53\n",
      "773 3241 54\n",
      "786 3296 55\n",
      "791 3313 56\n",
      "801 3353 57\n",
      "814 3410 58\n",
      "819 3439 59\n",
      "829 3471 60\n",
      "840 3518 61\n",
      "849 3567 62\n",
      "858 3606 63\n",
      "867 3649 64\n",
      "883 3723 65\n",
      "895 3773 66\n",
      "903 3815 67\n",
      "908 3834 68\n",
      "920 3880 69\n",
      "934 3944 70\n",
      "947 4007 71\n",
      "952 4032 72\n",
      "960 4064 73\n",
      "971 4123 74\n",
      "981 4173 75\n",
      "996 4234 76\n",
      "1004 4268 77\n",
      "1010 4300 78\n",
      "1017 4335 79\n",
      "1030 4390 80\n",
      "1037 4423 81\n",
      "1044 4454 82\n",
      "1054 4500 83\n",
      "1068 4568 84\n",
      "1077 4609 85\n",
      "1079 4621 86\n",
      "1087 4655 87\n",
      "1094 4688 88\n",
      "1105 4733 89\n",
      "1115 4775 90\n",
      "1123 4803 91\n",
      "1133 4857 92\n",
      "1140 4900 93\n",
      "1148 4938 94\n",
      "1157 4981 95\n",
      "1164 5018 96\n",
      "1175 5075 97\n",
      "1183 5115 98\n",
      "1192 5160 99\n",
      "1206 5226 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.989406779661017 8.629870737806407 \ttest: 0.9458128078817734 15.11980741499953\n",
      "retrain  2 :\n",
      "\ttrain: 0.9936440677966102 5.415172715678181 \ttest: 0.9458128078817734 15.810340965468454\n",
      "retrain  3 :\n",
      "\ttrain: 0.9978813559322034 3.9826728513016825 \ttest: 0.9507389162561576 16.352498394489533\n",
      "retrain  4 :\n",
      "\ttrain: 0.9978813559322034 3.161313186189315 \ttest: 0.9458128078817734 16.833779607235957\n",
      "retrain  5 :\n",
      "\ttrain: 0.9978813559322034 2.637549397470291 \ttest: 0.9458128078817734 17.245917398080564\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        11\n",
      "           1    1.00000   0.98438   0.99213        64\n",
      "           2    1.00000   1.00000   1.00000        31\n",
      "           3    1.00000   1.00000   1.00000        14\n",
      "           4    1.00000   1.00000   1.00000        14\n",
      "           5    1.00000   1.00000   1.00000        64\n",
      "           6    1.00000   1.00000   1.00000        31\n",
      "           7    1.00000   1.00000   1.00000        14\n",
      "           8    1.00000   1.00000   1.00000        10\n",
      "           9    1.00000   1.00000   1.00000        10\n",
      "          10    1.00000   1.00000   1.00000        14\n",
      "          11    1.00000   1.00000   1.00000        14\n",
      "          12    0.98462   1.00000   0.99225        64\n",
      "          13    1.00000   1.00000   1.00000        14\n",
      "          14    1.00000   1.00000   1.00000        61\n",
      "          15    1.00000   1.00000   1.00000        14\n",
      "          16    1.00000   1.00000   1.00000        14\n",
      "          17    1.00000   1.00000   1.00000        14\n",
      "\n",
      "    accuracy                        0.99788       472\n",
      "   macro avg    0.99915   0.99913   0.99913       472\n",
      "weighted avg    0.99791   0.99788   0.99788       472\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000         5\n",
      "           1    0.95652   0.81481   0.88000        27\n",
      "           2    1.00000   1.00000   1.00000        13\n",
      "           3    0.85714   1.00000   0.92308         6\n",
      "           4    1.00000   0.83333   0.90909         6\n",
      "           5    1.00000   0.89286   0.94340        28\n",
      "           6    1.00000   1.00000   1.00000        13\n",
      "           7    1.00000   1.00000   1.00000         6\n",
      "           8    1.00000   1.00000   1.00000         4\n",
      "           9    1.00000   1.00000   1.00000         5\n",
      "          10    1.00000   1.00000   1.00000         6\n",
      "          11    1.00000   1.00000   1.00000         6\n",
      "          12    0.78125   0.92593   0.84746        27\n",
      "          13    0.75000   1.00000   0.85714         6\n",
      "          14    1.00000   1.00000   1.00000        27\n",
      "          15    1.00000   1.00000   1.00000         6\n",
      "          16    1.00000   1.00000   1.00000         6\n",
      "          17    1.00000   1.00000   1.00000         6\n",
      "\n",
      "    accuracy                        0.94581       203\n",
      "   macro avg    0.96361   0.97039   0.96445       203\n",
      "weighted avg    0.95351   0.94581   0.94676       203\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1206\n",
      "Average of depth: 1.554726368159204\n",
      "Number of nodes: 5226\n",
      "28 110 1\n",
      "52 214 2\n",
      "73 291 3\n",
      "98 400 4\n",
      "115 467 5\n",
      "134 542 6\n",
      "157 631 7\n",
      "183 741 8\n",
      "202 816 9\n",
      "217 871 10\n",
      "239 951 11\n",
      "254 1012 12\n",
      "274 1086 13\n",
      "292 1156 14\n",
      "304 1196 15\n",
      "322 1268 16\n",
      "337 1329 17\n",
      "350 1382 18\n",
      "362 1438 19\n",
      "377 1497 20\n",
      "388 1542 21\n",
      "399 1585 22\n",
      "412 1638 23\n",
      "427 1709 24\n",
      "443 1779 25\n",
      "455 1823 26\n",
      "470 1890 27\n",
      "482 1938 28\n",
      "495 1985 29\n",
      "510 2058 30\n",
      "524 2112 31\n",
      "537 2161 32\n",
      "555 2235 33\n",
      "570 2300 34\n",
      "576 2328 35\n",
      "586 2368 36\n",
      "597 2417 37\n",
      "613 2485 38\n",
      "626 2534 39\n",
      "640 2600 40\n",
      "652 2648 41\n",
      "665 2699 42\n",
      "681 2769 43\n",
      "695 2845 44\n",
      "708 2902 45\n",
      "727 2987 46\n",
      "740 3042 47\n",
      "752 3098 48\n",
      "763 3147 49\n",
      "772 3188 50\n",
      "784 3228 51\n",
      "789 3243 52\n",
      "798 3280 53\n",
      "813 3345 54\n",
      "820 3378 55\n",
      "838 3460 56\n",
      "851 3521 57\n",
      "864 3578 58\n",
      "877 3627 59\n",
      "888 3670 60\n",
      "895 3703 61\n",
      "903 3737 62\n",
      "914 3772 63\n",
      "925 3821 64\n",
      "934 3860 65\n",
      "940 3882 66\n",
      "951 3937 67\n",
      "964 3996 68\n",
      "973 4039 69\n",
      "982 4078 70\n",
      "994 4138 71\n",
      "1007 4207 72\n",
      "1017 4237 73\n",
      "1026 4270 74\n",
      "1035 4309 75\n",
      "1053 4399 76\n",
      "1060 4428 77\n",
      "1066 4452 78\n",
      "1081 4525 79\n",
      "1091 4567 80\n",
      "1104 4626 81\n",
      "1112 4666 82\n",
      "1119 4695 83\n",
      "1127 4735 84\n",
      "1136 4778 85\n",
      "1144 4822 86\n",
      "1150 4846 87\n",
      "1154 4868 88\n",
      "1160 4892 89\n",
      "1172 4940 90\n",
      "1180 4982 91\n",
      "1193 5039 92\n",
      "1201 5071 93\n",
      "1206 5094 94\n",
      "1214 5128 95\n",
      "1219 5151 96\n",
      "1224 5164 97\n",
      "1235 5219 98\n",
      "1241 5243 99\n",
      "1250 5282 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.989406779661017 8.86640867533305 \ttest: 0.9556650246305419 14.281111628610455\n",
      "retrain  2 :\n",
      "\ttrain: 0.9936440677966102 5.775648717153226 \ttest: 0.9556650246305419 14.411100588522407\n",
      "retrain  3 :\n",
      "\ttrain: 0.9957627118644068 4.213155755259946 \ttest: 0.9556650246305419 14.607629337853183\n",
      "retrain  4 :\n",
      "\ttrain: 0.9978813559322034 3.2316747902666725 \ttest: 0.9556650246305419 14.78056762069242\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 2.5596499386092737 \ttest: 0.9556650246305419 14.920696333319643\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        11\n",
      "           1    1.00000   1.00000   1.00000        64\n",
      "           2    1.00000   1.00000   1.00000        31\n",
      "           3    1.00000   1.00000   1.00000        14\n",
      "           4    1.00000   1.00000   1.00000        14\n",
      "           5    1.00000   1.00000   1.00000        64\n",
      "           6    1.00000   1.00000   1.00000        31\n",
      "           7    1.00000   1.00000   1.00000        14\n",
      "           8    1.00000   1.00000   1.00000        10\n",
      "           9    1.00000   1.00000   1.00000        10\n",
      "          10    1.00000   1.00000   1.00000        14\n",
      "          11    1.00000   1.00000   1.00000        14\n",
      "          12    1.00000   1.00000   1.00000        64\n",
      "          13    1.00000   1.00000   1.00000        14\n",
      "          14    1.00000   1.00000   1.00000        61\n",
      "          15    1.00000   1.00000   1.00000        14\n",
      "          16    1.00000   1.00000   1.00000        14\n",
      "          17    1.00000   1.00000   1.00000        14\n",
      "\n",
      "    accuracy                        1.00000       472\n",
      "   macro avg    1.00000   1.00000   1.00000       472\n",
      "weighted avg    1.00000   1.00000   1.00000       472\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000         5\n",
      "           1    0.83333   0.92593   0.87719        27\n",
      "           2    1.00000   1.00000   1.00000        13\n",
      "           3    1.00000   1.00000   1.00000         6\n",
      "           4    1.00000   1.00000   1.00000         6\n",
      "           5    0.96296   0.92857   0.94545        28\n",
      "           6    1.00000   1.00000   1.00000        13\n",
      "           7    1.00000   1.00000   1.00000         6\n",
      "           8    1.00000   1.00000   1.00000         4\n",
      "           9    1.00000   1.00000   1.00000         5\n",
      "          10    1.00000   1.00000   1.00000         6\n",
      "          11    1.00000   1.00000   1.00000         6\n",
      "          12    0.88462   0.85185   0.86792        27\n",
      "          13    1.00000   0.83333   0.90909         6\n",
      "          14    1.00000   1.00000   1.00000        27\n",
      "          15    1.00000   1.00000   1.00000         6\n",
      "          16    1.00000   1.00000   1.00000         6\n",
      "          17    1.00000   1.00000   1.00000         6\n",
      "\n",
      "    accuracy                        0.95567       203\n",
      "   macro avg    0.98227   0.97443   0.97776       203\n",
      "weighted avg    0.95738   0.95567   0.95589       203\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1250\n",
      "Average of depth: 1.5144\n",
      "Number of nodes: 5282\n",
      "24 84 1\n",
      "47 169 2\n",
      "65 235 3\n",
      "82 288 4\n",
      "100 366 5\n",
      "119 435 6\n",
      "135 495 7\n",
      "154 582 8\n",
      "172 662 9\n",
      "189 719 10\n",
      "205 789 11\n",
      "223 873 12\n",
      "239 931 13\n",
      "260 1004 14\n",
      "276 1072 15\n",
      "293 1145 16\n",
      "310 1206 17\n",
      "322 1252 18\n",
      "332 1292 19\n",
      "350 1370 20\n",
      "365 1439 21\n",
      "380 1500 22\n",
      "393 1553 23\n",
      "406 1608 24\n",
      "426 1696 25\n",
      "441 1757 26\n",
      "456 1812 27\n",
      "468 1868 28\n",
      "484 1936 29\n",
      "499 1999 30\n",
      "514 2056 31\n",
      "529 2113 32\n",
      "542 2164 33\n",
      "555 2217 34\n",
      "567 2271 35\n",
      "578 2318 36\n",
      "595 2397 37\n",
      "603 2425 38\n",
      "618 2500 39\n",
      "630 2546 40\n",
      "639 2575 41\n",
      "652 2634 42\n",
      "662 2680 43\n",
      "674 2724 44\n",
      "685 2773 45\n",
      "692 2808 46\n",
      "703 2843 47\n",
      "707 2863 48\n",
      "717 2903 49\n",
      "727 2953 50\n",
      "733 2989 51\n",
      "745 3039 52\n",
      "754 3072 53\n",
      "765 3137 54\n",
      "782 3212 55\n",
      "794 3268 56\n",
      "806 3328 57\n",
      "815 3365 58\n",
      "825 3403 59\n",
      "837 3453 60\n",
      "845 3499 61\n",
      "854 3544 62\n",
      "861 3571 63\n",
      "872 3624 64\n",
      "887 3685 65\n",
      "894 3704 66\n",
      "905 3753 67\n",
      "913 3777 68\n",
      "927 3825 69\n",
      "930 3832 70\n",
      "939 3879 71\n",
      "951 3949 72\n",
      "960 3992 73\n",
      "973 4053 74\n",
      "979 4079 75\n",
      "984 4096 76\n",
      "993 4141 77\n",
      "1001 4179 78\n",
      "1011 4221 79\n",
      "1018 4252 80\n",
      "1022 4268 81\n",
      "1027 4291 82\n",
      "1034 4324 83\n",
      "1040 4344 84\n",
      "1050 4400 85\n",
      "1058 4438 86\n",
      "1070 4484 87\n",
      "1078 4520 88\n",
      "1089 4567 89\n",
      "1094 4588 90\n",
      "1101 4621 91\n",
      "1108 4650 92\n",
      "1114 4678 93\n",
      "1120 4706 94\n",
      "1128 4746 95\n",
      "1136 4784 96\n",
      "1147 4831 97\n",
      "1156 4860 98\n",
      "1166 4908 99\n",
      "1180 4984 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.9957627118644068 6.498935444907098 \ttest: 0.9113300492610837 22.639081459356838\n",
      "retrain  2 :\n",
      "\ttrain: 0.9978813559322034 3.9696312704250567 \ttest: 0.916256157635468 22.42360980016273\n",
      "retrain  3 :\n",
      "\ttrain: 0.9978813559322034 2.8759688312805123 \ttest: 0.9211822660098522 22.57730606534033\n",
      "retrain  4 :\n",
      "\ttrain: 0.9978813559322034 2.28841476091115 \ttest: 0.9211822660098522 22.79564215083852\n",
      "retrain  5 :\n",
      "\ttrain: 0.9978813559322034 1.9363004914651836 \ttest: 0.9211822660098522 23.013026882220736\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        11\n",
      "           1    0.98462   1.00000   0.99225        64\n",
      "           2    1.00000   1.00000   1.00000        31\n",
      "           3    1.00000   1.00000   1.00000        14\n",
      "           4    1.00000   1.00000   1.00000        14\n",
      "           5    1.00000   1.00000   1.00000        64\n",
      "           6    1.00000   1.00000   1.00000        31\n",
      "           7    1.00000   1.00000   1.00000        14\n",
      "           8    1.00000   1.00000   1.00000        10\n",
      "           9    1.00000   1.00000   1.00000        10\n",
      "          10    1.00000   1.00000   1.00000        14\n",
      "          11    1.00000   1.00000   1.00000        14\n",
      "          12    1.00000   0.98438   0.99213        64\n",
      "          13    1.00000   1.00000   1.00000        14\n",
      "          14    1.00000   1.00000   1.00000        61\n",
      "          15    1.00000   1.00000   1.00000        14\n",
      "          16    1.00000   1.00000   1.00000        14\n",
      "          17    1.00000   1.00000   1.00000        14\n",
      "\n",
      "    accuracy                        0.99788       472\n",
      "   macro avg    0.99915   0.99913   0.99913       472\n",
      "weighted avg    0.99791   0.99788   0.99788       472\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000         5\n",
      "           1    0.74286   0.96296   0.83871        27\n",
      "           2    1.00000   1.00000   1.00000        13\n",
      "           3    0.75000   1.00000   0.85714         6\n",
      "           4    1.00000   0.66667   0.80000         6\n",
      "           5    0.89286   0.89286   0.89286        28\n",
      "           6    1.00000   1.00000   1.00000        13\n",
      "           7    1.00000   1.00000   1.00000         6\n",
      "           8    1.00000   1.00000   1.00000         4\n",
      "           9    1.00000   1.00000   1.00000         5\n",
      "          10    1.00000   1.00000   1.00000         6\n",
      "          11    1.00000   1.00000   1.00000         6\n",
      "          12    0.90909   0.74074   0.81633        27\n",
      "          13    1.00000   0.50000   0.66667         6\n",
      "          14    1.00000   1.00000   1.00000        27\n",
      "          15    1.00000   1.00000   1.00000         6\n",
      "          16    1.00000   1.00000   1.00000         6\n",
      "          17    1.00000   1.00000   1.00000         6\n",
      "\n",
      "    accuracy                        0.92118       203\n",
      "   macro avg    0.96082   0.93129   0.93732       203\n",
      "weighted avg    0.93154   0.92118   0.91935       203\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1180\n",
      "Average of depth: 1.5110169491525425\n",
      "Number of nodes: 4984\n",
      "25 103 1\n",
      "53 211 2\n",
      "77 313 3\n",
      "100 406 4\n",
      "123 497 5\n",
      "144 574 6\n",
      "163 651 7\n",
      "183 727 8\n",
      "210 854 9\n",
      "234 944 10\n",
      "252 1016 11\n",
      "270 1100 12\n",
      "292 1180 13\n",
      "312 1264 14\n",
      "326 1318 15\n",
      "342 1390 16\n",
      "358 1442 17\n",
      "370 1496 18\n",
      "389 1579 19\n",
      "410 1678 20\n",
      "423 1733 21\n",
      "437 1791 22\n",
      "453 1861 23\n",
      "467 1909 24\n",
      "480 1958 25\n",
      "493 2017 26\n",
      "508 2080 27\n",
      "517 2113 28\n",
      "530 2170 29\n",
      "544 2240 30\n",
      "554 2280 31\n",
      "565 2329 32\n",
      "573 2363 33\n",
      "584 2406 34\n",
      "594 2446 35\n",
      "605 2499 36\n",
      "620 2566 37\n",
      "630 2608 38\n",
      "642 2654 39\n",
      "651 2697 40\n",
      "662 2740 41\n",
      "675 2793 42\n",
      "689 2849 43\n",
      "701 2895 44\n",
      "711 2937 45\n",
      "723 2999 46\n",
      "734 3046 47\n",
      "748 3116 48\n",
      "763 3179 49\n",
      "773 3219 50\n",
      "780 3252 51\n",
      "785 3275 52\n",
      "795 3319 53\n",
      "803 3347 54\n",
      "810 3390 55\n",
      "818 3424 56\n",
      "823 3447 57\n",
      "833 3493 58\n",
      "842 3534 59\n",
      "849 3559 60\n",
      "855 3585 61\n",
      "867 3645 62\n",
      "876 3690 63\n",
      "886 3736 64\n",
      "894 3784 65\n",
      "903 3823 66\n",
      "908 3840 67\n",
      "914 3866 68\n",
      "927 3929 69\n",
      "939 3985 70\n",
      "949 4023 71\n",
      "956 4050 72\n",
      "965 4099 73\n",
      "968 4110 74\n",
      "980 4170 75\n",
      "985 4193 76\n",
      "995 4231 77\n",
      "1001 4259 78\n",
      "1011 4303 79\n",
      "1016 4332 80\n",
      "1024 4372 81\n",
      "1036 4428 82\n",
      "1044 4468 83\n",
      "1057 4523 84\n",
      "1062 4540 85\n",
      "1071 4577 86\n",
      "1078 4616 87\n",
      "1091 4663 88\n",
      "1101 4713 89\n",
      "1111 4755 90\n",
      "1121 4799 91\n",
      "1132 4844 92\n",
      "1136 4856 93\n",
      "1142 4878 94\n",
      "1146 4894 95\n",
      "1156 4940 96\n",
      "1164 4978 97\n",
      "1176 5034 98\n",
      "1182 5056 99\n",
      "1189 5089 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.9936440677966102 7.409474227455123 \ttest: 0.9261083743842364 20.158248569491953\n",
      "retrain  2 :\n",
      "\ttrain: 0.9978813559322034 4.205573888913883 \ttest: 0.9310344827586207 20.86655446437486\n",
      "retrain  3 :\n",
      "\ttrain: 0.9978813559322034 2.9910202657979874 \ttest: 0.9310344827586207 21.497551720007138\n",
      "retrain  4 :\n",
      "\ttrain: 0.9978813559322034 2.3705810997184527 \ttest: 0.9310344827586207 21.982651632644213\n",
      "retrain  5 :\n",
      "\ttrain: 0.9978813559322034 2.004251969980659 \ttest: 0.9310344827586207 22.358699920313967\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        11\n",
      "           1    0.98462   1.00000   0.99225        64\n",
      "           2    1.00000   1.00000   1.00000        31\n",
      "           3    1.00000   1.00000   1.00000        14\n",
      "           4    1.00000   1.00000   1.00000        14\n",
      "           5    1.00000   1.00000   1.00000        64\n",
      "           6    1.00000   1.00000   1.00000        31\n",
      "           7    1.00000   1.00000   1.00000        14\n",
      "           8    1.00000   1.00000   1.00000        10\n",
      "           9    1.00000   1.00000   1.00000        10\n",
      "          10    1.00000   1.00000   1.00000        14\n",
      "          11    1.00000   1.00000   1.00000        14\n",
      "          12    1.00000   0.98438   0.99213        64\n",
      "          13    1.00000   1.00000   1.00000        14\n",
      "          14    1.00000   1.00000   1.00000        61\n",
      "          15    1.00000   1.00000   1.00000        14\n",
      "          16    1.00000   1.00000   1.00000        14\n",
      "          17    1.00000   1.00000   1.00000        14\n",
      "\n",
      "    accuracy                        0.99788       472\n",
      "   macro avg    0.99915   0.99913   0.99913       472\n",
      "weighted avg    0.99791   0.99788   0.99788       472\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000         5\n",
      "           1    0.77419   0.88889   0.82759        27\n",
      "           2    1.00000   1.00000   1.00000        13\n",
      "           3    1.00000   1.00000   1.00000         6\n",
      "           4    1.00000   0.83333   0.90909         6\n",
      "           5    0.92857   0.92857   0.92857        28\n",
      "           6    1.00000   1.00000   1.00000        13\n",
      "           7    1.00000   1.00000   1.00000         6\n",
      "           8    1.00000   1.00000   1.00000         4\n",
      "           9    1.00000   1.00000   1.00000         5\n",
      "          10    1.00000   1.00000   1.00000         6\n",
      "          11    1.00000   1.00000   1.00000         6\n",
      "          12    0.80000   0.74074   0.76923        27\n",
      "          13    1.00000   0.83333   0.90909         6\n",
      "          14    1.00000   1.00000   1.00000        27\n",
      "          15    1.00000   1.00000   1.00000         6\n",
      "          16    1.00000   1.00000   1.00000         6\n",
      "          17    1.00000   1.00000   1.00000         6\n",
      "\n",
      "    accuracy                        0.93103       203\n",
      "   macro avg    0.97238   0.95694   0.96353       203\n",
      "weighted avg    0.93351   0.93103   0.93115       203\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1189\n",
      "Average of depth: 1.5391084945332212\n",
      "Number of nodes: 5089\n",
      "28 106 1\n",
      "51 187 2\n",
      "69 251 3\n",
      "88 320 4\n",
      "113 415 5\n",
      "130 480 6\n",
      "152 560 7\n",
      "170 638 8\n",
      "191 735 9\n",
      "204 784 10\n",
      "221 851 11\n",
      "241 927 12\n",
      "252 976 13\n",
      "267 1041 14\n",
      "287 1113 15\n",
      "305 1183 16\n",
      "318 1232 17\n",
      "330 1284 18\n",
      "345 1353 19\n",
      "355 1395 20\n",
      "368 1440 21\n",
      "377 1473 22\n",
      "390 1532 23\n",
      "402 1580 24\n",
      "409 1603 25\n",
      "423 1673 26\n",
      "434 1708 27\n",
      "450 1770 28\n",
      "465 1833 29\n",
      "486 1918 30\n",
      "497 1967 31\n",
      "507 2003 32\n",
      "524 2068 33\n",
      "536 2114 34\n",
      "547 2165 35\n",
      "561 2213 36\n",
      "574 2268 37\n",
      "586 2324 38\n",
      "599 2375 39\n",
      "608 2418 40\n",
      "621 2471 41\n",
      "636 2530 42\n",
      "648 2574 43\n",
      "663 2637 44\n",
      "679 2701 45\n",
      "693 2761 46\n",
      "701 2803 47\n",
      "715 2865 48\n",
      "724 2906 49\n",
      "733 2949 50\n",
      "742 2996 51\n",
      "751 3035 52\n",
      "760 3076 53\n",
      "769 3115 54\n",
      "778 3152 55\n",
      "788 3196 56\n",
      "798 3240 57\n",
      "806 3274 58\n",
      "819 3323 59\n",
      "827 3353 60\n",
      "840 3400 61\n",
      "852 3454 62\n",
      "862 3496 63\n",
      "872 3536 64\n",
      "882 3580 65\n",
      "893 3625 66\n",
      "902 3672 67\n",
      "911 3705 68\n",
      "923 3763 69\n",
      "932 3798 70\n",
      "940 3838 71\n",
      "950 3886 72\n",
      "956 3910 73\n",
      "963 3939 74\n",
      "971 3971 75\n",
      "980 4006 76\n",
      "986 4028 77\n",
      "1001 4083 78\n",
      "1009 4133 79\n",
      "1019 4183 80\n",
      "1028 4220 81\n",
      "1038 4266 82\n",
      "1047 4311 83\n",
      "1053 4335 84\n",
      "1061 4375 85\n",
      "1075 4449 86\n",
      "1089 4517 87\n",
      "1099 4575 88\n",
      "1106 4604 89\n",
      "1113 4649 90\n",
      "1116 4662 91\n",
      "1128 4730 92\n",
      "1135 4763 93\n",
      "1143 4807 94\n",
      "1154 4854 95\n",
      "1159 4873 96\n",
      "1165 4903 97\n",
      "1168 4906 98\n",
      "1175 4937 99\n",
      "1182 4970 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.989406779661017 7.197367064107986 \ttest: 0.9211822660098522 24.464363049118795\n",
      "retrain  2 :\n",
      "\ttrain: 0.9936440677966102 4.876787463992361 \ttest: 0.9211822660098522 24.881935460110164\n",
      "retrain  3 :\n",
      "\ttrain: 0.9957627118644068 3.7795290119400757 \ttest: 0.9211822660098522 25.15961430975576\n",
      "retrain  4 :\n",
      "\ttrain: 0.9957627118644068 3.118805965843662 \ttest: 0.9211822660098522 25.387416016452278\n",
      "retrain  5 :\n",
      "\ttrain: 0.9978813559322034 2.6758406795987844 \ttest: 0.9261083743842364 25.58917553182878\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        11\n",
      "           1    0.98462   1.00000   0.99225        64\n",
      "           2    1.00000   1.00000   1.00000        31\n",
      "           3    1.00000   1.00000   1.00000        14\n",
      "           4    1.00000   1.00000   1.00000        14\n",
      "           5    1.00000   1.00000   1.00000        64\n",
      "           6    1.00000   1.00000   1.00000        31\n",
      "           7    1.00000   1.00000   1.00000        14\n",
      "           8    1.00000   1.00000   1.00000        10\n",
      "           9    1.00000   1.00000   1.00000        10\n",
      "          10    1.00000   1.00000   1.00000        14\n",
      "          11    1.00000   1.00000   1.00000        14\n",
      "          12    1.00000   0.98438   0.99213        64\n",
      "          13    1.00000   1.00000   1.00000        14\n",
      "          14    1.00000   1.00000   1.00000        61\n",
      "          15    1.00000   1.00000   1.00000        14\n",
      "          16    1.00000   1.00000   1.00000        14\n",
      "          17    1.00000   1.00000   1.00000        14\n",
      "\n",
      "    accuracy                        0.99788       472\n",
      "   macro avg    0.99915   0.99913   0.99913       472\n",
      "weighted avg    0.99791   0.99788   0.99788       472\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000         5\n",
      "           1    0.70270   0.96296   0.81250        27\n",
      "           2    1.00000   1.00000   1.00000        13\n",
      "           3    0.85714   1.00000   0.92308         6\n",
      "           4    1.00000   0.83333   0.90909         6\n",
      "           5    0.96296   0.92857   0.94545        28\n",
      "           6    1.00000   1.00000   1.00000        13\n",
      "           7    1.00000   1.00000   1.00000         6\n",
      "           8    1.00000   1.00000   1.00000         4\n",
      "           9    1.00000   1.00000   1.00000         5\n",
      "          10    1.00000   1.00000   1.00000         6\n",
      "          11    1.00000   1.00000   1.00000         6\n",
      "          12    0.89474   0.62963   0.73913        27\n",
      "          13    1.00000   0.83333   0.90909         6\n",
      "          14    1.00000   1.00000   1.00000        27\n",
      "          15    1.00000   1.00000   1.00000         6\n",
      "          16    1.00000   1.00000   1.00000         6\n",
      "          17    1.00000   1.00000   1.00000         6\n",
      "\n",
      "    accuracy                        0.92611       203\n",
      "   macro avg    0.96764   0.95488   0.95769       203\n",
      "weighted avg    0.93713   0.92611   0.92519       203\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1182\n",
      "Average of depth: 1.5101522842639594\n",
      "Number of nodes: 4970\n",
      "28 128 1\n",
      "52 222 2\n",
      "73 297 3\n",
      "97 401 4\n",
      "114 462 5\n",
      "134 540 6\n",
      "155 613 7\n",
      "172 676 8\n",
      "190 746 9\n",
      "208 810 10\n",
      "224 870 11\n",
      "241 925 12\n",
      "262 1016 13\n",
      "277 1075 14\n",
      "290 1132 15\n",
      "300 1174 16\n",
      "313 1225 17\n",
      "327 1273 18\n",
      "341 1327 19\n",
      "353 1375 20\n",
      "369 1431 21\n",
      "382 1482 22\n",
      "401 1555 23\n",
      "416 1622 24\n",
      "432 1700 25\n",
      "448 1758 26\n",
      "463 1823 27\n",
      "477 1887 28\n",
      "489 1943 29\n",
      "507 2005 30\n",
      "521 2065 31\n",
      "533 2115 32\n",
      "546 2168 33\n",
      "556 2210 34\n",
      "569 2257 35\n",
      "584 2316 36\n",
      "600 2380 37\n",
      "610 2420 38\n",
      "619 2461 39\n",
      "632 2516 40\n",
      "646 2590 41\n",
      "658 2632 42\n",
      "672 2692 43\n",
      "684 2756 44\n",
      "698 2824 45\n",
      "712 2898 46\n",
      "726 2976 47\n",
      "733 3001 48\n",
      "740 3028 49\n",
      "749 3063 50\n",
      "758 3102 51\n",
      "771 3167 52\n",
      "780 3216 53\n",
      "789 3247 54\n",
      "802 3304 55\n",
      "812 3346 56\n",
      "818 3380 57\n",
      "827 3413 58\n",
      "840 3464 59\n",
      "852 3508 60\n",
      "864 3570 61\n",
      "875 3623 62\n",
      "884 3656 63\n",
      "888 3666 64\n",
      "895 3697 65\n",
      "905 3745 66\n",
      "912 3784 67\n",
      "922 3828 68\n",
      "933 3883 69\n",
      "940 3912 70\n",
      "951 3965 71\n",
      "961 4005 72\n",
      "970 4046 73\n",
      "980 4082 74\n",
      "986 4108 75\n",
      "995 4145 76\n",
      "1004 4174 77\n",
      "1016 4228 78\n",
      "1029 4287 79\n",
      "1035 4315 80\n",
      "1041 4351 81\n",
      "1050 4400 82\n",
      "1060 4446 83\n",
      "1070 4490 84\n",
      "1076 4516 85\n",
      "1089 4591 86\n",
      "1102 4646 87\n",
      "1112 4678 88\n",
      "1119 4711 89\n",
      "1124 4736 90\n",
      "1133 4781 91\n",
      "1144 4828 92\n",
      "1152 4868 93\n",
      "1159 4893 94\n",
      "1173 4959 95\n",
      "1181 4995 96\n",
      "1187 5025 97\n",
      "1197 5065 98\n",
      "1205 5105 99\n",
      "1211 5137 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.9851694915254238 10.982202654348987 \ttest: 0.9556650246305419 15.204042199479181\n",
      "retrain  2 :\n",
      "\ttrain: 0.9957627118644068 7.3843923590548926 \ttest: 0.9605911330049262 15.002651711935258\n",
      "retrain  3 :\n",
      "\ttrain: 0.9978813559322034 5.662436312280769 \ttest: 0.9655172413793104 15.080198793384778\n",
      "retrain  4 :\n",
      "\ttrain: 0.9978813559322034 4.6234381170858505 \ttest: 0.9605911330049262 15.196390042968806\n",
      "retrain  5 :\n",
      "\ttrain: 0.9978813559322034 3.9233153536734706 \ttest: 0.9556650246305419 15.308446119380875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        11\n",
      "           1    0.98462   1.00000   0.99225        64\n",
      "           2    1.00000   1.00000   1.00000        31\n",
      "           3    1.00000   1.00000   1.00000        14\n",
      "           4    1.00000   1.00000   1.00000        14\n",
      "           5    1.00000   1.00000   1.00000        64\n",
      "           6    1.00000   1.00000   1.00000        31\n",
      "           7    1.00000   1.00000   1.00000        14\n",
      "           8    1.00000   1.00000   1.00000        10\n",
      "           9    1.00000   1.00000   1.00000        10\n",
      "          10    1.00000   1.00000   1.00000        14\n",
      "          11    1.00000   1.00000   1.00000        14\n",
      "          12    1.00000   0.98438   0.99213        64\n",
      "          13    1.00000   1.00000   1.00000        14\n",
      "          14    1.00000   1.00000   1.00000        61\n",
      "          15    1.00000   1.00000   1.00000        14\n",
      "          16    1.00000   1.00000   1.00000        14\n",
      "          17    1.00000   1.00000   1.00000        14\n",
      "\n",
      "    accuracy                        0.99788       472\n",
      "   macro avg    0.99915   0.99913   0.99913       472\n",
      "weighted avg    0.99791   0.99788   0.99788       472\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000         5\n",
      "           1    0.85714   0.88889   0.87273        27\n",
      "           2    1.00000   1.00000   1.00000        13\n",
      "           3    1.00000   1.00000   1.00000         6\n",
      "           4    1.00000   1.00000   1.00000         6\n",
      "           5    0.93333   1.00000   0.96552        28\n",
      "           6    1.00000   1.00000   1.00000        13\n",
      "           7    1.00000   1.00000   1.00000         6\n",
      "           8    1.00000   1.00000   1.00000         4\n",
      "           9    1.00000   1.00000   1.00000         5\n",
      "          10    1.00000   1.00000   1.00000         6\n",
      "          11    1.00000   1.00000   1.00000         6\n",
      "          12    0.88000   0.81481   0.84615        27\n",
      "          13    1.00000   0.83333   0.90909         6\n",
      "          14    1.00000   1.00000   1.00000        27\n",
      "          15    1.00000   1.00000   1.00000         6\n",
      "          16    1.00000   1.00000   1.00000         6\n",
      "          17    1.00000   1.00000   1.00000         6\n",
      "\n",
      "    accuracy                        0.95567       203\n",
      "   macro avg    0.98169   0.97428   0.97742       203\n",
      "weighted avg    0.95584   0.95567   0.95517       203\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1211\n",
      "Average of depth: 1.5161023947151115\n",
      "Number of nodes: 5137\n",
      "28 102 1\n",
      "48 176 2\n",
      "72 274 3\n",
      "92 350 4\n",
      "116 456 5\n",
      "139 543 6\n",
      "158 630 7\n",
      "174 692 8\n",
      "193 771 9\n",
      "212 842 10\n",
      "228 894 11\n",
      "245 961 12\n",
      "264 1050 13\n",
      "277 1105 14\n",
      "292 1154 15\n",
      "314 1246 16\n",
      "331 1315 17\n",
      "347 1377 18\n",
      "362 1436 19\n",
      "377 1495 20\n",
      "389 1543 21\n",
      "405 1611 22\n",
      "424 1700 23\n",
      "437 1765 24\n",
      "448 1806 25\n",
      "461 1855 26\n",
      "471 1889 27\n",
      "484 1948 28\n",
      "500 2020 29\n",
      "511 2061 30\n",
      "523 2105 31\n",
      "533 2153 32\n",
      "548 2210 33\n",
      "555 2239 34\n",
      "567 2301 35\n",
      "576 2342 36\n",
      "591 2403 37\n",
      "603 2447 38\n",
      "614 2502 39\n",
      "630 2574 40\n",
      "644 2650 41\n",
      "659 2711 42\n",
      "672 2760 43\n",
      "691 2849 44\n",
      "704 2908 45\n",
      "714 2958 46\n",
      "728 3006 47\n",
      "746 3088 48\n",
      "757 3133 49\n",
      "763 3163 50\n",
      "773 3197 51\n",
      "785 3249 52\n",
      "794 3280 53\n",
      "801 3311 54\n",
      "810 3348 55\n",
      "818 3388 56\n",
      "826 3416 57\n",
      "838 3462 58\n",
      "846 3496 59\n",
      "858 3550 60\n",
      "862 3568 61\n",
      "873 3621 62\n",
      "884 3670 63\n",
      "892 3710 64\n",
      "899 3743 65\n",
      "909 3787 66\n",
      "919 3829 67\n",
      "929 3869 68\n",
      "942 3916 69\n",
      "951 3951 70\n",
      "960 4004 71\n",
      "965 4025 72\n",
      "974 4068 73\n",
      "983 4103 74\n",
      "991 4135 75\n",
      "1001 4181 76\n",
      "1008 4204 77\n",
      "1021 4279 78\n",
      "1036 4356 79\n",
      "1042 4376 80\n",
      "1053 4429 81\n",
      "1059 4455 82\n",
      "1068 4494 83\n",
      "1078 4538 84\n",
      "1089 4581 85\n",
      "1103 4657 86\n",
      "1106 4668 87\n",
      "1115 4699 88\n",
      "1126 4744 89\n",
      "1136 4794 90\n",
      "1140 4812 91\n",
      "1154 4872 92\n",
      "1162 4906 93\n",
      "1169 4935 94\n",
      "1180 4984 95\n",
      "1192 5042 96\n",
      "1202 5106 97\n",
      "1209 5139 98\n",
      "1216 5168 99\n",
      "1227 5223 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.9936440677966102 6.90737029739097 \ttest: 0.9458128078817734 17.27469615854921\n",
      "retrain  2 :\n",
      "\ttrain: 0.9957627118644068 4.009086173042611 \ttest: 0.9507389162561576 17.928626342125604\n",
      "retrain  3 :\n",
      "\ttrain: 0.9978813559322034 2.883529600947637 \ttest: 0.9507389162561576 18.358088683656135\n",
      "retrain  4 :\n",
      "\ttrain: 0.9978813559322034 2.2998480575204026 \ttest: 0.9458128078817734 18.668688705574652\n",
      "retrain  5 :\n",
      "\ttrain: 0.9978813559322034 1.9516607597258089 \ttest: 0.9408866995073891 18.912218647261213\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        11\n",
      "           1    0.98462   1.00000   0.99225        64\n",
      "           2    1.00000   1.00000   1.00000        31\n",
      "           3    1.00000   1.00000   1.00000        14\n",
      "           4    1.00000   1.00000   1.00000        14\n",
      "           5    1.00000   1.00000   1.00000        64\n",
      "           6    1.00000   1.00000   1.00000        31\n",
      "           7    1.00000   1.00000   1.00000        14\n",
      "           8    1.00000   1.00000   1.00000        10\n",
      "           9    1.00000   1.00000   1.00000        10\n",
      "          10    1.00000   1.00000   1.00000        14\n",
      "          11    1.00000   1.00000   1.00000        14\n",
      "          12    1.00000   0.98438   0.99213        64\n",
      "          13    1.00000   1.00000   1.00000        14\n",
      "          14    1.00000   1.00000   1.00000        61\n",
      "          15    1.00000   1.00000   1.00000        14\n",
      "          16    1.00000   1.00000   1.00000        14\n",
      "          17    1.00000   1.00000   1.00000        14\n",
      "\n",
      "    accuracy                        0.99788       472\n",
      "   macro avg    0.99915   0.99913   0.99913       472\n",
      "weighted avg    0.99791   0.99788   0.99788       472\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000         5\n",
      "           1    0.88000   0.81481   0.84615        27\n",
      "           2    1.00000   1.00000   1.00000        13\n",
      "           3    0.85714   1.00000   0.92308         6\n",
      "           4    1.00000   0.83333   0.90909         6\n",
      "           5    0.93103   0.96429   0.94737        28\n",
      "           6    1.00000   1.00000   1.00000        13\n",
      "           7    1.00000   1.00000   1.00000         6\n",
      "           8    1.00000   1.00000   1.00000         4\n",
      "           9    1.00000   1.00000   1.00000         5\n",
      "          10    1.00000   1.00000   1.00000         6\n",
      "          11    1.00000   1.00000   1.00000         6\n",
      "          12    0.82143   0.85185   0.83636        27\n",
      "          13    0.83333   0.83333   0.83333         6\n",
      "          14    1.00000   1.00000   1.00000        27\n",
      "          15    1.00000   1.00000   1.00000         6\n",
      "          16    1.00000   1.00000   1.00000         6\n",
      "          17    1.00000   1.00000   1.00000         6\n",
      "\n",
      "    accuracy                        0.94089       203\n",
      "   macro avg    0.96239   0.96098   0.96085       203\n",
      "weighted avg    0.94163   0.94089   0.94063       203\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1227\n",
      "Average of depth: 1.5273023634881826\n",
      "Number of nodes: 5223\n",
      "28 98 1\n",
      "54 214 2\n",
      "75 295 3\n",
      "97 383 4\n",
      "122 488 5\n",
      "144 578 6\n",
      "165 661 7\n",
      "179 711 8\n",
      "197 787 9\n",
      "215 859 10\n",
      "233 931 11\n",
      "249 993 12\n",
      "262 1040 13\n",
      "274 1084 14\n",
      "292 1160 15\n",
      "305 1215 16\n",
      "323 1289 17\n",
      "336 1344 18\n",
      "349 1399 19\n",
      "364 1462 20\n",
      "380 1528 21\n",
      "395 1591 22\n",
      "407 1643 23\n",
      "426 1720 24\n",
      "439 1773 25\n",
      "452 1826 26\n",
      "466 1880 27\n",
      "480 1938 28\n",
      "495 2011 29\n",
      "510 2080 30\n",
      "525 2145 31\n",
      "536 2196 32\n",
      "549 2255 33\n",
      "568 2344 34\n",
      "579 2381 35\n",
      "591 2435 36\n",
      "596 2462 37\n",
      "604 2502 38\n",
      "617 2553 39\n",
      "627 2591 40\n",
      "640 2660 41\n",
      "650 2702 42\n",
      "667 2779 43\n",
      "676 2820 44\n",
      "681 2841 45\n",
      "691 2887 46\n",
      "701 2943 47\n",
      "712 2990 48\n",
      "722 3032 49\n",
      "733 3073 50\n",
      "745 3129 51\n",
      "759 3193 52\n",
      "770 3254 53\n",
      "777 3281 54\n",
      "788 3326 55\n",
      "801 3377 56\n",
      "812 3424 57\n",
      "824 3478 58\n",
      "830 3510 59\n",
      "841 3565 60\n",
      "851 3601 61\n",
      "859 3627 62\n",
      "869 3675 63\n",
      "879 3711 64\n",
      "891 3759 65\n",
      "897 3783 66\n",
      "901 3803 67\n",
      "910 3850 68\n",
      "922 3910 69\n",
      "933 3961 70\n",
      "941 3995 71\n",
      "946 4018 72\n",
      "959 4081 73\n",
      "971 4125 74\n",
      "985 4187 75\n",
      "999 4247 76\n",
      "1010 4298 77\n",
      "1023 4371 78\n",
      "1032 4416 79\n",
      "1042 4460 80\n",
      "1054 4514 81\n",
      "1058 4530 82\n",
      "1064 4554 83\n",
      "1076 4616 84\n",
      "1088 4668 85\n",
      "1099 4711 86\n",
      "1103 4727 87\n",
      "1114 4788 88\n",
      "1116 4796 89\n",
      "1125 4837 90\n",
      "1131 4861 91\n",
      "1140 4902 92\n",
      "1151 4949 93\n",
      "1165 5021 94\n",
      "1174 5052 95\n",
      "1179 5065 96\n",
      "1190 5108 97\n",
      "1199 5149 98\n",
      "1211 5207 99\n",
      "1217 5231 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.989406779661017 8.403476259312761 \ttest: 0.9261083743842364 19.947466644923573\n",
      "retrain  2 :\n",
      "\ttrain: 0.9957627118644068 4.903747605745639 \ttest: 0.916256157635468 21.20655149719316\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 3.208556139819295 \ttest: 0.9113300492610837 22.25577403496999\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 2.246472714089793 \ttest: 0.9113300492610837 23.10755621350416\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.65314489073954 \ttest: 0.9113300492610837 23.80380327593188\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        11\n",
      "           1    1.00000   1.00000   1.00000        64\n",
      "           2    1.00000   1.00000   1.00000        31\n",
      "           3    1.00000   1.00000   1.00000        14\n",
      "           4    1.00000   1.00000   1.00000        14\n",
      "           5    1.00000   1.00000   1.00000        64\n",
      "           6    1.00000   1.00000   1.00000        31\n",
      "           7    1.00000   1.00000   1.00000        14\n",
      "           8    1.00000   1.00000   1.00000        10\n",
      "           9    1.00000   1.00000   1.00000        10\n",
      "          10    1.00000   1.00000   1.00000        14\n",
      "          11    1.00000   1.00000   1.00000        14\n",
      "          12    1.00000   1.00000   1.00000        64\n",
      "          13    1.00000   1.00000   1.00000        14\n",
      "          14    1.00000   1.00000   1.00000        61\n",
      "          15    1.00000   1.00000   1.00000        14\n",
      "          16    1.00000   1.00000   1.00000        14\n",
      "          17    1.00000   1.00000   1.00000        14\n",
      "\n",
      "    accuracy                        1.00000       472\n",
      "   macro avg    1.00000   1.00000   1.00000       472\n",
      "weighted avg    1.00000   1.00000   1.00000       472\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000         5\n",
      "           1    0.80769   0.77778   0.79245        27\n",
      "           2    1.00000   1.00000   1.00000        13\n",
      "           3    0.85714   1.00000   0.92308         6\n",
      "           4    1.00000   0.83333   0.90909         6\n",
      "           5    0.86667   0.92857   0.89655        28\n",
      "           6    1.00000   1.00000   1.00000        13\n",
      "           7    1.00000   1.00000   1.00000         6\n",
      "           8    1.00000   1.00000   1.00000         4\n",
      "           9    1.00000   1.00000   1.00000         5\n",
      "          10    1.00000   1.00000   1.00000         6\n",
      "          11    1.00000   1.00000   1.00000         6\n",
      "          12    0.72414   0.77778   0.75000        27\n",
      "          13    1.00000   0.50000   0.66667         6\n",
      "          14    1.00000   1.00000   1.00000        27\n",
      "          15    1.00000   1.00000   1.00000         6\n",
      "          16    1.00000   1.00000   1.00000         6\n",
      "          17    1.00000   1.00000   1.00000         6\n",
      "\n",
      "    accuracy                        0.91133       203\n",
      "   macro avg    0.95865   0.93430   0.94099       203\n",
      "weighted avg    0.91512   0.91133   0.91006       203\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1217\n",
      "Average of depth: 1.5365653245686113\n",
      "Number of nodes: 5231\n",
      "23 79 1\n",
      "46 168 2\n",
      "68 254 3\n",
      "87 343 4\n",
      "105 421 5\n",
      "130 514 6\n",
      "150 590 7\n",
      "167 661 8\n",
      "185 733 9\n",
      "199 791 10\n",
      "215 869 11\n",
      "234 948 12\n",
      "248 1010 13\n",
      "268 1092 14\n",
      "283 1153 15\n",
      "297 1205 16\n",
      "316 1290 17\n",
      "332 1356 18\n",
      "346 1402 19\n",
      "362 1478 20\n",
      "376 1540 21\n",
      "390 1604 22\n",
      "402 1652 23\n",
      "406 1656 24\n",
      "426 1744 25\n",
      "438 1800 26\n",
      "456 1872 27\n",
      "471 1935 28\n",
      "489 2013 29\n",
      "503 2075 30\n",
      "517 2133 31\n",
      "528 2174 32\n",
      "535 2195 33\n",
      "547 2245 34\n",
      "562 2312 35\n",
      "566 2326 36\n",
      "583 2403 37\n",
      "591 2447 38\n",
      "606 2508 39\n",
      "620 2560 40\n",
      "627 2583 41\n",
      "641 2643 42\n",
      "654 2694 43\n",
      "665 2751 44\n",
      "674 2790 45\n",
      "686 2840 46\n",
      "698 2896 47\n",
      "710 2952 48\n",
      "719 2989 49\n",
      "729 3021 50\n",
      "740 3072 51\n",
      "751 3119 52\n",
      "760 3160 53\n",
      "775 3235 54\n",
      "783 3267 55\n",
      "795 3331 56\n",
      "803 3367 57\n",
      "813 3399 58\n",
      "823 3445 59\n",
      "835 3497 60\n",
      "845 3535 61\n",
      "852 3572 62\n",
      "868 3648 63\n",
      "872 3656 64\n",
      "879 3683 65\n",
      "888 3718 66\n",
      "901 3773 67\n",
      "909 3813 68\n",
      "917 3845 69\n",
      "921 3867 70\n",
      "931 3913 71\n",
      "938 3956 72\n",
      "947 3999 73\n",
      "954 4022 74\n",
      "961 4055 75\n",
      "972 4112 76\n",
      "982 4158 77\n",
      "992 4208 78\n",
      "1001 4259 79\n",
      "1004 4270 80\n",
      "1009 4303 81\n",
      "1019 4351 82\n",
      "1028 4390 83\n",
      "1036 4430 84\n",
      "1040 4456 85\n",
      "1050 4506 86\n",
      "1062 4562 87\n",
      "1069 4599 88\n",
      "1077 4629 89\n",
      "1086 4660 90\n",
      "1092 4686 91\n",
      "1102 4726 92\n",
      "1111 4761 93\n",
      "1119 4803 94\n",
      "1126 4830 95\n",
      "1136 4876 96\n",
      "1140 4894 97\n",
      "1145 4911 98\n",
      "1154 4956 99\n",
      "1159 4991 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 5.737711568207482 \ttest: 0.9261083743842364 21.928352854133284\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 2.7580711631003676 \ttest: 0.9261083743842364 23.21476225358749\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 1.65266087266657 \ttest: 0.9261083743842364 23.858071496636658\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 1.1042612210005078 \ttest: 0.9261083743842364 24.27537351758649\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 0.7900552088515681 \ttest: 0.9261083743842364 24.579649033721317\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        11\n",
      "           1    1.00000   1.00000   1.00000        64\n",
      "           2    1.00000   1.00000   1.00000        31\n",
      "           3    1.00000   1.00000   1.00000        14\n",
      "           4    1.00000   1.00000   1.00000        14\n",
      "           5    1.00000   1.00000   1.00000        64\n",
      "           6    1.00000   1.00000   1.00000        31\n",
      "           7    1.00000   1.00000   1.00000        14\n",
      "           8    1.00000   1.00000   1.00000        10\n",
      "           9    1.00000   1.00000   1.00000        10\n",
      "          10    1.00000   1.00000   1.00000        14\n",
      "          11    1.00000   1.00000   1.00000        14\n",
      "          12    1.00000   1.00000   1.00000        64\n",
      "          13    1.00000   1.00000   1.00000        14\n",
      "          14    1.00000   1.00000   1.00000        61\n",
      "          15    1.00000   1.00000   1.00000        14\n",
      "          16    1.00000   1.00000   1.00000        14\n",
      "          17    1.00000   1.00000   1.00000        14\n",
      "\n",
      "    accuracy                        1.00000       472\n",
      "   macro avg    1.00000   1.00000   1.00000       472\n",
      "weighted avg    1.00000   1.00000   1.00000       472\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000         5\n",
      "           1    0.72727   0.88889   0.80000        27\n",
      "           2    1.00000   1.00000   1.00000        13\n",
      "           3    0.85714   1.00000   0.92308         6\n",
      "           4    1.00000   0.83333   0.90909         6\n",
      "           5    1.00000   0.89286   0.94340        28\n",
      "           6    1.00000   1.00000   1.00000        13\n",
      "           7    1.00000   1.00000   1.00000         6\n",
      "           8    1.00000   1.00000   1.00000         4\n",
      "           9    1.00000   1.00000   1.00000         5\n",
      "          10    1.00000   1.00000   1.00000         6\n",
      "          11    1.00000   1.00000   1.00000         6\n",
      "          12    0.79167   0.70370   0.74510        27\n",
      "          13    1.00000   1.00000   1.00000         6\n",
      "          14    1.00000   1.00000   1.00000        27\n",
      "          15    1.00000   1.00000   1.00000         6\n",
      "          16    1.00000   1.00000   1.00000         6\n",
      "          17    1.00000   1.00000   1.00000         6\n",
      "\n",
      "    accuracy                        0.92611       203\n",
      "   macro avg    0.96534   0.96215   0.96226       203\n",
      "weighted avg    0.93179   0.92611   0.92673       203\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1159\n",
      "Average of depth: 1.54702329594478\n",
      "Number of nodes: 4991\n",
      "25 87 1\n",
      "51 195 2\n",
      "68 254 3\n",
      "91 339 4\n",
      "107 391 5\n",
      "128 490 6\n",
      "146 556 7\n",
      "168 652 8\n",
      "188 724 9\n",
      "211 825 10\n",
      "229 893 11\n",
      "243 955 12\n",
      "260 1028 13\n",
      "273 1077 14\n",
      "287 1133 15\n",
      "304 1204 16\n",
      "315 1255 17\n",
      "328 1308 18\n",
      "340 1350 19\n",
      "360 1426 20\n",
      "379 1493 21\n",
      "392 1546 22\n",
      "403 1593 23\n",
      "417 1659 24\n",
      "432 1718 25\n",
      "448 1772 26\n",
      "461 1827 27\n",
      "473 1883 28\n",
      "483 1935 29\n",
      "492 1972 30\n",
      "500 2010 31\n",
      "515 2079 32\n",
      "530 2140 33\n",
      "539 2187 34\n",
      "549 2241 35\n",
      "562 2296 36\n",
      "571 2333 37\n",
      "581 2379 38\n",
      "593 2435 39\n",
      "604 2470 40\n",
      "618 2542 41\n",
      "628 2578 42\n",
      "640 2624 43\n",
      "648 2648 44\n",
      "657 2687 45\n",
      "668 2726 46\n",
      "680 2790 47\n",
      "696 2858 48\n",
      "706 2904 49\n",
      "721 2969 50\n",
      "730 3012 51\n",
      "742 3070 52\n",
      "752 3108 53\n",
      "760 3144 54\n",
      "768 3178 55\n",
      "781 3233 56\n",
      "792 3284 57\n",
      "802 3324 58\n",
      "810 3358 59\n",
      "825 3425 60\n",
      "841 3501 61\n",
      "849 3531 62\n",
      "859 3569 63\n",
      "874 3640 64\n",
      "880 3662 65\n",
      "886 3680 66\n",
      "896 3730 67\n",
      "902 3750 68\n",
      "910 3784 69\n",
      "924 3852 70\n",
      "936 3900 71\n",
      "945 3943 72\n",
      "956 3994 73\n",
      "965 4037 74\n",
      "976 4084 75\n",
      "985 4119 76\n",
      "994 4162 77\n",
      "1007 4227 78\n",
      "1020 4282 79\n",
      "1030 4338 80\n",
      "1040 4390 81\n",
      "1048 4422 82\n",
      "1054 4450 83\n",
      "1063 4489 84\n",
      "1070 4536 85\n",
      "1079 4575 86\n",
      "1089 4615 87\n",
      "1101 4687 88\n",
      "1112 4758 89\n",
      "1120 4796 90\n",
      "1129 4843 91\n",
      "1134 4870 92\n",
      "1141 4897 93\n",
      "1145 4913 94\n",
      "1154 4964 95\n",
      "1165 5019 96\n",
      "1174 5058 97\n",
      "1181 5091 98\n",
      "1188 5126 99\n",
      "1199 5181 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.9957627118644068 7.985444008642221 \ttest: 0.9359605911330049 20.43567557673062\n",
      "retrain  2 :\n",
      "\ttrain: 0.9957627118644068 5.246063375223611 \ttest: 0.9359605911330049 20.519622750300847\n",
      "retrain  3 :\n",
      "\ttrain: 0.9957627118644068 4.031716679585413 \ttest: 0.9359605911330049 20.4936885311998\n",
      "retrain  4 :\n",
      "\ttrain: 0.9957627118644068 3.3110371829224663 \ttest: 0.9359605911330049 20.472523076504288\n",
      "retrain  5 :\n",
      "\ttrain: 0.9957627118644068 2.8261782636314794 \ttest: 0.9359605911330049 20.46181050499176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        11\n",
      "           1    0.98438   0.98438   0.98438        64\n",
      "           2    1.00000   1.00000   1.00000        31\n",
      "           3    1.00000   1.00000   1.00000        14\n",
      "           4    1.00000   1.00000   1.00000        14\n",
      "           5    1.00000   1.00000   1.00000        64\n",
      "           6    1.00000   1.00000   1.00000        31\n",
      "           7    1.00000   1.00000   1.00000        14\n",
      "           8    1.00000   1.00000   1.00000        10\n",
      "           9    1.00000   1.00000   1.00000        10\n",
      "          10    1.00000   1.00000   1.00000        14\n",
      "          11    1.00000   1.00000   1.00000        14\n",
      "          12    0.98438   0.98438   0.98438        64\n",
      "          13    1.00000   1.00000   1.00000        14\n",
      "          14    1.00000   1.00000   1.00000        61\n",
      "          15    1.00000   1.00000   1.00000        14\n",
      "          16    1.00000   1.00000   1.00000        14\n",
      "          17    1.00000   1.00000   1.00000        14\n",
      "\n",
      "    accuracy                        0.99576       472\n",
      "   macro avg    0.99826   0.99826   0.99826       472\n",
      "weighted avg    0.99576   0.99576   0.99576       472\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000         5\n",
      "           1    0.80645   0.92593   0.86207        27\n",
      "           2    1.00000   1.00000   1.00000        13\n",
      "           3    0.85714   1.00000   0.92308         6\n",
      "           4    1.00000   0.83333   0.90909         6\n",
      "           5    0.96154   0.89286   0.92593        28\n",
      "           6    1.00000   1.00000   1.00000        13\n",
      "           7    1.00000   1.00000   1.00000         6\n",
      "           8    1.00000   1.00000   1.00000         4\n",
      "           9    1.00000   1.00000   1.00000         5\n",
      "          10    1.00000   1.00000   1.00000         6\n",
      "          11    1.00000   1.00000   1.00000         6\n",
      "          12    0.88000   0.81481   0.84615        27\n",
      "          13    0.66667   0.66667   0.66667         6\n",
      "          14    1.00000   1.00000   1.00000        27\n",
      "          15    1.00000   1.00000   1.00000         6\n",
      "          16    1.00000   1.00000   1.00000         6\n",
      "          17    1.00000   1.00000   1.00000         6\n",
      "\n",
      "    accuracy                        0.93596       203\n",
      "   macro avg    0.95399   0.95187   0.95183       203\n",
      "weighted avg    0.93892   0.93596   0.93616       203\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 1199\n",
      "Average of depth: 1.548790658882402\n",
      "Number of nodes: 5181\n"
     ]
    }
   ],
   "source": [
    "def fit_trees():\n",
    "    learning_rate=1\n",
    "    max_depth=6\n",
    "    bins=8\n",
    "    lam=100\n",
    "\n",
    "    gtgp = GTGP(learning_rate=learning_rate,max_depth=max_depth,bins=bins,lam=lam)\n",
    "\n",
    "    total_size=10\n",
    "    elite_size = 10\n",
    "    epoch= 100\n",
    "    gp_epoch= 3\n",
    "    verbose = 1\n",
    "    tolerance= 0.1\n",
    "\n",
    "    gtgp.fit(X_train,y_train,total_size=total_size,elite_size = elite_size,epoch=epoch,gp_epoch=gp_epoch,tolerance=tolerance,verbose=verbose)\n",
    "\n",
    "    retrain_epoch= 5\n",
    "    alpha=0\n",
    "    beta=1\n",
    "    gammer=0\n",
    "\n",
    "    verbose=1\n",
    "    gtgp.lam = 10\n",
    "    gtgp.retrain_estimators(X_test,y_test,retrain_epoch=retrain_epoch,alpha=alpha,beta=beta,gammer=gammer,verbose=verbose)\n",
    "\n",
    "    return gtgp\n",
    "\n",
    "with open('./benchmark/'+dataset+'.csv','w') as f:\n",
    "        f.writelines(\"\")\n",
    "\n",
    "for i in range(30):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size,stratify=y, random_state=seeds[i])\n",
    "    y_train,y_test,y_train_one_hot,y_test_one_hot = to_one_hot(y_train,y_test)\n",
    "    gtgp = fit_trees()\n",
    "\n",
    "    print(classification_report(y_train,np.argmax(gtgp.train_p,axis=1),digits=5))\n",
    "    print(classification_report(y_test,np.argmax(gtgp.test_p,axis=1),digits=5))\n",
    "\n",
    "    num_trees,depth,num_nodes = gtgp.print_model()\n",
    "\n",
    "    train_acc = accuracy_score(y_train,np.argmax(gtgp.train_p,axis=1))\n",
    "    test_acc = accuracy_score(y_test,np.argmax(gtgp.test_p,axis=1))\n",
    "    train_f1 = f1_score(y_train,np.argmax(gtgp.train_p,axis=1),average='macro')\n",
    "    test_f1 = f1_score(y_test,np.argmax(gtgp.test_p,axis=1),average='macro')\n",
    "\n",
    "    # train_f1 = roc_auc_score(gtgp.y_one_hot.toarray(),(gtgp.train_p.T/np.sum(gtgp.train_p,axis=1)).T)\n",
    "    # test_f1 = roc_auc_score(y_test_one_hot.toarray(),(gtgp.test_p.T/np.sum(gtgp.test_p,axis=1)).T)\n",
    "\n",
    "    # train_f1 = roc_auc_score(gtgp.y_one_hot.toarray(),gtgp.train_p)\n",
    "    # test_f1 = roc_auc_score(y_test_one_hot.toarray(),gtgp.test_p)\n",
    "\n",
    "\n",
    "    with open('./benchmark/'+dataset+'.csv','a') as f:\n",
    "        s = str(train_acc)+\",\"+str(test_acc)+\",\"+str(train_f1)+\",\"+str(test_f1)+\",\"+str(num_trees)+\",\"+str(depth)+\",\"+str(num_nodes)+\"\\n\"\n",
    "        f.writelines(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662e91a5",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ed15d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "661630ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./benchmark_DC/'+dataset+'.csv','w') as f:\n",
    "    for i in range(30):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size,stratify=y, random_state=seeds[i])\n",
    "        clf = DecisionTreeClassifier()\n",
    "        clf.fit(X_train,y_train)\n",
    "        y_train,y_test,y_train_one_hot,y_test_one_hot = to_one_hot(y_train,y_test)\n",
    "\n",
    "        num_trees = 1\n",
    "        depth = clf.tree_.max_depth\n",
    "        num_nodes = clf.tree_.node_count\n",
    "\n",
    "        train_acc = accuracy_score(y_train,clf.predict(X_train))\n",
    "        test_acc = accuracy_score(y_test,clf.predict(X_test))\n",
    "        train_f1 = f1_score(y_train,clf.predict(X_train),average='macro')\n",
    "        test_f1 = f1_score(y_test,clf.predict(X_test),average='macro')\n",
    "\n",
    "        # train_roc = roc_auc_score(y_train_one_hot.toarray(),clf.predict_proba(X_train))\n",
    "        # test_roc = roc_auc_score(y_test_one_hot.toarray(),clf.predict_proba(X_test))\n",
    "\n",
    "        s = str(train_acc)+\",\"+str(test_acc)+\",\"+str(train_f1)+\",\"+str(test_f1)+\",\"+str(num_trees)+\",\"+str(depth)+\",\"+str(num_nodes)+\"\\n\"\n",
    "        f.writelines(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63afbae1",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "28fa8541",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "acfdd7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./benchmark_xgb/'+dataset+'.csv','w') as f:\n",
    "    for i in range(30):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size,stratify=y, random_state=seeds[i])\n",
    "        y_train,y_test,y_train_one_hot,y_test_one_hot = to_one_hot(y_train,y_test)\n",
    "        # xgb = xgboost.XGBClassifier(n_estimators=100,max_depth=6)\n",
    "        # xgb = xgboost.XGBClassifier(min_child_weight=0,max_depth=4)\n",
    "        xgb = xgboost.XGBClassifier(n_estimators=100,max_depth=3)\n",
    "        xgb.fit(X_train,y_train)\n",
    "\n",
    "        import json\n",
    "\n",
    "        def item_generator(json_input, lookup_key):\n",
    "            if isinstance(json_input, dict):\n",
    "                for k, v in json_input.items():\n",
    "                    if k == lookup_key:\n",
    "                        yield v\n",
    "                    else:\n",
    "                        yield from item_generator(v, lookup_key)\n",
    "            elif isinstance(json_input, list):\n",
    "                for item in json_input:\n",
    "                    yield from item_generator(item, lookup_key)\n",
    "\n",
    "        def tree_depth(json_text):\n",
    "            json_input = json.loads(json_text)\n",
    "            depths = list(item_generator(json_input, 'depth'))\n",
    "            return max(depths) + 1 if len(depths) != 0 else 1\n",
    "\n",
    "        train_acc = accuracy_score(y_train,xgb.predict(X_train))\n",
    "        test_acc = accuracy_score(y_test,xgb.predict(X_test))\n",
    "\n",
    "        train_f1 = f1_score(y_train,xgb.predict(X_train),average='macro')\n",
    "        test_f1 = f1_score(y_test,xgb.predict(X_test),average='macro')\n",
    "        # train_f1 = roc_auc_score(y_train_one_hot.toarray(),xgb.predict_proba(X_train))\n",
    "        # test_f1 = roc_auc_score(y_test_one_hot.toarray(),xgb.predict_proba(X_test))\n",
    "\n",
    "        booster = xgb.get_booster()\n",
    "\n",
    "        tree_df = booster.trees_to_dataframe()\n",
    "        depths = [tree_depth(x) for x in booster.get_dump(dump_format = \"json\")]\n",
    "        num_trees = len(depths)\n",
    "        depth = np.average(depths)\n",
    "        num_nodes = len(tree_df)\n",
    "\n",
    "        s = str(train_acc)+\",\"+str(test_acc)+\",\"+str(train_f1)+\",\"+str(test_f1)+\",\"+str(num_trees)+\",\"+str(depth)+\",\"+str(num_nodes)+\"\\n\"\n",
    "        f.writelines(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc363f99",
   "metadata": {},
   "source": [
    "# GDBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6e6d3435",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ef69c1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./benchmark_GBDT/'+dataset+'.csv','w') as f:\n",
    "    for i in range(30):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size,stratify=y, random_state=seeds[i])\n",
    "        y_train,y_test,y_train_one_hot,y_test_one_hot = to_one_hot(y_train,y_test)\n",
    "        # clf = GradientBoostingClassifier(n_estimators=1000)\n",
    "        clf = GradientBoostingClassifier(n_estimators=100)\n",
    "        clf.fit(X_train,y_train)\n",
    "\n",
    "        train_acc = accuracy_score(y_train,clf.predict(X_train))\n",
    "        test_acc = accuracy_score(y_test,clf.predict(X_test))\n",
    "        train_f1 = f1_score(y_train,clf.predict(X_train),average='macro')\n",
    "        test_f1 = f1_score(y_test,clf.predict(X_test),average='macro')\n",
    "        # train_f1 = roc_auc_score(y_train_one_hot.toarray(),clf.predict_proba(X_train))\n",
    "        # test_f1 = roc_auc_score(y_test_one_hot.toarray(),clf.predict_proba(X_test))\n",
    "\n",
    "\n",
    "        num_trees = len([ est for ests in clf.estimators_ for est in ests])\n",
    "        depth = np.average([ max(1,est.tree_.max_depth) for ests in clf.estimators_ for est in ests])\n",
    "        num_nodes = sum([ est.tree_.node_count for ests in clf.estimators_ for est in ests])\n",
    "\n",
    "        s = str(train_acc)+\",\"+str(test_acc)+\",\"+str(train_f1)+\",\"+str(test_f1)+\",\"+str(num_trees)+\",\"+str(depth)+\",\"+str(num_nodes)+\"\\n\"\n",
    "        f.writelines(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0ef54f",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8623bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3edfc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./benchmark_RF/'+dataset+'.csv','w') as f:\n",
    "    for i in range(30):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size,stratify=y, random_state=seeds[i])\n",
    "        y_train,y_test,y_train_one_hot,y_test_one_hot = to_one_hot(y_train,y_test)\n",
    "        # rfc = RandomForestClassifier(n_estimators=100)\n",
    "        rfc = RandomForestClassifier()\n",
    "        rfc.fit(X_train,y_train)\n",
    "\n",
    "        train_acc = accuracy_score(y_train,rfc.predict(X_train))\n",
    "        test_acc = accuracy_score(y_test,rfc.predict(X_test))\n",
    "        train_f1 = f1_score(y_train,rfc.predict(X_train),average='macro')\n",
    "        test_f1 = f1_score(y_test,rfc.predict(X_test),average='macro')\n",
    "        \n",
    "        # train_f1 = roc_auc_score(y_train_one_hot.toarray(),rfc.predict_proba(X_train))\n",
    "        # test_f1 = roc_auc_score(y_test_one_hot.toarray(),rfc.predict_proba(X_test))\n",
    "\n",
    "        num_trees = len(rfc.estimators_)\n",
    "        depth = np.average([est.tree_.max_depth for est in rfc.estimators_])\n",
    "        num_nodes = sum([est.tree_.node_count for est in rfc.estimators_])\n",
    "\n",
    "        s = str(train_acc)+\",\"+str(test_acc)+\",\"+str(train_f1)+\",\"+str(test_f1)+\",\"+str(num_trees)+\",\"+str(depth)+\",\"+str(num_nodes)+\"\\n\"\n",
    "        f.writelines(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49b66a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb3fc4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BStackGP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc-autonumbering": true,
  "toc-showcode": true,
  "toc-showmarkdowntxt": true,
  "vscode": {
   "interpreter": {
    "hash": "598cefc26d6e5a65b2978c65314d0610ea9dfe34c7d989c4b6d2528d500ccb7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
