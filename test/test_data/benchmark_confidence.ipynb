{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a8bc990-ebc5-46bd-bab4-f4091ce5b834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../script/\")\n",
    "\n",
    "import Functions\n",
    "from Engine import Engine\n",
    "from GTGP import GTGP\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report,accuracy_score,confusion_matrix,f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import importlib\n",
    "from time import time\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbad47da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.utils import shuffle\n",
    "def plot_roc_curve(true_y, y_prob):\n",
    "    \"\"\"\n",
    "    plots the roc curve based of the probabilities\n",
    "    \"\"\"\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(true_y, y_prob)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    print(roc_auc_score(true_y,prob[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c114de92",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "feedaa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/confidence.tsv\",delimiter='\\t')\n",
    "X = df.iloc[:,:-1].to_numpy().astype(\"float\")\n",
    "y = df.iloc[:,-1].to_numpy().astype(\"int\")\n",
    "\n",
    "seeds = [10086, 200,500,30506,30405,30420,10056,7059,40965,5398,869543,83491,823190,\n",
    "         48392,2810,48392,3498210,483902,859032,12890,538920,86954,54309,6504,9840,\n",
    "         219805,548,2981,432890,5438908,219094,5843902,60854,979,12890,2108,4093]\n",
    "train_size = 0.7\n",
    "dataset = 'confidence'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a2341bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(y,yt):\n",
    "    le = LabelEncoder()\n",
    "    ohe = OneHotEncoder()\n",
    "    y_train = le.fit_transform(y)\n",
    "    y_one_hot = ohe.fit_transform(y_train.reshape(-1,1))\n",
    "    \n",
    "    y_test = le.transform(yt)\n",
    "    yt_one_hot = ohe.transform(y_test.reshape(-1,1))\n",
    "    \n",
    "    return y_train,y_test,y_one_hot,yt_one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdd30c5",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f418f618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 19 1\n",
      "6 18 2\n",
      "6 18 3\n",
      "7 23 4\n",
      "8 30 5\n",
      "8 30 6\n",
      "9 27 7\n",
      "9 27 8\n",
      "9 27 9\n",
      "9 27 10\n",
      "9 27 11\n",
      "10 30 12\n",
      "10 30 13\n",
      "10 30 14\n",
      "10 30 15\n",
      "10 30 16\n",
      "10 30 17\n",
      "11 37 18\n",
      "11 35 19\n",
      "11 33 20\n",
      "11 33 21\n",
      "11 33 22\n",
      "11 33 23\n",
      "11 33 24\n",
      "11 33 25\n",
      "11 33 26\n",
      "11 33 27\n",
      "11 33 28\n",
      "11 33 29\n",
      "11 33 30\n",
      "11 33 31\n",
      "11 33 32\n",
      "11 33 33\n",
      "11 33 34\n",
      "11 33 35\n",
      "11 33 36\n",
      "11 33 37\n",
      "11 33 38\n",
      "11 33 39\n",
      "11 33 40\n",
      "12 44 41\n",
      "12 40 42\n",
      "13 53 43\n",
      "13 53 44\n",
      "13 53 45\n",
      "14 60 46\n",
      "14 60 47\n",
      "14 60 48\n",
      "14 54 49\n",
      "14 50 50\n",
      "14 50 51\n",
      "14 50 52\n",
      "14 50 53\n",
      "14 50 54\n",
      "14 48 55\n",
      "14 46 56\n",
      "14 46 57\n",
      "14 46 58\n",
      "14 46 59\n",
      "14 46 60\n",
      "15 53 61\n",
      "15 53 62\n",
      "15 51 63\n",
      "15 49 64\n",
      "15 49 65\n",
      "15 49 66\n",
      "15 49 67\n",
      "15 49 68\n",
      "15 49 69\n",
      "15 49 70\n",
      "15 49 71\n",
      "15 49 72\n",
      "15 49 73\n",
      "15 49 74\n",
      "15 49 75\n",
      "15 49 76\n",
      "15 49 77\n",
      "16 60 78\n",
      "16 52 79\n",
      "16 52 80\n",
      "16 52 81\n",
      "16 52 82\n",
      "16 52 83\n",
      "16 52 84\n",
      "16 52 85\n",
      "17 59 86\n",
      "17 59 87\n",
      "17 59 88\n",
      "17 59 89\n",
      "17 59 90\n",
      "17 59 91\n",
      "17 59 92\n",
      "18 66 93\n",
      "18 66 94\n",
      "18 66 95\n",
      "18 66 96\n",
      "18 66 97\n",
      "18 66 98\n",
      "18 66 99\n",
      "18 66 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 53.537798364400416 \ttest: 0.9090909090909091 24.480937134019904\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 39.85929033849257 \ttest: 0.9090909090909091 19.15656689488928\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 30.933889739160243 \ttest: 0.9090909090909091 15.756269777278975\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 24.857263052979206 \ttest: 0.9090909090909091 13.49251905623142\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 20.53021147032917 \ttest: 0.9090909090909091 11.914772923212944\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 17.32201730206568 \ttest: 0.9090909090909091 10.767079112519312\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 14.861411120155422 \ttest: 0.9090909090909091 9.900689327965868\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 12.921437506766887 \ttest: 0.9090909090909091 9.226104109826286\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 11.357538899599462 \ttest: 0.9090909090909091 8.68735426273204\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 10.073879831188796 \ttest: 0.9090909090909091 8.248065850571582\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 9.004546603236331 \ttest: 0.9090909090909091 7.883725104124941\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 8.102705556102308 \ttest: 0.9090909090909091 7.577254001214575\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 7.334129768330429 \ttest: 0.9090909090909091 7.316397044390352\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 6.673196853519658 \ttest: 0.9090909090909091 7.092127245763894\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 6.1003299341379975 \ttest: 0.9090909090909091 6.897642865735864\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 5.600309062176481 \ttest: 0.9090909090909091 6.72771686503852\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 5.161124443350807 \ttest: 0.9090909090909091 6.578263132873882\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 4.773177181223002 \ttest: 0.9090909090909091 6.446039703147957\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 4.428709261508527 \ttest: 0.9090909090909091 6.328440853089127\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 4.121388694378444 \ttest: 0.9090909090909091 6.223348317865481\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000         8\n",
      "           1    1.00000   1.00000   1.00000         9\n",
      "           2    1.00000   1.00000   1.00000         8\n",
      "           3    1.00000   1.00000   1.00000         9\n",
      "           4    1.00000   1.00000   1.00000         8\n",
      "           5    1.00000   1.00000   1.00000         8\n",
      "\n",
      "    accuracy                        1.00000        50\n",
      "   macro avg    1.00000   1.00000   1.00000        50\n",
      "weighted avg    1.00000   1.00000   1.00000        50\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   0.50000   0.66667         4\n",
      "           1    1.00000   1.00000   1.00000         3\n",
      "           2    0.66667   1.00000   0.80000         4\n",
      "           3    1.00000   1.00000   1.00000         3\n",
      "           4    1.00000   1.00000   1.00000         4\n",
      "           5    1.00000   1.00000   1.00000         4\n",
      "\n",
      "    accuracy                        0.90909        22\n",
      "   macro avg    0.94444   0.91667   0.91111        22\n",
      "weighted avg    0.93939   0.90909   0.90303        22\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 18\n",
      "Average of depth: 1.1666666666666667\n",
      "Number of nodes: 66\n",
      "6 28 1\n",
      "6 28 2\n",
      "5 15 3\n",
      "5 15 4\n",
      "6 22 5\n",
      "6 22 6\n",
      "6 22 7\n",
      "7 33 8\n",
      "7 33 9\n",
      "7 25 10\n",
      "7 25 11\n",
      "7 25 12\n",
      "7 23 13\n",
      "7 21 14\n",
      "7 21 15\n",
      "7 21 16\n",
      "7 21 17\n",
      "7 21 18\n",
      "7 21 19\n",
      "7 21 20\n",
      "7 21 21\n",
      "8 28 22\n",
      "8 28 23\n",
      "8 28 24\n",
      "8 28 25\n",
      "8 28 26\n",
      "8 28 27\n",
      "8 28 28\n",
      "8 28 29\n",
      "8 28 30\n",
      "8 28 31\n",
      "9 33 32\n",
      "9 33 33\n",
      "9 33 34\n",
      "9 33 35\n",
      "9 33 36\n",
      "10 46 37\n",
      "10 46 38\n",
      "10 46 39\n",
      "10 46 40\n",
      "11 53 41\n",
      "11 47 42\n",
      "11 43 43\n",
      "11 39 44\n",
      "11 39 45\n",
      "11 39 46\n",
      "11 39 47\n",
      "12 50 48\n",
      "12 50 49\n",
      "12 44 50\n",
      "12 42 51\n",
      "12 42 52\n",
      "12 42 53\n",
      "12 42 54\n",
      "12 42 55\n",
      "12 42 56\n",
      "12 42 57\n",
      "12 42 58\n",
      "13 51 59\n",
      "13 51 60\n",
      "13 51 61\n",
      "13 51 62\n",
      "13 51 63\n",
      "13 51 64\n",
      "13 51 65\n",
      "13 51 66\n",
      "13 51 67\n",
      "13 51 68\n",
      "13 51 69\n",
      "13 47 70\n",
      "13 45 71\n",
      "13 45 72\n",
      "13 45 73\n",
      "13 45 74\n",
      "13 45 75\n",
      "13 45 76\n",
      "13 45 77\n",
      "13 45 78\n",
      "13 45 79\n",
      "13 45 80\n",
      "13 45 81\n",
      "13 45 82\n",
      "13 45 83\n",
      "13 45 84\n",
      "13 45 85\n",
      "13 45 86\n",
      "13 45 87\n",
      "13 45 88\n",
      "13 45 89\n",
      "13 45 90\n",
      "13 45 91\n",
      "13 45 92\n",
      "13 45 93\n",
      "13 45 94\n",
      "13 45 95\n",
      "13 45 96\n",
      "13 45 97\n",
      "13 45 98\n",
      "13 45 99\n",
      "13 45 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 57.161143206785454 \ttest: 0.7272727272727273 26.387256648677607\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 44.88972347832304 \ttest: 0.7727272727272727 21.873026350934836\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 36.326250946850294 \ttest: 0.7727272727272727 18.754669318865687\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 30.173226907632532 \ttest: 0.7727272727272727 16.547060011278745\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 25.599082974147155 \ttest: 0.8181818181818182 14.937487773779333\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 22.08395112749848 \ttest: 0.8181818181818182 13.72832998034757\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 19.30172169271743 \ttest: 0.8181818181818182 12.794247198328721\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 17.044121435132055 \ttest: 0.8181818181818182 12.054505657923425\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 15.174656962653566 \ttest: 0.8181818181818182 11.455968620227384\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 13.601162524929416 \ttest: 0.8181818181818182 10.962794244390071\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 12.259414826629763 \ttest: 0.8181818181818182 10.550179678825256\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 11.103244960838452 \ttest: 0.8181818181818182 10.200519190415196\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 10.098471795585493 \ttest: 0.8181818181818182 9.901006824313509\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 9.21910450409423 \ttest: 0.8181818181818182 9.642112399532229\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 8.444911175125142 \ttest: 0.8181818181818182 9.416593116504517\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 7.759823540153758 \ttest: 0.8181818181818182 9.218839145020464\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 7.150863059888654 \ttest: 0.8181818181818182 9.044431221408123\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 6.607398788901428 \ttest: 0.8181818181818182 8.889835350627802\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 6.120621040750979 \ttest: 0.8181818181818182 8.752187861156685\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 5.683158690727517 \ttest: 0.8181818181818182 8.62914113585124\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000         8\n",
      "           1    1.00000   1.00000   1.00000         8\n",
      "           2    1.00000   1.00000   1.00000         8\n",
      "           3    1.00000   1.00000   1.00000         8\n",
      "           4    1.00000   1.00000   1.00000         9\n",
      "           5    1.00000   1.00000   1.00000         9\n",
      "\n",
      "    accuracy                        1.00000        50\n",
      "   macro avg    1.00000   1.00000   1.00000        50\n",
      "weighted avg    1.00000   1.00000   1.00000        50\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.66667   0.50000   0.57143         4\n",
      "           1    0.80000   1.00000   0.88889         4\n",
      "           2    0.66667   1.00000   0.80000         4\n",
      "           3    1.00000   1.00000   1.00000         4\n",
      "           4    1.00000   0.66667   0.80000         3\n",
      "           5    1.00000   0.66667   0.80000         3\n",
      "\n",
      "    accuracy                        0.81818        22\n",
      "   macro avg    0.85556   0.80556   0.81005        22\n",
      "weighted avg    0.84242   0.81818   0.81097        22\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 13\n",
      "Average of depth: 1.1538461538461537\n",
      "Number of nodes: 45\n",
      "5 19 1\n",
      "6 22 2\n",
      "7 33 3\n",
      "7 29 4\n",
      "7 21 5\n",
      "7 21 6\n",
      "8 32 7\n",
      "8 32 8\n",
      "8 32 9\n",
      "8 32 10\n",
      "8 32 11\n",
      "8 32 12\n",
      "8 32 13\n",
      "8 32 14\n",
      "9 35 15\n",
      "9 35 16\n",
      "10 42 17\n",
      "10 38 18\n",
      "10 38 19\n",
      "10 38 20\n",
      "10 38 21\n",
      "10 38 22\n",
      "10 38 23\n",
      "10 38 24\n",
      "10 38 25\n",
      "10 38 26\n",
      "11 45 27\n",
      "12 48 28\n",
      "12 48 29\n",
      "12 48 30\n",
      "12 48 31\n",
      "12 48 32\n",
      "12 48 33\n",
      "12 48 34\n",
      "12 48 35\n",
      "12 46 36\n",
      "12 44 37\n",
      "12 44 38\n",
      "12 44 39\n",
      "12 40 40\n",
      "12 40 41\n",
      "12 40 42\n",
      "12 40 43\n",
      "12 40 44\n",
      "12 40 45\n",
      "12 40 46\n",
      "14 54 47\n",
      "14 54 48\n",
      "14 54 49\n",
      "14 54 50\n",
      "14 52 51\n",
      "15 61 52\n",
      "15 61 53\n",
      "15 61 54\n",
      "15 61 55\n",
      "15 61 56\n",
      "15 55 57\n",
      "15 55 58\n",
      "15 53 59\n",
      "15 51 60\n",
      "15 49 61\n",
      "15 49 62\n",
      "15 49 63\n",
      "15 49 64\n",
      "15 49 65\n",
      "15 49 66\n",
      "15 49 67\n",
      "15 49 68\n",
      "15 49 69\n",
      "15 49 70\n",
      "15 49 71\n",
      "16 56 72\n",
      "16 52 73\n",
      "16 52 74\n",
      "16 52 75\n",
      "17 59 76\n",
      "17 59 77\n",
      "17 59 78\n",
      "17 57 79\n",
      "17 55 80\n",
      "17 55 81\n",
      "17 55 82\n",
      "17 55 83\n",
      "17 55 84\n",
      "18 62 85\n",
      "18 62 86\n",
      "18 62 87\n",
      "18 62 88\n",
      "18 62 89\n",
      "18 62 90\n",
      "18 62 91\n",
      "18 62 92\n",
      "18 62 93\n",
      "18 62 94\n",
      "18 62 95\n",
      "18 62 96\n",
      "18 62 97\n",
      "18 62 98\n",
      "18 62 99\n",
      "18 62 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 52.922920169171974 \ttest: 0.8181818181818182 24.153326302075683\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 39.03608952155898 \ttest: 0.8181818181818182 18.65398398267263\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 30.0678525208977 \ttest: 0.8181818181818182 15.161563434504838\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 24.01219965825344 \ttest: 0.8181818181818182 12.853580371999463\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 19.73167052192971 \ttest: 0.8181818181818182 11.262003135469243\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 16.580365052204925 \ttest: 0.8181818181818182 10.120906541801807\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 14.180164022791633 \ttest: 0.8181818181818182 9.275061301546737\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 12.30057453670198 \ttest: 0.8181818181818182 8.630399625715512\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 10.795037884113666 \ttest: 0.8181818181818182 8.127614965049021\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 9.566555807831984 \ttest: 0.8181818181818182 7.727876739084548\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 8.548569852671182 \ttest: 0.8181818181818182 7.404877004109194\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 7.693944635445222 \ttest: 0.8181818181818182 7.1402493720850515\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 6.968383897041496 \ttest: 0.8181818181818182 6.920835104410829\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 6.346351754531352 \ttest: 0.8181818181818182 6.736994097917891\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 5.808458594734473 \ttest: 0.8181818181818182 6.581527027494443\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 5.33973257615529 \ttest: 0.8181818181818182 6.448966911731407\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 4.9284442318380535 \ttest: 0.8181818181818182 6.33510106322273\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 4.5652871246184645 \ttest: 0.8181818181818182 6.236640916335599\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 4.242794147217038 \ttest: 0.8181818181818182 6.150989283328036\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 3.9549137184041747 \ttest: 0.8181818181818182 6.076073315726441\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000         9\n",
      "           1    1.00000   1.00000   1.00000         8\n",
      "           2    1.00000   1.00000   1.00000         8\n",
      "           3    1.00000   1.00000   1.00000         9\n",
      "           4    1.00000   1.00000   1.00000         8\n",
      "           5    1.00000   1.00000   1.00000         8\n",
      "\n",
      "    accuracy                        1.00000        50\n",
      "   macro avg    1.00000   1.00000   1.00000        50\n",
      "weighted avg    1.00000   1.00000   1.00000        50\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.50000   0.66667   0.57143         3\n",
      "           1    1.00000   0.75000   0.85714         4\n",
      "           2    0.75000   0.75000   0.75000         4\n",
      "           3    0.75000   1.00000   0.85714         3\n",
      "           4    1.00000   0.75000   0.85714         4\n",
      "           5    1.00000   1.00000   1.00000         4\n",
      "\n",
      "    accuracy                        0.81818        22\n",
      "   macro avg    0.83333   0.81944   0.81548        22\n",
      "weighted avg    0.85227   0.81818   0.82468        22\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 18\n",
      "Average of depth: 1.1111111111111112\n",
      "Number of nodes: 62\n",
      "6 32 1\n",
      "5 15 2\n",
      "5 15 3\n",
      "5 15 4\n",
      "5 15 5\n",
      "7 33 6\n",
      "7 29 7\n",
      "7 29 8\n",
      "7 29 9\n",
      "7 23 10\n",
      "7 21 11\n",
      "7 21 12\n",
      "7 21 13\n",
      "7 21 14\n",
      "7 21 15\n",
      "7 21 16\n",
      "7 21 17\n",
      "7 21 18\n",
      "7 21 19\n",
      "8 26 20\n",
      "9 33 21\n",
      "9 31 22\n",
      "9 31 23\n",
      "9 31 24\n",
      "9 31 25\n",
      "9 31 26\n",
      "9 31 27\n",
      "9 31 28\n",
      "9 31 29\n",
      "9 31 30\n",
      "9 31 31\n",
      "9 31 32\n",
      "9 31 33\n",
      "9 31 34\n",
      "9 31 35\n",
      "9 31 36\n",
      "9 31 37\n",
      "9 31 38\n",
      "9 31 39\n",
      "9 31 40\n",
      "9 31 41\n",
      "9 31 42\n",
      "9 31 43\n",
      "9 31 44\n",
      "9 31 45\n",
      "9 31 46\n",
      "9 31 47\n",
      "9 31 48\n",
      "9 31 49\n",
      "9 31 50\n",
      "9 31 51\n",
      "9 31 52\n",
      "9 31 53\n",
      "9 31 54\n",
      "9 31 55\n",
      "9 31 56\n",
      "10 44 57\n",
      "10 44 58\n",
      "10 34 59\n",
      "10 34 60\n",
      "10 34 61\n",
      "10 34 62\n",
      "10 34 63\n",
      "10 34 64\n",
      "10 34 65\n",
      "10 34 66\n",
      "10 34 67\n",
      "10 34 68\n",
      "10 34 69\n",
      "11 43 70\n",
      "11 43 71\n",
      "11 43 72\n",
      "11 43 73\n",
      "11 43 74\n",
      "11 43 75\n",
      "11 43 76\n",
      "11 43 77\n",
      "11 43 78\n",
      "11 43 79\n",
      "11 43 80\n",
      "11 43 81\n",
      "11 43 82\n",
      "11 43 83\n",
      "11 43 84\n",
      "11 43 85\n",
      "11 43 86\n",
      "11 43 87\n",
      "11 43 88\n",
      "11 43 89\n",
      "11 43 90\n",
      "11 43 91\n",
      "11 43 92\n",
      "11 43 93\n",
      "11 43 94\n",
      "11 43 95\n",
      "11 43 96\n",
      "11 43 97\n",
      "11 43 98\n",
      "11 43 99\n",
      "11 43 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 59.859887119961655 \ttest: 0.8636363636363636 26.743379049720225\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 48.77877455356466 \ttest: 0.8636363636363636 22.224768306370002\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 40.619485970653315 \ttest: 0.8636363636363636 18.94513407375598\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 34.50957217132354 \ttest: 0.8636363636363636 16.526947632945372\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 29.83247373773099 \ttest: 0.8636363636363636 14.70573608285324\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 26.166844063868503 \ttest: 0.8636363636363636 13.30194542258203\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 23.227409627956394 \ttest: 0.8636363636363636 12.19469665123765\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 20.820278055712585 \ttest: 0.8636363636363636 11.302283446739821\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 18.812155325705724 \ttest: 0.8636363636363636 10.568862717317543\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 17.109941887488517 \ttest: 0.8636363636363636 9.95568521791397\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 15.647397587879663 \ttest: 0.8636363636363636 9.435388264895817\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 14.37644177532405 \ttest: 0.8636363636363636 8.98828354442077\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 13.261449151861319 \ttest: 0.8636363636363636 8.599928536596165\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 12.275476553492846 \ttest: 0.8636363636363636 8.259522613448336\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 11.397738784743243 \ttest: 0.8636363636363636 7.958835399424518\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 10.611898182863944 \ttest: 0.8636363636363636 7.6914814195033525\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 9.904889195080296 \ttest: 0.8636363636363636 7.452422292531963\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 9.266098432501847 \ttest: 0.8636363636363636 7.237620118298496\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 8.686783635316083 \ttest: 0.8636363636363636 7.043792528614526\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 8.159655186180682 \ttest: 0.8636363636363636 6.868236953237657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000         8\n",
      "           1    1.00000   1.00000   1.00000         9\n",
      "           2    1.00000   1.00000   1.00000         8\n",
      "           3    1.00000   1.00000   1.00000         8\n",
      "           4    1.00000   1.00000   1.00000         8\n",
      "           5    1.00000   1.00000   1.00000         9\n",
      "\n",
      "    accuracy                        1.00000        50\n",
      "   macro avg    1.00000   1.00000   1.00000        50\n",
      "weighted avg    1.00000   1.00000   1.00000        50\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.66667   0.50000   0.57143         4\n",
      "           1    1.00000   1.00000   1.00000         3\n",
      "           2    0.60000   0.75000   0.66667         4\n",
      "           3    1.00000   1.00000   1.00000         4\n",
      "           4    1.00000   1.00000   1.00000         4\n",
      "           5    1.00000   1.00000   1.00000         3\n",
      "\n",
      "    accuracy                        0.86364        22\n",
      "   macro avg    0.87778   0.87500   0.87302        22\n",
      "weighted avg    0.86667   0.86364   0.86147        22\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 11\n",
      "Average of depth: 1.2727272727272727\n",
      "Number of nodes: 43\n",
      "5 25 1\n",
      "7 27 2\n",
      "7 21 3\n",
      "7 21 4\n",
      "9 39 5\n",
      "9 31 6\n",
      "9 31 7\n",
      "9 31 8\n",
      "9 31 9\n",
      "9 31 10\n",
      "9 31 11\n",
      "9 31 12\n",
      "9 31 13\n",
      "9 31 14\n",
      "10 38 15\n",
      "9 27 16\n",
      "9 27 17\n",
      "9 27 18\n",
      "9 27 19\n",
      "9 27 20\n",
      "9 27 21\n",
      "9 27 22\n",
      "9 27 23\n",
      "9 27 24\n",
      "9 27 25\n",
      "9 27 26\n",
      "10 34 27\n",
      "10 34 28\n",
      "10 34 29\n",
      "10 34 30\n",
      "10 34 31\n",
      "10 34 32\n",
      "10 32 33\n",
      "10 30 34\n",
      "11 39 35\n",
      "11 39 36\n",
      "11 39 37\n",
      "11 39 38\n",
      "11 35 39\n",
      "11 33 40\n",
      "11 33 41\n",
      "11 33 42\n",
      "11 33 43\n",
      "11 33 44\n",
      "11 33 45\n",
      "12 40 46\n",
      "12 40 47\n",
      "12 38 48\n",
      "12 36 49\n",
      "12 36 50\n",
      "12 36 51\n",
      "12 36 52\n",
      "12 36 53\n",
      "14 58 54\n",
      "14 58 55\n",
      "14 58 56\n",
      "14 52 57\n",
      "14 48 58\n",
      "15 57 59\n",
      "16 66 60\n",
      "15 51 61\n",
      "15 51 62\n",
      "15 49 63\n",
      "15 47 64\n",
      "15 47 65\n",
      "15 47 66\n",
      "15 45 67\n",
      "15 45 68\n",
      "15 45 69\n",
      "15 45 70\n",
      "15 45 71\n",
      "15 45 72\n",
      "15 45 73\n",
      "15 45 74\n",
      "15 45 75\n",
      "16 54 76\n",
      "17 63 77\n",
      "18 66 78\n",
      "18 64 79\n",
      "19 79 80\n",
      "19 69 81\n",
      "18 56 82\n",
      "18 54 83\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m30\u001b[39m):\n\u001b[0;32m     30\u001b[0m     X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, train_size\u001b[38;5;241m=\u001b[39mtrain_size,stratify\u001b[38;5;241m=\u001b[39my, random_state\u001b[38;5;241m=\u001b[39mseeds[i])\n\u001b[1;32m---> 31\u001b[0m     gtgp \u001b[38;5;241m=\u001b[39m \u001b[43mfit_trees\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28mprint\u001b[39m(classification_report(y_train,np\u001b[38;5;241m.\u001b[39margmax(gtgp\u001b[38;5;241m.\u001b[39mtrain_p,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),digits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28mprint\u001b[39m(classification_report(y_test,np\u001b[38;5;241m.\u001b[39margmax(gtgp\u001b[38;5;241m.\u001b[39mtest_p,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),digits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m))\n",
      "Cell \u001b[1;32mIn[28], line 16\u001b[0m, in \u001b[0;36mfit_trees\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     14\u001b[0m tolerance\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m---> 16\u001b[0m \u001b[43mgtgp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtotal_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43melite_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43melite_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgp_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgp_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m retrain_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m\n\u001b[0;32m     19\u001b[0m alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\zhouz\\OneDrive\\桌面\\Git\\GTGP\\test\\../script\\GTGP.py:98\u001b[0m, in \u001b[0;36mGTGP.fit\u001b[1;34m(self, X, y, total_size, elite_size, epoch, gp_epoch, tolerance, verbose)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epoch):\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(gp_epoch):\n\u001b[1;32m---> 98\u001b[0m         \u001b[43meg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43melite_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlog_odds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_odds\u001b[49m\u001b[43m,\u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstack,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlosses \u001b[38;5;241m=\u001b[39m eg\u001b[38;5;241m.\u001b[39madding_unique_node(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstack,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlosses,eg\u001b[38;5;241m.\u001b[39mnodes[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_features:],tolerance\u001b[38;5;241m=\u001b[39mtolerance)\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m eg\u001b[38;5;241m.\u001b[39mnodes[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_features:]:\n",
      "File \u001b[1;32mc:\\Users\\zhouz\\OneDrive\\桌面\\Git\\GTGP\\test\\../script\\Engine.py:136\u001b[0m, in \u001b[0;36mEngine.evolve\u001b[1;34m(self, total_size, elite_size, log_odds, p, tolerance, verbose)\u001b[0m\n\u001b[0;32m    128\u001b[0m new_nodes \u001b[38;5;241m=\u001b[39m [Node(\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    129\u001b[0m                     func\u001b[38;5;241m=\u001b[39mfuncs[index],\n\u001b[0;32m    130\u001b[0m                     sons\u001b[38;5;241m=\u001b[39msons[index],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    133\u001b[0m                     estimator\u001b[38;5;241m=\u001b[39mestimators[index]\n\u001b[0;32m    134\u001b[0m                 ) \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m rank[:elite_size]]\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m new_nodes:\n\u001b[1;32m--> 136\u001b[0m     \u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m# nodes,losses = self.adding_unique_node(stack=self.nodes[self.feature_space:],losses=self.losses[self.feature_space:],new_nodes=new_nodes,tolerance=tolerance)\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;66;03m# self.nodes += new_nodes\u001b[39;00m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;66;03m# self.losses += [node.estimator.loss for node in new_nodes]\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_nodes\n",
      "File \u001b[1;32mc:\\Users\\zhouz\\OneDrive\\桌面\\Git\\GTGP\\test\\../script\\Estimator.py:171\u001b[0m, in \u001b[0;36mEstimator_DC.get_metrics\u001b[1;34m(self, val, y)\u001b[0m\n\u001b[0;32m    169\u001b[0m val \u001b[38;5;241m=\u001b[39m val\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    170\u001b[0m bin_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclf\u001b[38;5;241m.\u001b[39mapply(val)\n\u001b[1;32m--> 171\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcrosstab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbin_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    173\u001b[0m bin_weight_by_class \u001b[38;5;241m=\u001b[39m (df\u001b[38;5;241m/\u001b[39mdf\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m    174\u001b[0m impurity_by_class_bin \u001b[38;5;241m=\u001b[39m ((df\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m/\u001b[39mdf\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\zhouz\\anaconda3\\envs\\BStackGP\\Lib\\site-packages\\pandas\\core\\reshape\\pivot.py:715\u001b[0m, in \u001b[0;36mcrosstab\u001b[1;34m(index, columns, values, rownames, colnames, aggfunc, margins, margins_name, dropna, normalize)\u001b[0m\n\u001b[0;32m    711\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maggfunc\u001b[39m\u001b[38;5;124m\"\u001b[39m: aggfunc}\n\u001b[0;32m    713\u001b[0m \u001b[38;5;66;03m# error: Argument 7 to \"pivot_table\" of \"DataFrame\" has incompatible type\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[38;5;66;03m# \"**Dict[str, object]\"; expected \"Union[...]\"\u001b[39;00m\n\u001b[1;32m--> 715\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpivot_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m__dummy__\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munique_rownames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munique_colnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmargins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmargins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmargins_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmargins_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m    723\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    725\u001b[0m \u001b[38;5;66;03m# Post-process\u001b[39;00m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m normalize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\zhouz\\anaconda3\\envs\\BStackGP\\Lib\\site-packages\\pandas\\core\\frame.py:8589\u001b[0m, in \u001b[0;36mDataFrame.pivot_table\u001b[1;34m(self, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name, observed, sort)\u001b[0m\n\u001b[0;32m   8572\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   8573\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_shared_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpivot_table\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   8574\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpivot_table\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   8585\u001b[0m     sort: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   8586\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m   8587\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpivot\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pivot_table\n\u001b[1;32m-> 8589\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpivot_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   8590\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8591\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8592\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8594\u001b[0m \u001b[43m        \u001b[49m\u001b[43maggfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maggfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmargins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmargins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmargins_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmargins_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8599\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8600\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8601\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\zhouz\\anaconda3\\envs\\BStackGP\\Lib\\site-packages\\pandas\\core\\reshape\\pivot.py:97\u001b[0m, in \u001b[0;36mpivot_table\u001b[1;34m(data, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name, observed, sort)\u001b[0m\n\u001b[0;32m     94\u001b[0m     table \u001b[38;5;241m=\u001b[39m concat(pieces, keys\u001b[38;5;241m=\u001b[39mkeys, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m table\u001b[38;5;241m.\u001b[39m__finalize__(data, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpivot_table\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 97\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[43m__internal_pivot_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43maggfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmargins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmargins_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m table\u001b[38;5;241m.\u001b[39m__finalize__(data, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpivot_table\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\zhouz\\anaconda3\\envs\\BStackGP\\Lib\\site-packages\\pandas\\core\\reshape\\pivot.py:167\u001b[0m, in \u001b[0;36m__internal_pivot_table\u001b[1;34m(data, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name, observed, sort)\u001b[0m\n\u001b[0;32m    164\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(values)\n\u001b[0;32m    166\u001b[0m grouped \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mgroupby(keys, observed\u001b[38;5;241m=\u001b[39mobserved, sort\u001b[38;5;241m=\u001b[39msort)\n\u001b[1;32m--> 167\u001b[0m agged \u001b[38;5;241m=\u001b[39m \u001b[43mgrouped\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43maggfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dropna \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(agged, ABCDataFrame) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(agged\u001b[38;5;241m.\u001b[39mcolumns):\n\u001b[0;32m    170\u001b[0m     agged \u001b[38;5;241m=\u001b[39m agged\u001b[38;5;241m.\u001b[39mdropna(how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\zhouz\\anaconda3\\envs\\BStackGP\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:1288\u001b[0m, in \u001b[0;36mDataFrameGroupBy.aggregate\u001b[1;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1285\u001b[0m     \u001b[38;5;66;03m# grouper specific aggregations\u001b[39;00m\n\u001b[0;32m   1286\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouper\u001b[38;5;241m.\u001b[39mnkeys \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1287\u001b[0m         \u001b[38;5;66;03m# test_groupby_as_index_series_scalar gets here with 'not self.as_index'\u001b[39;00m\n\u001b[1;32m-> 1288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_agg_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1289\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m args \u001b[38;5;129;01mor\u001b[39;00m kwargs:\n\u001b[0;32m   1290\u001b[0m         \u001b[38;5;66;03m# test_pass_args_kwargs gets here (with and without as_index)\u001b[39;00m\n\u001b[0;32m   1291\u001b[0m         \u001b[38;5;66;03m# can't return early\u001b[39;00m\n\u001b[0;32m   1292\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aggregate_frame(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\zhouz\\anaconda3\\envs\\BStackGP\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:1338\u001b[0m, in \u001b[0;36mDataFrameGroupBy._python_agg_general\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1335\u001b[0m \u001b[38;5;66;03m# iterate through \"columns\" ex exclusions to populate output dict\u001b[39;00m\n\u001b[0;32m   1336\u001b[0m output: \u001b[38;5;28mdict\u001b[39m[base\u001b[38;5;241m.\u001b[39mOutputKey, ArrayLike] \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m-> 1338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mngroups\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1339\u001b[0m     \u001b[38;5;66;03m# e.g. test_evaluate_with_empty_groups different path gets different\u001b[39;00m\n\u001b[0;32m   1340\u001b[0m     \u001b[38;5;66;03m#  result dtype in empty case.\u001b[39;00m\n\u001b[0;32m   1341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_python_apply_general(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selected_obj, is_agg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1343\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, obj \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterate_slices()):\n",
      "File \u001b[1;32mc:\\Users\\zhouz\\anaconda3\\envs\\BStackGP\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:653\u001b[0m, in \u001b[0;36mBaseGroupBy.ngroups\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    650\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    651\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    652\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mngroups\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m--> 653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mngroups\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\zhouz\\anaconda3\\envs\\BStackGP\\Lib\\site-packages\\pandas\\_libs\\properties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\zhouz\\anaconda3\\envs\\BStackGP\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:902\u001b[0m, in \u001b[0;36mBaseGrouper.ngroups\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    899\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;129m@cache_readonly\u001b[39m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mngroups\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m--> 902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult_index\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\zhouz\\anaconda3\\envs\\BStackGP\\Lib\\site-packages\\pandas\\_libs\\properties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\zhouz\\anaconda3\\envs\\BStackGP\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:915\u001b[0m, in \u001b[0;36mBaseGrouper.result_index\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroupings) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    913\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroupings[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mresult_index\u001b[38;5;241m.\u001b[39mrename(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m--> 915\u001b[0m codes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreconstructed_codes\u001b[49m\n\u001b[0;32m    916\u001b[0m levels \u001b[38;5;241m=\u001b[39m [ping\u001b[38;5;241m.\u001b[39mresult_index \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroupings]\n\u001b[0;32m    917\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m MultiIndex(\n\u001b[0;32m    918\u001b[0m     levels\u001b[38;5;241m=\u001b[39mlevels, codes\u001b[38;5;241m=\u001b[39mcodes, verify_integrity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames\n\u001b[0;32m    919\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\zhouz\\anaconda3\\envs\\BStackGP\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:906\u001b[0m, in \u001b[0;36mBaseGrouper.reconstructed_codes\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    904\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    905\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreconstructed_codes\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mintp]]:\n\u001b[1;32m--> 906\u001b[0m     codes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcodes\u001b[49m\n\u001b[0;32m    907\u001b[0m     ids, obs_ids, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup_info\n\u001b[0;32m    908\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m decons_obs_group_ids(ids, obs_ids, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape, codes, xnull\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\zhouz\\anaconda3\\envs\\BStackGP\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:824\u001b[0m, in \u001b[0;36mBaseGrouper.codes\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    821\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    822\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcodes\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39msignedinteger]]:\n\u001b[1;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[43mping\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcodes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mping\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupings\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\zhouz\\anaconda3\\envs\\BStackGP\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:824\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    821\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    822\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcodes\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39msignedinteger]]:\n\u001b[1;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mping\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcodes\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroupings]\n",
      "File \u001b[1;32mc:\\Users\\zhouz\\anaconda3\\envs\\BStackGP\\Lib\\site-packages\\pandas\\core\\groupby\\grouper.py:671\u001b[0m, in \u001b[0;36mGrouping.codes\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    670\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcodes\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39msignedinteger]:\n\u001b[1;32m--> 671\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_codes_and_uniques\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\zhouz\\anaconda3\\envs\\BStackGP\\Lib\\site-packages\\pandas\\_libs\\properties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\zhouz\\anaconda3\\envs\\BStackGP\\Lib\\site-packages\\pandas\\core\\groupby\\grouper.py:780\u001b[0m, in \u001b[0;36mGrouping._codes_and_uniques\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    775\u001b[0m     uniques \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_uniques\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;66;03m# GH35667, replace dropna=False with use_na_sentinel=False\u001b[39;00m\n\u001b[0;32m    778\u001b[0m     \u001b[38;5;66;03m# error: Incompatible types in assignment (expression has type \"Union[\u001b[39;00m\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;66;03m# ndarray[Any, Any], Index]\", variable has type \"Categorical\")\u001b[39;00m\n\u001b[1;32m--> 780\u001b[0m     codes, uniques \u001b[38;5;241m=\u001b[39m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[assignment]\u001b[39;49;00m\n\u001b[0;32m    781\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouping_vector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sort\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_na_sentinel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dropna\u001b[49m\n\u001b[0;32m    782\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    783\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m codes, uniques\n",
      "File \u001b[1;32mc:\\Users\\zhouz\\anaconda3\\envs\\BStackGP\\Lib\\site-packages\\pandas\\core\\algorithms.py:786\u001b[0m, in \u001b[0;36mfactorize\u001b[1;34m(values, sort, use_na_sentinel, size_hint)\u001b[0m\n\u001b[0;32m    779\u001b[0m     codes, uniques \u001b[38;5;241m=\u001b[39m factorize_array(\n\u001b[0;32m    780\u001b[0m         values,\n\u001b[0;32m    781\u001b[0m         use_na_sentinel\u001b[38;5;241m=\u001b[39muse_na_sentinel,\n\u001b[0;32m    782\u001b[0m         size_hint\u001b[38;5;241m=\u001b[39msize_hint,\n\u001b[0;32m    783\u001b[0m     )\n\u001b[0;32m    785\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sort \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 786\u001b[0m     uniques, codes \u001b[38;5;241m=\u001b[39m \u001b[43msafe_sort\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    787\u001b[0m \u001b[43m        \u001b[49m\u001b[43muniques\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_na_sentinel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_na_sentinel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m        \u001b[49m\u001b[43massume_unique\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    794\u001b[0m uniques \u001b[38;5;241m=\u001b[39m _reconstruct_data(uniques, original\u001b[38;5;241m.\u001b[39mdtype, original)\n\u001b[0;32m    796\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m codes, uniques\n",
      "File \u001b[1;32mc:\\Users\\zhouz\\anaconda3\\envs\\BStackGP\\Lib\\site-packages\\pandas\\core\\algorithms.py:1543\u001b[0m, in \u001b[0;36msafe_sort\u001b[1;34m(values, codes, use_na_sentinel, assume_unique, verify)\u001b[0m\n\u001b[0;32m   1541\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1542\u001b[0m     sorter \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39margsort()\n\u001b[1;32m-> 1543\u001b[0m     ordered \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mtake(sorter)\n\u001b[0;32m   1544\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   1545\u001b[0m     \u001b[38;5;66;03m# Previous sorters failed or were not applicable, try `_sort_mixed`\u001b[39;00m\n\u001b[0;32m   1546\u001b[0m     \u001b[38;5;66;03m# which would work, but which fails for special case of 1d arrays\u001b[39;00m\n\u001b[0;32m   1547\u001b[0m     \u001b[38;5;66;03m# with tuples.\u001b[39;00m\n\u001b[0;32m   1548\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m values\u001b[38;5;241m.\u001b[39msize \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mtuple\u001b[39m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def fit_trees():\n",
    "    learning_rate=0.1\n",
    "    max_depth=5\n",
    "    bins=8\n",
    "    lam=100\n",
    "\n",
    "    gtgp = GTGP(learning_rate=learning_rate,max_depth=max_depth,bins=bins,lam=lam)\n",
    "\n",
    "    total_size=10\n",
    "    elite_size = 10\n",
    "    epoch= 100\n",
    "    gp_epoch= 3\n",
    "    verbose = 1\n",
    "    tolerance=0.5\n",
    "\n",
    "    gtgp.fit(X_train,y_train,total_size=total_size,elite_size = elite_size,epoch=epoch,gp_epoch=gp_epoch,tolerance=tolerance,verbose=verbose)\n",
    "\n",
    "    retrain_epoch=20\n",
    "    alpha=0\n",
    "    beta=1\n",
    "    gammer=0\n",
    "\n",
    "    verbose=1\n",
    "    gtgp.lam = 10\n",
    "    gtgp.retrain_estimators(X_test,y_test,retrain_epoch=retrain_epoch,alpha=alpha,beta=beta,gammer=gammer,verbose=verbose)\n",
    "\n",
    "    return gtgp\n",
    "\n",
    "for i in range(30):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size,stratify=y, random_state=seeds[i])\n",
    "    gtgp = fit_trees()\n",
    "\n",
    "    print(classification_report(y_train,np.argmax(gtgp.train_p,axis=1),digits=5))\n",
    "    print(classification_report(y_test,np.argmax(gtgp.test_p,axis=1),digits=5))\n",
    "\n",
    "    num_trees,depth,num_nodes = gtgp.print_model()\n",
    "\n",
    "    train_acc = accuracy_score(y_train,np.argmax(gtgp.train_p,axis=1))\n",
    "    test_acc = accuracy_score(y_test,np.argmax(gtgp.test_p,axis=1))\n",
    "    train_f1 = f1_score(y_train,np.argmax(gtgp.train_p,axis=1),average='macro')\n",
    "    test_f1 = f1_score(y_test,np.argmax(gtgp.test_p,axis=1),average='macro')\n",
    "\n",
    "\n",
    "    with open('./benchmark/'+dataset+'.csv','a') as f:\n",
    "        s = str(train_acc)+\",\"+str(test_acc)+\",\"+str(train_f1)+\",\"+str(test_f1)+\",\"+str(num_trees)+\",\"+str(depth)+\",\"+str(num_nodes)+\"\\n\"\n",
    "        f.writelines(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c846b3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57 305 1\n",
      "127 729 2\n",
      "179 961 3\n",
      "217 1209 4\n",
      "255 1377 5\n",
      "296 1602 6\n",
      "339 1815 7\n",
      "372 1984 8\n",
      "412 2228 9\n",
      "448 2414 10\n",
      "491 2667 11\n",
      "529 2871 12\n",
      "558 3034 13\n",
      "589 3175 14\n",
      "618 3364 15\n",
      "644 3484 16\n",
      "680 3692 17\n",
      "718 3860 18\n",
      "737 4003 19\n",
      "781 4215 20\n",
      "809 4399 21\n",
      "837 4563 22\n",
      "875 4783 23\n",
      "906 4976 24\n",
      "943 5187 25\n",
      "959 5231 26\n",
      "980 5374 27\n",
      "1015 5591 28\n",
      "1038 5674 29\n",
      "1075 5843 30\n",
      "1103 6027 31\n",
      "1137 6361 32\n",
      "1162 6530 33\n",
      "1197 6755 34\n",
      "1226 6936 35\n",
      "1267 7255 36\n",
      "1287 7355 37\n",
      "1313 7517 38\n",
      "1336 7660 39\n",
      "1368 7856 40\n",
      "1401 8081 41\n",
      "1426 8192 42\n",
      "1447 8311 43\n",
      "1479 8537 44\n",
      "1510 8724 45\n",
      "1536 8874 46\n",
      "1566 9070 47\n",
      "1586 9152 48\n",
      "1603 9231 49\n",
      "1626 9332 50\n",
      "1652 9492 51\n",
      "1682 9672 52\n",
      "1705 9821 53\n",
      "1736 10016 54\n",
      "1757 10129 55\n",
      "1782 10280 56\n",
      "1809 10451 57\n",
      "1828 10558 58\n",
      "1851 10673 59\n",
      "1881 10843 60\n",
      "1900 10930 61\n",
      "1914 11010 62\n",
      "1935 11143 63\n",
      "1955 11243 64\n",
      "1974 11366 65\n",
      "1989 11441 66\n",
      "2008 11582 67\n",
      "2023 11653 68\n",
      "2051 11869 69\n",
      "2066 11932 70\n",
      "2093 12093 71\n",
      "2113 12227 72\n",
      "2132 12356 73\n",
      "2154 12520 74\n",
      "2181 12691 75\n",
      "2199 12795 76\n",
      "2215 12865 77\n",
      "2227 12929 78\n",
      "2255 13161 79\n",
      "2284 13398 80\n",
      "2296 13434 81\n",
      "2311 13547 82\n",
      "2319 13609 83\n",
      "2352 13846 84\n",
      "2358 13852 85\n",
      "2367 13903 86\n",
      "2381 13967 87\n",
      "2391 14029 88\n",
      "2406 14126 89\n",
      "2422 14224 90\n",
      "2439 14335 91\n",
      "2453 14409 92\n",
      "2482 14608 93\n",
      "2494 14672 94\n",
      "2520 14848 95\n",
      "2542 14954 96\n",
      "2572 15156 97\n",
      "2585 15237 98\n",
      "2613 15419 99\n",
      "2627 15497 100\n",
      "2635 15521 101\n",
      "2649 15569 102\n",
      "2671 15697 103\n",
      "2692 15858 104\n",
      "2710 15954 105\n",
      "2731 16109 106\n",
      "2742 16182 107\n",
      "2762 16350 108\n",
      "2780 16456 109\n",
      "2795 16595 110\n",
      "2826 16770 111\n",
      "2838 16830 112\n",
      "2866 17004 113\n",
      "2882 17124 114\n",
      "2899 17259 115\n",
      "2911 17315 116\n",
      "2927 17423 117\n",
      "2949 17541 118\n",
      "2967 17687 119\n",
      "2990 17832 120\n",
      "3011 17929 121\n",
      "3025 18019 122\n",
      "3040 18128 123\n",
      "3059 18259 124\n",
      "3075 18335 125\n",
      "3094 18470 126\n",
      "3115 18625 127\n",
      "3126 18694 128\n",
      "3136 18738 129\n",
      "3145 18801 130\n",
      "3158 18886 131\n",
      "3179 18995 132\n",
      "3197 19131 133\n",
      "3207 19137 134\n",
      "3221 19211 135\n",
      "3231 19281 136\n",
      "3244 19356 137\n",
      "3256 19418 138\n",
      "3264 19488 139\n",
      "3278 19578 140\n",
      "3291 19667 141\n",
      "3316 19846 142\n",
      "3333 19965 143\n",
      "3353 20105 144\n",
      "3369 20209 145\n",
      "3381 20279 146\n",
      "3399 20419 147\n",
      "3414 20524 148\n",
      "3429 20613 149\n",
      "3444 20726 150\n",
      "3459 20851 151\n",
      "3481 21051 152\n",
      "3493 21113 153\n",
      "3513 21223 154\n",
      "3534 21346 155\n",
      "3552 21450 156\n",
      "3568 21568 157\n",
      "3585 21697 158\n",
      "3602 21828 159\n",
      "3615 21935 160\n",
      "3626 22016 161\n",
      "3647 22171 162\n",
      "3659 22277 163\n",
      "3677 22389 164\n",
      "3688 22496 165\n",
      "3701 22587 166\n",
      "3717 22671 167\n",
      "3729 22727 168\n",
      "3739 22813 169\n",
      "3759 22995 170\n",
      "3780 23156 171\n",
      "3785 23157 172\n",
      "3795 23233 173\n",
      "3804 23318 174\n",
      "3824 23456 175\n",
      "3841 23545 176\n",
      "3855 23639 177\n",
      "3874 23802 178\n",
      "3891 23883 179\n",
      "3906 23992 180\n",
      "3920 24060 181\n",
      "3931 24161 182\n",
      "3950 24266 183\n",
      "3971 24473 184\n",
      "3983 24575 185\n",
      "3994 24654 186\n",
      "4007 24703 187\n",
      "4018 24766 188\n",
      "4035 24861 189\n",
      "4053 24969 190\n",
      "4065 25053 191\n",
      "4079 25175 192\n",
      "4091 25277 193\n",
      "4097 25307 194\n",
      "4111 25387 195\n",
      "4120 25438 196\n",
      "4132 25552 197\n",
      "4146 25644 198\n",
      "4164 25780 199\n",
      "4169 25829 200\n",
      "4177 25895 201\n",
      "4188 25964 202\n",
      "4204 26056 203\n",
      "4216 26132 204\n",
      "4235 26241 205\n",
      "4245 26279 206\n",
      "4272 26446 207\n",
      "4277 26475 208\n",
      "4287 26525 209\n",
      "4294 26576 210\n",
      "4305 26617 211\n",
      "4329 26791 212\n",
      "4344 26898 213\n",
      "4362 27038 214\n",
      "4370 27074 215\n",
      "4377 27099 216\n",
      "4390 27150 217\n",
      "4399 27215 218\n",
      "4412 27320 219\n",
      "4419 27359 220\n",
      "4429 27445 221\n",
      "4451 27611 222\n",
      "4463 27703 223\n",
      "4469 27733 224\n",
      "4488 27886 225\n",
      "4509 27999 226\n",
      "4522 28072 227\n",
      "4528 28100 228\n",
      "4537 28179 229\n",
      "4547 28253 230\n",
      "4559 28327 231\n",
      "4570 28392 232\n",
      "4582 28512 233\n",
      "4598 28650 234\n",
      "4612 28728 235\n",
      "4624 28822 236\n",
      "4648 29008 237\n",
      "4662 29134 238\n",
      "4667 29161 239\n",
      "4682 29320 240\n",
      "4696 29422 241\n",
      "4713 29565 242\n",
      "4731 29655 243\n",
      "4739 29711 244\n",
      "4742 29712 245\n",
      "4755 29801 246\n",
      "4771 29937 247\n",
      "4778 29986 248\n",
      "4787 30057 249\n",
      "4797 30171 250\n",
      "4806 30246 251\n",
      "4813 30283 252\n",
      "4823 30337 253\n",
      "4841 30447 254\n",
      "4850 30506 255\n",
      "4861 30561 256\n",
      "4874 30610 257\n",
      "4876 30624 258\n",
      "4893 30785 259\n",
      "4913 30941 260\n",
      "4921 30997 261\n",
      "4931 31029 262\n",
      "4938 31072 263\n",
      "4963 31381 264\n",
      "4968 31400 265\n",
      "4980 31480 266\n",
      "4987 31515 267\n",
      "5006 31690 268\n",
      "5026 31852 269\n",
      "5038 31922 270\n",
      "5048 31994 271\n",
      "5066 32120 272\n",
      "5072 32138 273\n",
      "5092 32276 274\n",
      "5108 32408 275\n",
      "5114 32442 276\n",
      "5137 32591 277\n",
      "5154 32708 278\n",
      "5163 32797 279\n",
      "5183 32915 280\n",
      "5191 32951 281\n",
      "5198 33002 282\n",
      "5207 33047 283\n",
      "5218 33146 284\n",
      "5231 33229 285\n",
      "5244 33312 286\n",
      "5253 33371 287\n",
      "5261 33397 288\n",
      "5275 33497 289\n",
      "5285 33569 290\n",
      "5297 33665 291\n",
      "5300 33686 292\n",
      "5303 33699 293\n",
      "5310 33756 294\n",
      "5325 33867 295\n",
      "5334 33946 296\n",
      "5348 34036 297\n",
      "5360 34124 298\n",
      "5370 34200 299\n",
      "5377 34257 300\n",
      "5385 34311 301\n",
      "5406 34434 302\n",
      "5425 34589 303\n",
      "5438 34718 304\n",
      "5454 34830 305\n",
      "5465 34905 306\n",
      "5481 35043 307\n",
      "5496 35164 308\n",
      "5507 35237 309\n",
      "5523 35335 310\n",
      "5541 35467 311\n",
      "5552 35530 312\n",
      "5557 35569 313\n",
      "5568 35662 314\n",
      "5578 35722 315\n",
      "5580 35734 316\n",
      "5588 35786 317\n",
      "5592 35796 318\n",
      "5604 35884 319\n",
      "5618 36004 320\n",
      "5626 36036 321\n",
      "5636 36090 322\n",
      "5652 36184 323\n",
      "5666 36280 324\n",
      "5678 36366 325\n",
      "5699 36555 326\n",
      "5711 36673 327\n",
      "5724 36774 328\n",
      "5735 36905 329\n",
      "5741 36927 330\n",
      "5751 36959 331\n",
      "5770 37116 332\n",
      "5783 37197 333\n",
      "5789 37231 334\n",
      "5795 37277 335\n",
      "5809 37405 336\n",
      "5825 37573 337\n",
      "5840 37686 338\n",
      "5850 37718 339\n",
      "5859 37777 340\n",
      "5868 37832 341\n",
      "5873 37841 342\n",
      "5884 37902 343\n",
      "5893 37975 344\n",
      "5900 37992 345\n",
      "5902 37996 346\n",
      "5911 38053 347\n",
      "5929 38199 348\n",
      "5937 38263 349\n",
      "5945 38313 350\n",
      "5961 38435 351\n",
      "5968 38494 352\n",
      "5976 38546 353\n",
      "5988 38636 354\n",
      "5995 38667 355\n",
      "6011 38761 356\n",
      "6025 38903 357\n",
      "6048 39062 358\n",
      "6055 39109 359\n",
      "6064 39170 360\n",
      "6081 39295 361\n",
      "6092 39338 362\n",
      "6107 39431 363\n",
      "6111 39449 364\n",
      "6116 39498 365\n",
      "6132 39640 366\n",
      "6136 39664 367\n",
      "6145 39735 368\n",
      "6155 39807 369\n",
      "6166 39902 370\n",
      "6182 40006 371\n",
      "6188 40028 372\n",
      "6196 40050 373\n",
      "6211 40147 374\n",
      "6227 40245 375\n",
      "6239 40323 376\n",
      "6253 40415 377\n",
      "6258 40448 378\n",
      "6264 40454 379\n",
      "6271 40499 380\n",
      "6285 40603 381\n",
      "6290 40632 382\n",
      "6303 40705 383\n",
      "6318 40832 384\n",
      "6322 40850 385\n",
      "6332 40918 386\n",
      "6347 41067 387\n",
      "6355 41107 388\n",
      "6360 41156 389\n",
      "6366 41208 390\n",
      "6372 41242 391\n",
      "6386 41360 392\n",
      "6397 41423 393\n",
      "6404 41468 394\n",
      "6417 41581 395\n",
      "6437 41693 396\n",
      "6444 41742 397\n",
      "6450 41814 398\n",
      "6458 41874 399\n",
      "6475 42013 400\n",
      "6485 42081 401\n",
      "6501 42209 402\n",
      "6510 42268 403\n",
      "6521 42321 404\n",
      "6531 42401 405\n",
      "6539 42443 406\n",
      "6545 42483 407\n",
      "6552 42532 408\n",
      "6564 42618 409\n",
      "6573 42699 410\n",
      "6584 42748 411\n",
      "6597 42839 412\n",
      "6604 42882 413\n",
      "6615 42973 414\n",
      "6622 42996 415\n",
      "6628 43030 416\n",
      "6635 43079 417\n",
      "6645 43147 418\n",
      "6657 43233 419\n",
      "6666 43290 420\n",
      "6680 43402 421\n",
      "6697 43543 422\n",
      "6707 43585 423\n",
      "6712 43624 424\n",
      "6720 43666 425\n",
      "6725 43691 426\n",
      "6736 43790 427\n",
      "6753 43903 428\n",
      "6759 43939 429\n",
      "6768 44000 430\n",
      "6776 44068 431\n",
      "6790 44174 432\n",
      "6805 44251 433\n",
      "6819 44369 434\n",
      "6839 44519 435\n",
      "6847 44567 436\n",
      "6856 44622 437\n",
      "6865 44671 438\n",
      "6871 44707 439\n",
      "6872 44698 440\n",
      "6878 44716 441\n",
      "6884 44744 442\n",
      "6896 44810 443\n",
      "6902 44846 444\n",
      "6913 44913 445\n",
      "6937 45117 446\n",
      "6940 45136 447\n",
      "6951 45233 448\n",
      "6967 45373 449\n",
      "6983 45477 450\n",
      "6993 45557 451\n",
      "7016 45728 452\n",
      "7034 45876 453\n",
      "7043 45947 454\n",
      "7050 46006 455\n",
      "7068 46136 456\n",
      "7073 46151 457\n",
      "7079 46177 458\n",
      "7091 46257 459\n",
      "7098 46324 460\n",
      "7102 46326 461\n",
      "7105 46341 462\n",
      "7115 46425 463\n",
      "7125 46487 464\n",
      "7137 46545 465\n",
      "7149 46611 466\n",
      "7158 46680 467\n",
      "7169 46727 468\n",
      "7179 46807 469\n",
      "7187 46859 470\n",
      "7192 46882 471\n",
      "7196 46894 472\n",
      "7204 46946 473\n",
      "7208 46970 474\n",
      "7216 47044 475\n",
      "7231 47141 476\n",
      "7243 47245 477\n",
      "7250 47296 478\n",
      "7256 47334 479\n",
      "7264 47388 480\n",
      "7272 47426 481\n",
      "7288 47526 482\n",
      "7292 47550 483\n",
      "7303 47639 484\n",
      "7314 47726 485\n",
      "7318 47738 486\n",
      "7328 47790 487\n",
      "7341 47881 488\n",
      "7353 47983 489\n",
      "7362 48056 490\n",
      "7381 48179 491\n",
      "7390 48294 492\n",
      "7403 48397 493\n",
      "7416 48480 494\n",
      "7427 48551 495\n",
      "7434 48602 496\n",
      "7450 48732 497\n",
      "7455 48777 498\n",
      "7466 48826 499\n",
      "7473 48861 500\n",
      "7485 48915 501\n",
      "7496 49046 502\n",
      "7503 49099 503\n",
      "7508 49128 504\n",
      "7517 49177 505\n",
      "7524 49262 506\n",
      "7528 49264 507\n",
      "7533 49295 508\n",
      "7540 49354 509\n",
      "7555 49471 510\n",
      "7566 49556 511\n",
      "7573 49603 512\n",
      "7580 49632 513\n",
      "7588 49682 514\n",
      "7597 49713 515\n",
      "7604 49772 516\n",
      "7618 49878 517\n",
      "7625 49931 518\n",
      "7636 50002 519\n",
      "7643 50049 520\n",
      "7648 50080 521\n",
      "7661 50157 522\n",
      "7663 50163 523\n",
      "7672 50222 524\n",
      "7681 50287 525\n",
      "7694 50378 526\n",
      "7704 50442 527\n",
      "7714 50526 528\n",
      "7726 50628 529\n",
      "7736 50716 530\n",
      "7740 50742 531\n",
      "7749 50817 532\n",
      "7756 50856 533\n",
      "7765 50923 534\n",
      "7783 51071 535\n",
      "7792 51148 536\n",
      "7805 51239 537\n",
      "7810 51268 538\n",
      "7817 51309 539\n",
      "7826 51364 540\n",
      "7832 51386 541\n",
      "7847 51487 542\n",
      "7862 51622 543\n",
      "7875 51721 544\n",
      "7882 51770 545\n",
      "7884 51774 546\n",
      "7892 51824 547\n",
      "7910 51988 548\n",
      "7923 52063 549\n",
      "7935 52141 550\n",
      "7940 52192 551\n",
      "7950 52254 552\n",
      "7960 52310 553\n",
      "7970 52364 554\n",
      "7973 52367 555\n",
      "7984 52446 556\n",
      "7996 52524 557\n",
      "8001 52551 558\n",
      "8008 52602 559\n",
      "8016 52652 560\n",
      "8025 52703 561\n",
      "8033 52733 562\n",
      "8045 52809 563\n",
      "8053 52849 564\n",
      "8064 52906 565\n",
      "8070 52950 566\n",
      "8079 53007 567\n",
      "8086 53050 568\n",
      "8092 53084 569\n",
      "8099 53147 570\n",
      "8108 53178 571\n",
      "8118 53276 572\n",
      "8127 53323 573\n",
      "8137 53393 574\n",
      "8150 53472 575\n",
      "8173 53647 576\n",
      "8182 53710 577\n",
      "8192 53762 578\n",
      "8201 53853 579\n",
      "8205 53857 580\n",
      "8214 53920 581\n",
      "8217 53957 582\n",
      "8225 54029 583\n",
      "8233 54085 584\n",
      "8239 54145 585\n",
      "8242 54172 586\n",
      "8245 54185 587\n",
      "8246 54186 588\n",
      "8254 54240 589\n",
      "8262 54288 590\n",
      "8266 54316 591\n",
      "8282 54470 592\n",
      "8294 54564 593\n",
      "8301 54629 594\n",
      "8307 54673 595\n",
      "8333 54915 596\n",
      "8341 54977 597\n",
      "8347 55017 598\n",
      "8361 55135 599\n",
      "8370 55188 600\n",
      "8383 55265 601\n",
      "8395 55359 602\n",
      "8400 55404 603\n",
      "8414 55546 604\n",
      "8431 55709 605\n",
      "8438 55768 606\n",
      "8447 55817 607\n",
      "8461 55917 608\n",
      "8466 55944 609\n",
      "8475 55985 610\n",
      "8479 55989 611\n",
      "8485 56049 612\n",
      "8495 56123 613\n",
      "8507 56209 614\n",
      "8515 56245 615\n",
      "8530 56354 616\n",
      "8542 56412 617\n",
      "8546 56446 618\n",
      "8551 56485 619\n",
      "8561 56517 620\n",
      "8567 56561 621\n",
      "8573 56587 622\n",
      "8586 56680 623\n",
      "8587 56681 624\n",
      "8593 56711 625\n",
      "8599 56735 626\n",
      "8606 56796 627\n",
      "8614 56846 628\n",
      "8619 56869 629\n",
      "8630 56932 630\n",
      "8640 57000 631\n",
      "8650 57074 632\n",
      "8663 57161 633\n",
      "8675 57237 634\n",
      "8686 57308 635\n",
      "8698 57376 636\n",
      "8711 57481 637\n",
      "8714 57512 638\n",
      "8726 57598 639\n",
      "8734 57666 640\n",
      "8739 57679 641\n",
      "8755 57815 642\n",
      "8769 57945 643\n",
      "8776 57992 644\n",
      "8783 58049 645\n",
      "8790 58112 646\n",
      "8804 58244 647\n",
      "8813 58307 648\n",
      "8826 58422 649\n",
      "8841 58515 650\n",
      "8849 58577 651\n",
      "8851 58575 652\n",
      "8855 58567 653\n",
      "8861 58639 654\n",
      "8872 58728 655\n",
      "8877 58763 656\n",
      "8882 58772 657\n",
      "8893 58839 658\n",
      "8899 58863 659\n",
      "8914 58982 660\n",
      "8926 59054 661\n",
      "8929 59071 662\n",
      "8938 59134 663\n",
      "8951 59205 664\n",
      "8960 59256 665\n",
      "8971 59357 666\n",
      "8973 59349 667\n",
      "8982 59424 668\n",
      "8989 59473 669\n",
      "8998 59550 670\n",
      "9004 59586 671\n",
      "9014 59644 672\n",
      "9020 59674 673\n",
      "9028 59738 674\n",
      "9037 59825 675\n",
      "9044 59862 676\n",
      "9052 59888 677\n",
      "9057 59923 678\n",
      "9066 60002 679\n",
      "9077 60109 680\n",
      "9087 60177 681\n",
      "9095 60247 682\n",
      "9100 60262 683\n",
      "9103 60285 684\n",
      "9116 60406 685\n",
      "9133 60519 686\n",
      "9139 60563 687\n",
      "9151 60659 688\n",
      "9153 60673 689\n",
      "9164 60744 690\n",
      "9173 60793 691\n",
      "9186 60882 692\n",
      "9189 60903 693\n",
      "9197 60945 694\n",
      "9205 60993 695\n",
      "9210 61016 696\n",
      "9221 61103 697\n",
      "9221 61097 698\n",
      "9228 61138 699\n",
      "9235 61191 700\n",
      "9241 61245 701\n",
      "9251 61315 702\n",
      "9252 61320 703\n",
      "9266 61428 704\n",
      "9271 61467 705\n",
      "9283 61559 706\n",
      "9290 61602 707\n",
      "9304 61762 708\n",
      "9313 61853 709\n",
      "9318 61884 710\n",
      "9321 61899 711\n",
      "9326 61932 712\n",
      "9328 61950 713\n",
      "9334 61986 714\n",
      "9341 62021 715\n",
      "9357 62133 716\n",
      "9365 62201 717\n",
      "9367 62205 718\n",
      "9370 62220 719\n",
      "9376 62242 720\n",
      "9384 62276 721\n",
      "9389 62307 722\n",
      "9394 62348 723\n",
      "9401 62385 724\n",
      "9404 62396 725\n",
      "9410 62420 726\n",
      "9423 62515 727\n",
      "9437 62609 728\n",
      "9443 62671 729\n",
      "9459 62783 730\n",
      "9465 62825 731\n",
      "9477 62911 732\n",
      "9489 62997 733\n",
      "9495 63033 734\n",
      "9505 63103 735\n",
      "9513 63177 736\n",
      "9519 63199 737\n",
      "9529 63247 738\n",
      "9538 63312 739\n",
      "9539 63313 740\n",
      "9544 63340 741\n",
      "9555 63425 742\n",
      "9562 63474 743\n",
      "9574 63586 744\n",
      "9588 63726 745\n",
      "9596 63772 746\n",
      "9606 63834 747\n",
      "9617 63877 748\n",
      "9622 63916 749\n",
      "9631 63995 750\n",
      "9642 64080 751\n",
      "9651 64149 752\n",
      "9654 64148 753\n",
      "9660 64190 754\n",
      "9665 64221 755\n",
      "9673 64269 756\n",
      "9679 64327 757\n",
      "9682 64336 758\n",
      "9691 64415 759\n",
      "9696 64456 760\n",
      "9700 64482 761\n",
      "9703 64497 762\n",
      "9713 64567 763\n",
      "9732 64698 764\n",
      "9740 64786 765\n",
      "9747 64847 766\n",
      "9756 64902 767\n",
      "9765 64951 768\n",
      "9771 64985 769\n",
      "9775 64995 770\n",
      "9777 64997 771\n",
      "9787 65061 772\n",
      "9791 65081 773\n",
      "9793 65095 774\n",
      "9801 65135 775\n",
      "9810 65198 776\n",
      "9819 65297 777\n",
      "9824 65316 778\n",
      "9832 65380 779\n",
      "9837 65407 780\n",
      "9853 65547 781\n",
      "9864 65618 782\n",
      "9868 65638 783\n",
      "9879 65735 784\n",
      "9889 65831 785\n",
      "9907 65957 786\n",
      "9913 66005 787\n",
      "9918 66038 788\n",
      "9929 66091 789\n",
      "9935 66113 790\n",
      "9947 66217 791\n",
      "9952 66264 792\n",
      "9955 66287 793\n",
      "9963 66349 794\n",
      "9976 66438 795\n",
      "9989 66519 796\n",
      "9997 66567 797\n",
      "10002 66596 798\n",
      "10005 66611 799\n",
      "10010 66640 800\n",
      "10031 66809 801\n",
      "10039 66859 802\n",
      "10046 66896 803\n",
      "10055 66955 804\n",
      "10062 66994 805\n",
      "10072 67094 806\n",
      "10078 67132 807\n",
      "10090 67240 808\n",
      "10094 67258 809\n",
      "10103 67317 810\n",
      "10112 67366 811\n",
      "10119 67427 812\n",
      "10123 67447 813\n",
      "10131 67501 814\n",
      "10134 67520 815\n",
      "10137 67527 816\n",
      "10142 67560 817\n",
      "10150 67602 818\n",
      "10159 67663 819\n",
      "10167 67711 820\n",
      "10171 67751 821\n",
      "10176 67766 822\n",
      "10184 67824 823\n",
      "10206 67988 824\n",
      "10214 68060 825\n",
      "10220 68098 826\n",
      "10231 68135 827\n",
      "10236 68178 828\n",
      "10252 68308 829\n",
      "10257 68333 830\n",
      "10266 68390 831\n",
      "10277 68463 832\n",
      "10290 68580 833\n",
      "10302 68662 834\n",
      "10311 68757 835\n",
      "10315 68805 836\n",
      "10324 68878 837\n",
      "10333 68933 838\n",
      "10339 68965 839\n",
      "10349 69043 840\n",
      "10358 69104 841\n",
      "10368 69160 842\n",
      "10377 69207 843\n",
      "10386 69256 844\n",
      "10398 69328 845\n",
      "10406 69382 846\n",
      "10415 69455 847\n",
      "10419 69473 848\n",
      "10423 69483 849\n",
      "10430 69524 850\n",
      "10439 69587 851\n",
      "10442 69618 852\n",
      "10448 69664 853\n",
      "10458 69740 854\n",
      "10466 69790 855\n",
      "10475 69851 856\n",
      "10478 69870 857\n",
      "10487 69949 858\n",
      "10497 70035 859\n",
      "10506 70098 860\n",
      "10517 70155 861\n",
      "10530 70238 862\n",
      "10535 70261 863\n",
      "10544 70320 864\n",
      "10550 70352 865\n",
      "10560 70438 866\n",
      "10570 70522 867\n",
      "10576 70574 868\n",
      "10579 70591 869\n",
      "10585 70631 870\n",
      "10601 70777 871\n",
      "10607 70793 872\n",
      "10608 70782 873\n",
      "10622 70912 874\n",
      "10629 70971 875\n",
      "10641 71049 876\n",
      "10646 71042 877\n",
      "10648 71058 878\n",
      "10653 71089 879\n",
      "10657 71117 880\n",
      "10667 71189 881\n",
      "10674 71234 882\n",
      "10679 71275 883\n",
      "10682 71278 884\n",
      "10690 71328 885\n",
      "10698 71368 886\n",
      "10709 71431 887\n",
      "10710 71440 888\n",
      "10722 71538 889\n",
      "10735 71649 890\n",
      "10737 71659 891\n",
      "10743 71697 892\n",
      "10747 71693 893\n",
      "10755 71745 894\n",
      "10763 71813 895\n",
      "10770 71878 896\n",
      "10779 71965 897\n",
      "10783 71997 898\n",
      "10798 72116 899\n",
      "10805 72163 900\n",
      "10823 72285 901\n",
      "10834 72368 902\n",
      "10841 72411 903\n",
      "10847 72435 904\n",
      "10850 72424 905\n",
      "10853 72435 906\n",
      "10856 72450 907\n",
      "10861 72499 908\n",
      "10869 72563 909\n",
      "10880 72636 910\n",
      "10890 72716 911\n",
      "10892 72736 912\n",
      "10902 72788 913\n",
      "10917 72925 914\n",
      "10923 72965 915\n",
      "10933 73017 916\n",
      "10946 73100 917\n",
      "10951 73145 918\n",
      "10957 73185 919\n",
      "10962 73214 920\n",
      "10973 73291 921\n",
      "10977 73329 922\n",
      "10985 73379 923\n",
      "10992 73424 924\n",
      "10997 73463 925\n",
      "11009 73557 926\n",
      "11012 73572 927\n",
      "11023 73663 928\n",
      "11038 73762 929\n",
      "11044 73798 930\n",
      "11050 73844 931\n",
      "11050 73834 932\n",
      "11057 73889 933\n",
      "11067 73999 934\n",
      "11078 74084 935\n",
      "11084 74126 936\n",
      "11092 74216 937\n",
      "11097 74237 938\n",
      "11102 74264 939\n",
      "11109 74301 940\n",
      "11113 74311 941\n",
      "11113 74311 942\n",
      "11115 74323 943\n",
      "11124 74378 944\n",
      "11135 74447 945\n",
      "11151 74609 946\n",
      "11154 74620 947\n",
      "11170 74746 948\n",
      "11182 74822 949\n",
      "11187 74851 950\n",
      "11188 74828 951\n",
      "11191 74827 952\n",
      "11195 74825 953\n",
      "11199 74841 954\n",
      "11204 74876 955\n",
      "11209 74895 956\n",
      "11213 74915 957\n",
      "11220 74970 958\n",
      "11223 74987 959\n",
      "11230 75050 960\n",
      "11233 75061 961\n",
      "11240 75106 962\n",
      "11251 75173 963\n",
      "11257 75207 964\n",
      "11263 75255 965\n",
      "11272 75346 966\n",
      "11279 75381 967\n",
      "11287 75445 968\n",
      "11299 75525 969\n",
      "11313 75635 970\n",
      "11319 75681 971\n",
      "11325 75707 972\n",
      "11338 75822 973\n",
      "11346 75858 974\n",
      "11353 75899 975\n",
      "11365 75973 976\n",
      "11373 76001 977\n",
      "11376 76018 978\n",
      "11387 76099 979\n",
      "11397 76159 980\n",
      "11402 76164 981\n",
      "11407 76185 982\n",
      "11411 76219 983\n",
      "11414 76248 984\n",
      "11423 76335 985\n",
      "11428 76346 986\n",
      "11436 76406 987\n",
      "11441 76425 988\n",
      "11447 76449 989\n",
      "11460 76550 990\n",
      "11469 76673 991\n",
      "11473 76695 992\n",
      "11478 76712 993\n",
      "11484 76750 994\n",
      "11489 76773 995\n",
      "11499 76867 996\n",
      "11509 76937 997\n",
      "11510 76944 998\n",
      "11520 77000 999\n",
      "11526 77058 1000\n",
      "11534 77130 1001\n",
      "11536 77120 1002\n",
      "11551 77221 1003\n",
      "11556 77238 1004\n",
      "11569 77353 1005\n",
      "11573 77383 1006\n",
      "11579 77431 1007\n",
      "11588 77494 1008\n",
      "11595 77509 1009\n",
      "11600 77556 1010\n",
      "11606 77632 1011\n",
      "11616 77718 1012\n",
      "11626 77812 1013\n",
      "11632 77858 1014\n",
      "11639 77897 1015\n",
      "11649 77977 1016\n",
      "11653 77985 1017\n",
      "11664 78090 1018\n",
      "11668 78118 1019\n",
      "11674 78152 1020\n",
      "11678 78180 1021\n",
      "11683 78197 1022\n",
      "11688 78242 1023\n",
      "11695 78283 1024\n",
      "11705 78331 1025\n",
      "11713 78371 1026\n",
      "11726 78486 1027\n",
      "11740 78588 1028\n",
      "11748 78640 1029\n",
      "11751 78637 1030\n",
      "11758 78682 1031\n",
      "11771 78781 1032\n",
      "11773 78787 1033\n",
      "11777 78809 1034\n",
      "11781 78823 1035\n",
      "11790 78910 1036\n",
      "11795 78945 1037\n",
      "11807 79053 1038\n",
      "11817 79153 1039\n",
      "11823 79193 1040\n",
      "11839 79333 1041\n",
      "11845 79365 1042\n",
      "11852 79394 1043\n",
      "11858 79432 1044\n",
      "11860 79420 1045\n",
      "11868 79470 1046\n",
      "11875 79517 1047\n",
      "11893 79643 1048\n",
      "11904 79718 1049\n",
      "11911 79763 1050\n",
      "11916 79772 1051\n",
      "11921 79805 1052\n",
      "11928 79862 1053\n",
      "11935 79917 1054\n",
      "11951 80109 1055\n",
      "11962 80208 1056\n",
      "11968 80244 1057\n",
      "11974 80282 1058\n",
      "11976 80294 1059\n",
      "11983 80361 1060\n",
      "11984 80366 1061\n",
      "11992 80422 1062\n",
      "12001 80479 1063\n",
      "12010 80544 1064\n",
      "12020 80604 1065\n",
      "12028 80656 1066\n",
      "12035 80689 1067\n",
      "12049 80815 1068\n",
      "12054 80858 1069\n",
      "12058 80884 1070\n",
      "12062 80898 1071\n",
      "12074 80988 1072\n",
      "12076 80972 1073\n",
      "12087 81059 1074\n",
      "12103 81203 1075\n",
      "12112 81278 1076\n",
      "12118 81330 1077\n",
      "12125 81371 1078\n",
      "12129 81399 1079\n",
      "12135 81427 1080\n",
      "12141 81465 1081\n",
      "12153 81547 1082\n",
      "12161 81601 1083\n",
      "12174 81698 1084\n",
      "12179 81713 1085\n",
      "12186 81754 1086\n",
      "12193 81761 1087\n",
      "12204 81820 1088\n",
      "12210 81852 1089\n",
      "12222 81960 1090\n",
      "12234 82056 1091\n",
      "12241 82107 1092\n",
      "12242 82088 1093\n",
      "12246 82114 1094\n",
      "12253 82169 1095\n",
      "12258 82212 1096\n",
      "12263 82249 1097\n",
      "12270 82300 1098\n",
      "12278 82350 1099\n",
      "12280 82356 1100\n",
      "12283 82375 1101\n",
      "12293 82431 1102\n",
      "12305 82509 1103\n",
      "12312 82542 1104\n",
      "12314 82554 1105\n",
      "12321 82597 1106\n",
      "12332 82656 1107\n",
      "12334 82668 1108\n",
      "12335 82675 1109\n",
      "12348 82782 1110\n",
      "12352 82810 1111\n",
      "12360 82856 1112\n",
      "12364 82900 1113\n",
      "12369 82933 1114\n",
      "12374 82968 1115\n",
      "12388 83052 1116\n",
      "12392 83066 1117\n",
      "12398 83134 1118\n",
      "12406 83184 1119\n",
      "12416 83252 1120\n",
      "12428 83342 1121\n",
      "12435 83391 1122\n",
      "12441 83427 1123\n",
      "12448 83456 1124\n",
      "12452 83464 1125\n",
      "12462 83542 1126\n",
      "12470 83616 1127\n",
      "12476 83652 1128\n",
      "12484 83694 1129\n",
      "12495 83777 1130\n",
      "12501 83833 1131\n",
      "12511 83893 1132\n",
      "12523 84007 1133\n",
      "12524 83984 1134\n",
      "12531 84035 1135\n",
      "12543 84135 1136\n",
      "12547 84171 1137\n",
      "12553 84201 1138\n",
      "12562 84254 1139\n",
      "12571 84315 1140\n",
      "12578 84356 1141\n",
      "12589 84423 1142\n",
      "12594 84444 1143\n",
      "12605 84549 1144\n",
      "12611 84601 1145\n",
      "12626 84714 1146\n",
      "12638 84806 1147\n",
      "12645 84843 1148\n",
      "12653 84929 1149\n",
      "12658 84962 1150\n",
      "12666 84994 1151\n",
      "12674 85040 1152\n",
      "12682 85110 1153\n",
      "12699 85265 1154\n",
      "12711 85355 1155\n",
      "12720 85412 1156\n",
      "12727 85457 1157\n",
      "12729 85469 1158\n",
      "12732 85476 1159\n",
      "12737 85497 1160\n",
      "12746 85558 1161\n",
      "12754 85608 1162\n",
      "12766 85704 1163\n",
      "12775 85811 1164\n",
      "12778 85842 1165\n",
      "12783 85845 1166\n",
      "12787 85867 1167\n",
      "12799 85941 1168\n",
      "12807 85989 1169\n",
      "12820 86122 1170\n",
      "12831 86219 1171\n",
      "12844 86370 1172\n",
      "12850 86410 1173\n",
      "12862 86480 1174\n",
      "12870 86534 1175\n",
      "12875 86573 1176\n",
      "12887 86663 1177\n",
      "12892 86672 1178\n",
      "12897 86695 1179\n",
      "12907 86785 1180\n",
      "12913 86855 1181\n",
      "12915 86857 1182\n",
      "12920 86892 1183\n",
      "12928 86958 1184\n",
      "12936 87004 1185\n",
      "12940 87040 1186\n",
      "12950 87142 1187\n",
      "12959 87201 1188\n",
      "12972 87296 1189\n",
      "12977 87325 1190\n",
      "12980 87340 1191\n",
      "12982 87358 1192\n",
      "12990 87436 1193\n",
      "12995 87475 1194\n",
      "13001 87493 1195\n",
      "13010 87566 1196\n",
      "13016 87612 1197\n",
      "13020 87644 1198\n",
      "13029 87717 1199\n",
      "13034 87734 1200\n",
      "13035 87727 1201\n",
      "13037 87745 1202\n",
      "13052 87858 1203\n",
      "13057 87899 1204\n",
      "13062 87932 1205\n",
      "13065 87933 1206\n",
      "13071 87997 1207\n",
      "13075 88013 1208\n",
      "13082 88086 1209\n",
      "13096 88166 1210\n",
      "13104 88228 1211\n",
      "13107 88251 1212\n",
      "13111 88269 1213\n",
      "13117 88325 1214\n",
      "13121 88347 1215\n",
      "13131 88435 1216\n",
      "13139 88485 1217\n",
      "13142 88514 1218\n",
      "13149 88557 1219\n",
      "13155 88627 1220\n",
      "13161 88669 1221\n",
      "13161 88665 1222\n",
      "13169 88739 1223\n",
      "13174 88766 1224\n",
      "13185 88883 1225\n",
      "13186 88880 1226\n",
      "13194 88918 1227\n",
      "13198 88940 1228\n",
      "13201 88955 1229\n",
      "13210 89038 1230\n",
      "13217 89081 1231\n",
      "13224 89136 1232\n",
      "13231 89177 1233\n",
      "13240 89262 1234\n",
      "13248 89322 1235\n",
      "13262 89444 1236\n",
      "13267 89481 1237\n",
      "13274 89516 1238\n",
      "13278 89518 1239\n",
      "13281 89545 1240\n",
      "13284 89556 1241\n",
      "13291 89605 1242\n",
      "13300 89624 1243\n",
      "13302 89624 1244\n",
      "13306 89650 1245\n",
      "13315 89697 1246\n",
      "13325 89769 1247\n",
      "13333 89845 1248\n",
      "13338 89900 1249\n",
      "13350 89988 1250\n",
      "13357 90031 1251\n",
      "13364 90080 1252\n",
      "13372 90122 1253\n",
      "13385 90225 1254\n",
      "13386 90218 1255\n",
      "13394 90272 1256\n",
      "13400 90302 1257\n",
      "13408 90360 1258\n",
      "13416 90414 1259\n",
      "13424 90484 1260\n",
      "13432 90544 1261\n",
      "13439 90589 1262\n",
      "13446 90644 1263\n",
      "13453 90701 1264\n",
      "13458 90702 1265\n",
      "13465 90729 1266\n",
      "13467 90713 1267\n",
      "13473 90763 1268\n",
      "13482 90830 1269\n",
      "13488 90842 1270\n",
      "13495 90895 1271\n",
      "13507 90971 1272\n",
      "13509 90979 1273\n",
      "13523 91051 1274\n",
      "13529 91091 1275\n",
      "13541 91165 1276\n",
      "13542 91170 1277\n",
      "13544 91178 1278\n",
      "13552 91226 1279\n",
      "13557 91269 1280\n",
      "13564 91308 1281\n",
      "13569 91351 1282\n",
      "13577 91413 1283\n",
      "13580 91446 1284\n",
      "13583 91463 1285\n",
      "13597 91553 1286\n",
      "13606 91610 1287\n",
      "13612 91626 1288\n",
      "13616 91636 1289\n",
      "13618 91650 1290\n",
      "13626 91702 1291\n",
      "13632 91746 1292\n",
      "13642 91790 1293\n",
      "13648 91822 1294\n",
      "13651 91833 1295\n",
      "13658 91864 1296\n",
      "13666 91898 1297\n",
      "13671 91929 1298\n",
      "13675 91947 1299\n",
      "13680 91984 1300\n",
      "13696 92142 1301\n",
      "13703 92195 1302\n",
      "13710 92234 1303\n",
      "13719 92315 1304\n",
      "13722 92336 1305\n",
      "13726 92348 1306\n",
      "13731 92369 1307\n",
      "13744 92478 1308\n",
      "13747 92521 1309\n",
      "13749 92521 1310\n",
      "13753 92549 1311\n",
      "13760 92582 1312\n",
      "13767 92607 1313\n",
      "13771 92599 1314\n",
      "13775 92629 1315\n",
      "13777 92639 1316\n",
      "13791 92735 1317\n",
      "13798 92814 1318\n",
      "13804 92864 1319\n",
      "13805 92861 1320\n",
      "13811 92907 1321\n",
      "13821 92973 1322\n",
      "13829 93037 1323\n",
      "13841 93097 1324\n",
      "13853 93233 1325\n",
      "13854 93230 1326\n",
      "13859 93229 1327\n",
      "13862 93252 1328\n",
      "13868 93294 1329\n",
      "13872 93332 1330\n",
      "13877 93375 1331\n",
      "13885 93451 1332\n",
      "13895 93517 1333\n",
      "13897 93533 1334\n",
      "13903 93565 1335\n",
      "13906 93568 1336\n",
      "13912 93602 1337\n",
      "13913 93609 1338\n",
      "13919 93637 1339\n",
      "13927 93675 1340\n",
      "13932 93728 1341\n",
      "13937 93759 1342\n",
      "13944 93818 1343\n",
      "13955 93917 1344\n",
      "13959 93955 1345\n",
      "13967 93993 1346\n",
      "13969 93999 1347\n",
      "13980 94098 1348\n",
      "13984 94114 1349\n",
      "13988 94130 1350\n",
      "13993 94177 1351\n",
      "13997 94203 1352\n",
      "14003 94247 1353\n",
      "14010 94276 1354\n",
      "14012 94306 1355\n",
      "14015 94325 1356\n",
      "14019 94351 1357\n",
      "14025 94411 1358\n",
      "14034 94476 1359\n",
      "14039 94489 1360\n",
      "14044 94506 1361\n",
      "14053 94569 1362\n",
      "14058 94600 1363\n",
      "14068 94688 1364\n",
      "14075 94739 1365\n",
      "14079 94779 1366\n",
      "14082 94790 1367\n",
      "14084 94796 1368\n",
      "14092 94830 1369\n",
      "14100 94882 1370\n",
      "14105 94939 1371\n",
      "14108 94956 1372\n",
      "14111 94991 1373\n",
      "14128 95106 1374\n",
      "14129 95097 1375\n",
      "14139 95175 1376\n",
      "14148 95226 1377\n",
      "14163 95335 1378\n",
      "14169 95361 1379\n",
      "14176 95410 1380\n",
      "14185 95475 1381\n",
      "14196 95554 1382\n",
      "14199 95565 1383\n",
      "14209 95655 1384\n",
      "14222 95752 1385\n",
      "14234 95840 1386\n",
      "14238 95852 1387\n",
      "14242 95884 1388\n",
      "14255 95969 1389\n",
      "14259 95997 1390\n",
      "14266 96042 1391\n",
      "14272 96072 1392\n",
      "14276 96100 1393\n",
      "14286 96160 1394\n",
      "14292 96180 1395\n",
      "14299 96241 1396\n",
      "14319 96451 1397\n",
      "14327 96525 1398\n",
      "14330 96540 1399\n",
      "14338 96586 1400\n",
      "14349 96651 1401\n",
      "14354 96676 1402\n",
      "14366 96764 1403\n",
      "14368 96770 1404\n",
      "14383 96937 1405\n",
      "14387 96959 1406\n",
      "14391 96985 1407\n",
      "14400 97052 1408\n",
      "14402 97052 1409\n",
      "14418 97212 1410\n",
      "14424 97240 1411\n",
      "14430 97258 1412\n",
      "14436 97304 1413\n",
      "14445 97353 1414\n",
      "14448 97372 1415\n",
      "14460 97462 1416\n",
      "14462 97466 1417\n",
      "14470 97522 1418\n",
      "14478 97570 1419\n",
      "14481 97587 1420\n",
      "14488 97622 1421\n",
      "14500 97728 1422\n",
      "14510 97796 1423\n",
      "14516 97836 1424\n",
      "14525 97883 1425\n",
      "14534 97950 1426\n",
      "14538 97954 1427\n",
      "14545 97991 1428\n",
      "14552 98084 1429\n",
      "14560 98150 1430\n",
      "14564 98172 1431\n",
      "14565 98169 1432\n",
      "14569 98199 1433\n",
      "14577 98249 1434\n",
      "14578 98234 1435\n",
      "14586 98286 1436\n",
      "14602 98398 1437\n",
      "14607 98429 1438\n",
      "14615 98471 1439\n",
      "14626 98566 1440\n",
      "14635 98627 1441\n",
      "14638 98648 1442\n",
      "14639 98653 1443\n",
      "14641 98653 1444\n",
      "14645 98667 1445\n",
      "14649 98711 1446\n",
      "14654 98732 1447\n",
      "14657 98743 1448\n",
      "14666 98798 1449\n",
      "14673 98845 1450\n",
      "14679 98929 1451\n",
      "14682 98952 1452\n",
      "14693 99017 1453\n",
      "14698 99030 1454\n",
      "14698 99022 1455\n",
      "14705 99057 1456\n",
      "14712 99100 1457\n",
      "14721 99159 1458\n",
      "14731 99219 1459\n",
      "14735 99239 1460\n",
      "14738 99236 1461\n",
      "14744 99282 1462\n",
      "14747 99303 1463\n",
      "14750 99318 1464\n",
      "14752 99324 1465\n",
      "14755 99339 1466\n",
      "14755 99325 1467\n",
      "14759 99351 1468\n",
      "14764 99386 1469\n",
      "14770 99402 1470\n",
      "14776 99442 1471\n",
      "14780 99468 1472\n",
      "14794 99614 1473\n",
      "14804 99674 1474\n",
      "14807 99681 1475\n",
      "14814 99716 1476\n",
      "14820 99742 1477\n",
      "14824 99762 1478\n",
      "14828 99764 1479\n",
      "14845 99885 1480\n",
      "14851 99921 1481\n",
      "14857 99961 1482\n",
      "14859 99963 1483\n",
      "14875 100087 1484\n",
      "14878 100096 1485\n",
      "14885 100153 1486\n",
      "14892 100206 1487\n",
      "14896 100232 1488\n",
      "14903 100265 1489\n",
      "14907 100291 1490\n",
      "14911 100323 1491\n",
      "14915 100359 1492\n",
      "14917 100365 1493\n",
      "14930 100462 1494\n",
      "14947 100605 1495\n",
      "14955 100657 1496\n",
      "14960 100696 1497\n",
      "14962 100708 1498\n",
      "14970 100750 1499\n",
      "14973 100769 1500\n",
      "14982 100812 1501\n",
      "14985 100831 1502\n",
      "14998 100934 1503\n",
      "15002 100964 1504\n",
      "15012 101024 1505\n",
      "15020 101098 1506\n",
      "15030 101178 1507\n",
      "15035 101215 1508\n",
      "15043 101283 1509\n",
      "15046 101304 1510\n",
      "15049 101313 1511\n",
      "15060 101394 1512\n",
      "15071 101509 1513\n",
      "15075 101543 1514\n",
      "15077 101535 1515\n",
      "15089 101643 1516\n",
      "15101 101729 1517\n",
      "15102 101714 1518\n",
      "15103 101717 1519\n",
      "15106 101732 1520\n",
      "15107 101733 1521\n",
      "15114 101762 1522\n",
      "15124 101820 1523\n",
      "15135 101907 1524\n",
      "15140 101938 1525\n",
      "15152 102020 1526\n",
      "15163 102103 1527\n",
      "15166 102116 1528\n",
      "15170 102140 1529\n",
      "15177 102181 1530\n",
      "15181 102205 1531\n",
      "15191 102269 1532\n",
      "15205 102375 1533\n",
      "15211 102429 1534\n",
      "15217 102459 1535\n",
      "15221 102475 1536\n",
      "15228 102524 1537\n",
      "15233 102531 1538\n",
      "15236 102544 1539\n",
      "15246 102632 1540\n",
      "15257 102751 1541\n",
      "15262 102790 1542\n",
      "15267 102811 1543\n",
      "15271 102841 1544\n",
      "15280 102896 1545\n",
      "15284 102906 1546\n",
      "15289 102937 1547\n",
      "15293 102959 1548\n",
      "15295 102979 1549\n",
      "15300 103016 1550\n",
      "15303 103035 1551\n",
      "15314 103110 1552\n",
      "15324 103170 1553\n",
      "15332 103214 1554\n",
      "15335 103253 1555\n",
      "15339 103285 1556\n",
      "15342 103296 1557\n",
      "15346 103322 1558\n",
      "15352 103346 1559\n",
      "15355 103339 1560\n",
      "15359 103389 1561\n",
      "15374 103524 1562\n",
      "15375 103525 1563\n",
      "15381 103561 1564\n",
      "15387 103581 1565\n",
      "15394 103620 1566\n",
      "15397 103631 1567\n",
      "15402 103666 1568\n",
      "15408 103700 1569\n",
      "15409 103685 1570\n",
      "15416 103764 1571\n",
      "15419 103783 1572\n",
      "15428 103856 1573\n",
      "15440 103974 1574\n",
      "15447 104015 1575\n",
      "15453 104023 1576\n",
      "15462 104082 1577\n",
      "15470 104146 1578\n",
      "15475 104177 1579\n",
      "15483 104251 1580\n",
      "15488 104290 1581\n",
      "15495 104347 1582\n",
      "15504 104400 1583\n",
      "15508 104418 1584\n",
      "15520 104486 1585\n",
      "15528 104556 1586\n",
      "15532 104572 1587\n",
      "15546 104730 1588\n",
      "15548 104744 1589\n",
      "15553 104799 1590\n",
      "15565 104921 1591\n",
      "15570 104966 1592\n",
      "15574 105012 1593\n",
      "15578 105048 1594\n",
      "15586 105102 1595\n",
      "15594 105150 1596\n",
      "15600 105210 1597\n",
      "15608 105276 1598\n",
      "15621 105463 1599\n",
      "15628 105484 1600\n",
      "15630 105478 1601\n",
      "15633 105493 1602\n",
      "15636 105508 1603\n",
      "15643 105565 1604\n",
      "15647 105591 1605\n",
      "15654 105638 1606\n",
      "15658 105662 1607\n",
      "15665 105693 1608\n",
      "15674 105756 1609\n",
      "15687 105849 1610\n",
      "15693 105893 1611\n",
      "15702 105922 1612\n",
      "15708 105960 1613\n",
      "15714 106004 1614\n",
      "15719 105991 1615\n",
      "15724 105988 1616\n",
      "15732 106030 1617\n",
      "15739 106067 1618\n",
      "15744 106092 1619\n",
      "15750 106168 1620\n",
      "15752 106170 1621\n",
      "15763 106267 1622\n",
      "15766 106278 1623\n",
      "15775 106339 1624\n",
      "15782 106394 1625\n",
      "15789 106455 1626\n",
      "15800 106540 1627\n",
      "15805 106587 1628\n",
      "15812 106634 1629\n",
      "15818 106664 1630\n",
      "15825 106741 1631\n",
      "15828 106774 1632\n",
      "15836 106850 1633\n",
      "15839 106863 1634\n",
      "15853 107017 1635\n",
      "15861 107109 1636\n",
      "15869 107171 1637\n",
      "15870 107172 1638\n",
      "15880 107264 1639\n",
      "15886 107312 1640\n",
      "15889 107323 1641\n",
      "15896 107376 1642\n",
      "15904 107436 1643\n",
      "15908 107458 1644\n",
      "15915 107517 1645\n",
      "15917 107527 1646\n",
      "15924 107596 1647\n",
      "15941 107729 1648\n",
      "15951 107797 1649\n",
      "15955 107807 1650\n",
      "15963 107887 1651\n",
      "15967 107909 1652\n",
      "15981 108051 1653\n",
      "15990 108112 1654\n",
      "15992 108108 1655\n",
      "15998 108154 1656\n",
      "16009 108259 1657\n",
      "16013 108285 1658\n",
      "16023 108385 1659\n",
      "16029 108433 1660\n",
      "16036 108482 1661\n",
      "16046 108548 1662\n",
      "16049 108547 1663\n",
      "16056 108580 1664\n",
      "16061 108627 1665\n",
      "16065 108667 1666\n",
      "16071 108709 1667\n",
      "16079 108777 1668\n",
      "16083 108805 1669\n",
      "16089 108831 1670\n",
      "16099 108881 1671\n",
      "16102 108898 1672\n",
      "16106 108908 1673\n",
      "16106 108902 1674\n",
      "16110 108932 1675\n",
      "16117 108959 1676\n",
      "16126 109022 1677\n",
      "16128 109012 1678\n",
      "16134 109040 1679\n",
      "16136 109040 1680\n",
      "16140 109058 1681\n",
      "16150 109142 1682\n",
      "16156 109174 1683\n",
      "16162 109208 1684\n",
      "16166 109234 1685\n",
      "16172 109268 1686\n",
      "16185 109469 1687\n",
      "16195 109543 1688\n",
      "16198 109536 1689\n",
      "16211 109637 1690\n",
      "16218 109672 1691\n",
      "16223 109707 1692\n",
      "16227 109733 1693\n",
      "16232 109786 1694\n",
      "16244 109900 1695\n",
      "16250 109942 1696\n",
      "16257 109981 1697\n",
      "16263 110027 1698\n",
      "16268 110060 1699\n",
      "16272 110090 1700\n",
      "16279 110141 1701\n",
      "16283 110159 1702\n",
      "16288 110184 1703\n",
      "16293 110235 1704\n",
      "16296 110248 1705\n",
      "16306 110366 1706\n",
      "16309 110381 1707\n",
      "16322 110478 1708\n",
      "16327 110493 1709\n",
      "16339 110571 1710\n",
      "16344 110580 1711\n",
      "16350 110626 1712\n"
     ]
    }
   ],
   "source": [
    "learning_rate=0.1\n",
    "max_depth=10\n",
    "bins=8\n",
    "lam=1\n",
    "\n",
    "gtgp = GTGP(learning_rate=learning_rate,max_depth=max_depth,bins=bins,lam=lam)\n",
    "\n",
    "total_size=10\n",
    "elite_size = 10\n",
    "epoch=2000\n",
    "gp_epoch=10\n",
    "verbose = 1\n",
    "re_train_epoch = 20\n",
    "tolerance=0.0001\n",
    "\n",
    "gtgp.fit(X_train,y_train,total_size=total_size,elite_size = elite_size,epoch=epoch,gp_epoch=gp_epoch,tolerance=tolerance,verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f14a601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrain  1 :\n",
      "\ttrain: 0.784918268519106 14296.751469714116 \ttest: 0.7819222419577659 6216.069217129345\n",
      "retrain  2 :\n",
      "\ttrain: 0.7991076148787244 13328.290914812329 \ttest: 0.7947010065127295 5855.7129043267505\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      7\u001b[0m gtgp\u001b[38;5;241m.\u001b[39mlam \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m----> 8\u001b[0m train_acc,test_acc,train_sse,test_sse \u001b[38;5;241m=\u001b[39m \u001b[43mgtgp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrain_estimators\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43mretrain_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretrain_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgammer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgammer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# verbose=0\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# gtgp.retrain_estimators(retrain_epoch=retrain_epoch,alpha=alpha,beta=beta,gammer=gammer,verbose=verbose)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zhouz\\OneDrive\\桌面\\Git\\GTGP\\test\\../script\\GTGP.py:113\u001b[0m, in \u001b[0;36mGTGP.retrain_estimators\u001b[1;34m(self, X_test, y_test, retrain_epoch, alpha, beta, gammer, verbose)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j,tree \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(stack):\n\u001b[0;32m    112\u001b[0m     tree\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mlam \u001b[38;5;241m=\u001b[39m  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlam \u001b[38;5;241m+\u001b[39m beta \u001b[38;5;241m*\u001b[39m tree\u001b[38;5;241m.\u001b[39mnumNode \u001b[38;5;241m+\u001b[39m gammer \u001b[38;5;241m*\u001b[39m tree\u001b[38;5;241m.\u001b[39mdepth\n\u001b[1;32m--> 113\u001b[0m     grads \u001b[38;5;241m=\u001b[39m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_grads_bin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_one_hot\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m     log_odds,p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_log_p(grads,log_odds,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_rate)\n\u001b[0;32m    116\u001b[0m     test_grads \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mpredict_grad(X_test)\n",
      "File \u001b[1;32mc:\\Users\\zhouz\\OneDrive\\桌面\\Git\\GTGP\\test\\../script\\Estimator.py:78\u001b[0m, in \u001b[0;36mEstimator_DC.set_grads_bin\u001b[1;34m(self, residual, p, alpha)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_grads_bin\u001b[39m(\u001b[38;5;28mself\u001b[39m,residual,p,alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m     77\u001b[0m     residual_bin \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([np\u001b[38;5;241m.\u001b[39msum(residual[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m==\u001b[39mi],axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mterminals])\n\u001b[1;32m---> 78\u001b[0m     cover_bin \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack(\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultiply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mterminals\u001b[49m\u001b[43m]\u001b[49m) \u001b[38;5;241m+\u001b[39m alpha\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_depth\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;66;03m# residual_bin = np.stack([np.sum(residual[self.index==i],axis=0) for i in range(self.bins)])\u001b[39;00m\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;66;03m# cover_bin = np.stack([np.sum(np.multiply(p[self.index==i],1-p[self.index==i]),axis=0) for i in range(self.bins)])\u001b[39;00m\n\u001b[0;32m     83\u001b[0m     cover_bin \u001b[38;5;241m=\u001b[39m cover_bin \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlam \u001b[38;5;66;03m#lambda\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zhouz\\OneDrive\\桌面\\Git\\GTGP\\test\\../script\\Estimator.py:78\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_grads_bin\u001b[39m(\u001b[38;5;28mself\u001b[39m,residual,p,alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m     77\u001b[0m     residual_bin \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([np\u001b[38;5;241m.\u001b[39msum(residual[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m==\u001b[39mi],axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mterminals])\n\u001b[1;32m---> 78\u001b[0m     cover_bin \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultiply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mterminals]) \u001b[38;5;241m+\u001b[39m alpha\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_depth\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;66;03m# residual_bin = np.stack([np.sum(residual[self.index==i],axis=0) for i in range(self.bins)])\u001b[39;00m\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;66;03m# cover_bin = np.stack([np.sum(np.multiply(p[self.index==i],1-p[self.index==i]),axis=0) for i in range(self.bins)])\u001b[39;00m\n\u001b[0;32m     83\u001b[0m     cover_bin \u001b[38;5;241m=\u001b[39m cover_bin \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlam \u001b[38;5;66;03m#lambda\u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36msum\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\zhouz\\anaconda3\\envs\\BStackGP\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:2324\u001b[0m, in \u001b[0;36msum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2321\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[0;32m   2322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[1;32m-> 2324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2325\u001b[0m \u001b[43m                      \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\zhouz\\anaconda3\\envs\\BStackGP\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     84\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[1;32m---> 86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "retrain_epoch=30\n",
    "alpha=1\n",
    "beta=1\n",
    "gammer=0\n",
    "\n",
    "verbose=1\n",
    "gtgp.lam = 1\n",
    "train_acc,test_acc,train_sse,test_sse = gtgp.retrain_estimators(X_test,y_test,retrain_epoch=retrain_epoch,alpha=alpha,beta=beta,gammer=gammer,verbose=verbose)\n",
    "\n",
    "\n",
    "# verbose=0\n",
    "# gtgp.retrain_estimators(retrain_epoch=retrain_epoch,alpha=alpha,beta=beta,gammer=gammer,verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9225e6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------GTGP-------------\n",
      "Number of Trees: 4790\n",
      "Average of depth: 2.1217118997912316\n",
      "Number of nodes: 29108\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.70522   0.22153   0.33715      4514\n",
      "           1    0.79308   0.80153   0.79728     11644\n",
      "           2    0.87025   0.95333   0.90989     31131\n",
      "\n",
      "    accuracy                        0.84610     47289\n",
      "   macro avg    0.78952   0.65880   0.68144     47289\n",
      "weighted avg    0.83549   0.84610   0.82749     47289\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.55904   0.15659   0.24465      1935\n",
      "           1    0.75735   0.77419   0.76568      4991\n",
      "           2    0.86023   0.94289   0.89966     13342\n",
      "\n",
      "    accuracy                        0.82628     20268\n",
      "   macro avg    0.72554   0.62456   0.63666     20268\n",
      "weighted avg    0.80614   0.82628   0.80414     20268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gtgp.print_model()\n",
    "\n",
    "print(classification_report(y_train,np.argmax(gtgp.train_p,axis=1),digits=5))\n",
    "print(classification_report(y_test,np.argmax(gtgp.test_p,axis=1),digits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662e91a5",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ed15d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "661630ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size,stratify=y, random_state=seeds[i])\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(X_train,y_train)\n",
    "\n",
    "    num_trees = 1\n",
    "    depth = clf.tree_.max_depth\n",
    "    num_nodes = clf.tree_.node_count\n",
    "\n",
    "    train_acc = accuracy_score(y_train,clf.predict(X_train))\n",
    "    test_acc = accuracy_score(y_test,clf.predict(X_test))\n",
    "    train_f1 = f1_score(y_train,clf.predict(X_train),average='macro')\n",
    "    test_f1 = f1_score(y_test,clf.predict(X_test),average='macro')\n",
    "\n",
    "    with open('./benchmark_DC/'+dataset+'.csv','a') as f:\n",
    "        s = str(train_acc)+\",\"+str(test_acc)+\",\"+str(train_f1)+\",\"+str(test_f1)+\",\"+str(num_trees)+\",\"+str(depth)+\",\"+str(num_nodes)+\"\\n\"\n",
    "        f.writelines(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63afbae1",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28fa8541",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "acfdd7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size,stratify=y, random_state=seeds[i])\n",
    "    xgb = xgboost.XGBClassifier(n_estimators=100)\n",
    "    # xgb = xgboost.XGBClassifier(min_child_weight=0,max_depth=4)\n",
    "    # xgb = xgboost.XGBClassifier()\n",
    "    xgb.fit(X_train,y_train)\n",
    "\n",
    "    import json\n",
    "\n",
    "    def item_generator(json_input, lookup_key):\n",
    "        if isinstance(json_input, dict):\n",
    "            for k, v in json_input.items():\n",
    "                if k == lookup_key:\n",
    "                    yield v\n",
    "                else:\n",
    "                    yield from item_generator(v, lookup_key)\n",
    "        elif isinstance(json_input, list):\n",
    "            for item in json_input:\n",
    "                yield from item_generator(item, lookup_key)\n",
    "\n",
    "    def tree_depth(json_text):\n",
    "        json_input = json.loads(json_text)\n",
    "        depths = list(item_generator(json_input, 'depth'))\n",
    "        return max(depths) + 1 if len(depths) != 0 else 1\n",
    "\n",
    "    train_acc = accuracy_score(y_train,xgb.predict(X_train))\n",
    "    test_acc = accuracy_score(y_test,xgb.predict(X_test))\n",
    "    train_f1 = f1_score(y_train,xgb.predict(X_train),average='macro')\n",
    "    test_f1 = f1_score(y_test,xgb.predict(X_test),average='macro')\n",
    "\n",
    "    booster = xgb.get_booster()\n",
    "\n",
    "    tree_df = booster.trees_to_dataframe()\n",
    "    depths = [tree_depth(x) for x in booster.get_dump(dump_format = \"json\")]\n",
    "    num_trees = len(depths)\n",
    "    depth = np.average(depths)\n",
    "    num_nodes = len(tree_df)\n",
    "\n",
    "    with open('./benchmark_xgb/'+dataset+'.csv','a') as f:\n",
    "        s = str(train_acc)+\",\"+str(test_acc)+\",\"+str(train_f1)+\",\"+str(test_f1)+\",\"+str(num_trees)+\",\"+str(depth)+\",\"+str(num_nodes)+\"\\n\"\n",
    "        f.writelines(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc363f99",
   "metadata": {},
   "source": [
    "# GDBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e6d3435",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef69c1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size,stratify=y, random_state=seeds[i])\n",
    "    # clf = GradientBoostingClassifier(n_estimators=1000)\n",
    "    clf = GradientBoostingClassifier()\n",
    "    clf.fit(X_train,y_train)\n",
    "\n",
    "    train_acc = accuracy_score(y_train,clf.predict(X_train))\n",
    "    test_acc = accuracy_score(y_test,clf.predict(X_test))\n",
    "    train_f1 = f1_score(y_train,clf.predict(X_train),average='macro')\n",
    "    test_f1 = f1_score(y_test,clf.predict(X_test),average='macro')\n",
    "\n",
    "    num_trees = len([ est for ests in clf.estimators_ for est in ests])\n",
    "    depth = np.average([ max(1,est.tree_.max_depth) for ests in clf.estimators_ for est in ests])\n",
    "    num_nodes = sum([ est.tree_.node_count for ests in clf.estimators_ for est in ests])\n",
    "\n",
    "    with open('./benchmark_GBDT/'+dataset+'.csv','a') as f:\n",
    "        s = str(train_acc)+\",\"+str(test_acc)+\",\"+str(train_f1)+\",\"+str(test_f1)+\",\"+str(num_trees)+\",\"+str(depth)+\",\"+str(num_nodes)+\"\\n\"\n",
    "        f.writelines(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0ef54f",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8623bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3edfc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size,stratify=y, random_state=seeds[i])\n",
    "    rfc = RandomForestClassifier()\n",
    "    rfc.fit(X_train,y_train)\n",
    "\n",
    "    train_acc = accuracy_score(y_train,rfc.predict(X_train))\n",
    "    test_acc = accuracy_score(y_test,rfc.predict(X_test))\n",
    "    train_f1 = f1_score(y_train,rfc.predict(X_train),average='macro')\n",
    "    test_f1 = f1_score(y_test,rfc.predict(X_test),average='macro')\n",
    "\n",
    "    num_trees = len(rfc.estimators_)\n",
    "    depth = np.average([est.tree_.max_depth for est in rfc.estimators_])\n",
    "    num_nodes = sum([est.tree_.node_count for est in rfc.estimators_])\n",
    "\n",
    "    with open('./benchmark_RF/'+dataset+'.csv','a') as f:\n",
    "        s = str(train_acc)+\",\"+str(test_acc)+\",\"+str(train_f1)+\",\"+str(test_f1)+\",\"+str(num_trees)+\",\"+str(depth)+\",\"+str(num_nodes)+\"\\n\"\n",
    "        f.writelines(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49b66a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb3fc4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BStackGP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc-autonumbering": true,
  "toc-showcode": true,
  "toc-showmarkdowntxt": true,
  "vscode": {
   "interpreter": {
    "hash": "598cefc26d6e5a65b2978c65314d0610ea9dfe34c7d989c4b6d2528d500ccb7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
