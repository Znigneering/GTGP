{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a8bc990-ebc5-46bd-bab4-f4091ce5b834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../script/\")\n",
    "\n",
    "import Functions\n",
    "from Engine import Engine\n",
    "from GTGP import GTGP\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report,accuracy_score,confusion_matrix,f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import importlib\n",
    "from time import time\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbad47da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.utils import shuffle\n",
    "def plot_roc_curve(true_y, y_prob):\n",
    "    \"\"\"\n",
    "    plots the roc curve based of the probabilities\n",
    "    \"\"\"\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(true_y, y_prob)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    print(roc_auc_score(true_y,prob[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c114de92",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "feedaa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/molecular_biology_promoters.tsv\",delimiter='\\t')\n",
    "X = df.iloc[:,:-1].to_numpy().astype(\"float\")\n",
    "y = df.iloc[:,-1].to_numpy().astype(\"int\")\n",
    "\n",
    "seeds = [10086, 200,500,30506,30405,30420,10056,7059,40965,5398,869543,83491,823190,\n",
    "         48392,2810,48392,3498210,483902,859032,12890,538920,86954,54309,6504,9840,\n",
    "         219805,548,2981,432890,5438908,219094,5843902,60854,979,12890,2108,4093]\n",
    "train_size = 0.7\n",
    "dataset = 'molecular'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a2341bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(y,yt):\n",
    "    le = LabelEncoder()\n",
    "    ohe = OneHotEncoder()\n",
    "    y_train = le.fit_transform(y)\n",
    "    y_one_hot = ohe.fit_transform(y_train.reshape(-1,1))\n",
    "    \n",
    "    y_test = le.transform(yt)\n",
    "    yt_one_hot = ohe.transform(y_test.reshape(-1,1))\n",
    "    \n",
    "    return y_train,y_test,y_one_hot,yt_one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdd30c5",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f418f618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 70 1\n",
      "28 92 2\n",
      "33 109 3\n",
      "38 124 4\n",
      "43 143 5\n",
      "48 156 6\n",
      "52 172 7\n",
      "56 188 8\n",
      "59 201 9\n",
      "62 212 10\n",
      "65 223 11\n",
      "68 230 12\n",
      "71 239 13\n",
      "72 244 14\n",
      "73 247 15\n",
      "76 260 16\n",
      "77 261 17\n",
      "79 265 18\n",
      "85 281 19\n",
      "86 284 20\n",
      "91 303 21\n",
      "93 305 22\n",
      "94 310 23\n",
      "95 315 24\n",
      "98 322 25\n",
      "98 318 26\n",
      "98 316 27\n",
      "98 314 28\n",
      "102 330 29\n",
      "103 335 30\n",
      "106 344 31\n",
      "110 358 32\n",
      "111 361 33\n",
      "114 370 34\n",
      "115 371 35\n",
      "118 382 36\n",
      "119 385 37\n",
      "119 383 38\n",
      "119 381 39\n",
      "120 382 40\n",
      "120 382 41\n",
      "120 382 42\n",
      "123 395 43\n",
      "124 398 44\n",
      "124 396 45\n",
      "126 400 46\n",
      "127 403 47\n",
      "127 403 48\n",
      "129 409 49\n",
      "129 409 50\n",
      "129 409 51\n",
      "130 414 52\n",
      "130 414 53\n",
      "131 425 54\n",
      "131 425 55\n",
      "131 425 56\n",
      "131 425 57\n",
      "132 428 58\n",
      "134 436 59\n",
      "136 444 60\n",
      "137 447 61\n",
      "139 455 62\n",
      "140 460 63\n",
      "139 453 64\n",
      "139 453 65\n",
      "140 456 66\n",
      "140 456 67\n",
      "141 459 68\n",
      "141 455 69\n",
      "141 453 70\n",
      "141 453 71\n",
      "141 453 72\n",
      "141 451 73\n",
      "141 451 74\n",
      "142 450 75\n",
      "142 450 76\n",
      "143 453 77\n",
      "143 453 78\n",
      "143 453 79\n",
      "143 453 80\n",
      "143 453 81\n",
      "143 453 82\n",
      "143 453 83\n",
      "144 454 84\n",
      "145 457 85\n",
      "147 459 86\n",
      "149 465 87\n",
      "149 465 88\n",
      "150 470 89\n",
      "150 470 90\n",
      "152 478 91\n",
      "152 478 92\n",
      "152 476 93\n",
      "154 482 94\n",
      "154 482 95\n",
      "154 482 96\n",
      "154 482 97\n",
      "154 482 98\n",
      "154 482 99\n",
      "154 482 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.9864864864864865 12.679013563243608 \ttest: 0.875 9.228049322255009\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 6.836374287600769 \ttest: 0.875 7.508387766698104\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 4.352581333529766 \ttest: 0.875 6.811639559445047\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 3.0021605773396494 \ttest: 0.84375 6.448056217681075\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 2.178830850586936 \ttest: 0.84375 6.228945695127028\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 1.6416413441473523 \ttest: 0.84375 6.084265534049389\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 1.2740309445212863 \ttest: 0.84375 5.982542440503113\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 1.0129889914160763 \ttest: 0.84375 5.907688669707403\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.8219311071807512 \ttest: 0.84375 5.850681810853807\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.6784900221115712 \ttest: 0.84375 5.806094202114236\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.5684239639093104 \ttest: 0.84375 5.770475793446012\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.48235480670645137 \ttest: 0.8125 5.741533832219419\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.41392713010790866 \ttest: 0.8125 5.7176877120178045\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.35872479736456064 \ttest: 0.8125 5.697813731375552\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.3136106749579104 \ttest: 0.8125 5.68109186063789\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.276311942444946 \ttest: 0.8125 5.666910088799506\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.2451526689603921 \ttest: 0.8125 5.654802674630075\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.21887724922515428 \ttest: 0.8125 5.644409102903452\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.19653133379330423 \ttest: 0.8125 5.635446094244967\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.17737997703466768 \ttest: 0.8125 5.627688078921925\n",
      "retrain  21 :\n",
      "\ttrain: 1.0 0.1608503784828182 \ttest: 0.8125 5.620953297134696\n",
      "retrain  22 :\n",
      "\ttrain: 1.0 0.14649118329811184 \ttest: 0.8125 5.615093723845188\n",
      "retrain  23 :\n",
      "\ttrain: 1.0 0.13394312559591118 \ttest: 0.8125 5.609987645867844\n",
      "retrain  24 :\n",
      "\ttrain: 1.0 0.12291756538229806 \ttest: 0.8125 5.605534111846401\n",
      "retrain  25 :\n",
      "\ttrain: 1.0 0.11318059947832992 \ttest: 0.8125 5.601648726654799\n",
      "retrain  26 :\n",
      "\ttrain: 1.0 0.1045411619929309 \ttest: 0.8125 5.598260425419301\n",
      "retrain  27 :\n",
      "\ttrain: 1.0 0.09684201632668704 \ttest: 0.8125 5.595308971179449\n",
      "retrain  28 :\n",
      "\ttrain: 1.0 0.08995286749068045 \ttest: 0.8125 5.592742993849458\n",
      "retrain  29 :\n",
      "\ttrain: 1.0 0.0837650462375967 \ttest: 0.8125 5.590518438793749\n",
      "retrain  30 :\n",
      "\ttrain: 1.0 0.07818737031178907 \ttest: 0.8125 5.588597328692703\n",
      "retrain  31 :\n",
      "\ttrain: 1.0 0.07314289567791084 \ttest: 0.8125 5.586946767405924\n",
      "retrain  32 :\n",
      "\ttrain: 1.0 0.06856634667716845 \ttest: 0.8125 5.585538132486574\n",
      "retrain  33 :\n",
      "\ttrain: 1.0 0.06440206848303431 \ttest: 0.8125 5.584346416021315\n",
      "retrain  34 :\n",
      "\ttrain: 1.0 0.06060238455697008 \ttest: 0.8125 5.583349683022647\n",
      "retrain  35 :\n",
      "\ttrain: 1.0 0.05712627050282326 \ttest: 0.8125 5.582528623681307\n",
      "retrain  36 :\n",
      "\ttrain: 1.0 0.053938276852234346 \ttest: 0.8125 5.581866181085901\n",
      "retrain  37 :\n",
      "\ttrain: 1.0 0.05100764901184263 \ttest: 0.8125 5.5813472400197846\n",
      "retrain  38 :\n",
      "\ttrain: 1.0 0.04830760436013258 \ttest: 0.8125 5.580958365494232\n",
      "retrain  39 :\n",
      "\ttrain: 1.0 0.045814735355654695 \ttest: 0.84375 5.580687582018255\n",
      "retrain  40 :\n",
      "\ttrain: 1.0 0.04350851426569348 \ttest: 0.84375 5.580524186416922\n",
      "retrain  41 :\n",
      "\ttrain: 1.0 0.04137088029093271 \ttest: 0.84375 5.580458588421582\n",
      "retrain  42 :\n",
      "\ttrain: 1.0 0.039385893844134386 \ttest: 0.84375 5.58048217436283\n",
      "retrain  43 :\n",
      "\ttrain: 1.0 0.037539445830203105 \ttest: 0.84375 5.58058719017137\n",
      "retrain  44 :\n",
      "\ttrain: 1.0 0.03581901218610292 \ttest: 0.84375 5.580766640586413\n",
      "retrain  45 :\n",
      "\ttrain: 1.0 0.03421344583174481 \ttest: 0.84375 5.58101420202616\n",
      "retrain  46 :\n",
      "\ttrain: 1.0 0.03271279967687757 \ttest: 0.84375 5.581324147020547\n",
      "retrain  47 :\n",
      "\ttrain: 1.0 0.03130817551444746 \ttest: 0.84375 5.58169127846635\n",
      "retrain  48 :\n",
      "\ttrain: 1.0 0.029991594576302336 \ttest: 0.84375 5.582110872256791\n",
      "retrain  49 :\n",
      "\ttrain: 1.0 0.02875588628477371 \ttest: 0.84375 5.582578627075887\n",
      "retrain  50 :\n",
      "\ttrain: 1.0 0.027594592343683486 \ttest: 0.84375 5.583090620342748\n",
      "retrain  51 :\n",
      "\ttrain: 1.0 0.02650188380566052 \ttest: 0.84375 5.583643269451515\n",
      "retrain  52 :\n",
      "\ttrain: 1.0 0.02547248915334213 \ttest: 0.84375 5.58423329758504\n",
      "retrain  53 :\n",
      "\ttrain: 1.0 0.024501631758820593 \ttest: 0.84375 5.5848577034902664\n",
      "retrain  54 :\n",
      "\ttrain: 1.0 0.023584975353262903 \ttest: 0.84375 5.585513734694759\n",
      "retrain  55 :\n",
      "\ttrain: 1.0 0.022718576358548806 \ttest: 0.84375 5.586198863720162\n",
      "retrain  56 :\n",
      "\ttrain: 1.0 0.021898842114194104 \ttest: 0.84375 5.586910766912396\n",
      "retrain  57 :\n",
      "\ttrain: 1.0 0.021122494183013815 \ttest: 0.84375 5.587647305562342\n",
      "retrain  58 :\n",
      "\ttrain: 1.0 0.02038653604374481 \ttest: 0.84375 5.588406509036067\n",
      "retrain  59 :\n",
      "\ttrain: 1.0 0.019688224582827735 \ttest: 0.84375 5.589186559672252\n",
      "retrain  60 :\n",
      "\ttrain: 1.0 0.019025044884486694 \ttest: 0.84375 5.5899857792370575\n",
      "retrain  61 :\n",
      "\ttrain: 1.0 0.018394687891157335 \ttest: 0.84375 5.5908026167544715\n",
      "retrain  62 :\n",
      "\ttrain: 1.0 0.017795030567643852 \ttest: 0.84375 5.591635637553992\n",
      "retrain  63 :\n",
      "\ttrain: 1.0 0.017224118254123705 \ttest: 0.84375 5.59248351339771\n",
      "retrain  64 :\n",
      "\ttrain: 1.0 0.01668014893688472 \ttest: 0.84375 5.593345013566401\n",
      "retrain  65 :\n",
      "\ttrain: 1.0 0.01616145920280284 \ttest: 0.84375 5.59421899679918\n",
      "retrain  66 :\n",
      "\ttrain: 1.0 0.015666511675138817 \ttest: 0.84375 5.595104403994251\n",
      "retrain  67 :\n",
      "\ttrain: 1.0 0.015193883755149183 \ttest: 0.84375 5.596000251589431\n",
      "retrain  68 :\n",
      "\ttrain: 1.0 0.014742257517011866 \ttest: 0.84375 5.5969056255509075\n",
      "retrain  69 :\n",
      "\ttrain: 1.0 0.014310410623274764 \ttest: 0.84375 5.597819675906996\n",
      "retrain  70 :\n",
      "\ttrain: 1.0 0.01389720814496027 \ttest: 0.84375 5.598741611771082\n",
      "retrain  71 :\n",
      "\ttrain: 1.0 0.013501595185022228 \ttest: 0.84375 5.599670696804301\n",
      "retrain  72 :\n",
      "\ttrain: 1.0 0.013122590216415235 \ttest: 0.84375 5.600606245074027\n",
      "retrain  73 :\n",
      "\ttrain: 1.0 0.012759279056892572 \ttest: 0.84375 5.601547617269249\n",
      "retrain  74 :\n",
      "\ttrain: 1.0 0.012410809412053837 \ttest: 0.84375 5.6024942172380925\n",
      "retrain  75 :\n",
      "\ttrain: 1.0 0.01207638592632384 \ttest: 0.84375 5.603445488816529\n",
      "retrain  76 :\n",
      "\ttrain: 1.0 0.011755265688640843 \ttest: 0.84375 5.604400912920736\n",
      "retrain  77 :\n",
      "\ttrain: 1.0 0.011446754145813792 \ttest: 0.84375 5.605360004878289\n",
      "retrain  78 :\n",
      "\ttrain: 1.0 0.011150201381904468 \ttest: 0.84375 5.606322311976186\n",
      "retrain  79 :\n",
      "\ttrain: 1.0 0.010864998726707494 \ttest: 0.84375 5.607287411205791\n",
      "retrain  80 :\n",
      "\ttrain: 1.0 0.010590575660533404 \ttest: 0.84375 5.608254907186922\n",
      "retrain  81 :\n",
      "\ttrain: 1.0 0.010326396986125844 \ttest: 0.84375 5.609224430255068\n",
      "retrain  82 :\n",
      "\ttrain: 1.0 0.010071960241729214 \ttest: 0.84375 5.610195634697301\n",
      "retrain  83 :\n",
      "\ttrain: 1.0 0.00982679333212882 \ttest: 0.84375 5.611168197123909\n",
      "retrain  84 :\n",
      "\ttrain: 1.0 0.009590452356957272 \ttest: 0.84375 5.612141814964007\n",
      "retrain  85 :\n",
      "\ttrain: 1.0 0.00936251961774536 \ttest: 0.84375 5.613116205074514\n",
      "retrain  86 :\n",
      "\ttrain: 1.0 0.009142601787125521 \ttest: 0.84375 5.614091102452925\n",
      "retrain  87 :\n",
      "\ttrain: 1.0 0.008930328225307281 \ttest: 0.84375 5.615066259045184\n",
      "retrain  88 :\n",
      "\ttrain: 1.0 0.008725349430459899 \ttest: 0.84375 5.616041442640762\n",
      "retrain  89 :\n",
      "\ttrain: 1.0 0.008527335610984996 \ttest: 0.84375 5.61701643584782\n",
      "retrain  90 :\n",
      "\ttrain: 1.0 0.008335975368860181 \ttest: 0.84375 5.617991035141932\n",
      "retrain  91 :\n",
      "\ttrain: 1.0 0.008150974484301408 \ttest: 0.84375 5.61896504998247\n",
      "retrain  92 :\n",
      "\ttrain: 1.0 0.007972054792943582 \ttest: 0.84375 5.619938301991262\n",
      "retrain  93 :\n",
      "\ttrain: 1.0 0.007798953147588302 \ttest: 0.84375 5.620910624188619\n",
      "retrain  94 :\n",
      "\ttrain: 1.0 0.00763142045732744 \ttest: 0.84375 5.621881860282258\n",
      "retrain  95 :\n",
      "\ttrain: 1.0 0.007469220797530741 \ttest: 0.84375 5.622851864005009\n",
      "retrain  96 :\n",
      "\ttrain: 1.0 0.007312130584795349 \ttest: 0.84375 5.623820498497619\n",
      "retrain  97 :\n",
      "\ttrain: 1.0 0.007159937811501425 \ttest: 0.84375 5.624787635733163\n",
      "retrain  98 :\n",
      "\ttrain: 1.0 0.007012441335109459 \ttest: 0.84375 5.625753155980015\n",
      "retrain  99 :\n",
      "\ttrain: 1.0 0.0068694502177759145 \ttest: 0.84375 5.626716947300409\n",
      "retrain  100 :\n",
      "\ttrain: 1.0 0.00673078311226213 \ttest: 0.84375 5.627678905082067\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        37\n",
      "           1    1.00000   1.00000   1.00000        37\n",
      "\n",
      "    accuracy                        1.00000        74\n",
      "   macro avg    1.00000   1.00000   1.00000        74\n",
      "weighted avg    1.00000   1.00000   1.00000        74\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   0.68750   0.81481        16\n",
      "           1    0.76190   1.00000   0.86486        16\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.88095   0.84375   0.83984        32\n",
      "weighted avg    0.88095   0.84375   0.83984        32\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 154\n",
      "Average of depth: 1.0584415584415585\n",
      "Number of nodes: 482\n",
      "18 56 1\n",
      "29 101 2\n",
      "35 123 3\n",
      "40 136 4\n",
      "44 146 5\n",
      "50 162 6\n",
      "53 173 7\n",
      "57 187 8\n",
      "59 193 9\n",
      "65 213 10\n",
      "70 232 11\n",
      "70 230 12\n",
      "72 234 13\n",
      "74 240 14\n",
      "75 245 15\n",
      "77 251 16\n",
      "79 257 17\n",
      "80 264 18\n",
      "80 262 19\n",
      "82 268 20\n",
      "82 264 21\n",
      "83 263 22\n",
      "85 271 23\n",
      "87 277 24\n",
      "90 288 25\n",
      "91 287 26\n",
      "91 287 27\n",
      "95 301 28\n",
      "98 308 29\n",
      "100 314 30\n",
      "100 314 31\n",
      "103 329 32\n",
      "103 327 33\n",
      "104 330 34\n",
      "105 331 35\n",
      "106 334 36\n",
      "107 339 37\n",
      "108 342 38\n",
      "110 348 39\n",
      "111 351 40\n",
      "111 351 41\n",
      "114 368 42\n",
      "114 366 43\n",
      "115 371 44\n",
      "118 382 45\n",
      "119 385 46\n",
      "119 385 47\n",
      "119 385 48\n",
      "120 388 49\n",
      "122 386 50\n",
      "123 391 51\n",
      "124 394 52\n",
      "125 397 53\n",
      "126 400 54\n",
      "126 400 55\n",
      "126 400 56\n",
      "127 403 57\n",
      "127 403 58\n",
      "127 403 59\n",
      "129 411 60\n",
      "129 411 61\n",
      "131 417 62\n",
      "131 417 63\n",
      "131 417 64\n",
      "132 418 65\n",
      "132 418 66\n",
      "132 418 67\n",
      "132 418 68\n",
      "133 421 69\n",
      "135 425 70\n",
      "136 430 71\n",
      "136 430 72\n",
      "136 430 73\n",
      "136 428 74\n",
      "136 428 75\n",
      "136 428 76\n",
      "136 428 77\n",
      "136 428 78\n",
      "136 428 79\n",
      "136 428 80\n",
      "136 428 81\n",
      "136 428 82\n",
      "136 428 83\n",
      "136 428 84\n",
      "137 431 85\n",
      "138 436 86\n",
      "138 436 87\n",
      "139 439 88\n",
      "140 444 89\n",
      "140 444 90\n",
      "140 442 91\n",
      "140 440 92\n",
      "142 448 93\n",
      "142 448 94\n",
      "143 451 95\n",
      "143 451 96\n",
      "143 451 97\n",
      "143 451 98\n",
      "143 449 99\n",
      "143 449 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 12.312720777232698 \ttest: 0.90625 8.134788469138794\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 5.911229038238016 \ttest: 0.90625 5.9076986336694715\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 3.4400349042603677 \ttest: 0.90625 5.023076374570673\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 2.2350417125155913 \ttest: 0.90625 4.585663343017892\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.560454009586948 \ttest: 0.90625 4.338193648519962\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 1.1466309809737365 \ttest: 0.90625 4.185336376945457\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 0.875544618160873 \ttest: 0.90625 4.08506177155107\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.6888995357391066 \ttest: 0.90625 4.016416631091036\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.5552562223929631 \ttest: 0.90625 3.9679628000276446\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.45647748750609396 \ttest: 0.90625 3.9330068389916555\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.38152476846732375 \ttest: 0.90625 3.9074110941582263\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.32337948654250753 \ttest: 0.90625 3.8885020025129036\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.277413164777179 \ttest: 0.90625 3.8744878804607223\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.24047746075378215 \ttest: 0.90625 3.8641308461979404\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.21037297966131038 \ttest: 0.90625 3.8565532369872995\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.1855271879801304 \ttest: 0.90625 3.8511188364643854\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.1647925941757219 \ttest: 0.90625 3.8473575162626146\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.1473166049185179 \ttest: 0.90625 3.844916010821385\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.13245544781074264 \ttest: 0.90625 3.843524932468277\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.11971594188143356 \ttest: 0.90625 3.8429761656517862\n",
      "retrain  21 :\n",
      "\ttrain: 1.0 0.10871530300037718 \ttest: 0.90625 3.8431070611759086\n",
      "retrain  22 :\n",
      "\ttrain: 1.0 0.09915288878865776 \ttest: 0.90625 3.843789185245451\n",
      "retrain  23 :\n",
      "\ttrain: 1.0 0.0907900061548732 \ttest: 0.90625 3.844920180651917\n",
      "retrain  24 :\n",
      "\ttrain: 1.0 0.0834352623888982 \ttest: 0.90625 3.846417792833112\n",
      "retrain  25 :\n",
      "\ttrain: 1.0 0.07693379090883459 \ttest: 0.90625 3.848215426541688\n",
      "retrain  26 :\n",
      "\ttrain: 1.0 0.07115922622262885 \ttest: 0.90625 3.8502588008217673\n",
      "retrain  27 :\n",
      "\ttrain: 1.0 0.06600765672053992 \ttest: 0.90625 3.85250340282987\n",
      "retrain  28 :\n",
      "\ttrain: 1.0 0.0613930186184031 \ttest: 0.90625 3.8549125299503424\n",
      "retrain  29 :\n",
      "\ttrain: 1.0 0.05724355246970844 \ttest: 0.90625 3.857455770133744\n",
      "retrain  30 :\n",
      "\ttrain: 1.0 0.05349905174917734 \ttest: 0.90625 3.860107812136556\n",
      "retrain  31 :\n",
      "\ttrain: 1.0 0.050108707924907306 \ttest: 0.90625 3.862847506558563\n",
      "retrain  32 :\n",
      "\ttrain: 1.0 0.04702940902729964 \ttest: 0.90625 3.86565711928266\n",
      "retrain  33 :\n",
      "\ttrain: 1.0 0.0442243860851238 \ttest: 0.90625 3.868521733772861\n",
      "retrain  34 :\n",
      "\ttrain: 1.0 0.041662128639231424 \ttest: 0.90625 3.871428769454104\n",
      "retrain  35 :\n",
      "\ttrain: 1.0 0.03931551002797305 \ttest: 0.90625 3.8743675912851376\n",
      "retrain  36 :\n",
      "\ttrain: 1.0 0.03716107742082547 \ttest: 0.90625 3.8773291914692947\n",
      "retrain  37 :\n",
      "\ttrain: 1.0 0.03517847214341431 \ttest: 0.90625 3.8803059286012407\n",
      "retrain  38 :\n",
      "\ttrain: 1.0 0.033349953722887044 \ttest: 0.90625 3.8832913128239603\n",
      "retrain  39 :\n",
      "\ttrain: 1.0 0.031660007016070565 \ttest: 0.90625 3.8862798280555664\n",
      "retrain  40 :\n",
      "\ttrain: 1.0 0.03009501628210774 \ttest: 0.90625 3.889266784244939\n",
      "retrain  41 :\n",
      "\ttrain: 1.0 0.02864299349811409 \ttest: 0.90625 3.8922481940773612\n",
      "retrain  42 :\n",
      "\ttrain: 1.0 0.02729335086004698 \ttest: 0.90625 3.8952206696841833\n",
      "retrain  43 :\n",
      "\ttrain: 1.0 0.02603670945798629 \ttest: 0.90625 3.898181335794121\n",
      "retrain  44 :\n",
      "\ttrain: 1.0 0.02486473771004495 \ttest: 0.90625 3.901127756456872\n",
      "retrain  45 :\n",
      "\ttrain: 1.0 0.02377001438942805 \ttest: 0.90625 3.90405787301667\n",
      "retrain  46 :\n",
      "\ttrain: 1.0 0.022745912064849702 \ttest: 0.90625 3.9069699514472402\n",
      "retrain  47 :\n",
      "\ttrain: 1.0 0.021786497555847138 \ttest: 0.90625 3.9098625375055773\n",
      "retrain  48 :\n",
      "\ttrain: 1.0 0.02088644662710395 \ttest: 0.90625 3.912734418439247\n",
      "retrain  49 :\n",
      "\ttrain: 1.0 0.02004097064443943 \ttest: 0.90625 3.9155845902050928\n",
      "retrain  50 :\n",
      "\ttrain: 1.0 0.0192457533162583 \ttest: 0.90625 3.918412229337809\n",
      "retrain  51 :\n",
      "\ttrain: 1.0 0.018496895968492442 \ttest: 0.90625 3.9212166687534493\n",
      "retrain  52 :\n",
      "\ttrain: 1.0 0.017790870064294563 \ttest: 0.90625 3.9239973768925367\n",
      "retrain  53 :\n",
      "\ttrain: 1.0 0.01712447589434763 \ttest: 0.90625 3.926753939705333\n",
      "retrain  54 :\n",
      "\ttrain: 1.0 0.016494806539316252 \ttest: 0.90625 3.929486045062351\n",
      "retrain  55 :\n",
      "\ttrain: 1.0 0.015899216350320825 \ttest: 0.90625 3.9321934692395217\n",
      "retrain  56 :\n",
      "\ttrain: 1.0 0.015335293312379874 \ttest: 0.90625 3.934876065182393\n",
      "retrain  57 :\n",
      "\ttrain: 1.0 0.014800834754327561 \ttest: 0.90625 3.937533752299355\n",
      "retrain  58 :\n",
      "\ttrain: 1.0 0.014293825950586644 \ttest: 0.90625 3.9401665075718735\n",
      "retrain  59 :\n",
      "\ttrain: 1.0 0.013812421228413665 \ttest: 0.90625 3.942774357801501\n",
      "retrain  60 :\n",
      "\ttrain: 1.0 0.013354927251288567 \ttest: 0.90625 3.9453573728400646\n",
      "retrain  61 :\n",
      "\ttrain: 1.0 0.0129197881969771 \ttest: 0.90625 3.947915659671738\n",
      "retrain  62 :\n",
      "\ttrain: 1.0 0.012505572589053698 \ttest: 0.90625 3.9504493572346577\n",
      "retrain  63 :\n",
      "\ttrain: 1.0 0.012110961574640304 \ttest: 0.90625 3.952958631885572\n",
      "retrain  64 :\n",
      "\ttrain: 1.0 0.011734738469857642 \ttest: 0.90625 3.9554436734246097\n",
      "retrain  65 :\n",
      "\ttrain: 1.0 0.01137577941886866 \ttest: 0.90625 3.9579046916086407\n",
      "retrain  66 :\n",
      "\ttrain: 1.0 0.011033045033134719 \ttest: 0.90625 3.9603419130914865\n",
      "retrain  67 :\n",
      "\ttrain: 1.0 0.010705572895194818 \ttest: 0.90625 3.9627555787375957\n",
      "retrain  68 :\n",
      "\ttrain: 1.0 0.010392470826400062 \ttest: 0.90625 3.9651459412628496\n",
      "retrain  69 :\n",
      "\ttrain: 1.0 0.010092910830994485 \ttest: 0.90625 3.96751326316233\n",
      "retrain  70 :\n",
      "\ttrain: 1.0 0.009806123640066684 \ttest: 0.90625 3.9698578148900765\n",
      "retrain  71 :\n",
      "\ttrain: 1.0 0.009531393788478738 \ttest: 0.90625 3.972179873260366\n",
      "retrain  72 :\n",
      "\ttrain: 1.0 0.00926805516614821 \ttest: 0.90625 3.9744797200439788\n",
      "retrain  73 :\n",
      "\ttrain: 1.0 0.009015486992208506 \ttest: 0.90625 3.976757640736192\n",
      "retrain  74 :\n",
      "\ttrain: 1.0 0.008773110166766669 \ttest: 0.90625 3.979013923476215\n",
      "retrain  75 :\n",
      "\ttrain: 1.0 0.008540383960355967 \ttest: 0.90625 3.981248858100258\n",
      "retrain  76 :\n",
      "\ttrain: 1.0 0.00831680300585821 \ttest: 0.90625 3.9834627353125884\n",
      "retrain  77 :\n",
      "\ttrain: 1.0 0.008101894561747532 \ttest: 0.90625 3.9856558459609057\n",
      "retrain  78 :\n",
      "\ttrain: 1.0 0.007895216019067761 \ttest: 0.90625 3.987828480403916\n",
      "retrain  79 :\n",
      "\ttrain: 1.0 0.007696352627668075 \ttest: 0.90625 3.989980927960506\n",
      "retrain  80 :\n",
      "\ttrain: 1.0 0.007504915419951025 \ttest: 0.90625 3.9921134764311357\n",
      "retrain  81 :\n",
      "\ttrain: 1.0 0.007320539312781088 \ttest: 0.90625 3.9942264116831825\n",
      "retrain  82 :\n",
      "\ttrain: 1.0 0.007142881370308121 \ttest: 0.90625 3.996320017292937\n",
      "retrain  83 :\n",
      "\ttrain: 1.0 0.006971619212313457 \ttest: 0.90625 3.9983945742377935\n",
      "retrain  84 :\n",
      "\ttrain: 1.0 0.00680644955432266 \ttest: 0.90625 4.000450360632903\n",
      "retrain  85 :\n",
      "\ttrain: 1.0 0.00664708686717332 \ttest: 0.90625 4.002487651507243\n",
      "retrain  86 :\n",
      "\ttrain: 1.0 0.006493262145004416 \ttest: 0.90625 4.00450671861461\n",
      "retrain  87 :\n",
      "\ttrain: 1.0 0.006344721771766907 \ttest: 0.90625 4.006507830275541\n",
      "retrain  88 :\n",
      "\ttrain: 1.0 0.006201226477359173 \ttest: 0.90625 4.008491251246644\n",
      "retrain  89 :\n",
      "\ttrain: 1.0 0.0060625503753850155 \ttest: 0.90625 4.010457242614186\n",
      "retrain  90 :\n",
      "\ttrain: 1.0 0.005928480075325379 \ttest: 0.90625 4.012406061709141\n",
      "retrain  91 :\n",
      "\ttrain: 1.0 0.0057988138626235974 \ttest: 0.90625 4.014337962041236\n",
      "retrain  92 :\n",
      "\ttrain: 1.0 0.005673360940815043 \ttest: 0.90625 4.016253193249748\n",
      "retrain  93 :\n",
      "\ttrain: 1.0 0.005551940730396495 \ttest: 0.90625 4.018152001069117\n",
      "retrain  94 :\n",
      "\ttrain: 1.0 0.005434382219634663 \ttest: 0.90625 4.020034627307604\n",
      "retrain  95 :\n",
      "\ttrain: 1.0 0.005320523362965721 \ttest: 0.90625 4.021901309837434\n",
      "retrain  96 :\n",
      "\ttrain: 1.0 0.005210210523042182 \ttest: 0.90625 4.02375228259503\n",
      "retrain  97 :\n",
      "\ttrain: 1.0 0.005103297952847444 \ttest: 0.90625 4.025587775590104\n",
      "retrain  98 :\n",
      "\ttrain: 1.0 0.004999647314624952 \ttest: 0.90625 4.027408014922486\n",
      "retrain  99 :\n",
      "\ttrain: 1.0 0.004899127232662914 \ttest: 0.90625 4.029213222805709\n",
      "retrain  100 :\n",
      "\ttrain: 1.0 0.004801612877240282 \ttest: 0.90625 4.031003617596479\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        37\n",
      "           1    1.00000   1.00000   1.00000        37\n",
      "\n",
      "    accuracy                        1.00000        74\n",
      "   macro avg    1.00000   1.00000   1.00000        74\n",
      "weighted avg    1.00000   1.00000   1.00000        74\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.93333   0.87500   0.90323        16\n",
      "           1    0.88235   0.93750   0.90909        16\n",
      "\n",
      "    accuracy                        0.90625        32\n",
      "   macro avg    0.90784   0.90625   0.90616        32\n",
      "weighted avg    0.90784   0.90625   0.90616        32\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 143\n",
      "Average of depth: 1.062937062937063\n",
      "Number of nodes: 449\n",
      "16 52 1\n",
      "23 73 2\n",
      "31 99 3\n",
      "38 128 4\n",
      "43 139 5\n",
      "48 158 6\n",
      "50 166 7\n",
      "53 177 8\n",
      "58 192 9\n",
      "60 196 10\n",
      "63 203 11\n",
      "65 209 12\n",
      "68 222 13\n",
      "69 229 14\n",
      "72 240 15\n",
      "75 245 16\n",
      "78 252 17\n",
      "80 256 18\n",
      "81 257 19\n",
      "84 266 20\n",
      "87 277 21\n",
      "90 290 22\n",
      "94 304 23\n",
      "94 302 24\n",
      "98 316 25\n",
      "102 330 26\n",
      "106 348 27\n",
      "108 352 28\n",
      "111 357 29\n",
      "111 355 30\n",
      "113 363 31\n",
      "113 363 32\n",
      "114 366 33\n",
      "116 376 34\n",
      "119 387 35\n",
      "122 396 36\n",
      "122 396 37\n",
      "124 402 38\n",
      "126 408 39\n",
      "127 411 40\n",
      "129 419 41\n",
      "129 419 42\n",
      "130 422 43\n",
      "131 425 44\n",
      "132 430 45\n",
      "134 434 46\n",
      "134 430 47\n",
      "138 444 48\n",
      "139 445 49\n",
      "139 445 50\n",
      "141 451 51\n",
      "142 458 52\n",
      "143 463 53\n",
      "145 473 54\n",
      "145 471 55\n",
      "145 471 56\n",
      "145 469 57\n",
      "145 469 58\n",
      "148 486 59\n",
      "148 480 60\n",
      "150 486 61\n",
      "151 487 62\n",
      "151 481 63\n",
      "152 482 64\n",
      "153 487 65\n",
      "154 490 66\n",
      "154 488 67\n",
      "154 488 68\n",
      "155 493 69\n",
      "156 496 70\n",
      "157 499 71\n",
      "157 497 72\n",
      "157 495 73\n",
      "157 495 74\n",
      "157 495 75\n",
      "157 495 76\n",
      "158 498 77\n",
      "158 498 78\n",
      "161 513 79\n",
      "161 513 80\n",
      "161 513 81\n",
      "162 516 82\n",
      "162 516 83\n",
      "162 516 84\n",
      "165 525 85\n",
      "165 525 86\n",
      "165 525 87\n",
      "167 529 88\n",
      "169 541 89\n",
      "169 541 90\n",
      "170 546 91\n",
      "170 546 92\n",
      "170 546 93\n",
      "170 544 94\n",
      "171 549 95\n",
      "173 555 96\n",
      "175 563 97\n",
      "175 561 98\n",
      "176 568 99\n",
      "176 562 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.9864864864864865 8.569717281134496 \ttest: 0.78125 10.718231191709542\n",
      "retrain  2 :\n",
      "\ttrain: 0.9864864864864865 4.017730888254607 \ttest: 0.78125 10.107399121424383\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 2.411911528466131 \ttest: 0.75 10.0008928784248\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 1.612688990791699 \ttest: 0.75 10.000305084117583\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.1470037233616235 \ttest: 0.75 10.03244521234145\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 0.8514718037540647 \ttest: 0.75 10.076527826568428\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 0.6532655024761761 \ttest: 0.75 10.124760489449375\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.5147644449907325 \ttest: 0.75 10.17372279637286\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.41473519920806556 \ttest: 0.75 10.221807496397599\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.34046536489719914 \ttest: 0.75 10.26826091563709\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.2840016041723177 \ttest: 0.75 10.312759860042561\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.2401872024373903 \ttest: 0.75 10.355205189844567\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.20557558266203846 \ttest: 0.75 10.395614818598748\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.17780127201498785 \ttest: 0.75 10.434066230875095\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.15520223921753867 \ttest: 0.75 10.47066499152807\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.1365859954022517 \ttest: 0.75 10.50552738002127\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.1210807137745389 \ttest: 0.75 10.538770884138373\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.10803811479934948 \ttest: 0.75 10.57050913491848\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.09696869988065605 \ttest: 0.75 10.600849372110801\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.08749768014191076 \ttest: 0.75 10.629891352154964\n",
      "retrain  21 :\n",
      "\ttrain: 1.0 0.079334431277965 \ttest: 0.75 10.657727070612214\n",
      "retrain  22 :\n",
      "\ttrain: 1.0 0.07225096373495053 \ttest: 0.75 10.68444093313871\n",
      "retrain  23 :\n",
      "\ttrain: 1.0 0.06606651085785264 \ttest: 0.75 10.710110160927368\n",
      "retrain  24 :\n",
      "\ttrain: 1.0 0.060636338236014664 \ttest: 0.75 10.73480530560349\n",
      "retrain  25 :\n",
      "\ttrain: 1.0 0.055843510510416756 \ttest: 0.75 10.758590801296528\n",
      "retrain  26 :\n",
      "\ttrain: 1.0 0.05159275985511217 \ttest: 0.75 10.7815255130301\n",
      "retrain  27 :\n",
      "\ttrain: 1.0 0.04780586778022318 \ttest: 0.75 10.803663259331241\n",
      "retrain  28 :\n",
      "\ttrain: 1.0 0.04441815003871735 \ttest: 0.75 10.82505329812631\n",
      "retrain  29 :\n",
      "\ttrain: 1.0 0.04137575484768524 \ttest: 0.75 10.845740771572725\n",
      "retrain  30 :\n",
      "\ttrain: 1.0 0.03863356718824372 \ttest: 0.75 10.865767109276955\n",
      "retrain  31 :\n",
      "\ttrain: 1.0 0.03615356927774555 \ttest: 0.75 10.88517039146287\n",
      "retrain  32 :\n",
      "\ttrain: 1.0 0.033903547608150994 \ttest: 0.75 10.9039856747478\n",
      "retrain  33 :\n",
      "\ttrain: 1.0 0.031856065599159454 \ttest: 0.75 10.922245283665504\n",
      "retrain  34 :\n",
      "\ttrain: 1.0 0.029987641509188694 \ttest: 0.75 10.939979071197655\n",
      "retrain  35 :\n",
      "\ttrain: 1.0 0.02827808619926108 \ttest: 0.75 10.957214651493176\n",
      "retrain  36 :\n",
      "\ttrain: 1.0 0.026709966304304212 \ttest: 0.75 10.973977607763057\n",
      "retrain  37 :\n",
      "\ttrain: 1.0 0.025268166472086157 \ttest: 0.75 10.990291678094456\n",
      "retrain  38 :\n",
      "\ttrain: 1.0 0.02393953037635871 \ttest: 0.75 11.006178921666685\n",
      "retrain  39 :\n",
      "\ttrain: 1.0 0.022712564757510094 \ttest: 0.75 11.02165986759297\n",
      "retrain  40 :\n",
      "\ttrain: 1.0 0.021577194189323898 \ttest: 0.75 11.036753648366643\n",
      "retrain  41 :\n",
      "\ttrain: 1.0 0.020524556900142182 \ttest: 0.75 11.051478119664282\n",
      "retrain  42 :\n",
      "\ttrain: 1.0 0.0195468339978095 \ttest: 0.75 11.06584996805336\n",
      "retrain  43 :\n",
      "\ttrain: 1.0 0.018637106011325 \ttest: 0.75 11.079884807968469\n",
      "retrain  44 :\n",
      "\ttrain: 1.0 0.01778923187931042 \ttest: 0.75 11.093597269157158\n",
      "retrain  45 :\n",
      "\ttrain: 1.0 0.01699774646861384 \ttest: 0.75 11.107001075652569\n",
      "retrain  46 :\n",
      "\ttrain: 1.0 0.016257773457116972 \ttest: 0.75 11.120109117203254\n",
      "retrain  47 :\n",
      "\ttrain: 1.0 0.015564951009328046 \ttest: 0.75 11.132933513979621\n",
      "retrain  48 :\n",
      "\ttrain: 1.0 0.014915368146588111 \ttest: 0.75 11.145485675278955\n",
      "retrain  49 :\n",
      "\ttrain: 1.0 0.014305510092313818 \ttest: 0.75 11.15777635286576\n",
      "retrain  50 :\n",
      "\ttrain: 1.0 0.013732211177021898 \ttest: 0.75 11.169815689509615\n",
      "retrain  51 :\n",
      "\ttrain: 1.0 0.013192614133622188 \ttest: 0.75 11.18161326321745\n",
      "retrain  52 :\n",
      "\ttrain: 1.0 0.012684134812775536 \ttest: 0.75 11.193178127599996\n",
      "retrain  53 :\n",
      "\ttrain: 1.0 0.01220443151044746 \ttest: 0.75 11.20451884876212\n",
      "retrain  54 :\n",
      "\ttrain: 1.0 0.011751378232543056 \ttest: 0.75 11.215643539062873\n",
      "retrain  55 :\n",
      "\ttrain: 1.0 0.011323041330497614 \ttest: 0.75 11.226559888052533\n",
      "retrain  56 :\n",
      "\ttrain: 1.0 0.010917659031511436 \ttest: 0.75 11.237275190860139\n",
      "retrain  57 :\n",
      "\ttrain: 1.0 0.010533623461397338 \ttest: 0.75 11.247796374275158\n",
      "retrain  58 :\n",
      "\ttrain: 1.0 0.010169464819656922 \ttest: 0.75 11.25813002074083\n",
      "retrain  59 :\n",
      "\ttrain: 1.0 0.009823837417736628 \ttest: 0.75 11.268282390453512\n",
      "retrain  60 :\n",
      "\ttrain: 1.0 0.009495507334301795 \ttest: 0.75 11.278259441741959\n",
      "retrain  61 :\n",
      "\ttrain: 1.0 0.009183341477306973 \ttest: 0.75 11.288066849882503\n",
      "retrain  62 :\n",
      "\ttrain: 1.0 0.008886297872852273 \ttest: 0.75 11.297710024489955\n",
      "retrain  63 :\n",
      "\ttrain: 1.0 0.008603417026285143 \ttest: 0.75 11.307194125610074\n",
      "retrain  64 :\n",
      "\ttrain: 1.0 0.008333814222538009 \ttest: 0.75 11.316524078626685\n",
      "retrain  65 :\n",
      "\ttrain: 1.0 0.008076672650947705 \ttest: 0.75 11.325704588085475\n",
      "retrain  66 :\n",
      "\ttrain: 1.0 0.007831237255316594 \ttest: 0.75 11.334740150526454\n",
      "retrain  67 :\n",
      "\ttrain: 1.0 0.007596809223198499 \ttest: 0.75 11.343635066408247\n",
      "retrain  68 :\n",
      "\ttrain: 1.0 0.007372741039687345 \ttest: 0.75 11.35239345119939\n",
      "retrain  69 :\n",
      "\ttrain: 1.0 0.007158432040659697 \ttest: 0.75 11.361019245704826\n",
      "retrain  70 :\n",
      "\ttrain: 1.0 0.006953324408724949 \ttest: 0.75 11.369516225689281\n",
      "retrain  71 :\n",
      "\ttrain: 1.0 0.006756899562280953 \ttest: 0.75 11.377888010853734\n",
      "retrain  72 :\n",
      "\ttrain: 1.0 0.006568674894230514 \ttest: 0.75 11.386138073215884\n",
      "retrain  73 :\n",
      "\ttrain: 1.0 0.006388200822237188 \ttest: 0.75 11.39426974494108\n",
      "retrain  74 :\n",
      "\ttrain: 1.0 0.0062150581170055605 \ttest: 0.75 11.402286225666012\n",
      "retrain  75 :\n",
      "\ttrain: 1.0 0.006048855479069953 \ttest: 0.75 11.410190589353697\n",
      "retrain  76 :\n",
      "\ttrain: 1.0 0.005889227338050148 \ttest: 0.75 11.417985790715012\n",
      "retrain  77 :\n",
      "\ttrain: 1.0 0.005735831851360584 \ttest: 0.75 11.42567467122898\n",
      "retrain  78 :\n",
      "\ttrain: 1.0 0.00558834908199995 \ttest: 0.75 11.433259964791288\n",
      "retrain  79 :\n",
      "\ttrain: 1.0 0.005446479337358332 \ttest: 0.75 11.440744303017988\n",
      "retrain  80 :\n",
      "\ttrain: 1.0 0.00530994165300044 \ttest: 0.75 11.448130220229176\n",
      "retrain  81 :\n",
      "\ttrain: 1.0 0.005178472407157889 \ttest: 0.75 11.455420158135352\n",
      "retrain  82 :\n",
      "\ttrain: 1.0 0.00505182405322214 \ttest: 0.75 11.46261647024734\n",
      "retrain  83 :\n",
      "\ttrain: 1.0 0.00492976395890204 \ttest: 0.75 11.46972142602896\n",
      "retrain  84 :\n",
      "\ttrain: 1.0 0.004812073341918977 \ttest: 0.75 11.476737214810129\n",
      "retrain  85 :\n",
      "\ttrain: 1.0 0.004698546293181157 \ttest: 0.75 11.483665949476638\n",
      "retrain  86 :\n",
      "\ttrain: 1.0 0.004588988879322456 \ttest: 0.75 11.490509669951695\n",
      "retrain  87 :\n",
      "\ttrain: 1.0 0.004483218317327728 \ttest: 0.75 11.497270346482992\n",
      "retrain  88 :\n",
      "\ttrain: 1.0 0.004381062214708485 \ttest: 0.75 11.503949882748167\n",
      "retrain  89 :\n",
      "\ttrain: 1.0 0.004282357869350958 \ttest: 0.75 11.510550118790455\n",
      "retrain  90 :\n",
      "\ttrain: 1.0 0.004186951623745019 \ttest: 0.75 11.517072833795488\n",
      "retrain  91 :\n",
      "\ttrain: 1.0 0.004094698268823846 \ttest: 0.75 11.523519748719416\n",
      "retrain  92 :\n",
      "\ttrain: 1.0 0.004005460493109318 \ttest: 0.75 11.529892528777655\n",
      "retrain  93 :\n",
      "\ttrain: 1.0 0.003919108373274049 \ttest: 0.75 11.536192785803092\n",
      "retrain  94 :\n",
      "\ttrain: 1.0 0.0038355189026015504 \ttest: 0.75 11.542422080481742\n",
      "retrain  95 :\n",
      "\ttrain: 1.0 0.00375457555415931 \ttest: 0.75 11.548581924473416\n",
      "retrain  96 :\n",
      "\ttrain: 1.0 0.0036761678757966333 \ttest: 0.75 11.55467378242438\n",
      "retrain  97 :\n",
      "\ttrain: 1.0 0.0036001911143469798 \ttest: 0.75 11.560699073878505\n",
      "retrain  98 :\n",
      "\ttrain: 1.0 0.0035265458666542773 \ttest: 0.75 11.566659175092907\n",
      "retrain  99 :\n",
      "\ttrain: 1.0 0.0034551377552589236 \ttest: 0.75 11.572555420763809\n",
      "retrain  100 :\n",
      "\ttrain: 1.0 0.003385877126773117 \ttest: 0.75 11.578389105667778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        37\n",
      "           1    1.00000   1.00000   1.00000        37\n",
      "\n",
      "    accuracy                        1.00000        74\n",
      "   macro avg    1.00000   1.00000   1.00000        74\n",
      "weighted avg    1.00000   1.00000   1.00000        74\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.83333   0.62500   0.71429        16\n",
      "           1    0.70000   0.87500   0.77778        16\n",
      "\n",
      "    accuracy                        0.75000        32\n",
      "   macro avg    0.76667   0.75000   0.74603        32\n",
      "weighted avg    0.76667   0.75000   0.74603        32\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 176\n",
      "Average of depth: 1.0909090909090908\n",
      "Number of nodes: 562\n",
      "19 77 1\n",
      "29 105 2\n",
      "34 118 3\n",
      "39 131 4\n",
      "43 143 5\n",
      "52 168 6\n",
      "55 185 7\n",
      "58 194 8\n",
      "62 206 9\n",
      "66 216 10\n",
      "71 235 11\n",
      "71 235 12\n",
      "75 251 13\n",
      "76 254 14\n",
      "81 277 15\n",
      "83 283 16\n",
      "83 283 17\n",
      "83 283 18\n",
      "87 295 19\n",
      "88 294 20\n",
      "88 292 21\n",
      "90 300 22\n",
      "92 310 23\n",
      "93 311 24\n",
      "94 310 25\n",
      "94 310 26\n",
      "95 311 27\n",
      "97 319 28\n",
      "100 330 29\n",
      "101 337 30\n",
      "101 335 31\n",
      "103 343 32\n",
      "104 346 33\n",
      "102 326 34\n",
      "102 326 35\n",
      "105 337 36\n",
      "106 340 37\n",
      "106 340 38\n",
      "106 340 39\n",
      "107 345 40\n",
      "107 345 41\n",
      "107 345 42\n",
      "107 345 43\n",
      "108 348 44\n",
      "108 348 45\n",
      "111 357 46\n",
      "113 363 47\n",
      "115 373 48\n",
      "115 371 49\n",
      "116 374 50\n",
      "117 377 51\n",
      "120 386 52\n",
      "120 386 53\n",
      "120 386 54\n",
      "120 382 55\n",
      "120 382 56\n",
      "120 382 57\n",
      "120 382 58\n",
      "120 382 59\n",
      "121 383 60\n",
      "122 386 61\n",
      "123 391 62\n",
      "124 394 63\n",
      "124 394 64\n",
      "124 394 65\n",
      "124 394 66\n",
      "126 402 67\n",
      "126 400 68\n",
      "127 407 69\n",
      "128 418 70\n",
      "129 421 71\n",
      "129 421 72\n",
      "129 421 73\n",
      "129 421 74\n",
      "129 421 75\n",
      "129 421 76\n",
      "130 424 77\n",
      "131 427 78\n",
      "131 427 79\n",
      "131 427 80\n",
      "131 427 81\n",
      "131 427 82\n",
      "132 430 83\n",
      "133 435 84\n",
      "135 443 85\n",
      "135 443 86\n",
      "135 443 87\n",
      "135 435 88\n",
      "136 440 89\n",
      "136 440 90\n",
      "136 440 91\n",
      "136 440 92\n",
      "137 445 93\n",
      "138 450 94\n",
      "138 450 95\n",
      "138 450 96\n",
      "138 450 97\n",
      "138 450 98\n",
      "138 450 99\n",
      "139 455 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 13.03642803058739 \ttest: 0.875 9.827975043448866\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 6.479341368497168 \ttest: 0.875 7.775582236783949\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 3.882501998196667 \ttest: 0.875 6.851177563943841\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 2.582669870569672 \ttest: 0.875 6.34477626946832\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.83641784259868 \ttest: 0.875 6.031925233973376\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 1.3684731845012856 \ttest: 0.875 5.822905568975963\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 1.0562875130496654 \ttest: 0.875 5.675501615049775\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.8381163681633386 \ttest: 0.875 5.567409305248026\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.6799916689171539 \ttest: 0.875 5.4857941051444685\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.5619541930506005 \ttest: 0.875 5.422773812856745\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.47165621506951955 \ttest: 0.875 5.3732539754402495\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.4011337730287456 \ttest: 0.875 5.333803917824258\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.3450694818159053 \ttest: 0.875 5.302034226863944\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.2998074354681117 \ttest: 0.875 5.2762332590313\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.2627698693106857 \ttest: 0.875 5.255145341521544\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.2320988356607506 \ttest: 0.875 5.2378303017296854\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.2064290483454389 \ttest: 0.90625 5.223571624319247\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.18473986757030483 \ttest: 0.90625 5.211814723548349\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.1662564879092839 \ttest: 0.90625 5.202124444401408\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.15038253648392585 \ttest: 0.90625 5.194155174629006\n",
      "retrain  21 :\n",
      "\ttrain: 1.0 0.13665320003924242 \ttest: 0.90625 5.187629425529259\n",
      "retrain  22 :\n",
      "\ttrain: 1.0 0.12470205526053037 \ttest: 0.90625 5.182322220936709\n",
      "retrain  23 :\n",
      "\ttrain: 1.0 0.11423722204113125 \ttest: 0.90625 5.178049545637043\n",
      "retrain  24 :\n",
      "\ttrain: 1.0 0.10502397025604884 \ttest: 0.90625 5.1746596796487605\n",
      "retrain  25 :\n",
      "\ttrain: 1.0 0.0968718648498735 \ttest: 0.90625 5.172026615949491\n",
      "retrain  26 :\n",
      "\ttrain: 1.0 0.08962514894542775 \ttest: 0.90625 5.170045003590729\n",
      "retrain  27 :\n",
      "\ttrain: 1.0 0.08315546821954353 \ttest: 0.90625 5.168626222036156\n",
      "retrain  28 :\n",
      "\ttrain: 1.0 0.0773563091080985 \ttest: 0.90625 5.1676953043433045\n",
      "retrain  29 :\n",
      "\ttrain: 1.0 0.0721387059418973 \ttest: 0.90625 5.1671885042384895\n",
      "retrain  30 :\n",
      "\ttrain: 1.0 0.06742789762190443 \ttest: 0.90625 5.167051356535839\n",
      "retrain  31 :\n",
      "\ttrain: 1.0 0.0631607018897586 \ttest: 0.90625 5.167237119076276\n",
      "retrain  32 :\n",
      "\ttrain: 1.0 0.05928343693677486 \ttest: 0.90625 5.167705512265583\n",
      "retrain  33 :\n",
      "\ttrain: 1.0 0.05575026411518037 \ttest: 0.90625 5.168421692624026\n",
      "retrain  34 :\n",
      "\ttrain: 1.0 0.05252185726971838 \ttest: 0.90625 5.169355411733787\n",
      "retrain  35 :\n",
      "\ttrain: 1.0 0.0495643273470025 \ttest: 0.90625 5.170480323105761\n",
      "retrain  36 :\n",
      "\ttrain: 1.0 0.046848347962629794 \ttest: 0.90625 5.1717734078446345\n",
      "retrain  37 :\n",
      "\ttrain: 1.0 0.044348440241638594 \ttest: 0.90625 5.173214496317578\n",
      "retrain  38 :\n",
      "\ttrain: 1.0 0.04204238470664653 \ttest: 0.90625 5.174785867859993\n",
      "retrain  39 :\n",
      "\ttrain: 1.0 0.03991073512541858 \ttest: 0.90625 5.176471914264437\n",
      "retrain  40 :\n",
      "\ttrain: 1.0 0.03793641465625253 \ttest: 0.90625 5.1782588556743585\n",
      "retrain  41 :\n",
      "\ttrain: 1.0 0.036104378785154996 \ttest: 0.90625 5.180134499746688\n",
      "retrain  42 :\n",
      "\ttrain: 1.0 0.034401332752746636 \ttest: 0.90625 5.182088036707097\n",
      "retrain  43 :\n",
      "\ttrain: 1.0 0.03281549365511933 \ttest: 0.90625 5.18410986431138\n",
      "retrain  44 :\n",
      "\ttrain: 1.0 0.03133638934413785 \ttest: 0.90625 5.1861914378299385\n",
      "retrain  45 :\n",
      "\ttrain: 1.0 0.029954687777319605 \ttest: 0.90625 5.188325141053648\n",
      "retrain  46 :\n",
      "\ttrain: 1.0 0.028662051671568885 \ttest: 0.90625 5.190504175026778\n",
      "retrain  47 :\n",
      "\ttrain: 1.0 0.027451014271153887 \ttest: 0.90625 5.192722461783361\n",
      "retrain  48 :\n",
      "\ttrain: 1.0 0.026314872803370273 \ttest: 0.90625 5.194974560825947\n",
      "retrain  49 :\n",
      "\ttrain: 1.0 0.02524759680730223 \ttest: 0.90625 5.1972555964624405\n",
      "retrain  50 :\n",
      "\ttrain: 1.0 0.02424374901418669 \ttest: 0.90625 5.199561194424631\n",
      "retrain  51 :\n",
      "\ttrain: 1.0 0.023298416856986994 \ttest: 0.90625 5.201887426445078\n",
      "retrain  52 :\n",
      "\ttrain: 1.0 0.02240715301120271 \ttest: 0.90625 5.204230761677493\n",
      "retrain  53 :\n",
      "\ttrain: 1.0 0.02156592363374458 \ttest: 0.90625 5.206588024018382\n",
      "retrain  54 :\n",
      "\ttrain: 1.0 0.02077106318370988 \ttest: 0.90625 5.20895635453105\n",
      "retrain  55 :\n",
      "\ttrain: 1.0 0.02001923488740861 \ttest: 0.90625 5.211333178292554\n",
      "retrain  56 :\n",
      "\ttrain: 1.0 0.01930739605738428 \ttest: 0.90625 5.213716175084123\n",
      "retrain  57 :\n",
      "\ttrain: 1.0 0.018632767597303167 \ttest: 0.90625 5.216103253429445\n",
      "retrain  58 :\n",
      "\ttrain: 1.0 0.017992807126129967 \ttest: 0.90625 5.218492527555722\n",
      "retrain  59 :\n",
      "\ttrain: 1.0 0.017385185239711266 \ttest: 0.90625 5.220882296912041\n",
      "retrain  60 :\n",
      "\ttrain: 1.0 0.016807764498774004 \ttest: 0.90625 5.223271027930009\n",
      "retrain  61 :\n",
      "\ttrain: 1.0 0.016258580791845882 \ttest: 0.90625 5.225657337754408\n",
      "retrain  62 :\n",
      "\ttrain: 1.0 0.015735826771700073 \ttest: 0.90625 5.228039979708142\n",
      "retrain  63 :\n",
      "\ttrain: 1.0 0.015237837106221577 \ttest: 0.90625 5.230417830286788\n",
      "retrain  64 :\n",
      "\ttrain: 1.0 0.014763075320404575 \ttest: 0.90625 5.232789877504716\n",
      "retrain  65 :\n",
      "\ttrain: 1.0 0.014310122036591228 \ttest: 0.90625 5.235155210437615\n",
      "retrain  66 :\n",
      "\ttrain: 1.0 0.013877664445939561 \ttest: 0.90625 5.237513009825792\n",
      "retrain  67 :\n",
      "\ttrain: 1.0 0.013464486866189805 \ttest: 0.90625 5.239862539619645\n",
      "retrain  68 :\n",
      "\ttrain: 1.0 0.01306946225968662 \ttest: 0.90625 5.242203139363229\n",
      "retrain  69 :\n",
      "\ttrain: 1.0 0.012691544601810125 \ttest: 0.90625 5.2445342173245315\n",
      "retrain  70 :\n",
      "\ttrain: 1.0 0.012329762003888094 \ttest: 0.90625 5.246855244291973\n",
      "retrain  71 :\n",
      "\ttrain: 1.0 0.011983210506649213 \ttest: 0.90625 5.249165747966271\n",
      "retrain  72 :\n",
      "\ttrain: 1.0 0.011651048470626917 \ttest: 0.90625 5.251465307884991\n",
      "retrain  73 :\n",
      "\ttrain: 1.0 0.011332491498874796 \ttest: 0.90625 5.253753550824416\n",
      "retrain  74 :\n",
      "\ttrain: 1.0 0.011026807835113166 \ttest: 0.90625 5.25603014662966\n",
      "retrain  75 :\n",
      "\ttrain: 1.0 0.01073331418716705 \ttest: 0.90625 5.258294804429481\n",
      "retrain  76 :\n",
      "\ttrain: 1.0 0.01045137193141913 \ttest: 0.90625 5.260547269197122\n",
      "retrain  77 :\n",
      "\ttrain: 1.0 0.010180383659114733 \ttest: 0.90625 5.262787318622738\n",
      "retrain  78 :\n",
      "\ttrain: 1.0 0.009919790029821752 \ttest: 0.90625 5.265014760266731\n",
      "retrain  79 :\n",
      "\ttrain: 1.0 0.009669066901256098 \ttest: 0.90625 5.267229428966662\n",
      "retrain  80 :\n",
      "\ttrain: 1.0 0.009427722708108894 \ttest: 0.90625 5.269431184473221\n",
      "retrain  81 :\n",
      "\ttrain: 1.0 0.009195296065518393 \ttest: 0.90625 5.2716199092934355\n",
      "retrain  82 :\n",
      "\ttrain: 1.0 0.00897135357547554 \ttest: 0.90625 5.273795506721483\n",
      "retrain  83 :\n",
      "\ttrain: 1.0 0.008755487816781272 \ttest: 0.90625 5.275957899039553\n",
      "retrain  84 :\n",
      "\ttrain: 1.0 0.008547315501229957 \ttest: 0.90625 5.278107025872968\n",
      "retrain  85 :\n",
      "\ttrain: 1.0 0.008346475780509444 \ttest: 0.90625 5.280242842685388\n",
      "retrain  86 :\n",
      "\ttrain: 1.0 0.008152628689915951 \ttest: 0.90625 5.282365319401305\n",
      "retrain  87 :\n",
      "\ttrain: 1.0 0.00796545371640664 \ttest: 0.90625 5.284474439144386\n",
      "retrain  88 :\n",
      "\ttrain: 1.0 0.007784648479777169 \ttest: 0.90625 5.286570197081217\n",
      "retrain  89 :\n",
      "\ttrain: 1.0 0.007609927516875083 \ttest: 0.90625 5.28865259936115\n",
      "retrain  90 :\n",
      "\ttrain: 1.0 0.007441021159760522 \ttest: 0.90625 5.2907216621437545\n",
      "retrain  91 :\n",
      "\ttrain: 1.0 0.0072776744996162586 \ttest: 0.90625 5.292777410706224\n",
      "retrain  92 :\n",
      "\ttrain: 1.0 0.007119646429005013 \ttest: 0.90625 5.294819878623821\n",
      "retrain  93 :\n",
      "\ttrain: 1.0 0.006966708755782239 \ttest: 0.90625 5.2968491070170725\n",
      "retrain  94 :\n",
      "\ttrain: 1.0 0.006818645382608091 \ttest: 0.90625 5.298865143860001\n",
      "retrain  95 :\n",
      "\ttrain: 1.0 0.006675251546571961 \ttest: 0.90625 5.300868043344252\n",
      "retrain  96 :\n",
      "\ttrain: 1.0 0.0065363331139529045 \ttest: 0.90625 5.302857865294383\n",
      "retrain  97 :\n",
      "\ttrain: 1.0 0.00640170592559821 \ttest: 0.90625 5.304834674630069\n",
      "retrain  98 :\n",
      "\ttrain: 1.0 0.006271195188813861 \ttest: 0.90625 5.306798540871304\n",
      "retrain  99 :\n",
      "\ttrain: 1.0 0.006144634912031377 \ttest: 0.90625 5.308749537683079\n",
      "retrain  100 :\n",
      "\ttrain: 1.0 0.006021867378849452 \ttest: 0.90625 5.310687742456289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        37\n",
      "           1    1.00000   1.00000   1.00000        37\n",
      "\n",
      "    accuracy                        1.00000        74\n",
      "   macro avg    1.00000   1.00000   1.00000        74\n",
      "weighted avg    1.00000   1.00000   1.00000        74\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.88235   0.93750   0.90909        16\n",
      "           1    0.93333   0.87500   0.90323        16\n",
      "\n",
      "    accuracy                        0.90625        32\n",
      "   macro avg    0.90784   0.90625   0.90616        32\n",
      "weighted avg    0.90784   0.90625   0.90616        32\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 139\n",
      "Average of depth: 1.1366906474820144\n",
      "Number of nodes: 455\n",
      "21 75 1\n",
      "31 113 2\n",
      "42 154 3\n",
      "47 169 4\n",
      "53 189 5\n",
      "58 198 6\n",
      "60 202 7\n",
      "65 217 8\n",
      "70 232 9\n",
      "73 241 10\n",
      "74 242 11\n",
      "77 251 12\n",
      "80 258 13\n",
      "84 270 14\n",
      "87 279 15\n",
      "87 279 16\n",
      "90 292 17\n",
      "92 298 18\n",
      "92 296 19\n",
      "96 312 20\n",
      "97 311 21\n",
      "98 314 22\n",
      "100 328 23\n",
      "103 337 24\n",
      "105 347 25\n",
      "106 346 26\n",
      "106 346 27\n",
      "106 346 28\n",
      "106 346 29\n",
      "108 354 30\n",
      "109 357 31\n",
      "112 370 32\n",
      "113 373 33\n",
      "114 374 34\n",
      "116 380 35\n",
      "118 386 36\n",
      "118 386 37\n",
      "119 389 38\n",
      "119 387 39\n",
      "119 387 40\n",
      "120 390 41\n",
      "121 391 42\n",
      "122 394 43\n",
      "122 394 44\n",
      "123 399 45\n",
      "125 407 46\n",
      "125 407 47\n",
      "126 410 48\n",
      "126 408 49\n",
      "127 411 50\n",
      "128 416 51\n",
      "128 416 52\n",
      "129 419 53\n",
      "129 419 54\n",
      "129 419 55\n",
      "130 422 56\n",
      "130 422 57\n",
      "131 425 58\n",
      "132 430 59\n",
      "133 435 60\n",
      "133 433 61\n",
      "133 433 62\n",
      "134 436 63\n",
      "135 441 64\n",
      "137 449 65\n",
      "137 449 66\n",
      "139 455 67\n",
      "139 455 68\n",
      "140 458 69\n",
      "142 466 70\n",
      "142 466 71\n",
      "142 464 72\n",
      "143 469 73\n",
      "143 469 74\n",
      "143 469 75\n",
      "145 475 76\n",
      "147 483 77\n",
      "147 481 78\n",
      "148 484 79\n",
      "148 484 80\n",
      "148 484 81\n",
      "149 489 82\n",
      "151 495 83\n",
      "151 495 84\n",
      "153 501 85\n",
      "153 501 86\n",
      "153 501 87\n",
      "154 504 88\n",
      "154 502 89\n",
      "155 499 90\n",
      "155 499 91\n",
      "155 499 92\n",
      "155 499 93\n",
      "156 508 94\n",
      "156 506 95\n",
      "156 506 96\n",
      "158 512 97\n",
      "158 512 98\n",
      "158 512 99\n",
      "160 518 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 10.624553482160277 \ttest: 0.8125 11.027565127603086\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 4.827614127036528 \ttest: 0.8125 9.705530760569118\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 2.733613297940372 \ttest: 0.8125 9.191077329955844\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 1.746222954267397 \ttest: 0.8125 8.941291226060034\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.2050790761679653 \ttest: 0.8125 8.803213391188915\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 0.8781115038431723 \ttest: 0.8125 8.720420465839595\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 0.6663575486660278 \ttest: 0.8125 8.66809637187832\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.5218513146186864 \ttest: 0.8125 8.633911006840414\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.419103063726759 \ttest: 0.8125 8.611165637228547\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.34358376131746543 \ttest: 0.78125 8.595963983825921\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.2865388098957781 \ttest: 0.78125 8.58591457003762\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.24244844454651554 \ttest: 0.78125 8.579484381969603\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.20769843799584858 \ttest: 0.78125 8.575654944070099\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.1798452296476723 \ttest: 0.78125 8.5737291079156\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.15719062635534978 \ttest: 0.78125 8.573217468816333\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.1385258622771786 \ttest: 0.78125 8.5737689696751\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.12297229032808463 \ttest: 0.78125 8.575127073656082\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.1098792535462931 \ttest: 0.78125 8.577101276661427\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.09875688767192325 \ttest: 0.78125 8.579548117530464\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.08923087297814684 \ttest: 0.78125 8.582358234197212\n",
      "retrain  21 :\n",
      "\ttrain: 1.0 0.0810113285577481 \ttest: 0.78125 8.58544736434148\n",
      "retrain  22 :\n",
      "\ttrain: 1.0 0.0738710263648437 \ttest: 0.78125 8.588749976611595\n",
      "retrain  23 :\n",
      "\ttrain: 1.0 0.06762987288005234 \ttest: 0.78125 8.592214691083253\n",
      "retrain  24 :\n",
      "\ttrain: 1.0 0.062143684159740656 \ttest: 0.78125 8.595800938541505\n",
      "retrain  25 :\n",
      "\ttrain: 1.0 0.0572959516716965 \ttest: 0.78125 8.599476491438251\n",
      "retrain  26 :\n",
      "\ttrain: 1.0 0.05299172376944619 \ttest: 0.78125 8.603215617261188\n",
      "retrain  27 :\n",
      "\ttrain: 1.0 0.049153005005379995 \ttest: 0.78125 8.606997682334816\n",
      "retrain  28 :\n",
      "\ttrain: 1.0 0.04571525865704195 \ttest: 0.78125 8.610806085631411\n",
      "retrain  29 :\n",
      "\ttrain: 1.0 0.04262472080949706 \ttest: 0.78125 8.61462743711829\n",
      "retrain  30 :\n",
      "\ttrain: 1.0 0.03983631814280507 \ttest: 0.78125 8.61845091920897\n",
      "retrain  31 :\n",
      "\ttrain: 1.0 0.03731203949386897 \ttest: 0.78125 8.622267786650585\n",
      "retrain  32 :\n",
      "\ttrain: 1.0 0.035019651815600905 \ttest: 0.78125 8.62607097201866\n",
      "retrain  33 :\n",
      "\ttrain: 1.0 0.032931679896663485 \ttest: 0.78125 8.62985477244918\n",
      "retrain  34 :\n",
      "\ttrain: 1.0 0.031024589805118963 \ttest: 0.78125 8.633614599347979\n",
      "retrain  35 :\n",
      "\ttrain: 1.0 0.029278130942081475 \ttest: 0.78125 8.637346777276129\n",
      "retrain  36 :\n",
      "\ttrain: 1.0 0.027674802509629046 \ttest: 0.78125 8.641048381494834\n",
      "retrain  37 :\n",
      "\ttrain: 1.0 0.02619941826051354 \ttest: 0.78125 8.644717106094973\n",
      "retrain  38 :\n",
      "\ttrain: 1.0 0.02483874940479518 \ttest: 0.78125 8.64835115646676\n",
      "retrain  39 :\n",
      "\ttrain: 1.0 0.023581230061883354 \ttest: 0.78125 8.651949161247655\n",
      "retrain  40 :\n",
      "\ttrain: 1.0 0.0224167130639916 \ttest: 0.78125 8.655510099939356\n",
      "retrain  41 :\n",
      "\ttrain: 1.0 0.02133626652410017 \ttest: 0.78125 8.659033243191361\n",
      "retrain  42 :\n",
      "\ttrain: 1.0 0.020332003584430516 \ttest: 0.78125 8.66251810337117\n",
      "retrain  43 :\n",
      "\ttrain: 1.0 0.019396939310527127 \ttest: 0.78125 8.665964393524602\n",
      "retrain  44 :\n",
      "\ttrain: 1.0 0.018524869901789875 \ttest: 0.78125 8.669371993207239\n",
      "retrain  45 :\n",
      "\ttrain: 1.0 0.01771027033350753 \ttest: 0.78125 8.672740919964568\n",
      "retrain  46 :\n",
      "\ttrain: 1.0 0.016948207289124485 \ttest: 0.78125 8.676071305472702\n",
      "retrain  47 :\n",
      "\ttrain: 1.0 0.016234264830449326 \ttest: 0.78125 8.679363375537335\n",
      "retrain  48 :\n",
      "\ttrain: 1.0 0.01556448072242952 \ttest: 0.78125 8.682617433297015\n",
      "retrain  49 :\n",
      "\ttrain: 1.0 0.014935291704328363 \ttest: 0.78125 8.685833845095505\n",
      "retrain  50 :\n",
      "\ttrain: 1.0 0.014343486300821096 \ttest: 0.78125 8.689013028583704\n",
      "retrain  51 :\n",
      "\ttrain: 1.0 0.013786164010208478 \ttest: 0.78125 8.692155442688847\n",
      "retrain  52 :\n",
      "\ttrain: 1.0 0.013260699904651651 \ttest: 0.78125 8.6952615791514\n",
      "retrain  53 :\n",
      "\ttrain: 1.0 0.012764713838416462 \ttest: 0.78125 8.698331955381152\n",
      "retrain  54 :\n",
      "\ttrain: 1.0 0.012296043591899636 \ttest: 0.78125 8.701367108425735\n",
      "retrain  55 :\n",
      "\ttrain: 1.0 0.011852721387444195 \ttest: 0.78125 8.70436758987908\n",
      "retrain  56 :\n",
      "\ttrain: 1.0 0.011432953302182584 \ttest: 0.78125 8.707333961585427\n",
      "retrain  57 :\n",
      "\ttrain: 1.0 0.011035101176975514 \ttest: 0.78125 8.71026679201793\n",
      "retrain  58 :\n",
      "\ttrain: 1.0 0.01065766668181576 \ttest: 0.78125 8.713166653229958\n",
      "retrain  59 :\n",
      "\ttrain: 1.0 0.010299277249135817 \ttest: 0.78125 8.71603411829341\n",
      "retrain  60 :\n",
      "\ttrain: 1.0 0.009958673629143995 \ttest: 0.78125 8.718869759151534\n",
      "retrain  61 :\n",
      "\ttrain: 1.0 0.009634698857101475 \ttest: 0.78125 8.721674144824993\n",
      "retrain  62 :\n",
      "\ttrain: 1.0 0.0093262884525507 \ttest: 0.78125 8.724447839919133\n",
      "retrain  63 :\n",
      "\ttrain: 1.0 0.009032461695890778 \ttest: 0.78125 8.727191403388353\n",
      "retrain  64 :\n",
      "\ttrain: 1.0 0.008752313849167583 \ttest: 0.78125 8.729905387519931\n",
      "retrain  65 :\n",
      "\ttrain: 1.0 0.008485009206157659 \ttest: 0.78125 8.732590337105322\n",
      "retrain  66 :\n",
      "\ttrain: 1.0 0.008229774872312006 \ttest: 0.78125 8.735246788771551\n",
      "retrain  67 :\n",
      "\ttrain: 1.0 0.007985895188329512 \ttest: 0.78125 8.73787527044937\n",
      "retrain  68 :\n",
      "\ttrain: 1.0 0.007752706722415776 \ttest: 0.78125 8.74047630095811\n",
      "retrain  69 :\n",
      "\ttrain: 1.0 0.007529593765951918 \ttest: 0.78125 8.743050389690147\n",
      "retrain  70 :\n",
      "\ttrain: 1.0 0.0073159842756013605 \ttest: 0.78125 8.74559803638024\n",
      "retrain  71 :\n",
      "\ttrain: 1.0 0.007111346212030304 \ttest: 0.78125 8.74811973094714\n",
      "retrain  72 :\n",
      "\ttrain: 1.0 0.0069151842315819615 \ttest: 0.75 8.75061595339657\n",
      "retrain  73 :\n",
      "\ttrain: 1.0 0.006727036692575201 \ttest: 0.75 8.753087173776311\n",
      "retrain  74 :\n",
      "\ttrain: 1.0 0.0065464729425142795 \ttest: 0.75 8.755533852175311\n",
      "retrain  75 :\n",
      "\ttrain: 1.0 0.006373090856504728 \ttest: 0.75 8.757956438759926\n",
      "retrain  76 :\n",
      "\ttrain: 1.0 0.006206514600655298 \ttest: 0.75 8.760355373841325\n",
      "retrain  77 :\n",
      "\ttrain: 1.0 0.006046392597283164 \ttest: 0.75 8.762731087968955\n",
      "retrain  78 :\n",
      "\ttrain: 1.0 0.0058923956713915066 \ttest: 0.75 8.765084002045606\n",
      "retrain  79 :\n",
      "\ttrain: 1.0 0.005744215360207002 \ttest: 0.75 8.767414527460314\n",
      "retrain  80 :\n",
      "\ttrain: 1.0 0.005601562369596779 \ttest: 0.75 8.76972306623578\n",
      "retrain  81 :\n",
      "\ttrain: 1.0 0.005464165162967193 \ttest: 0.75 8.772010011187529\n",
      "retrain  82 :\n",
      "\ttrain: 1.0 0.0053317686698150235 \ttest: 0.75 8.774275746092334\n",
      "retrain  83 :\n",
      "\ttrain: 1.0 0.005204133102480841 \ttest: 0.75 8.77652064586386\n",
      "retrain  84 :\n",
      "\ttrain: 1.0 0.005081032870872753 \ttest: 0.75 8.778745076733713\n",
      "retrain  85 :\n",
      "\ttrain: 1.0 0.004962255586003235 \ttest: 0.75 8.780949396436366\n",
      "retrain  86 :\n",
      "\ttrain: 1.0 0.004847601144133342 \ttest: 0.75 8.783133954396645\n",
      "retrain  87 :\n",
      "\ttrain: 1.0 0.004736880884161193 \ttest: 0.75 8.78529909191866\n",
      "retrain  88 :\n",
      "\ttrain: 1.0 0.00462991681163953 \ttest: 0.75 8.787445142375226\n",
      "retrain  89 :\n",
      "\ttrain: 1.0 0.004526540883471103 \ttest: 0.75 8.78957243139696\n",
      "retrain  90 :\n",
      "\ttrain: 1.0 0.004426594347922212 \ttest: 0.75 8.79168127706036\n",
      "retrain  91 :\n",
      "\ttrain: 1.0 0.004329927135120905 \ttest: 0.75 8.793771990074305\n",
      "retrain  92 :\n",
      "\ttrain: 1.0 0.0042363972936761175 \ttest: 0.75 8.795844873964501\n",
      "retrain  93 :\n",
      "\ttrain: 1.0 0.004145870469473913 \ttest: 0.75 8.797900225255427\n",
      "retrain  94 :\n",
      "\ttrain: 1.0 0.004058219423081795 \ttest: 0.75 8.799938333649525\n",
      "retrain  95 :\n",
      "\ttrain: 1.0 0.003973323582528533 \ttest: 0.75 8.801959482203275\n",
      "retrain  96 :\n",
      "\ttrain: 1.0 0.0038910686285277586 \ttest: 0.75 8.803963947500037\n",
      "retrain  97 :\n",
      "\ttrain: 1.0 0.0038113461094842873 \ttest: 0.75 8.805951999819396\n",
      "retrain  98 :\n",
      "\ttrain: 1.0 0.0037340530838649087 \ttest: 0.75 8.807923903302953\n",
      "retrain  99 :\n",
      "\ttrain: 1.0 0.0036590917877340405 \ttest: 0.75 8.809879916116431\n",
      "retrain  100 :\n",
      "\ttrain: 1.0 0.003586369325451511 \ttest: 0.75 8.81182029060802\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        37\n",
      "           1    1.00000   1.00000   1.00000        37\n",
      "\n",
      "    accuracy                        1.00000        74\n",
      "   macro avg    1.00000   1.00000   1.00000        74\n",
      "weighted avg    1.00000   1.00000   1.00000        74\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.78571   0.68750   0.73333        16\n",
      "           1    0.72222   0.81250   0.76471        16\n",
      "\n",
      "    accuracy                        0.75000        32\n",
      "   macro avg    0.75397   0.75000   0.74902        32\n",
      "weighted avg    0.75397   0.75000   0.74902        32\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 160\n",
      "Average of depth: 1.10625\n",
      "Number of nodes: 518\n",
      "16 52 1\n",
      "32 114 2\n",
      "41 141 3\n",
      "45 151 4\n",
      "50 164 5\n",
      "54 176 6\n",
      "60 198 7\n",
      "65 215 8\n",
      "69 225 9\n",
      "71 231 10\n",
      "75 247 11\n",
      "77 253 12\n",
      "78 258 13\n",
      "80 262 14\n",
      "84 280 15\n",
      "87 299 16\n",
      "92 316 17\n",
      "94 320 18\n",
      "96 330 19\n",
      "97 327 20\n",
      "99 329 21\n",
      "100 332 22\n",
      "101 335 23\n",
      "103 339 24\n",
      "103 339 25\n",
      "103 339 26\n",
      "103 339 27\n",
      "104 342 28\n",
      "106 350 29\n",
      "109 367 30\n",
      "110 372 31\n",
      "111 375 32\n",
      "112 372 33\n",
      "112 368 34\n",
      "113 367 35\n",
      "114 364 36\n",
      "115 363 37\n",
      "118 376 38\n",
      "120 382 39\n",
      "122 384 40\n",
      "123 387 41\n",
      "124 390 42\n",
      "125 393 43\n",
      "126 396 44\n",
      "126 396 45\n",
      "126 396 46\n",
      "128 402 47\n",
      "128 402 48\n",
      "129 405 49\n",
      "131 411 50\n",
      "131 411 51\n",
      "132 414 52\n",
      "133 417 53\n",
      "134 420 54\n",
      "134 420 55\n",
      "136 430 56\n",
      "137 429 57\n",
      "137 429 58\n",
      "137 427 59\n",
      "138 430 60\n",
      "138 430 61\n",
      "138 430 62\n",
      "139 433 63\n",
      "139 433 64\n",
      "139 433 65\n",
      "141 441 66\n",
      "141 441 67\n",
      "142 444 68\n",
      "142 444 69\n",
      "142 444 70\n",
      "142 444 71\n",
      "142 444 72\n",
      "142 444 73\n",
      "143 447 74\n",
      "143 447 75\n",
      "144 454 76\n",
      "144 454 77\n",
      "145 459 78\n",
      "145 459 79\n",
      "145 459 80\n",
      "145 459 81\n",
      "146 458 82\n",
      "146 458 83\n",
      "146 458 84\n",
      "146 458 85\n",
      "146 458 86\n",
      "146 458 87\n",
      "146 458 88\n",
      "146 458 89\n",
      "146 458 90\n",
      "146 456 91\n",
      "146 456 92\n",
      "147 461 93\n",
      "149 465 94\n",
      "149 465 95\n",
      "149 463 96\n",
      "150 466 97\n",
      "150 466 98\n",
      "150 466 99\n",
      "150 466 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 12.022036022594419 \ttest: 0.90625 8.50648099477888\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 5.761897099130639 \ttest: 0.90625 6.558841674000728\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 3.388752281129219 \ttest: 0.90625 5.77966172435319\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 2.2331207447074712 \ttest: 0.90625 5.370072566920132\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.5807416766222655 \ttest: 0.90625 5.117549374324759\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 1.175504599673391 \ttest: 0.90625 4.945541907399345\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 0.90645617797303 \ttest: 0.90625 4.820284812342851\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.7188487602619519 \ttest: 0.90625 4.724646192919291\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.5829938628872611 \ttest: 0.90625 4.649008544205554\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.4816044699024 \ttest: 0.90625 4.587547454680491\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.40404188895891274 \ttest: 0.875 4.536522625146545\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.3434629336385656 \ttest: 0.875 4.493417734805444\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.29530367183240724 \ttest: 0.875 4.4564748048423795\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.2564268818600639 \ttest: 0.875 4.424426753489674\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.2246199064140873 \ttest: 0.875 4.396336084432868\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.19828715564046556 \ttest: 0.875 4.371493514839827\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.17625547362702765 \ttest: 0.875 4.349352009677706\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.15764738066953726 \ttest: 0.875 4.329482548924147\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.1417964421511027 \ttest: 0.875 4.311543684530922\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.1281895112542688 \ttest: 0.875 4.295260103885099\n",
      "retrain  21 :\n",
      "\ttrain: 1.0 0.11642653535453637 \ttest: 0.875 4.280407227252072\n",
      "retrain  22 :\n",
      "\ttrain: 1.0 0.10619209111279068 \ttest: 0.875 4.266799939931687\n",
      "retrain  23 :\n",
      "\ttrain: 1.0 0.0972349043808963 \ttest: 0.875 4.2542842152758364\n",
      "retrain  24 :\n",
      "\ttrain: 1.0 0.08935290165548193 \ttest: 0.875 4.242730795768416\n",
      "retrain  25 :\n",
      "\ttrain: 1.0 0.0823821547077334 \ttest: 0.875 4.232030363391878\n",
      "retrain  26 :\n",
      "\ttrain: 1.0 0.07618860520072337 \ttest: 0.875 4.222089803778511\n",
      "retrain  27 :\n",
      "\ttrain: 1.0 0.0706618009379997 \ttest: 0.875 4.212829284600522\n",
      "retrain  28 :\n",
      "\ttrain: 1.0 0.06571010568208907 \ttest: 0.875 4.204179947641871\n",
      "retrain  29 :\n",
      "\ttrain: 1.0 0.06125700069949646 \ttest: 0.875 4.196082068682172\n",
      "retrain  30 :\n",
      "\ttrain: 1.0 0.057238203690530426 \ttest: 0.875 4.188483577754359\n",
      "retrain  31 :\n",
      "\ttrain: 1.0 0.05359940572957568 \ttest: 0.875 4.1813388597184975\n",
      "retrain  32 :\n",
      "\ttrain: 1.0 0.050294479769636205 \ttest: 0.875 4.17460777485098\n",
      "retrain  33 :\n",
      "\ttrain: 1.0 0.04728405206524876 \ttest: 0.875 4.1682548535729165\n",
      "retrain  34 :\n",
      "\ttrain: 1.0 0.04453435515556871 \ttest: 0.875 4.162248630088875\n",
      "retrain  35 :\n",
      "\ttrain: 1.0 0.042016300947396404 \ttest: 0.875 4.156561087646882\n",
      "retrain  36 :\n",
      "\ttrain: 1.0 0.03970472708507236 \ttest: 0.875 4.1511671941081305\n",
      "retrain  37 :\n",
      "\ttrain: 1.0 0.03757778067243661 \ttest: 0.90625 4.14604451105538\n",
      "retrain  38 :\n",
      "\ttrain: 1.0 0.03561641155924065 \ttest: 0.90625 4.141172863147055\n",
      "retrain  39 :\n",
      "\ttrain: 1.0 0.033803953554701116 \ttest: 0.90625 4.136534057109449\n",
      "retrain  40 :\n",
      "\ttrain: 1.0 0.03212577660868318 \ttest: 0.90625 4.132111641848036\n",
      "retrain  41 :\n",
      "\ttrain: 1.0 0.030568996584222942 \ttest: 0.90625 4.127890702795005\n",
      "retrain  42 :\n",
      "\ttrain: 1.0 0.02912223200844528 \ttest: 0.90625 4.123857684900207\n",
      "retrain  43 :\n",
      "\ttrain: 1.0 0.02777539933372651 \ttest: 0.90625 4.120000239696301\n",
      "retrain  44 :\n",
      "\ttrain: 1.0 0.026519539915837633 \ttest: 0.90625 4.116307092686\n",
      "retrain  45 :\n",
      "\ttrain: 1.0 0.025346673231378222 \ttest: 0.90625 4.112767927955208\n",
      "retrain  46 :\n",
      "\ttrain: 1.0 0.024249671895910874 \ttest: 0.90625 4.109373287445191\n",
      "retrain  47 :\n",
      "\ttrain: 1.0 0.023222154869299273 \ttest: 0.90625 4.106114482746418\n",
      "retrain  48 :\n",
      "\ttrain: 1.0 0.022258395893251577 \ttest: 0.90625 4.102983517626694\n",
      "retrain  49 :\n",
      "\ttrain: 1.0 0.021353244734168594 \ttest: 0.90625 4.0999730197929605\n",
      "retrain  50 :\n",
      "\ttrain: 1.0 0.020502059229894135 \ttest: 0.90625 4.097076180621966\n",
      "retrain  51 :\n",
      "\ttrain: 1.0 0.019700646483329545 \ttest: 0.90625 4.094286701789884\n",
      "retrain  52 :\n",
      "\ttrain: 1.0 0.018945211825771986 \ttest: 0.90625 4.09159874789259\n",
      "retrain  53 :\n",
      "\ttrain: 1.0 0.018232314401277417 \ttest: 0.90625 4.0890069042828445\n",
      "retrain  54 :\n",
      "\ttrain: 1.0 0.01755882841052746 \ttest: 0.90625 4.086506139463269\n",
      "retrain  55 :\n",
      "\ttrain: 1.0 0.016921909206639576 \ttest: 0.90625 4.084091771468273\n",
      "retrain  56 :\n",
      "\ttrain: 1.0 0.016318963562457107 \ttest: 0.90625 4.081759437747609\n",
      "retrain  57 :\n",
      "\ttrain: 1.0 0.015747623534152246 \ttest: 0.90625 4.079505068131326\n",
      "retrain  58 :\n",
      "\ttrain: 1.0 0.015205723433504844 \ttest: 0.90625 4.07732486051276\n",
      "retrain  59 :\n",
      "\ttrain: 1.0 0.014691279494222765 \ttest: 0.90625 4.075215258934511\n",
      "retrain  60 :\n",
      "\ttrain: 1.0 0.014202471878748988 \ttest: 0.90625 4.073172933803559\n",
      "retrain  61 :\n",
      "\ttrain: 1.0 0.01373762872326 \ttest: 0.90625 4.071194763996921\n",
      "retrain  62 :\n",
      "\ttrain: 1.0 0.013295211961708242 \ttest: 0.90625 4.069277820649373\n",
      "retrain  63 :\n",
      "\ttrain: 1.0 0.012873804706183205 \ttest: 0.90625 4.067419352440769\n",
      "retrain  64 :\n",
      "\ttrain: 1.0 0.012472099991697738 \ttest: 0.90625 4.065616772222841\n",
      "retrain  65 :\n",
      "\ttrain: 1.0 0.012088890719674833 \ttest: 0.90625 4.063867644844622\n",
      "retrain  66 :\n",
      "\ttrain: 1.0 0.01172306065667825 \ttest: 0.90625 4.062169676052462\n",
      "retrain  67 :\n",
      "\ttrain: 1.0 0.011373576363929654 \ttest: 0.90625 4.060520702355026\n",
      "retrain  68 :\n",
      "\ttrain: 1.0 0.011039479949401304 \ttest: 0.90625 4.058918681756347\n",
      "retrain  69 :\n",
      "\ttrain: 1.0 0.010719882548201614 \ttest: 0.90625 4.0573616852710215\n",
      "retrain  70 :\n",
      "\ttrain: 1.0 0.010413958448937895 \ttest: 0.90625 4.055847889145227\n",
      "retrain  71 :\n",
      "\ttrain: 1.0 0.010120939794045259 \ttest: 0.90625 4.054375567715662\n",
      "retrain  72 :\n",
      "\ttrain: 1.0 0.009840111790965035 \ttest: 0.90625 4.0529430868459375\n",
      "retrain  73 :\n",
      "\ttrain: 1.0 0.009570808378746186 \ttest: 0.90625 4.051548897886395\n",
      "retrain  74 :\n",
      "\ttrain: 1.0 0.009312408301308946 \ttest: 0.90625 4.050191532109061\n",
      "retrain  75 :\n",
      "\ttrain: 1.0 0.009064331544397165 \ttest: 0.90625 4.0488695955745015\n",
      "retrain  76 :\n",
      "\ttrain: 1.0 0.00882603609828134 \ttest: 0.90625 4.04758176439179\n",
      "retrain  77 :\n",
      "\ttrain: 1.0 0.008597015012662832 \ttest: 0.90625 4.0463267803367104\n",
      "retrain  78 :\n",
      "\ttrain: 1.0 0.00837679371406278 \ttest: 0.90625 4.045103446796903\n",
      "retrain  79 :\n",
      "\ttrain: 1.0 0.008164927559331741 \ttest: 0.90625 4.043910625015678\n",
      "retrain  80 :\n",
      "\ttrain: 1.0 0.007960999601854691 \ttest: 0.90625 4.042747230609013\n",
      "retrain  81 :\n",
      "\ttrain: 1.0 0.007764618549604732 \ttest: 0.90625 4.041612230332761\n",
      "retrain  82 :\n",
      "\ttrain: 1.0 0.00757541689646755 \ttest: 0.90625 4.040504639079216\n",
      "retrain  83 :\n",
      "\ttrain: 1.0 0.0073930492102551384 \ttest: 0.90625 4.039423517084195\n",
      "retrain  84 :\n",
      "\ttrain: 1.0 0.007217190562590018 \ttest: 0.90625 4.038367967327548\n",
      "retrain  85 :\n",
      "\ttrain: 1.0 0.0070475350873968326 \ttest: 0.90625 4.037337133111556\n",
      "retrain  86 :\n",
      "\ttrain: 1.0 0.006883794656116098 \ttest: 0.90625 4.036330195803138\n",
      "retrain  87 :\n",
      "\ttrain: 1.0 0.006725697658974448 \ttest: 0.90625 4.03534637272698\n",
      "retrain  88 :\n",
      "\ttrain: 1.0 0.006572987882729267 \ttest: 0.90625 4.0343849151979425\n",
      "retrain  89 :\n",
      "\ttrain: 1.0 0.0064254234762666056 \ttest: 0.90625 4.033445106682027\n",
      "retrain  90 :\n",
      "\ttrain: 1.0 0.0062827759962887225 \ttest: 0.90625 4.032526261076186\n",
      "retrain  91 :\n",
      "\ttrain: 1.0 0.006144829526089069 \ttest: 0.90625 4.031627721098076\n",
      "retrain  92 :\n",
      "\ttrain: 1.0 0.006011379861093664 \ttest: 0.90625 4.030748856777577\n",
      "retrain  93 :\n",
      "\ttrain: 1.0 0.005882233755455832 \ttest: 0.90625 4.029889064042655\n",
      "retrain  94 :\n",
      "\ttrain: 1.0 0.0057572082245341116 \ttest: 0.90625 4.029047763392687\n",
      "retrain  95 :\n",
      "\ttrain: 1.0 0.005636129898570862 \ttest: 0.90625 4.028224398653004\n",
      "retrain  96 :\n",
      "\ttrain: 1.0 0.005518834423325107 \ttest: 0.90625 4.027418435804863\n",
      "retrain  97 :\n",
      "\ttrain: 1.0 0.005405165903804749 \ttest: 0.90625 4.026629361885556\n",
      "retrain  98 :\n",
      "\ttrain: 1.0 0.0052949763875958554 \ttest: 0.90625 4.025856683953774\n",
      "retrain  99 :\n",
      "\ttrain: 1.0 0.005188125384603044 \ttest: 0.90625 4.025099928115737\n",
      "retrain  100 :\n",
      "\ttrain: 1.0 0.005084479420300204 \ttest: 0.90625 4.024358638607948\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        37\n",
      "           1    1.00000   1.00000   1.00000        37\n",
      "\n",
      "    accuracy                        1.00000        74\n",
      "   macro avg    1.00000   1.00000   1.00000        74\n",
      "weighted avg    1.00000   1.00000   1.00000        74\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.93333   0.87500   0.90323        16\n",
      "           1    0.88235   0.93750   0.90909        16\n",
      "\n",
      "    accuracy                        0.90625        32\n",
      "   macro avg    0.90784   0.90625   0.90616        32\n",
      "weighted avg    0.90784   0.90625   0.90616        32\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 150\n",
      "Average of depth: 1.04\n",
      "Number of nodes: 466\n",
      "19 67 1\n",
      "28 100 2\n",
      "32 108 3\n",
      "40 132 4\n",
      "45 151 5\n",
      "50 166 6\n",
      "54 180 7\n",
      "55 181 8\n",
      "57 183 9\n",
      "58 186 10\n",
      "64 204 11\n",
      "66 208 12\n",
      "69 217 13\n",
      "71 223 14\n",
      "72 226 15\n",
      "74 234 16\n",
      "73 225 17\n",
      "75 229 18\n",
      "76 232 19\n",
      "80 246 20\n",
      "80 244 21\n",
      "83 253 22\n",
      "86 264 23\n",
      "88 272 24\n",
      "89 277 25\n",
      "90 280 26\n",
      "91 287 27\n",
      "91 287 28\n",
      "93 295 29\n",
      "94 298 30\n",
      "95 301 31\n",
      "96 302 32\n",
      "99 307 33\n",
      "99 307 34\n",
      "100 314 35\n",
      "100 314 36\n",
      "102 322 37\n",
      "103 325 38\n",
      "106 336 39\n",
      "109 347 40\n",
      "110 350 41\n",
      "110 348 42\n",
      "110 348 43\n",
      "110 348 44\n",
      "111 351 45\n",
      "111 351 46\n",
      "111 351 47\n",
      "112 356 48\n",
      "112 356 49\n",
      "113 359 50\n",
      "114 362 51\n",
      "114 358 52\n",
      "115 361 53\n",
      "115 361 54\n",
      "116 362 55\n",
      "116 362 56\n",
      "117 365 57\n",
      "117 365 58\n",
      "118 368 59\n",
      "119 371 60\n",
      "119 371 61\n",
      "119 371 62\n",
      "119 371 63\n",
      "119 371 64\n",
      "119 371 65\n",
      "119 371 66\n",
      "120 374 67\n",
      "121 379 68\n",
      "122 382 69\n",
      "125 391 70\n",
      "125 389 71\n",
      "125 389 72\n",
      "125 389 73\n",
      "126 398 74\n",
      "126 398 75\n",
      "127 395 76\n",
      "127 395 77\n",
      "127 395 78\n",
      "127 393 79\n",
      "127 393 80\n",
      "127 393 81\n",
      "127 393 82\n",
      "127 393 83\n",
      "128 396 84\n",
      "128 394 85\n",
      "128 394 86\n",
      "130 406 87\n",
      "130 406 88\n",
      "132 414 89\n",
      "132 414 90\n",
      "132 414 91\n",
      "132 414 92\n",
      "132 414 93\n",
      "132 414 94\n",
      "132 412 95\n",
      "133 415 96\n",
      "134 420 97\n",
      "135 423 98\n",
      "135 423 99\n",
      "135 423 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 13.591642966470573 \ttest: 1.0 8.435392619845917\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 6.791431153487448 \ttest: 1.0 5.993409995060119\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 4.061758001791657 \ttest: 1.0 4.890692097479374\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 2.696722409515469 \ttest: 1.0 4.266005590319249\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.9154698642705292 \ttest: 1.0 3.860513345598606\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 1.4267753602581221 \ttest: 1.0 3.573664081558628\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 1.101231837260078 \ttest: 1.0 3.358592000512351\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.8738984740713074 \ttest: 1.0 3.1904662727136825\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.7091805726430516 \ttest: 1.0 3.0548524068568668\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.5862218168221769 \ttest: 1.0 2.942756656244924\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.49214444191708384 \ttest: 1.0 2.8482668710240144\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.4186528794284195 \ttest: 1.0 2.7673277263094045\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.3602123274000768 \ttest: 1.0 2.6970596248338135\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.3130187623996849 \ttest: 1.0 2.6353582737921473\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.27439028273980615 \ttest: 1.0 2.5806482310327494\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.24239378271320067 \ttest: 1.0 2.5317252794069143\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.21560852438925462 \ttest: 1.0 2.4876522694787617\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.19297217930526792 \ttest: 1.0 2.4476883331710395\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.17367808719750516 \ttest: 1.0 2.4112395863786515\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.15710518612637564 \ttest: 1.0 2.37782405175704\n",
      "retrain  21 :\n",
      "\ttrain: 1.0 0.14276928555912896 \ttest: 1.0 2.347046220241918\n",
      "retrain  22 :\n",
      "\ttrain: 1.0 0.13028858217467665 \ttest: 1.0 2.318578286599748\n",
      "retrain  23 :\n",
      "\ttrain: 1.0 0.11935886448463784 \ttest: 1.0 2.2921460950663084\n",
      "retrain  24 :\n",
      "\ttrain: 1.0 0.10973542417816712 \ttest: 1.0 2.267518466513642\n",
      "retrain  25 :\n",
      "\ttrain: 1.0 0.10121968422047167 \ttest: 1.0 2.244498991273076\n",
      "retrain  26 :\n",
      "\ttrain: 1.0 0.09364919275274824 \ttest: 1.0 2.222919645342921\n",
      "retrain  27 :\n",
      "\ttrain: 1.0 0.08689005109300613 \ttest: 1.0 2.20263577250647\n",
      "retrain  28 :\n",
      "\ttrain: 1.0 0.08083112389582406 \ttest: 1.0 2.1835221018371964\n",
      "retrain  29 :\n",
      "\ttrain: 1.0 0.07537956913634589 \ttest: 1.0 2.1654695586449444\n",
      "retrain  30 :\n",
      "\ttrain: 1.0 0.07045735595323008 \ttest: 1.0 2.1483826896072302\n",
      "retrain  31 :\n",
      "\ttrain: 1.0 0.06599852922805385 \ttest: 1.0 2.1321775677867274\n",
      "retrain  32 :\n",
      "\ttrain: 1.0 0.06194704386918727 \ttest: 1.0 2.1167800758709614\n",
      "retrain  33 :\n",
      "\ttrain: 1.0 0.058255037510946045 \ttest: 1.0 2.102124489930052\n",
      "retrain  34 :\n",
      "\ttrain: 1.0 0.05488144334162047 \ttest: 1.0 2.0881523037653094\n",
      "retrain  35 :\n",
      "\ttrain: 1.0 0.05179086882773688 \ttest: 1.0 2.0748112472413647\n",
      "retrain  36 :\n",
      "\ttrain: 1.0 0.048952683801041036 \ttest: 1.0 2.0620544620671675\n",
      "retrain  37 :\n",
      "\ttrain: 1.0 0.04634027451529042 \ttest: 1.0 2.049839806174176\n",
      "retrain  38 :\n",
      "\ttrain: 1.0 0.04393043011890478 \ttest: 1.0 2.0381292637481443\n",
      "retrain  39 :\n",
      "\ttrain: 1.0 0.041702835415489393 \ttest: 1.0 2.026888442548875\n",
      "retrain  40 :\n",
      "\ttrain: 1.0 0.039639649431499585 \ttest: 1.0 2.01608614372539\n",
      "retrain  41 :\n",
      "\ttrain: 1.0 0.037725153635782785 \ttest: 1.0 2.005693992141671\n",
      "retrain  42 :\n",
      "\ttrain: 1.0 0.03594545699137448 \ttest: 1.0 1.9956861174487894\n",
      "retrain  43 :\n",
      "\ttrain: 1.0 0.03428824760892607 \ttest: 1.0 1.986038877906338\n",
      "retrain  44 :\n",
      "\ttrain: 1.0 0.032742582793009956 \ttest: 1.0 1.9767306203703967\n",
      "retrain  45 :\n",
      "\ttrain: 1.0 0.03129871086079515 \ttest: 1.0 1.967741471003558\n",
      "retrain  46 :\n",
      "\ttrain: 1.0 0.029947919367197165 \ttest: 1.0 1.9590531521834702\n",
      "retrain  47 :\n",
      "\ttrain: 1.0 0.02868240536696528 \ttest: 1.0 1.9506488218351756\n",
      "retrain  48 :\n",
      "\ttrain: 1.0 0.02749516413948471 \ttest: 1.0 1.9425129320243069\n",
      "retrain  49 :\n",
      "\ttrain: 1.0 0.026379893440010477 \ttest: 1.0 1.9346311041503417\n",
      "retrain  50 :\n",
      "\ttrain: 1.0 0.025330910855153363 \ttest: 1.0 1.9269900184930404\n",
      "retrain  51 :\n",
      "\ttrain: 1.0 0.024343082256605607 \ttest: 1.0 1.9195773162078038\n",
      "retrain  52 :\n",
      "\ttrain: 1.0 0.023411759685432812 \ttest: 1.0 1.9123815121504844\n",
      "retrain  53 :\n",
      "\ttrain: 1.0 0.022532727275461597 \ttest: 1.0 1.9053919171497573\n",
      "retrain  54 :\n",
      "\ttrain: 1.0 0.021702154050668873 \ttest: 1.0 1.8985985685440885\n",
      "retrain  55 :\n",
      "\ttrain: 1.0 0.020916552617724463 \ttest: 1.0 1.8919921679675502\n",
      "retrain  56 :\n",
      "\ttrain: 1.0 0.02017274292863489 \ttest: 1.0 1.8855640255096706\n",
      "retrain  57 :\n",
      "\ttrain: 1.0 0.019467820415883144 \ttest: 1.0 1.8793060094937968\n",
      "retrain  58 :\n",
      "\ttrain: 1.0 0.01879912790843562 \ttest: 1.0 1.8732105012196327\n",
      "retrain  59 :\n",
      "\ttrain: 1.0 0.01816423082539958 \ttest: 1.0 1.8672703541017666\n",
      "retrain  60 :\n",
      "\ttrain: 1.0 0.017560895218105076 \ttest: 1.0 1.8614788567095775\n",
      "retrain  61 :\n",
      "\ttrain: 1.0 0.01698706829350394 \ttest: 1.0 1.8558296992768277\n",
      "retrain  62 :\n",
      "\ttrain: 1.0 0.016440861104076512 \ttest: 1.0 1.8503169433033535\n",
      "retrain  63 :\n",
      "\ttrain: 1.0 0.015920533133599684 \ttest: 1.0 1.844934993917759\n",
      "retrain  64 :\n",
      "\ttrain: 1.0 0.015424478545523715 \ttest: 1.0 1.8396785747101831\n",
      "retrain  65 :\n",
      "\ttrain: 1.0 0.014951213892452072 \ttest: 1.0 1.8345427047789338\n",
      "retrain  66 :\n",
      "\ttrain: 1.0 0.014499367112244402 \ttest: 1.0 1.8295226777649032\n",
      "retrain  67 :\n",
      "\ttrain: 1.0 0.014067667659323147 \ttest: 1.0 1.8246140426738489\n",
      "retrain  68 :\n",
      "\ttrain: 1.0 0.013654937639493818 \ttest: 1.0 1.819812586309426\n",
      "retrain  69 :\n",
      "\ttrain: 1.0 0.013260083833505108 \ttest: 1.0 1.8151143171597592\n",
      "retrain  70 :\n",
      "\ttrain: 1.0 0.012882090509114664 \ttest: 1.0 1.8105154505977437\n",
      "retrain  71 :\n",
      "\ttrain: 1.0 0.012520012933949776 \ttest: 1.0 1.8060123952705434\n",
      "retrain  72 :\n",
      "\ttrain: 1.0 0.012172971512263608 \ttest: 1.0 1.8016017405671365\n",
      "retrain  73 :\n",
      "\ttrain: 1.0 0.011840146478039375 \ttest: 1.0 1.7972802450645748\n",
      "retrain  74 :\n",
      "\ttrain: 1.0 0.011520773085002507 \ttest: 1.0 1.7930448258639933\n",
      "retrain  75 :\n",
      "\ttrain: 1.0 0.011214137241140794 \ttest: 1.0 1.788892548736626\n",
      "retrain  76 :\n",
      "\ttrain: 1.0 0.010919571541461608 \ttest: 1.0 1.7848206190081792\n",
      "retrain  77 :\n",
      "\ttrain: 1.0 0.010636451658056666 \ttest: 1.0 1.7808263731171292\n",
      "retrain  78 :\n",
      "\ttrain: 1.0 0.010364193051211706 \ttest: 1.0 1.7769072707888998\n",
      "retrain  79 :\n",
      "\ttrain: 1.0 0.010102247969382193 \ttest: 1.0 1.7730608877735667\n",
      "retrain  80 :\n",
      "\ttrain: 1.0 0.009850102709435312 \ttest: 1.0 1.769284909099787\n",
      "retrain  81 :\n",
      "\ttrain: 1.0 0.009607275111701301 \ttest: 1.0 1.7655771228021835\n",
      "retrain  82 :\n",
      "\ttrain: 1.0 0.009373312267141526 \ttest: 1.0 1.7619354140834258\n",
      "retrain  83 :\n",
      "\ttrain: 1.0 0.009147788416375723 \ttest: 1.0 1.7583577598758842\n",
      "retrain  84 :\n",
      "\ttrain: 1.0 0.008930303022458997 \ttest: 1.0 1.7548422237709453\n",
      "retrain  85 :\n",
      "\ttrain: 1.0 0.00872047900119792 \ttest: 1.0 1.7513869512869906\n",
      "retrain  86 :\n",
      "\ttrain: 1.0 0.008517961094474811 \ttest: 1.0 1.7479901654496381\n",
      "retrain  87 :\n",
      "\ttrain: 1.0 0.00832241437353868 \ttest: 1.0 1.7446501626601907\n",
      "retrain  88 :\n",
      "\ttrain: 1.0 0.008133522860542525 \ttest: 1.0 1.7413653088303565\n",
      "retrain  89 :\n",
      "\ttrain: 1.0 0.007950988257781302 \ttest: 1.0 1.7381340357631938\n",
      "retrain  90 :\n",
      "\ttrain: 1.0 0.007774528775130545 \ttest: 1.0 1.7349548377619648\n",
      "retrain  91 :\n",
      "\ttrain: 1.0 0.00760387804711633 \ttest: 1.0 1.731826268450129\n",
      "retrain  92 :\n",
      "\ttrain: 1.0 0.007438784131879572 \ttest: 1.0 1.7287469377871196\n",
      "retrain  93 :\n",
      "\ttrain: 1.0 0.007279008585039637 \ttest: 1.0 1.7257155092658067\n",
      "retrain  94 :\n",
      "\ttrain: 1.0 0.007124325602126858 \ttest: 1.0 1.7227306972787362\n",
      "retrain  95 :\n",
      "\ttrain: 1.0 0.006974521223848509 \ttest: 1.0 1.7197912646412405\n",
      "retrain  96 :\n",
      "\ttrain: 1.0 0.006829392598986678 \ttest: 1.0 1.716896020260514\n",
      "retrain  97 :\n",
      "\ttrain: 1.0 0.006688747300205014 \ttest: 1.0 1.714043816940579\n",
      "retrain  98 :\n",
      "\ttrain: 1.0 0.006552402688472502 \ttest: 1.0 1.7112335493138924\n",
      "retrain  99 :\n",
      "\ttrain: 1.0 0.006420185322199533 \ttest: 1.0 1.7084641518910277\n",
      "retrain  100 :\n",
      "\ttrain: 1.0 0.006291930407530378 \ttest: 1.0 1.7057345972205618\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        37\n",
      "           1    1.00000   1.00000   1.00000        37\n",
      "\n",
      "    accuracy                        1.00000        74\n",
      "   macro avg    1.00000   1.00000   1.00000        74\n",
      "weighted avg    1.00000   1.00000   1.00000        74\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        16\n",
      "           1    1.00000   1.00000   1.00000        16\n",
      "\n",
      "    accuracy                        1.00000        32\n",
      "   macro avg    1.00000   1.00000   1.00000        32\n",
      "weighted avg    1.00000   1.00000   1.00000        32\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 135\n",
      "Average of depth: 1.0592592592592593\n",
      "Number of nodes: 423\n",
      "18 58 1\n",
      "27 91 2\n",
      "34 112 3\n",
      "40 132 4\n",
      "45 151 5\n",
      "51 171 6\n",
      "53 179 7\n",
      "59 201 8\n",
      "65 225 9\n",
      "72 254 10\n",
      "78 272 11\n",
      "84 290 12\n",
      "85 293 13\n",
      "88 298 14\n",
      "89 299 15\n",
      "89 295 16\n",
      "93 309 17\n",
      "94 314 18\n",
      "98 326 19\n",
      "101 335 20\n",
      "101 335 21\n",
      "104 344 22\n",
      "104 334 23\n",
      "106 344 24\n",
      "107 345 25\n",
      "110 354 26\n",
      "112 360 27\n",
      "113 363 28\n",
      "114 366 29\n",
      "115 367 30\n",
      "117 373 31\n",
      "117 373 32\n",
      "118 378 33\n",
      "118 378 34\n",
      "124 398 35\n",
      "127 405 36\n",
      "128 408 37\n",
      "129 409 38\n",
      "131 413 39\n",
      "132 416 40\n",
      "132 416 41\n",
      "133 419 42\n",
      "134 422 43\n",
      "135 425 44\n",
      "136 430 45\n",
      "137 435 46\n",
      "137 433 47\n",
      "137 433 48\n",
      "141 445 49\n",
      "141 445 50\n",
      "143 455 51\n",
      "143 455 52\n",
      "144 460 53\n",
      "144 460 54\n",
      "145 465 55\n",
      "145 463 56\n",
      "145 459 57\n",
      "146 462 58\n",
      "147 467 59\n",
      "147 467 60\n",
      "147 467 61\n",
      "148 470 62\n",
      "148 470 63\n",
      "149 473 64\n",
      "151 483 65\n",
      "152 486 66\n",
      "154 494 67\n",
      "156 502 68\n",
      "158 508 69\n",
      "159 511 70\n",
      "159 511 71\n",
      "159 511 72\n",
      "160 516 73\n",
      "160 512 74\n",
      "163 523 75\n",
      "163 521 76\n",
      "162 512 77\n",
      "162 512 78\n",
      "163 515 79\n",
      "163 515 80\n",
      "165 527 81\n",
      "165 527 82\n",
      "165 527 83\n",
      "165 527 84\n",
      "167 529 85\n",
      "167 529 86\n",
      "168 532 87\n",
      "168 532 88\n",
      "168 530 89\n",
      "169 533 90\n",
      "170 534 91\n",
      "170 534 92\n",
      "170 534 93\n",
      "170 534 94\n",
      "170 534 95\n",
      "172 542 96\n",
      "173 547 97\n",
      "173 547 98\n",
      "173 547 99\n",
      "174 550 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 9.728852641233315 \ttest: 0.78125 11.234478564714518\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 4.796628361169087 \ttest: 0.8125 10.38345555735437\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 2.9445773790032144 \ttest: 0.8125 10.095673728497747\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 1.9935692071726803 \ttest: 0.84375 9.963805577669747\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.4308561961268538 \ttest: 0.84375 9.893750617430225\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 1.0702236365915931 \ttest: 0.84375 9.853620851731065\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 0.8263381721656671 \ttest: 0.84375 9.829849963275683\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.6545970048166648 \ttest: 0.84375 9.81576147485934\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.529674464892878 \ttest: 0.84375 9.807726981644809\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.4363279751073137 \ttest: 0.84375 9.803629186507415\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.36496430625249765 \ttest: 0.84375 9.802165038764736\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.30932245680709747 \ttest: 0.84375 9.802498905614438\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.26518921313471466 \ttest: 0.84375 9.804077126006327\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.22965356692497754 \ttest: 0.84375 9.806523070016024\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.20065722155313473 \ttest: 0.84375 9.80957496296736\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.1767147390482615 \ttest: 0.84375 9.813047620110176\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.15673435808458303 \ttest: 0.84375 9.816808131277782\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.13990039564887988 \ttest: 0.84375 9.820759982152167\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.1255943417031664 \ttest: 0.875 9.82483243735609\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.11334085101695363 \ttest: 0.875 9.828973294109513\n",
      "retrain  21 :\n",
      "\ttrain: 1.0 0.10277010275811266 \ttest: 0.875 9.833143846067681\n",
      "retrain  22 :\n",
      "\ttrain: 1.0 0.09359113206033248 \ttest: 0.875 9.837315326710076\n",
      "retrain  23 :\n",
      "\ttrain: 1.0 0.08557264839558626 \ttest: 0.875 9.841466361567317\n",
      "retrain  24 :\n",
      "\ttrain: 1.0 0.0785290465111681 \ttest: 0.875 9.845581119755789\n",
      "retrain  25 :\n",
      "\ttrain: 1.0 0.07231007313098188 \ttest: 0.875 9.849647957503183\n",
      "retrain  26 :\n",
      "\ttrain: 1.0 0.06679310334195576 \ttest: 0.875 9.853658412483604\n",
      "retrain  27 :\n",
      "\ttrain: 1.0 0.06187730397015155 \ttest: 0.875 9.857606451358162\n",
      "retrain  28 :\n",
      "\ttrain: 1.0 0.05747917774520096 \ttest: 0.875 9.861487902110301\n",
      "retrain  29 :\n",
      "\ttrain: 1.0 0.053529129123231434 \ttest: 0.875 9.865300022619543\n",
      "retrain  30 :\n",
      "\ttrain: 1.0 0.049968793919531344 \ttest: 0.875 9.869041170609787\n",
      "retrain  31 :\n",
      "\ttrain: 1.0 0.04674894554243125 \ttest: 0.875 9.872710549671908\n",
      "retrain  32 :\n",
      "\ttrain: 1.0 0.04382784047902838 \ttest: 0.875 9.876308012819742\n",
      "retrain  33 :\n",
      "\ttrain: 1.0 0.04116990126984432 \ttest: 0.875 9.879833909868209\n",
      "retrain  34 :\n",
      "\ttrain: 1.0 0.038744660876750006 \ttest: 0.875 9.8832889684084\n",
      "retrain  35 :\n",
      "\ttrain: 1.0 0.036525911045013605 \ttest: 0.875 9.886674200694499\n",
      "retrain  36 :\n",
      "\ttrain: 1.0 0.03449101100659134 \ttest: 0.875 9.88999083062453\n",
      "retrain  37 :\n",
      "\ttrain: 1.0 0.03262032306770985 \ttest: 0.875 9.893240236380729\n",
      "retrain  38 :\n",
      "\ttrain: 1.0 0.030896749249485836 \ttest: 0.875 9.896423905328707\n",
      "retrain  39 :\n",
      "\ttrain: 1.0 0.029305348898818983 \ttest: 0.875 9.899543398552067\n",
      "retrain  40 :\n",
      "\ttrain: 1.0 0.027833021552670978 \ttest: 0.875 9.902600322987695\n",
      "retrain  41 :\n",
      "\ttrain: 1.0 0.02646824267827127 \ttest: 0.875 9.905596309575724\n",
      "retrain  42 :\n",
      "\ttrain: 1.0 0.025200842483377214 \ttest: 0.875 9.908532996182092\n",
      "retrain  43 :\n",
      "\ttrain: 1.0 0.02402181998378361 \ttest: 0.875 9.911412014316717\n",
      "retrain  44 :\n",
      "\ttrain: 1.0 0.02292318606944861 \ttest: 0.875 9.914234978875925\n",
      "retrain  45 :\n",
      "\ttrain: 1.0 0.021897830529636453 \ttest: 0.875 9.917003480297673\n",
      "retrain  46 :\n",
      "\ttrain: 1.0 0.020939408958985106 \ttest: 0.875 9.919719078643432\n",
      "retrain  47 :\n",
      "\ttrain: 1.0 0.020042246228849862 \ttest: 0.875 9.922383299218904\n",
      "retrain  48 :\n",
      "\ttrain: 1.0 0.01920125381595752 \ttest: 0.875 9.924997629423416\n",
      "retrain  49 :\n",
      "\ttrain: 1.0 0.01841185876711931 \ttest: 0.875 9.927563516579369\n",
      "retrain  50 :\n",
      "\ttrain: 1.0 0.01766994247040032 \ttest: 0.875 9.930082366541846\n",
      "retrain  51 :\n",
      "\ttrain: 1.0 0.01697178771972436 \ttest: 0.875 9.932555542927634\n",
      "retrain  52 :\n",
      "\ttrain: 1.0 0.016314032816893986 \ttest: 0.875 9.93498436683399\n",
      "retrain  53 :\n",
      "\ttrain: 1.0 0.015693631664512472 \ttest: 0.875 9.937370116942471\n",
      "retrain  54 :\n",
      "\ttrain: 1.0 0.015107818974762273 \ttest: 0.875 9.93971402992338\n",
      "retrain  55 :\n",
      "\ttrain: 1.0 0.014554079859872436 \ttest: 0.875 9.9420173010725\n",
      "retrain  56 :\n",
      "\ttrain: 1.0 0.014030123186281194 \ttest: 0.875 9.944281085124942\n",
      "retrain  57 :\n",
      "\ttrain: 1.0 0.013533858170641271 \ttest: 0.875 9.946506497201558\n",
      "retrain  58 :\n",
      "\ttrain: 1.0 0.01306337377565547 \ttest: 0.875 9.948694613851963\n",
      "retrain  59 :\n",
      "\ttrain: 1.0 0.012616920530251303 \ttest: 0.875 9.950846474165202\n",
      "retrain  60 :\n",
      "\ttrain: 1.0 0.012192894454203594 \ttest: 0.875 9.952963080924828\n",
      "retrain  61 :\n",
      "\ttrain: 1.0 0.01178982281393557 \ttest: 0.875 9.955045401789711\n",
      "retrain  62 :\n",
      "\ttrain: 1.0 0.011406351475430834 \ttest: 0.875 9.957094370485795\n",
      "retrain  63 :\n",
      "\ttrain: 1.0 0.011041233653254455 \ttest: 0.875 9.95911088799699\n",
      "retrain  64 :\n",
      "\ttrain: 1.0 0.010693319882645193 \ttest: 0.875 9.961095823745893\n",
      "retrain  65 :\n",
      "\ttrain: 1.0 0.010361549065355288 \ttest: 0.875 9.963050016757238\n",
      "retrain  66 :\n",
      "\ttrain: 1.0 0.010044940460078738 \ttest: 0.875 9.964974276798404\n",
      "retrain  67 :\n",
      "\ttrain: 1.0 0.009742586505496389 \ttest: 0.875 9.966869385492863\n",
      "retrain  68 :\n",
      "\ttrain: 1.0 0.009453646378654796 \ttest: 0.875 9.968736097403454\n",
      "retrain  69 :\n",
      "\ttrain: 1.0 0.009177340203977018 \ttest: 0.875 9.970575141083309\n",
      "retrain  70 :\n",
      "\ttrain: 1.0 0.008912943839005125 \ttest: 0.875 9.972387220092937\n",
      "retrain  71 :\n",
      "\ttrain: 1.0 0.00865978417226963 \ttest: 0.875 9.974173013982611\n",
      "retrain  72 :\n",
      "\ttrain: 1.0 0.008417234876696773 \ttest: 0.875 9.975933179239604\n",
      "retrain  73 :\n",
      "\ttrain: 1.0 0.008184712568892237 \ttest: 0.875 9.977668350200283\n",
      "retrain  74 :\n",
      "\ttrain: 1.0 0.007961673330638856 \ttest: 0.875 9.97937913992726\n",
      "retrain  75 :\n",
      "\ttrain: 1.0 0.00774760955415215 \ttest: 0.875 9.981066141052148\n",
      "retrain  76 :\n",
      "\ttrain: 1.0 0.0075420470771634 \ttest: 0.875 9.982729926584485\n",
      "retrain  77 :\n",
      "\ttrain: 1.0 0.007344542577842549 \ttest: 0.875 9.984371050687784\n",
      "retrain  78 :\n",
      "\ttrain: 1.0 0.007154681203014665 \ttest: 0.875 9.985990049423439\n",
      "retrain  79 :\n",
      "\ttrain: 1.0 0.006972074406131294 \ttest: 0.875 9.987587441463601\n",
      "retrain  80 :\n",
      "\ttrain: 1.0 0.006796357974093323 \ttest: 0.875 9.989163728773974\n",
      "retrain  81 :\n",
      "\ttrain: 1.0 0.006627190224333258 \ttest: 0.875 9.9907193972676\n",
      "retrain  82 :\n",
      "\ttrain: 1.0 0.006464250355595863 \ttest: 0.875 9.992254917430753\n",
      "retrain  83 :\n",
      "\ttrain: 1.0 0.006307236937644558 \ttest: 0.875 9.993770744921935\n",
      "retrain  84 :\n",
      "\ttrain: 1.0 0.00615586652669717 \ttest: 0.875 9.995267321145128\n",
      "retrain  85 :\n",
      "\ttrain: 1.0 0.006009872394785941 \ttest: 0.875 9.996745073798305\n",
      "retrain  86 :\n",
      "\ttrain: 1.0 0.0058690033624684765 \ttest: 0.875 9.998204417398256\n",
      "retrain  87 :\n",
      "\ttrain: 1.0 0.005733022725405211 \ttest: 0.875 9.99964575378273\n",
      "retrain  88 :\n",
      "\ttrain: 1.0 0.00560170726628686 \ttest: 0.875 10.001069472590917\n",
      "retrain  89 :\n",
      "\ttrain: 1.0 0.005474846344452932 \ttest: 0.875 10.002475951723149\n",
      "retrain  90 :\n",
      "\ttrain: 1.0 0.005352241056306604 \ttest: 0.875 10.003865557780827\n",
      "retrain  91 :\n",
      "\ttrain: 1.0 0.005233703460310884 \ttest: 0.875 10.005238646487406\n",
      "retrain  92 :\n",
      "\ttrain: 1.0 0.0051190558609579585 \ttest: 0.875 10.006595563091299\n",
      "retrain  93 :\n",
      "\ttrain: 1.0 0.005008130146644056 \ttest: 0.875 10.00793664275157\n",
      "retrain  94 :\n",
      "\ttrain: 1.0 0.004900767176867441 \ttest: 0.875 10.009262210907137\n",
      "retrain  95 :\n",
      "\ttrain: 1.0 0.004796816214599238 \ttest: 0.875 10.010572583630278\n",
      "retrain  96 :\n",
      "\ttrain: 1.0 0.004696134400065856 \ttest: 0.875 10.011868067965175\n",
      "retrain  97 :\n",
      "\ttrain: 1.0 0.004598586262529783 \ttest: 0.875 10.013148962252144\n",
      "retrain  98 :\n",
      "\ttrain: 1.0 0.004504043266968445 \ttest: 0.875 10.014415556438244\n",
      "retrain  99 :\n",
      "\ttrain: 1.0 0.004412383392832345 \ttest: 0.875 10.015668132374882\n",
      "retrain  100 :\n",
      "\ttrain: 1.0 0.004323490742316953 \ttest: 0.875 10.016906964103022\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        37\n",
      "           1    1.00000   1.00000   1.00000        37\n",
      "\n",
      "    accuracy                        1.00000        74\n",
      "   macro avg    1.00000   1.00000   1.00000        74\n",
      "weighted avg    1.00000   1.00000   1.00000        74\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.87500   0.87500   0.87500        16\n",
      "           1    0.87500   0.87500   0.87500        16\n",
      "\n",
      "    accuracy                        0.87500        32\n",
      "   macro avg    0.87500   0.87500   0.87500        32\n",
      "weighted avg    0.87500   0.87500   0.87500        32\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 174\n",
      "Average of depth: 1.0804597701149425\n",
      "Number of nodes: 550\n",
      "18 66 1\n",
      "30 114 2\n",
      "40 146 3\n",
      "48 164 4\n",
      "54 182 5\n",
      "58 194 6\n",
      "61 203 7\n",
      "65 211 8\n",
      "66 212 9\n",
      "68 216 10\n",
      "71 225 11\n",
      "71 225 12\n",
      "73 231 13\n",
      "75 241 14\n",
      "78 252 15\n",
      "81 259 16\n",
      "81 257 17\n",
      "82 260 18\n",
      "86 276 19\n",
      "86 274 20\n",
      "87 277 21\n",
      "90 294 22\n",
      "91 295 23\n",
      "92 296 24\n",
      "93 299 25\n",
      "93 297 26\n",
      "93 297 27\n",
      "95 305 28\n",
      "96 308 29\n",
      "99 319 30\n",
      "101 327 31\n",
      "105 343 32\n",
      "107 349 33\n",
      "109 355 34\n",
      "111 361 35\n",
      "111 361 36\n",
      "113 367 37\n",
      "114 370 38\n",
      "117 381 39\n",
      "117 381 40\n",
      "118 384 41\n",
      "119 387 42\n",
      "119 387 43\n",
      "119 387 44\n",
      "119 387 45\n",
      "119 385 46\n",
      "119 385 47\n",
      "119 385 48\n",
      "119 383 49\n",
      "119 383 50\n",
      "119 381 51\n",
      "120 380 52\n",
      "120 380 53\n",
      "121 383 54\n",
      "121 383 55\n",
      "121 381 56\n",
      "121 381 57\n",
      "121 381 58\n",
      "123 387 59\n",
      "124 390 60\n",
      "125 393 61\n",
      "125 393 62\n",
      "126 396 63\n",
      "126 396 64\n",
      "127 399 65\n",
      "127 399 66\n",
      "128 402 67\n",
      "128 402 68\n",
      "128 402 69\n",
      "128 402 70\n",
      "128 402 71\n",
      "130 410 72\n",
      "131 413 73\n",
      "131 413 74\n",
      "131 413 75\n",
      "131 413 76\n",
      "134 428 77\n",
      "135 431 78\n",
      "136 434 79\n",
      "136 434 80\n",
      "136 432 81\n",
      "136 430 82\n",
      "136 430 83\n",
      "136 430 84\n",
      "137 429 85\n",
      "137 429 86\n",
      "137 429 87\n",
      "137 429 88\n",
      "137 429 89\n",
      "137 427 90\n",
      "137 427 91\n",
      "137 427 92\n",
      "137 427 93\n",
      "137 427 94\n",
      "138 432 95\n",
      "138 430 96\n",
      "138 430 97\n",
      "138 430 98\n",
      "138 430 99\n",
      "138 430 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 13.596352969738993 \ttest: 0.875 10.05628020496708\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 6.679038911936267 \ttest: 0.9375 8.042077925941703\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 3.9323089478269724 \ttest: 0.90625 7.157435281624792\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 2.5804982529539493 \ttest: 0.90625 6.688762349734407\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.817715237943935 \ttest: 0.90625 6.407532913419169\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 1.345899287852208 \ttest: 0.90625 6.223582334661096\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 1.0342892136655415 \ttest: 0.90625 6.095486352347835\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.8181101514815716 \ttest: 0.90625 6.001963181336887\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.6622658411546606 \ttest: 0.90625 5.931113998216687\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.5463912826686117 \ttest: 0.90625 5.875832061110211\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.45801276703269755 \ttest: 0.90625 5.831642338838313\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.38914788759376295 \ttest: 0.90625 5.7956023944693005\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.33449965739660437 \ttest: 0.875 5.765706525901308\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.2904438656809741 \ttest: 0.875 5.740545259054094\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.25443498246595286 \ttest: 0.875 5.719101927668822\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.22464401126390593 \ttest: 0.875 5.70062644981321\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.1997303507703843 \ttest: 0.875 5.684554394275635\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.17869390803087157 \ttest: 0.875 5.670453579296205\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.16077679467003536 \ttest: 0.875 5.657987937918997\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.14539651075677437 \ttest: 0.875 5.646892513853738\n",
      "retrain  21 :\n",
      "\ttrain: 1.0 0.13209961802308326 \ttest: 0.875 5.6369558100803445\n",
      "retrain  22 :\n",
      "\ttrain: 1.0 0.12052903936772891 \ttest: 0.875 5.628007102238856\n",
      "retrain  23 :\n",
      "\ttrain: 1.0 0.11040059987804177 \ttest: 0.875 5.619907171214322\n",
      "retrain  24 :\n",
      "\ttrain: 1.0 0.10148594786688092 \ttest: 0.875 5.612541432947601\n",
      "retrain  25 :\n",
      "\ttrain: 1.0 0.09359995223377068 \ttest: 0.875 5.6058147765094315\n",
      "retrain  26 :\n",
      "\ttrain: 1.0 0.0865912872793008 \ttest: 0.875 5.599647637698183\n",
      "retrain  27 :\n",
      "\ttrain: 1.0 0.08033531824934786 \ttest: 0.875 5.593972978501726\n",
      "retrain  28 :\n",
      "\ttrain: 1.0 0.07472866849669789 \ttest: 0.875 5.588733939101589\n",
      "retrain  29 :\n",
      "\ttrain: 1.0 0.06968503007442674 \ttest: 0.875 5.583881995007556\n",
      "retrain  30 :\n",
      "\ttrain: 1.0 0.06513190369861575 \ttest: 0.875 5.579375497672986\n",
      "retrain  31 :\n",
      "\ttrain: 1.0 0.061008040333071493 \ttest: 0.875 5.5751785091511135\n",
      "retrain  32 :\n",
      "\ttrain: 1.0 0.05726141743247262 \ttest: 0.875 5.571259864312841\n",
      "retrain  33 :\n",
      "\ttrain: 1.0 0.053847626189880274 \ttest: 0.875 5.567592410707501\n",
      "retrain  34 :\n",
      "\ttrain: 1.0 0.050728577333463594 \ttest: 0.875 5.5641523882256445\n",
      "retrain  35 :\n",
      "\ttrain: 1.0 0.04787145572401859 \ttest: 0.875 5.560918919621841\n",
      "retrain  36 :\n",
      "\ttrain: 1.0 0.045247870690973246 \ttest: 0.875 5.5578735895761575\n",
      "retrain  37 :\n",
      "\ttrain: 1.0 0.042833161418092056 \ttest: 0.875 5.555000094943306\n",
      "retrain  38 :\n",
      "\ttrain: 1.0 0.04060582594436153 \ttest: 0.875 5.552283952602002\n",
      "retrain  39 :\n",
      "\ttrain: 1.0 0.038547049322959444 \ttest: 0.875 5.5497122541896715\n",
      "retrain  40 :\n",
      "\ttrain: 1.0 0.03664031178225882 \ttest: 0.875 5.547273459217143\n",
      "retrain  41 :\n",
      "\ttrain: 1.0 0.034871061789463115 \ttest: 0.875 5.544957219769374\n",
      "retrain  42 :\n",
      "\ttrain: 1.0 0.03322644204320248 \ttest: 0.875 5.542754231333326\n",
      "retrain  43 :\n",
      "\ttrain: 1.0 0.031695058845596175 \ttest: 0.875 5.54065610534189\n",
      "retrain  44 :\n",
      "\ttrain: 1.0 0.03026678719606332 \ttest: 0.875 5.53865525985051\n",
      "retrain  45 :\n",
      "\ttrain: 1.0 0.028932605434199385 \ttest: 0.875 5.536744825420701\n",
      "retrain  46 :\n",
      "\ttrain: 1.0 0.027684454431368008 \ttest: 0.875 5.5349185638098914\n",
      "retrain  47 :\n",
      "\ttrain: 1.0 0.026515117261114322 \ttest: 0.875 5.5331707974889515\n",
      "retrain  48 :\n",
      "\ttrain: 1.0 0.025418116020796154 \ttest: 0.875 5.531496348349251\n",
      "retrain  49 :\n",
      "\ttrain: 1.0 0.024387623071919738 \ttest: 0.875 5.529890484237324\n",
      "retrain  50 :\n",
      "\ttrain: 1.0 0.02341838444600146 \ttest: 0.875 5.528348872180203\n",
      "retrain  51 :\n",
      "\ttrain: 1.0 0.02250565355061207 \ttest: 0.875 5.5268675373487595\n",
      "retrain  52 :\n",
      "\ttrain: 1.0 0.021645133625428387 \ttest: 0.875 5.525442826957713\n",
      "retrain  53 :\n",
      "\ttrain: 1.0 0.02083292765529545 \ttest: 0.875 5.524071378425921\n",
      "retrain  54 :\n",
      "\ttrain: 1.0 0.020065494658000713 \ttest: 0.875 5.5227500912241\n",
      "retrain  55 :\n",
      "\ttrain: 1.0 0.01933961143774747 \ttest: 0.875 5.5214761019231595\n",
      "retrain  56 :\n",
      "\ttrain: 1.0 0.018652339038353425 \ttest: 0.875 5.520246762028191\n",
      "retrain  57 :\n",
      "\ttrain: 1.0 0.01800099324869717 \ttest: 0.875 5.519059618243307\n",
      "retrain  58 :\n",
      "\ttrain: 1.0 0.017383118611434517 \ttest: 0.875 5.517912394863086\n",
      "retrain  59 :\n",
      "\ttrain: 1.0 0.0167964654681579 \ttest: 0.875 5.516802978028974\n",
      "retrain  60 :\n",
      "\ttrain: 1.0 0.016238969642903493 \ttest: 0.875 5.515729401625043\n",
      "retrain  61 :\n",
      "\ttrain: 1.0 0.015708734423595955 \ttest: 0.875 5.514689834618081\n",
      "retrain  62 :\n",
      "\ttrain: 1.0 0.015204014549576799 \ttest: 0.875 5.513682569672925\n",
      "retrain  63 :\n",
      "\ttrain: 1.0 0.014723201954353109 \ttest: 0.875 5.512706012896192\n",
      "retrain  64 :\n",
      "\ttrain: 1.0 0.014264813047403449 \ttest: 0.875 5.5117586745804825\n",
      "retrain  65 :\n",
      "\ttrain: 1.0 0.013827477348332274 \ttest: 0.875 5.510839160837381\n",
      "retrain  66 :\n",
      "\ttrain: 1.0 0.013409927311731292 \ttest: 0.875 5.50994616602159\n",
      "retrain  67 :\n",
      "\ttrain: 1.0 0.013010989202492756 \ttest: 0.875 5.509078465860554\n",
      "retrain  68 :\n",
      "\ttrain: 1.0 0.012629574899612498 \ttest: 0.875 5.508234911214327\n",
      "retrain  69 :\n",
      "\ttrain: 1.0 0.012264674522202711 \ttest: 0.875 5.50741442239946\n",
      "retrain  70 :\n",
      "\ttrain: 1.0 0.011915349784909886 \ttest: 0.875 5.506615984018501\n",
      "retrain  71 :\n",
      "\ttrain: 1.0 0.011580728001540022 \ttest: 0.875 5.505838640243472\n",
      "retrain  72 :\n",
      "\ttrain: 1.0 0.011259996665709903 \ttest: 0.875 5.505081490507614\n",
      "retrain  73 :\n",
      "\ttrain: 1.0 0.01095239854600741 \ttest: 0.875 5.50434368556491\n",
      "retrain  74 :\n",
      "\ttrain: 1.0 0.010657227240653162 \ttest: 0.875 5.503624423881314\n",
      "retrain  75 :\n",
      "\ttrain: 1.0 0.01037382314317702 \ttest: 0.875 5.502922948325701\n",
      "retrain  76 :\n",
      "\ttrain: 1.0 0.010101569776297316 \ttest: 0.875 5.50223854313193\n",
      "retrain  77 :\n",
      "\ttrain: 1.0 0.009839890456137855 \ttest: 0.875 5.501570531106526\n",
      "retrain  78 :\n",
      "\ttrain: 1.0 0.009588245253237114 \ttest: 0.875 5.500918271059194\n",
      "retrain  79 :\n",
      "\ttrain: 1.0 0.009346128220585257 \ttest: 0.875 5.500281155435729\n",
      "retrain  80 :\n",
      "\ttrain: 1.0 0.0091130648622369 \ttest: 0.875 5.499658608134997\n",
      "retrain  81 :\n",
      "\ttrain: 1.0 0.008888609818956436 \ttest: 0.875 5.499050082493553\n",
      "retrain  82 :\n",
      "\ttrain: 1.0 0.008672344749910972 \ttest: 0.875 5.498455059423097\n",
      "retrain  83 :\n",
      "\ttrain: 1.0 0.008463876391678775 \ttest: 0.875 5.497873045687436\n",
      "retrain  84 :\n",
      "\ttrain: 1.0 0.008262834777828949 \ttest: 0.875 5.4973035723069295\n",
      "retrain  85 :\n",
      "\ttrain: 1.0 0.008068871604084552 \ttest: 0.875 5.496746193079611\n",
      "retrain  86 :\n",
      "\ttrain: 1.0 0.007881658725635395 \ttest: 0.875 5.496200483209098\n",
      "retrain  87 :\n",
      "\ttrain: 1.0 0.007700886774544021 \ttest: 0.875 5.495666038030495\n",
      "retrain  88 :\n",
      "\ttrain: 1.0 0.007526263886411186 \ttest: 0.875 5.495142471826174\n",
      "retrain  89 :\n",
      "\ttrain: 1.0 0.007357514526552318 \ttest: 0.875 5.49462941672417\n",
      "retrain  90 :\n",
      "\ttrain: 1.0 0.007194378406904742 \ttest: 0.875 5.494126521672542\n",
      "retrain  91 :\n",
      "\ttrain: 1.0 0.00703660948574523 \ttest: 0.875 5.493633451483669\n",
      "retrain  92 :\n",
      "\ttrain: 1.0 0.006883975043067347 \ttest: 0.875 5.493149885942978\n",
      "retrain  93 :\n",
      "\ttrain: 1.0 0.006736254825153969 \ttest: 0.875 5.492675518977128\n",
      "retrain  94 :\n",
      "\ttrain: 1.0 0.006593240252494919 \ttest: 0.875 5.49221005787704\n",
      "retrain  95 :\n",
      "\ttrain: 1.0 0.006454733685749981 \ttest: 0.875 5.491753222571644\n",
      "retrain  96 :\n",
      "\ttrain: 1.0 0.006320547744950023 \ttest: 0.875 5.491304744948497\n",
      "retrain  97 :\n",
      "\ttrain: 1.0 0.006190504677573259 \ttest: 0.875 5.4908643682177924\n",
      "retrain  98 :\n",
      "\ttrain: 1.0 0.0060644357715298625 \ttest: 0.875 5.490431846316588\n",
      "retrain  99 :\n",
      "\ttrain: 1.0 0.0059421808094481145 \ttest: 0.875 5.490006943350277\n",
      "retrain  100 :\n",
      "\ttrain: 1.0 0.005823587560975985 \ttest: 0.875 5.4895894330686525\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        37\n",
      "           1    1.00000   1.00000   1.00000        37\n",
      "\n",
      "    accuracy                        1.00000        74\n",
      "   macro avg    1.00000   1.00000   1.00000        74\n",
      "weighted avg    1.00000   1.00000   1.00000        74\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.83333   0.93750   0.88235        16\n",
      "           1    0.92857   0.81250   0.86667        16\n",
      "\n",
      "    accuracy                        0.87500        32\n",
      "   macro avg    0.88095   0.87500   0.87451        32\n",
      "weighted avg    0.88095   0.87500   0.87451        32\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 138\n",
      "Average of depth: 1.0579710144927537\n",
      "Number of nodes: 430\n",
      "16 58 1\n",
      "24 84 2\n",
      "31 115 3\n",
      "39 133 4\n",
      "43 139 5\n",
      "51 167 6\n",
      "58 198 7\n",
      "62 214 8\n",
      "65 227 9\n",
      "66 224 10\n",
      "70 240 11\n",
      "73 245 12\n",
      "75 253 13\n",
      "77 259 14\n",
      "77 259 15\n",
      "78 264 16\n",
      "79 267 17\n",
      "79 267 18\n",
      "80 268 19\n",
      "81 271 20\n",
      "85 279 21\n",
      "87 285 22\n",
      "87 285 23\n",
      "89 289 24\n",
      "92 294 25\n",
      "92 294 26\n",
      "93 297 27\n",
      "93 297 28\n",
      "94 298 29\n",
      "96 306 30\n",
      "97 309 31\n",
      "98 312 32\n",
      "98 312 33\n",
      "99 315 34\n",
      "100 318 35\n",
      "103 327 36\n",
      "104 332 37\n",
      "104 332 38\n",
      "104 332 39\n",
      "104 332 40\n",
      "104 332 41\n",
      "104 332 42\n",
      "106 344 43\n",
      "106 344 44\n",
      "107 347 45\n",
      "108 350 46\n",
      "109 353 47\n",
      "109 351 48\n",
      "109 351 49\n",
      "109 349 50\n",
      "111 355 51\n",
      "111 355 52\n",
      "111 355 53\n",
      "112 360 54\n",
      "112 358 55\n",
      "113 361 56\n",
      "114 364 57\n",
      "116 370 58\n",
      "116 370 59\n",
      "117 371 60\n",
      "117 371 61\n",
      "117 371 62\n",
      "119 381 63\n",
      "119 381 64\n",
      "121 387 65\n",
      "121 387 66\n",
      "122 394 67\n",
      "122 394 68\n",
      "122 394 69\n",
      "123 397 70\n",
      "124 402 71\n",
      "125 403 72\n",
      "125 403 73\n",
      "125 403 74\n",
      "125 403 75\n",
      "126 406 76\n",
      "127 409 77\n",
      "128 412 78\n",
      "128 410 79\n",
      "128 410 80\n",
      "128 410 81\n",
      "128 410 82\n",
      "128 410 83\n",
      "129 413 84\n",
      "130 416 85\n",
      "131 421 86\n",
      "133 429 87\n",
      "133 429 88\n",
      "133 429 89\n",
      "133 429 90\n",
      "133 429 91\n",
      "135 435 92\n",
      "136 438 93\n",
      "136 438 94\n",
      "136 438 95\n",
      "137 443 96\n",
      "138 448 97\n",
      "138 444 98\n",
      "139 449 99\n",
      "139 447 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 14.010269307364105 \ttest: 0.90625 9.526098028654864\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 7.150614611938101 \ttest: 0.90625 7.453950678694834\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 4.340961520391089 \ttest: 0.90625 6.534725244077617\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 2.912604581588616 \ttest: 0.90625 6.0282988579364805\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 2.084195970348376 \ttest: 0.90625 5.708792910369047\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 1.5605279590489163 \ttest: 0.90625 5.488287323305977\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 1.2088052925541395 \ttest: 0.90625 5.326279924199777\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.9616202309866037 \ttest: 0.90625 5.20171014685187\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.7816393036034086 \ttest: 0.90625 5.102587222912441\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.6467842079857671 \ttest: 0.90625 5.021588410555842\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.5433125883760135 \ttest: 0.90625 4.953986168474829\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.4623107546220617 \ttest: 0.90625 4.89658812367327\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.3977967202004691 \ttest: 0.90625 4.847157405385051\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.34563893362630366 \ttest: 0.90625 4.804077579814049\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.3029126422285463 \ttest: 0.90625 4.766149729181581\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.2675025086578987 \ttest: 0.90625 4.732464587727397\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.2378494704955207 \ttest: 0.90625 4.70231917817194\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.21278504639957763 \ttest: 0.90625 4.675160829709378\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.19142026200052034 \ttest: 0.90625 4.6505485987661075\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.17306959734424798 \ttest: 0.90625 4.628126069912004\n",
      "retrain  21 :\n",
      "\ttrain: 1.0 0.15719791762725457 \ttest: 0.90625 4.6076017885828495\n",
      "retrain  22 :\n",
      "\ttrain: 1.0 0.14338280376781448 \ttest: 0.90625 4.588734928113752\n",
      "retrain  23 :\n",
      "\ttrain: 1.0 0.1312873966590903 \ttest: 0.90625 4.571324619680477\n",
      "retrain  24 :\n",
      "\ttrain: 1.0 0.12064054223962471 \ttest: 0.90625 4.555201892332667\n",
      "retrain  25 :\n",
      "\ttrain: 1.0 0.11122208549118426 \ttest: 0.90625 4.540223503620926\n",
      "retrain  26 :\n",
      "\ttrain: 1.0 0.10285184766287905 \ttest: 0.90625 4.526267160185404\n",
      "retrain  27 :\n",
      "\ttrain: 1.0 0.09538127290581097 \ttest: 0.90625 4.5132277742073965\n",
      "retrain  28 :\n",
      "\ttrain: 1.0 0.08868703305645839 \ttest: 0.90625 4.501014501489118\n",
      "retrain  29 :\n",
      "\ttrain: 1.0 0.08266608498900674 \ttest: 0.90625 4.489548376100076\n",
      "retrain  30 :\n",
      "\ttrain: 1.0 0.07723181676696486 \ttest: 0.90625 4.478760405165383\n",
      "retrain  31 :\n",
      "\ttrain: 1.0 0.07231101788309642 \ttest: 0.90625 4.468590022043364\n",
      "retrain  32 :\n",
      "\ttrain: 1.0 0.06784147891861465 \ttest: 0.90625 4.458983821174083\n",
      "retrain  33 :\n",
      "\ttrain: 1.0 0.06377007604260441 \ttest: 0.90625 4.449894516171094\n",
      "retrain  34 :\n",
      "\ttrain: 1.0 0.060051231976513464 \ttest: 0.90625 4.441280076240113\n",
      "retrain  35 :\n",
      "\ttrain: 1.0 0.056645671477737594 \ttest: 0.90625 4.43310300609219\n",
      "retrain  36 :\n",
      "\ttrain: 1.0 0.053519408871324683 \ttest: 0.90625 4.42532974211734\n",
      "retrain  37 :\n",
      "\ttrain: 1.0 0.05064291963655772 \ttest: 0.90625 4.417930143361583\n",
      "retrain  38 :\n",
      "\ttrain: 1.0 0.04799045890786331 \ttest: 0.90625 4.410877060279855\n",
      "retrain  39 :\n",
      "\ttrain: 1.0 0.04553949794904011 \ttest: 0.90625 4.404145967660447\n",
      "retrain  40 :\n",
      "\ttrain: 1.0 0.04327025590113781 \ttest: 0.90625 4.397714650782017\n",
      "retrain  41 :\n",
      "\ttrain: 1.0 0.04116530888877086 \ttest: 0.90625 4.391562935954186\n",
      "retrain  42 :\n",
      "\ttrain: 1.0 0.039209262261986504 \ttest: 0.90625 4.385672458242379\n",
      "retrain  43 :\n",
      "\ttrain: 1.0 0.037388474618543485 \ttest: 0.90625 4.380026460488034\n",
      "retrain  44 :\n",
      "\ttrain: 1.0 0.03569082449232895 \ttest: 0.90625 4.374609618782376\n",
      "retrain  45 :\n",
      "\ttrain: 1.0 0.03410551235483736 \ttest: 0.90625 4.369407890393444\n",
      "retrain  46 :\n",
      "\ttrain: 1.0 0.032622891968510336 \ttest: 0.90625 4.3644083808259575\n",
      "retrain  47 :\n",
      "\ttrain: 1.0 0.031234326236558793 \ttest: 0.90625 4.359599227245738\n",
      "retrain  48 :\n",
      "\ttrain: 1.0 0.029932063576895013 \ttest: 0.90625 4.354969495951\n",
      "retrain  49 :\n",
      "\ttrain: 1.0 0.02870913155630599 \ttest: 0.90625 4.350509091942257\n",
      "retrain  50 :\n",
      "\ttrain: 1.0 0.027559245092128353 \ttest: 0.90625 4.346208678946838\n",
      "retrain  51 :\n",
      "\ttrain: 1.0 0.026476726991123016 \ttest: 0.90625 4.342059608505654\n",
      "retrain  52 :\n",
      "\ttrain: 1.0 0.0254564389712816 \ttest: 0.90625 4.3380538569387985\n",
      "retrain  53 :\n",
      "\ttrain: 1.0 0.024493721619327925 \ttest: 0.90625 4.334183969180778\n",
      "retrain  54 :\n",
      "\ttrain: 1.0 0.023584341988354896 \ttest: 0.90625 4.330443008621947\n",
      "retrain  55 :\n",
      "\ttrain: 1.0 0.0227244477471273 \ttest: 0.90625 4.326824512215147\n",
      "retrain  56 :\n",
      "\ttrain: 1.0 0.02191052696360281 \ttest: 0.90625 4.323322450209692\n",
      "retrain  57 :\n",
      "\ttrain: 1.0 0.021139372746960147 \ttest: 0.90625 4.319931189962086\n",
      "retrain  58 :\n",
      "\ttrain: 1.0 0.020408052090285945 \ttest: 0.90625 4.3166454633468465\n",
      "retrain  59 :\n",
      "\ttrain: 1.0 0.01971387835440384 \ttest: 0.90625 4.313460337353734\n",
      "retrain  60 :\n",
      "\ttrain: 1.0 0.019054386915628135 \ttest: 0.90625 4.3103711875113895\n",
      "retrain  61 :\n",
      "\ttrain: 1.0 0.018427313569312397 \ttest: 0.90625 4.307373673823385\n",
      "retrain  62 :\n",
      "\ttrain: 1.0 0.01783057533923424 \ttest: 0.90625 4.304463718942091\n",
      "retrain  63 :\n",
      "\ttrain: 1.0 0.017262253391975804 \ttest: 0.90625 4.301637488339707\n",
      "retrain  64 :\n",
      "\ttrain: 1.0 0.01672057779704891 \ttest: 0.90625 4.298891372265105\n",
      "retrain  65 :\n",
      "\ttrain: 1.0 0.01620391390882244 \ttest: 0.90625 4.296221969300374\n",
      "retrain  66 :\n",
      "\ttrain: 1.0 0.015710750176362802 \ttest: 0.90625 4.293626071352971\n",
      "retrain  67 :\n",
      "\ttrain: 1.0 0.01523968721294501 \ttest: 0.90625 4.291100649938404\n",
      "retrain  68 :\n",
      "\ttrain: 1.0 0.014789427978928722 \ttest: 0.90625 4.288642843624942\n",
      "retrain  69 :\n",
      "\ttrain: 1.0 0.014358768950503337 \ttest: 0.90625 4.286249946526406\n",
      "retrain  70 :\n",
      "\ttrain: 1.0 0.013946592162970978 \ttest: 0.90625 4.283919397741682\n",
      "retrain  71 :\n",
      "\ttrain: 1.0 0.013551858031159346 \ttest: 0.90625 4.281648771650728\n",
      "retrain  72 :\n",
      "\ttrain: 1.0 0.013173598861573363 \ttest: 0.90625 4.27943576898661\n",
      "retrain  73 :\n",
      "\ttrain: 1.0 0.012810912981290095 \ttest: 0.90625 4.2772782086116345\n",
      "retrain  74 :\n",
      "\ttrain: 1.0 0.012462959417611521 \ttest: 0.90625 4.275174019933214\n",
      "retrain  75 :\n",
      "\ttrain: 1.0 0.012128953070313083 \ttest: 0.90625 4.273121235901788\n",
      "retrain  76 :\n",
      "\ttrain: 1.0 0.011808160325136818 \ttest: 0.90625 4.271117986538995\n",
      "retrain  77 :\n",
      "\ttrain: 1.0 0.01149989506311163 \ttest: 0.90625 4.2691624929495395\n",
      "retrain  78 :\n",
      "\ttrain: 1.0 0.011203515025468356 \ttest: 0.90625 4.267253061774817\n",
      "retrain  79 :\n",
      "\ttrain: 1.0 0.01091841849845284 \ttest: 0.90625 4.265388080050493\n",
      "retrain  80 :\n",
      "\ttrain: 1.0 0.010644041286315607 \ttest: 0.90625 4.2635660104339195\n",
      "retrain  81 :\n",
      "\ttrain: 1.0 0.010379853944246838 \ttest: 0.90625 4.261785386770497\n",
      "retrain  82 :\n",
      "\ttrain: 1.0 0.010125359246094787 \ttest: 0.90625 4.260044809971071\n",
      "retrain  83 :\n",
      "\ttrain: 1.0 0.009880089864408881 \ttest: 0.90625 4.2583429441750305\n",
      "retrain  84 :\n",
      "\ttrain: 1.0 0.009643606242733697 \ttest: 0.90625 4.256678513176106\n",
      "retrain  85 :\n",
      "\ttrain: 1.0 0.0094154946421874 \ttest: 0.90625 4.25505029709003\n",
      "retrain  86 :\n",
      "\ttrain: 1.0 0.009195365346222364 \ttest: 0.90625 4.253457129245006\n",
      "retrain  87 :\n",
      "\ttrain: 1.0 0.008982851009118173 \ttest: 0.90625 4.251897893277712\n",
      "retrain  88 :\n",
      "\ttrain: 1.0 0.00877760513522352 \ttest: 0.90625 4.250371520419067\n",
      "retrain  89 :\n",
      "\ttrain: 1.0 0.00857930067726597 \ttest: 0.90625 4.248876986955346\n",
      "retrain  90 :\n",
      "\ttrain: 1.0 0.008387628743208907 \ttest: 0.90625 4.247413311851468\n",
      "retrain  91 :\n",
      "\ttrain: 1.0 0.00820229740216714 \ttest: 0.90625 4.245979554524464\n",
      "retrain  92 :\n",
      "\ttrain: 1.0 0.008023030580814947 \ttest: 0.90625 4.244574812756061\n",
      "retrain  93 :\n",
      "\ttrain: 1.0 0.007849567042543842 \ttest: 0.90625 4.243198220734299\n",
      "retrain  94 :\n",
      "\ttrain: 1.0 0.007681659442363392 \ttest: 0.90625 4.241848947214907\n",
      "retrain  95 :\n",
      "\ttrain: 1.0 0.007519073451198489 \ttest: 0.90625 4.2405261937939205\n",
      "retrain  96 :\n",
      "\ttrain: 1.0 0.007361586943827462 \ttest: 0.90625 4.239229193283745\n",
      "retrain  97 :\n",
      "\ttrain: 1.0 0.00720898924523671 \ttest: 0.90625 4.2379572081854135\n",
      "retrain  98 :\n",
      "\ttrain: 1.0 0.007061080430644005 \ttest: 0.90625 4.236709529250465\n",
      "retrain  99 :\n",
      "\ttrain: 1.0 0.00691767067487229 \ttest: 0.90625 4.235485474126296\n",
      "retrain  100 :\n",
      "\ttrain: 1.0 0.006778579647142224 \ttest: 0.90625 4.234284386079379\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        37\n",
      "           1    1.00000   1.00000   1.00000        37\n",
      "\n",
      "    accuracy                        1.00000        74\n",
      "   macro avg    1.00000   1.00000   1.00000        74\n",
      "weighted avg    1.00000   1.00000   1.00000        74\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.88235   0.93750   0.90909        16\n",
      "           1    0.93333   0.87500   0.90323        16\n",
      "\n",
      "    accuracy                        0.90625        32\n",
      "   macro avg    0.90784   0.90625   0.90616        32\n",
      "weighted avg    0.90784   0.90625   0.90616        32\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 139\n",
      "Average of depth: 1.0935251798561152\n",
      "Number of nodes: 447\n",
      "19 67 1\n",
      "29 95 2\n",
      "36 124 3\n",
      "42 146 4\n",
      "47 155 5\n",
      "51 163 6\n",
      "56 180 7\n",
      "60 188 8\n",
      "65 209 9\n",
      "69 223 10\n",
      "74 248 11\n",
      "75 247 12\n",
      "78 258 13\n",
      "81 265 14\n",
      "83 269 15\n",
      "84 272 16\n",
      "86 278 17\n",
      "86 276 18\n",
      "87 279 19\n",
      "90 288 20\n",
      "91 291 21\n",
      "95 311 22\n",
      "97 317 23\n",
      "101 333 24\n",
      "101 333 25\n",
      "101 333 26\n",
      "102 332 27\n",
      "106 346 28\n",
      "107 347 29\n",
      "107 347 30\n",
      "107 339 31\n",
      "110 348 32\n",
      "111 349 33\n",
      "111 349 34\n",
      "112 354 35\n",
      "113 357 36\n",
      "115 365 37\n",
      "117 373 38\n",
      "119 383 39\n",
      "119 381 40\n",
      "120 382 41\n",
      "120 382 42\n",
      "121 385 43\n",
      "123 391 44\n",
      "124 394 45\n",
      "124 394 46\n",
      "125 399 47\n",
      "126 404 48\n",
      "126 404 49\n",
      "127 409 50\n",
      "127 409 51\n",
      "128 414 52\n",
      "128 414 53\n",
      "128 414 54\n",
      "129 419 55\n",
      "130 416 56\n",
      "130 416 57\n",
      "130 416 58\n",
      "130 416 59\n",
      "131 417 60\n",
      "131 417 61\n",
      "131 417 62\n",
      "131 417 63\n",
      "131 417 64\n",
      "131 417 65\n",
      "131 417 66\n",
      "132 420 67\n",
      "134 428 68\n",
      "135 431 69\n",
      "137 437 70\n",
      "138 440 71\n",
      "139 441 72\n",
      "140 446 73\n",
      "140 446 74\n",
      "140 446 75\n",
      "140 446 76\n",
      "142 452 77\n",
      "142 452 78\n",
      "142 452 79\n",
      "142 452 80\n",
      "142 452 81\n",
      "142 452 82\n",
      "146 470 83\n",
      "146 470 84\n",
      "146 470 85\n",
      "148 476 86\n",
      "148 476 87\n",
      "149 481 88\n",
      "149 481 89\n",
      "150 484 90\n",
      "152 492 91\n",
      "152 492 92\n",
      "152 492 93\n",
      "152 490 94\n",
      "152 488 95\n",
      "153 493 96\n",
      "153 493 97\n",
      "154 496 98\n",
      "154 496 99\n",
      "155 497 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.9864864864864865 10.962211134616414 \ttest: 0.875 9.13343897793255\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 5.204985708993256 \ttest: 0.875 7.312792664527964\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 3.0741357415565433 \ttest: 0.875 6.566809358210696\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 2.0323196163901054 \ttest: 0.875 6.1792261216896955\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.4395985686470596 \ttest: 0.875 5.948641419345521\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 1.0694444466407482 \ttest: 0.875 5.799211434694302\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 0.823138783631863 \ttest: 0.875 5.696560170952399\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.6514024263813204 \ttest: 0.875 5.623022132942541\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.5272199466329964 \ttest: 0.875 5.568663789085347\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.4347373226000607 \ttest: 0.875 5.527508689282475\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.3641532737288928 \ttest: 0.875 5.495766578984377\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.3091513163853984 \ttest: 0.875 5.4709297553701\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.2655187411780665 \ttest: 0.875 5.451280283952862\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.23036322721365468 \ttest: 0.875 5.435606406044448\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.20164873374478587 \ttest: 0.875 5.423031891881743\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.17791035850273518 \ttest: 0.875 5.412909420180628\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.15807361143257087 \ttest: 0.875 5.404751779161102\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.14133672172844503 \ttest: 0.875 5.39818621322335\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.12709213949943607 \ttest: 0.875 5.392923376037591\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.11487305204685294 \ttest: 0.875 5.388735753423671\n",
      "retrain  21 :\n",
      "\ttrain: 1.0 0.1043162392894031 \ttest: 0.875 5.385442374475124\n",
      "retrain  22 :\n",
      "\ttrain: 1.0 0.09513582623476094 \ttest: 0.875 5.382897788504313\n",
      "retrain  23 :\n",
      "\ttrain: 1.0 0.08710444123115514 \ttest: 0.875 5.380983992006174\n",
      "retrain  24 :\n",
      "\ttrain: 1.0 0.08003949434613475 \ttest: 0.875 5.379604431480414\n",
      "retrain  25 :\n",
      "\ttrain: 1.0 0.07379305161673815 \ttest: 0.875 5.378679490254132\n",
      "retrain  26 :\n",
      "\ttrain: 1.0 0.06824427134974162 \ttest: 0.875 5.378143051612064\n",
      "retrain  27 :\n",
      "\ttrain: 1.0 0.0632936903057485 \ttest: 0.875 5.3779398529374465\n",
      "retrain  28 :\n",
      "\ttrain: 1.0 0.05885886209198733 \ttest: 0.875 5.378023428305816\n",
      "retrain  29 :\n",
      "\ttrain: 1.0 0.054870995328474254 \ttest: 0.875 5.378354493786403\n",
      "retrain  30 :\n",
      "\ttrain: 1.0 0.05127233890652885 \ttest: 0.875 5.378899669282928\n",
      "retrain  31 :\n",
      "\ttrain: 1.0 0.04801413108336633 \ttest: 0.875 5.379630458685947\n",
      "retrain  32 :\n",
      "\ttrain: 1.0 0.04505497807178521 \ttest: 0.875 5.380522430080542\n",
      "retrain  33 :\n",
      "\ttrain: 1.0 0.04235956264773882 \ttest: 0.875 5.381554552194087\n",
      "retrain  34 :\n",
      "\ttrain: 1.0 0.03989760841670667 \ttest: 0.875 5.382708653823739\n",
      "retrain  35 :\n",
      "\ttrain: 1.0 0.03764304366069302 \ttest: 0.875 5.383968980775961\n",
      "retrain  36 :\n",
      "\ttrain: 1.0 0.035573322119807606 \ttest: 0.875 5.385321830658253\n",
      "retrain  37 :\n",
      "\ttrain: 1.0 0.033668868020813085 \ttest: 0.875 5.386755250230272\n",
      "retrain  38 :\n",
      "\ttrain: 1.0 0.03191262011092515 \ttest: 0.875 5.388258783332773\n",
      "retrain  39 :\n",
      "\ttrain: 1.0 0.030289655067239005 \ttest: 0.875 5.389823259943153\n",
      "retrain  40 :\n",
      "\ttrain: 1.0 0.02878687491429044 \ttest: 0.875 5.391440618854556\n",
      "retrain  41 :\n",
      "\ttrain: 1.0 0.027392746342552527 \ttest: 0.875 5.393103757985896\n",
      "retrain  42 :\n",
      "\ttrain: 1.0 0.02609708233170558 \ttest: 0.875 5.394806407508918\n",
      "retrain  43 :\n",
      "\ttrain: 1.0 0.024890858429104802 \ttest: 0.875 5.396543021904306\n",
      "retrain  44 :\n",
      "\ttrain: 1.0 0.023766057552249246 \ttest: 0.875 5.3983086877903474\n",
      "retrain  45 :\n",
      "\ttrain: 1.0 0.022715538375430177 \ttest: 0.875 5.400099044948877\n",
      "retrain  46 :\n",
      "\ttrain: 1.0 0.02173292330080675 \ttest: 0.875 5.401910218437644\n",
      "retrain  47 :\n",
      "\ttrain: 1.0 0.020812502759931142 \ttest: 0.875 5.403738760051162\n",
      "retrain  48 :\n",
      "\ttrain: 1.0 0.019949153186424026 \ttest: 0.875 5.405581597692938\n",
      "retrain  49 :\n",
      "\ttrain: 1.0 0.019138266477041276 \ttest: 0.875 5.407435991466128\n",
      "retrain  50 :\n",
      "\ttrain: 1.0 0.01837568914204176 \ttest: 0.875 5.409299495488236\n",
      "retrain  51 :\n",
      "\ttrain: 1.0 0.017657669656064724 \ttest: 0.875 5.411169924598072\n",
      "retrain  52 :\n",
      "\ttrain: 1.0 0.01698081277277339 \ttest: 0.875 5.41304532525669\n",
      "retrain  53 :\n",
      "\ttrain: 1.0 0.01634203977210727 \ttest: 0.875 5.414923950054035\n",
      "retrain  54 :\n",
      "\ttrain: 1.0 0.015738553777349323 \ttest: 0.875 5.416804235324174\n",
      "retrain  55 :\n",
      "\ttrain: 1.0 0.015167809417622309 \ttest: 0.875 5.418684781447622\n",
      "retrain  56 :\n",
      "\ttrain: 1.0 0.014627486225636737 \ttest: 0.875 5.420564335482382\n",
      "retrain  57 :\n",
      "\ttrain: 1.0 0.01411546525508778 \ttest: 0.875 5.422441775817996\n",
      "retrain  58 :\n",
      "\ttrain: 1.0 0.013629808480684305 \ttest: 0.875 5.424316098591275\n",
      "retrain  59 :\n",
      "\ttrain: 1.0 0.013168740609311044 \ttest: 0.875 5.426186405639513\n",
      "retrain  60 :\n",
      "\ttrain: 1.0 0.01273063298562398 \ttest: 0.875 5.428051893798518\n",
      "retrain  61 :\n",
      "\ttrain: 1.0 0.012313989321351419 \ttest: 0.875 5.4299118453793564\n",
      "retrain  62 :\n",
      "\ttrain: 1.0 0.011917433016260057 \ttest: 0.875 5.431765619680361\n",
      "retrain  63 :\n",
      "\ttrain: 1.0 0.011539695871393238 \ttest: 0.875 5.433612645410127\n",
      "retrain  64 :\n",
      "\ttrain: 1.0 0.011179608022817037 \ttest: 0.875 5.435452413913708\n",
      "retrain  65 :\n",
      "\ttrain: 1.0 0.010836088947554806 \ttest: 0.875 5.437284473108206\n",
      "retrain  66 :\n",
      "\ttrain: 1.0 0.010508139413338034 \ttest: 0.875 5.439108422046017\n",
      "retrain  67 :\n",
      "\ttrain: 1.0 0.010194834260814585 \ttest: 0.875 5.440923906034401\n",
      "retrain  68 :\n",
      "\ttrain: 1.0 0.0098953159214032 \ttest: 0.875 5.442730612248845\n",
      "retrain  69 :\n",
      "\ttrain: 1.0 0.009608788586451653 \ttest: 0.875 5.444528265785532\n",
      "retrain  70 :\n",
      "\ttrain: 1.0 0.009334512954067503 \ttest: 0.875 5.446316626104796\n",
      "retrain  71 :\n",
      "\ttrain: 1.0 0.009071801489213374 \ttest: 0.875 5.4480954838232485\n",
      "retrain  72 :\n",
      "\ttrain: 1.0 0.008820014140616452 \ttest: 0.875 5.449864657817301\n",
      "retrain  73 :\n",
      "\ttrain: 1.0 0.008578554464924096 \ttest: 0.875 5.45162399260516\n",
      "retrain  74 :\n",
      "\ttrain: 1.0 0.008346866114500015 \ttest: 0.875 5.453373355978194\n",
      "retrain  75 :\n",
      "\ttrain: 1.0 0.008124429650433043 \ttest: 0.875 5.455112636855874\n",
      "retrain  76 :\n",
      "\ttrain: 1.0 0.007910759646833996 \ttest: 0.875 5.456841743341462\n",
      "retrain  77 :\n",
      "\ttrain: 1.0 0.007705402056422311 \ttest: 0.875 5.4585606009581\n",
      "retrain  78 :\n",
      "\ttrain: 1.0 0.007507931810831272 \ttest: 0.875 5.46026915104725\n",
      "retrain  79 :\n",
      "\ttrain: 1.0 0.007317950632059127 \ttest: 0.875 5.4619673493134275\n",
      "retrain  80 :\n",
      "\ttrain: 1.0 0.007135085034121148 \ttest: 0.875 5.46365516450082\n",
      "retrain  81 :\n",
      "\ttrain: 1.0 0.006958984496264078 \ttest: 0.875 5.465332577189008\n",
      "retrain  82 :\n",
      "\ttrain: 1.0 0.006789319791131773 \ttest: 0.875 5.466999578696322\n",
      "retrain  83 :\n",
      "\ttrain: 1.0 0.00662578145305735 \ttest: 0.875 5.468656170080582\n",
      "retrain  84 :\n",
      "\ttrain: 1.0 0.006468078373232038 \ttest: 0.875 5.470302361227993\n",
      "retrain  85 :\n",
      "\ttrain: 1.0 0.006315936509892567 \ttest: 0.875 5.471938170021964\n",
      "retrain  86 :\n",
      "\ttrain: 1.0 0.0061690977029003335 \ttest: 0.875 5.473563621584437\n",
      "retrain  87 :\n",
      "\ttrain: 1.0 0.006027318583176266 \ttest: 0.875 5.475178747583017\n",
      "retrain  88 :\n",
      "\ttrain: 1.0 0.005890369568423622 \ttest: 0.875 5.476783585597964\n",
      "retrain  89 :\n",
      "\ttrain: 1.0 0.005758033937430719 \ttest: 0.875 5.478378178543538\n",
      "retrain  90 :\n",
      "\ttrain: 1.0 0.005630106976011247 \ttest: 0.875 5.47996257413891\n",
      "retrain  91 :\n",
      "\ttrain: 1.0 0.005506395188321569 \ttest: 0.875 5.481536824424147\n",
      "retrain  92 :\n",
      "\ttrain: 1.0 0.005386715567902656 \ttest: 0.875 5.483100985317336\n",
      "retrain  93 :\n",
      "\ttrain: 1.0 0.005270894923337923 \ttest: 0.875 5.484655116209186\n",
      "retrain  94 :\n",
      "\ttrain: 1.0 0.005158769253904124 \ttest: 0.875 5.48619927959191\n",
      "retrain  95 :\n",
      "\ttrain: 1.0 0.005050183171027513 \ttest: 0.875 5.4877335407193275\n",
      "retrain  96 :\n",
      "\ttrain: 1.0 0.004944989361748226 \ttest: 0.875 5.489257967295597\n",
      "retrain  97 :\n",
      "\ttrain: 1.0 0.004843048090745393 \ttest: 0.875 5.49077262919006\n",
      "retrain  98 :\n",
      "\ttrain: 1.0 0.004744226737790777 \ttest: 0.875 5.49227759817603\n",
      "retrain  99 :\n",
      "\ttrain: 1.0 0.004648399367781527 \ttest: 0.875 5.493772947691459\n",
      "retrain  100 :\n",
      "\ttrain: 1.0 0.004555446330758073 \ttest: 0.875 5.495258752619698\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        37\n",
      "           1    1.00000   1.00000   1.00000        37\n",
      "\n",
      "    accuracy                        1.00000        74\n",
      "   macro avg    1.00000   1.00000   1.00000        74\n",
      "weighted avg    1.00000   1.00000   1.00000        74\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.92857   0.81250   0.86667        16\n",
      "           1    0.83333   0.93750   0.88235        16\n",
      "\n",
      "    accuracy                        0.87500        32\n",
      "   macro avg    0.88095   0.87500   0.87451        32\n",
      "weighted avg    0.88095   0.87500   0.87451        32\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 155\n",
      "Average of depth: 1.103225806451613\n",
      "Number of nodes: 497\n",
      "17 53 1\n",
      "32 110 2\n",
      "39 133 3\n",
      "44 146 4\n",
      "47 159 5\n",
      "49 167 6\n",
      "52 176 7\n",
      "52 174 8\n",
      "54 178 9\n",
      "58 194 10\n",
      "63 215 11\n",
      "67 229 12\n",
      "69 237 13\n",
      "70 238 14\n",
      "73 247 15\n",
      "77 267 16\n",
      "78 264 17\n",
      "80 272 18\n",
      "83 281 19\n",
      "86 294 20\n",
      "87 297 21\n",
      "88 296 22\n",
      "90 306 23\n",
      "91 309 24\n",
      "94 320 25\n",
      "97 331 26\n",
      "98 332 27\n",
      "99 335 28\n",
      "99 335 29\n",
      "99 333 30\n",
      "100 336 31\n",
      "101 339 32\n",
      "102 342 33\n",
      "102 342 34\n",
      "103 347 35\n",
      "104 352 36\n",
      "105 355 37\n",
      "107 361 38\n",
      "108 364 39\n",
      "110 370 40\n",
      "113 381 41\n",
      "114 384 42\n",
      "114 384 43\n",
      "114 384 44\n",
      "114 382 45\n",
      "114 382 46\n",
      "114 380 47\n",
      "114 380 48\n",
      "114 380 49\n",
      "118 394 50\n",
      "118 394 51\n",
      "118 394 52\n",
      "118 394 53\n",
      "118 394 54\n",
      "120 400 55\n",
      "121 403 56\n",
      "122 406 57\n",
      "122 406 58\n",
      "123 411 59\n",
      "123 407 60\n",
      "124 410 61\n",
      "126 420 62\n",
      "127 423 63\n",
      "127 423 64\n",
      "128 426 65\n",
      "129 429 66\n",
      "129 427 67\n",
      "129 427 68\n",
      "129 427 69\n",
      "129 427 70\n",
      "134 448 71\n",
      "135 451 72\n",
      "139 477 73\n",
      "140 480 74\n",
      "140 476 75\n",
      "141 479 76\n",
      "142 482 77\n",
      "142 480 78\n",
      "142 480 79\n",
      "142 480 80\n",
      "142 480 81\n",
      "142 480 82\n",
      "143 475 83\n",
      "143 475 84\n",
      "143 475 85\n",
      "144 478 86\n",
      "144 478 87\n",
      "144 478 88\n",
      "144 478 89\n",
      "147 487 90\n",
      "147 487 91\n",
      "147 481 92\n",
      "147 481 93\n",
      "147 479 94\n",
      "148 484 95\n",
      "148 484 96\n",
      "148 484 97\n",
      "150 490 98\n",
      "152 500 99\n",
      "152 500 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 10.876190807955659 \ttest: 0.8125 9.548730938542223\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 5.104528610954594 \ttest: 0.78125 8.320761202417698\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 3.012865031007439 \ttest: 0.78125 7.96240630365365\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 1.9983004146495005 \ttest: 0.78125 7.825716602419979\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.4210784546449458 \ttest: 0.78125 7.76633573962334\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 1.059548241446467 \ttest: 0.78125 7.739939568997961\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 0.8180927885035112 \ttest: 0.78125 7.729635677027512\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.649123461469325 \ttest: 0.78125 7.727930078641637\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.5265349777733347 \ttest: 0.78125 7.731107349077742\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.4349717826893257 \ttest: 0.78125 7.737165118168994\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.36491194703170843 \ttest: 0.78125 7.744953420759652\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.31019915152968713 \ttest: 0.78125 7.753778860114185\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.2667144567373875 \ttest: 0.78125 7.763207471970538\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.2316214659669438 \ttest: 0.78125 7.7729599337813795\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.20291802489268218 \ttest: 0.78125 7.782852769948269\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.17916003286532312 \ttest: 0.78125 7.792763840003228\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.15928589530724374 \ttest: 0.78125 7.802611295380123\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.14250188523729385 \ttest: 0.78125 7.812340328535845\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.12820547910370156 \ttest: 0.78125 7.821914597044586\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.11593299257151812 \ttest: 0.78125 7.8313105418745135\n",
      "retrain  21 :\n",
      "\ttrain: 1.0 0.10532312940222624 \ttest: 0.78125 7.840513546967788\n",
      "retrain  22 :\n",
      "\ttrain: 1.0 0.0960911691542641 \ttest: 0.78125 7.849515298517511\n",
      "retrain  23 :\n",
      "\ttrain: 1.0 0.0880104017632187 \ttest: 0.78125 7.858311942392371\n",
      "retrain  24 :\n",
      "\ttrain: 1.0 0.08089858310153662 \ttest: 0.78125 7.866902782392745\n",
      "retrain  25 :\n",
      "\ttrain: 1.0 0.0746079237601815 \ttest: 0.78125 7.8752893509479325\n",
      "retrain  26 :\n",
      "\ttrain: 1.0 0.06901759984193165 \ttest: 0.78125 7.88347473997376\n",
      "retrain  27 :\n",
      "\ttrain: 1.0 0.06402808779183364 \ttest: 0.78125 7.891463115757217\n",
      "retrain  28 :\n",
      "\ttrain: 1.0 0.05955683460457035 \ttest: 0.78125 7.899259365462476\n",
      "retrain  29 :\n",
      "\ttrain: 1.0 0.05553491676293214 \ttest: 0.78125 7.906868838694326\n",
      "retrain  30 :\n",
      "\ttrain: 1.0 0.05190443898162343 \ttest: 0.78125 7.914297158295605\n",
      "retrain  31 :\n",
      "\ttrain: 1.0 0.04861649195763675 \ttest: 0.78125 7.921550081939482\n",
      "retrain  32 :\n",
      "\ttrain: 1.0 0.04562953640712358 \ttest: 0.78125 7.928633401219609\n",
      "retrain  33 :\n",
      "\ttrain: 1.0 0.04290811498790445 \ttest: 0.78125 7.9355528685635734\n",
      "retrain  34 :\n",
      "\ttrain: 1.0 0.04042181846729548 \ttest: 0.78125 7.94231414487429\n",
      "retrain  35 :\n",
      "\ttrain: 1.0 0.038144450539139604 \ttest: 0.78125 7.948922762658291\n",
      "retrain  36 :\n",
      "\ttrain: 1.0 0.0360533489682677 \ttest: 0.78125 7.95538410074489\n",
      "retrain  37 :\n",
      "\ttrain: 1.0 0.03412883059319219 \ttest: 0.78125 7.961703367683947\n",
      "retrain  38 :\n",
      "\ttrain: 1.0 0.03235373509236028 \ttest: 0.78125 7.967885591634475\n",
      "retrain  39 :\n",
      "\ttrain: 1.0 0.03071304798303284 \ttest: 0.78125 7.973935615094151\n",
      "retrain  40 :\n",
      "\ttrain: 1.0 0.029193587551144658 \ttest: 0.78125 7.979858093220802\n",
      "retrain  41 :\n",
      "\ttrain: 1.0 0.027783743648425167 \ttest: 0.78125 7.9856574947982715\n",
      "retrain  42 :\n",
      "\ttrain: 1.0 0.02647325878886534 \ttest: 0.78125 7.991338105126188\n",
      "retrain  43 :\n",
      "\ttrain: 1.0 0.02525304391283164 \ttest: 0.78125 7.996904030285384\n",
      "retrain  44 :\n",
      "\ttrain: 1.0 0.024115022698478508 \ttest: 0.78125 8.002359202361726\n",
      "retrain  45 :\n",
      "\ttrain: 1.0 0.02305199948674354 \ttest: 0.78125 8.007707385311123\n",
      "retrain  46 :\n",
      "\ttrain: 1.0 0.022057546823114622 \ttest: 0.78125 8.012952181225167\n",
      "retrain  47 :\n",
      "\ttrain: 1.0 0.021125909363049596 \ttest: 0.78125 8.018097036815565\n",
      "retrain  48 :\n",
      "\ttrain: 1.0 0.02025192148127042 \ttest: 0.78125 8.02314524998093\n",
      "retrain  49 :\n",
      "\ttrain: 1.0 0.019430936400865094 \ttest: 0.78125 8.028099976354136\n",
      "retrain  50 :\n",
      "\ttrain: 1.0 0.01865876504131688 \ttest: 0.78125 8.032964235755498\n",
      "retrain  51 :\n",
      "\ttrain: 1.0 0.017931623094628715 \ttest: 0.78125 8.037740918497587\n",
      "retrain  52 :\n",
      "\ttrain: 1.0 0.01724608509066724 \ttest: 0.78125 8.04243279150349\n",
      "retrain  53 :\n",
      "\ttrain: 1.0 0.016599044418442413 \ttest: 0.78125 8.04704250421257\n",
      "retrain  54 :\n",
      "\ttrain: 1.0 0.01598767843847384 \ttest: 0.78125 8.051572594257108\n",
      "retrain  55 :\n",
      "\ttrain: 1.0 0.015409417959912068 \ttest: 0.78125 8.056025492900424\n",
      "retrain  56 :\n",
      "\ttrain: 1.0 0.014861920470422042 \ttest: 0.78125 8.060403530232495\n",
      "retrain  57 :\n",
      "\ttrain: 1.0 0.014343046601548403 \ttest: 0.78125 8.064708940123083\n",
      "retrain  58 :\n",
      "\ttrain: 1.0 0.013850839391009371 \ttest: 0.78125 8.068943864935541\n",
      "retrain  59 :\n",
      "\ttrain: 1.0 0.013383505969020847 \ttest: 0.78125 8.073110360006568\n",
      "retrain  60 :\n",
      "\ttrain: 1.0 0.012939401350679804 \ttest: 0.78125 8.077210397898785\n",
      "retrain  61 :\n",
      "\ttrain: 1.0 0.012517014062532385 \ttest: 0.78125 8.081245872434167\n",
      "retrain  62 :\n",
      "\ttrain: 1.0 0.012114953370250262 \ttest: 0.78125 8.085218602516937\n",
      "retrain  63 :\n",
      "\ttrain: 1.0 0.011731937907090019 \ttest: 0.78125 8.08913033575509\n",
      "retrain  64 :\n",
      "\ttrain: 1.0 0.011366785530533195 \ttest: 0.78125 8.092982751889783\n",
      "retrain  65 :\n",
      "\ttrain: 1.0 0.011018404258035144 \ttest: 0.78125 8.096777466041933\n",
      "retrain  66 :\n",
      "\ttrain: 1.0 0.01068578415283416 \ttest: 0.78125 8.100516031785236\n",
      "retrain  67 :\n",
      "\ttrain: 1.0 0.010367990047855793 \ttest: 0.78125 8.104199944054624\n",
      "retrain  68 :\n",
      "\ttrain: 1.0 0.010064155010355999 \ttest: 0.78125 8.10783064189894\n",
      "retrain  69 :\n",
      "\ttrain: 1.0 0.00977347446247318 \ttest: 0.78125 8.111409511086242\n",
      "retrain  70 :\n",
      "\ttrain: 1.0 0.009495200883618191 \ttest: 0.78125 8.114937886569917\n",
      "retrain  71 :\n",
      "\ttrain: 1.0 0.009228639029901117 \ttest: 0.78125 8.118417054823306\n",
      "retrain  72 :\n",
      "\ttrain: 1.0 0.00897314161379026 \ttest: 0.78125 8.12184825605027\n",
      "retrain  73 :\n",
      "\ttrain: 1.0 0.008728105394117378 \ttest: 0.78125 8.12523268627872\n",
      "retrain  74 :\n",
      "\ttrain: 1.0 0.00849296763253711 \ttest: 0.78125 8.128571499343755\n",
      "retrain  75 :\n",
      "\ttrain: 1.0 0.008267202877755432 \ttest: 0.78125 8.131865808766763\n",
      "retrain  76 :\n",
      "\ttrain: 1.0 0.008050320043370737 \ttest: 0.78125 8.135116689536362\n",
      "retrain  77 :\n",
      "\ttrain: 1.0 0.007841859749119714 \ttest: 0.78125 8.138325179796878\n",
      "retrain  78 :\n",
      "\ttrain: 1.0 0.007641391898768696 \ttest: 0.78125 8.141492282449619\n",
      "retrain  79 :\n",
      "\ttrain: 1.0 0.007448513470907466 \ttest: 0.78125 8.144618966671965\n",
      "retrain  80 :\n",
      "\ttrain: 1.0 0.0072628465015468005 \ttest: 0.78125 8.147706169358925\n",
      "retrain  81 :\n",
      "\ttrain: 1.0 0.007084036239741799 \ttest: 0.78125 8.150754796491645\n",
      "retrain  82 :\n",
      "\ttrain: 1.0 0.006911749459504549 \ttest: 0.78125 8.153765724436967\n",
      "retrain  83 :\n",
      "\ttrain: 1.0 0.006745672913067058 \ttest: 0.78125 8.156739801181974\n",
      "retrain  84 :\n",
      "\ttrain: 1.0 0.006585511912141427 \ttest: 0.78125 8.159677847507199\n",
      "retrain  85 :\n",
      "\ttrain: 1.0 0.006430989025225482 \ttest: 0.78125 8.162580658101923\n",
      "retrain  86 :\n",
      "\ttrain: 1.0 0.006281842880241915 \ttest: 0.78125 8.165449002624822\n",
      "retrain  87 :\n",
      "\ttrain: 1.0 0.0061378270628976135 \ttest: 0.78125 8.168283626713011\n",
      "retrain  88 :\n",
      "\ttrain: 1.0 0.005998709102124958 \ttest: 0.78125 8.17108525294234\n",
      "retrain  89 :\n",
      "\ttrain: 1.0 0.005864269534833126 \ttest: 0.78125 8.173854581741626\n",
      "retrain  90 :\n",
      "\ttrain: 1.0 0.0057343010429688245 \ttest: 0.78125 8.17659229226335\n",
      "retrain  91 :\n",
      "\ttrain: 1.0 0.005608607656572512 \ttest: 0.78125 8.179299043213225\n",
      "retrain  92 :\n",
      "\ttrain: 1.0 0.005487004017129392 \ttest: 0.78125 8.181975473640804\n",
      "retrain  93 :\n",
      "\ttrain: 1.0 0.005369314696061944 \ttest: 0.78125 8.184622203693301\n",
      "retrain  94 :\n",
      "\ttrain: 1.0 0.005255373563700807 \ttest: 0.78125 8.187239835334525\n",
      "retrain  95 :\n",
      "\ttrain: 1.0 0.0051450232045092345 \ttest: 0.78125 8.189828953030865\n",
      "retrain  96 :\n",
      "\ttrain: 1.0 0.005038114374729771 \ttest: 0.78125 8.192390124405986\n",
      "retrain  97 :\n",
      "\ttrain: 1.0 0.004934505498975077 \ttest: 0.78125 8.194923900865955\n",
      "retrain  98 :\n",
      "\ttrain: 1.0 0.004834062202601914 \ttest: 0.78125 8.197430818196297\n",
      "retrain  99 :\n",
      "\ttrain: 1.0 0.0047366568769928435 \ttest: 0.78125 8.199911397132459\n",
      "retrain  100 :\n",
      "\ttrain: 1.0 0.004642168275127512 \ttest: 0.78125 8.20236614390506\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        37\n",
      "           1    1.00000   1.00000   1.00000        37\n",
      "\n",
      "    accuracy                        1.00000        74\n",
      "   macro avg    1.00000   1.00000   1.00000        74\n",
      "weighted avg    1.00000   1.00000   1.00000        74\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.76471   0.81250   0.78788        16\n",
      "           1    0.80000   0.75000   0.77419        16\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.78235   0.78125   0.78104        32\n",
      "weighted avg    0.78235   0.78125   0.78104        32\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 152\n",
      "Average of depth: 1.118421052631579\n",
      "Number of nodes: 500\n",
      "23 79 1\n",
      "34 106 2\n",
      "43 139 3\n",
      "47 147 4\n",
      "54 172 5\n",
      "60 192 6\n",
      "65 215 7\n",
      "71 235 8\n",
      "72 238 9\n",
      "75 247 10\n",
      "76 248 11\n",
      "81 265 12\n",
      "84 276 13\n",
      "86 282 14\n",
      "89 289 15\n",
      "90 292 16\n",
      "91 297 17\n",
      "92 298 18\n",
      "93 301 19\n",
      "93 301 20\n",
      "96 314 21\n",
      "99 325 22\n",
      "100 326 23\n",
      "100 324 24\n",
      "100 318 25\n",
      "100 316 26\n",
      "102 320 27\n",
      "102 320 28\n",
      "102 320 29\n",
      "103 323 30\n",
      "105 329 31\n",
      "106 332 32\n",
      "107 335 33\n",
      "108 338 34\n",
      "108 338 35\n",
      "108 338 36\n",
      "110 344 37\n",
      "112 350 38\n",
      "114 358 39\n",
      "114 358 40\n",
      "114 356 41\n",
      "115 363 42\n",
      "115 363 43\n",
      "115 363 44\n",
      "115 363 45\n",
      "115 363 46\n",
      "118 376 47\n",
      "118 376 48\n",
      "119 379 49\n",
      "121 385 50\n",
      "124 398 51\n",
      "124 396 52\n",
      "126 402 53\n",
      "128 408 54\n",
      "130 414 55\n",
      "130 414 56\n",
      "130 414 57\n",
      "131 419 58\n",
      "134 428 59\n",
      "134 426 60\n",
      "134 426 61\n",
      "134 426 62\n",
      "134 426 63\n",
      "134 426 64\n",
      "134 426 65\n",
      "134 426 66\n",
      "134 426 67\n",
      "135 427 68\n",
      "135 427 69\n",
      "135 427 70\n",
      "135 427 71\n",
      "138 438 72\n",
      "138 438 73\n",
      "138 438 74\n",
      "139 447 75\n",
      "141 455 76\n",
      "142 460 77\n",
      "142 454 78\n",
      "142 454 79\n",
      "142 454 80\n",
      "143 457 81\n",
      "143 455 82\n",
      "143 455 83\n",
      "143 455 84\n",
      "143 455 85\n",
      "144 458 86\n",
      "145 461 87\n",
      "145 461 88\n",
      "146 464 89\n",
      "146 462 90\n",
      "147 465 91\n",
      "147 465 92\n",
      "147 465 93\n",
      "147 465 94\n",
      "148 466 95\n",
      "148 466 96\n",
      "150 474 97\n",
      "150 474 98\n",
      "150 474 99\n",
      "151 479 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 11.120038294054654 \ttest: 0.8125 9.923275158445957\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 5.56994585489342 \ttest: 0.8125 8.541478120468115\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 3.4463232046372445 \ttest: 0.8125 8.030246114111863\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 2.35818516910512 \ttest: 0.84375 7.783924519781404\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.7131023017732263 \ttest: 0.84375 7.646702914595987\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 1.296791599502705 \ttest: 0.84375 7.563216093699549\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 1.012504172051441 \ttest: 0.84375 7.509465425395048\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.8101658930554967 \ttest: 0.84375 7.4735751228356975\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.6614189897891078 \ttest: 0.875 7.449082269105984\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.5491484432136076 \ttest: 0.875 7.432207270244607\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.46251705557825695 \ttest: 0.875 7.42061149998713\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.3943966362052738 \ttest: 0.875 7.412780881304423\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.33994931856016875 \ttest: 0.875 7.407698204128087\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.29580334840183753 \ttest: 0.875 7.404658781752848\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.2595542768476717 \ttest: 0.875 7.403161710379962\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.22945264773054047 \ttest: 0.875 7.4028430929552105\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.20420269811973069 \ttest: 0.875 7.4034335939842135\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.1828292977054713 \ttest: 0.875 7.40473064299769\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.16458801526970862 \ttest: 0.875 7.406579751516818\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.14890311493181752 \ttest: 0.875 7.408861665480487\n",
      "retrain  21 :\n",
      "\ttrain: 1.0 0.1353240372847438 \ttest: 0.875 7.411483350379568\n",
      "retrain  22 :\n",
      "\ttrain: 1.0 0.12349435561020117 \ttest: 0.875 7.414371551188317\n",
      "retrain  23 :\n",
      "\ttrain: 1.0 0.11312930145437375 \ttest: 0.875 7.4174681172763\n",
      "retrain  24 :\n",
      "\ttrain: 1.0 0.10399927230292783 \ttest: 0.875 7.42072655929282\n",
      "retrain  25 :\n",
      "\ttrain: 1.0 0.09591757738496748 \ttest: 0.875 7.424109480142052\n",
      "retrain  26 :\n",
      "\ttrain: 1.0 0.08873122716782217 \ttest: 0.875 7.42758663537848\n",
      "retrain  27 :\n",
      "\ttrain: 1.0 0.08231393637822253 \ttest: 0.875 7.431133452985119\n",
      "retrain  28 :\n",
      "\ttrain: 1.0 0.07656075568084286 \ttest: 0.875 7.434729892583441\n",
      "retrain  29 :\n",
      "\ttrain: 1.0 0.0713839147404107 \ttest: 0.875 7.438359558289718\n",
      "retrain  30 :\n",
      "\ttrain: 1.0 0.06670957545533104 \ttest: 0.875 7.442009003089854\n",
      "retrain  31 :\n",
      "\ttrain: 1.0 0.062475275540115977 \ttest: 0.875 7.445667179213034\n",
      "retrain  32 :\n",
      "\ttrain: 1.0 0.05862790038168728 \ttest: 0.875 7.44932500079346\n",
      "retrain  33 :\n",
      "\ttrain: 1.0 0.05512206252004889 \ttest: 0.875 7.45297499360527\n",
      "retrain  34 :\n",
      "\ttrain: 1.0 0.051918798127838145 \ttest: 0.875 7.456611012835429\n",
      "retrain  35 :\n",
      "\ttrain: 1.0 0.04898451183547163 \ttest: 0.875 7.460228014400219\n",
      "retrain  36 :\n",
      "\ttrain: 1.0 0.04629011747559297 \ttest: 0.875 7.463821868679474\n",
      "retrain  37 :\n",
      "\ttrain: 1.0 0.043810334408142824 \ttest: 0.875 7.467389208063897\n",
      "retrain  38 :\n",
      "\ttrain: 1.0 0.04152310816506125 \ttest: 0.875 7.470927301613523\n",
      "retrain  39 :\n",
      "\ttrain: 1.0 0.039409131023638314 \ttest: 0.875 7.474433951572694\n",
      "retrain  40 :\n",
      "\ttrain: 1.0 0.03745144335486624 \ttest: 0.875 7.477907407595879\n",
      "retrain  41 :\n",
      "\ttrain: 1.0 0.03563510061362404 \ttest: 0.875 7.481346295394357\n",
      "retrain  42 :\n",
      "\ttrain: 1.0 0.03394689394429231 \ttest: 0.875 7.4847495571782785\n",
      "retrain  43 :\n",
      "\ttrain: 1.0 0.032375114791233686 \ttest: 0.875 7.488116401787983\n",
      "retrain  44 :\n",
      "\ttrain: 1.0 0.030909355793415957 \ttest: 0.875 7.49144626281663\n",
      "retrain  45 :\n",
      "\ttrain: 1.0 0.02954034172929392 \ttest: 0.875 7.494738763348805\n",
      "retrain  46 :\n",
      "\ttrain: 1.0 0.028259785454239187 \ttest: 0.875 7.497993686196227\n",
      "retrain  47 :\n",
      "\ttrain: 1.0 0.027060264708092203 \ttest: 0.875 7.501210948716306\n",
      "retrain  48 :\n",
      "\ttrain: 1.0 0.02593511641786618 \ttest: 0.875 7.5043905814636656\n",
      "retrain  49 :\n",
      "\ttrain: 1.0 0.02487834572084127 \ttest: 0.875 7.5075327100570775\n",
      "retrain  50 :\n",
      "\ttrain: 1.0 0.023884547417472944 \ttest: 0.875 7.510637539751478\n",
      "retrain  51 :\n",
      "\ttrain: 1.0 0.022948837955851495 \ttest: 0.875 7.513705342291845\n",
      "retrain  52 :\n",
      "\ttrain: 1.0 0.022066796368666486 \ttest: 0.875 7.516736444696813\n",
      "retrain  53 :\n",
      "\ttrain: 1.0 0.021234412844431505 \ttest: 0.875 7.51973121967813\n",
      "retrain  54 :\n",
      "\ttrain: 1.0 0.0204480438286284 \ttest: 0.875 7.522690077449949\n",
      "retrain  55 :\n",
      "\ttrain: 1.0 0.01970437272653827 \ttest: 0.875 7.525613458721406\n",
      "retrain  56 :\n",
      "\ttrain: 1.0 0.01900037542503555 \ttest: 0.875 7.528501828698641\n",
      "retrain  57 :\n",
      "\ttrain: 1.0 0.018333289971274577 \ttest: 0.875 7.531355671949564\n",
      "retrain  58 :\n",
      "\ttrain: 1.0 0.01770058984657571 \ttest: 0.875 7.534175488007193\n",
      "retrain  59 :\n",
      "\ttrain: 1.0 0.017099960357600502 \ttest: 0.875 7.536961787606343\n",
      "retrain  60 :\n",
      "\ttrain: 1.0 0.01652927773705435 \ttest: 0.875 7.53971508946418\n",
      "retrain  61 :\n",
      "\ttrain: 1.0 0.015986590605070992 \ttest: 0.875 7.54243591752847\n",
      "retrain  62 :\n",
      "\ttrain: 1.0 0.015470103492055656 \ttest: 0.875 7.545124798628455\n",
      "retrain  63 :\n",
      "\ttrain: 1.0 0.014978162165682058 \ttest: 0.875 7.547782260472788\n",
      "retrain  64 :\n",
      "\ttrain: 1.0 0.01450924054024108 \ttest: 0.875 7.550408829946886\n",
      "retrain  65 :\n",
      "\ttrain: 1.0 0.014061928976693776 \ttest: 0.875 7.553005031668805\n",
      "retrain  66 :\n",
      "\ttrain: 1.0 0.01363492380745334 \ttest: 0.875 7.55557138676852\n",
      "retrain  67 :\n",
      "\ttrain: 1.0 0.013227017941837598 \ttest: 0.875 7.5581084118603705\n",
      "retrain  68 :\n",
      "\ttrain: 1.0 0.0128370924268843 \ttest: 0.875 7.560616618182564\n",
      "retrain  69 :\n",
      "\ttrain: 1.0 0.012464108854304571 \ttest: 0.875 7.563096510881254\n",
      "retrain  70 :\n",
      "\ttrain: 1.0 0.012107102518176142 \ttest: 0.875 7.56554858841972\n",
      "retrain  71 :\n",
      "\ttrain: 1.0 0.011765176239887633 \ttest: 0.875 7.567973342095772\n",
      "retrain  72 :\n",
      "\ttrain: 1.0 0.011437494787130372 \ttest: 0.875 7.5703712556528595\n",
      "retrain  73 :\n",
      "\ttrain: 1.0 0.011123279822631275 \ttest: 0.875 7.572742804972124\n",
      "retrain  74 :\n",
      "\ttrain: 1.0 0.010821805326033856 \ttest: 0.875 7.5750884578345\n",
      "retrain  75 :\n",
      "\ttrain: 1.0 0.010532393439035882 \ttest: 0.875 7.577408673743228\n",
      "retrain  76 :\n",
      "\ttrain: 1.0 0.01025441068972354 \ttest: 0.875 7.579703903798527\n",
      "retrain  77 :\n",
      "\ttrain: 1.0 0.009987264557128082 \ttest: 0.875 7.5819745906171745\n",
      "retrain  78 :\n",
      "\ttrain: 1.0 0.009730400341472493 \ttest: 0.875 7.5842211682906955\n",
      "retrain  79 :\n",
      "\ttrain: 1.0 0.009483298309463815 \ttest: 0.875 7.586444062376689\n",
      "retrain  80 :\n",
      "\ttrain: 1.0 0.009245471087394838 \ttest: 0.875 7.58864368991848\n",
      "retrain  81 :\n",
      "\ttrain: 1.0 0.009016461277811173 \ttest: 0.875 7.590820459488963\n",
      "retrain  82 :\n",
      "\ttrain: 1.0 0.008795839278132076 \ttest: 0.875 7.592974771254978\n",
      "retrain  83 :\n",
      "\ttrain: 1.0 0.008583201281932119 \ttest: 0.875 7.595107017059048\n",
      "retrain  84 :\n",
      "\ttrain: 1.0 0.008378167445637151 \ttest: 0.875 7.597217580515723\n",
      "retrain  85 :\n",
      "\ttrain: 1.0 0.008180380205195471 \ttest: 0.875 7.599306837120118\n",
      "retrain  86 :\n",
      "\ttrain: 1.0 0.007989502728885732 \ttest: 0.875 7.601375154366503\n",
      "retrain  87 :\n",
      "\ttrain: 1.0 0.007805217493841251 \ttest: 0.875 7.603422891875189\n",
      "retrain  88 :\n",
      "\ttrain: 1.0 0.007627224975128926 \ttest: 0.875 7.605450401526031\n",
      "retrain  89 :\n",
      "\ttrain: 1.0 0.007455242437339976 \ttest: 0.875 7.607458027597213\n",
      "retrain  90 :\n",
      "\ttrain: 1.0 0.007289002819644862 \ttest: 0.875 7.60944610690809\n",
      "retrain  91 :\n",
      "\ttrain: 1.0 0.007128253706153062 \ttest: 0.875 7.611414968965034\n",
      "retrain  92 :\n",
      "\ttrain: 1.0 0.006972756374209008 \ttest: 0.875 7.613364936109383\n",
      "retrain  93 :\n",
      "\ttrain: 1.0 0.006822284913963762 \ttest: 0.875 7.615296323666705\n",
      "retrain  94 :\n",
      "\ttrain: 1.0 0.006676625413194328 \ttest: 0.875 7.617209440096679\n",
      "retrain  95 :\n",
      "\ttrain: 1.0 0.006535575201909881 \ttest: 0.875 7.619104587143055\n",
      "retrain  96 :\n",
      "\ttrain: 1.0 0.006398942151791723 \ttest: 0.875 7.62098205998313\n",
      "retrain  97 :\n",
      "\ttrain: 1.0 0.006266544025970758 \ttest: 0.875 7.622842147376342\n",
      "retrain  98 :\n",
      "\ttrain: 1.0 0.006138207875055823 \ttest: 0.875 7.62468513181163\n",
      "retrain  99 :\n",
      "\ttrain: 1.0 0.006013769475695956 \ttest: 0.875 7.62651128965322\n",
      "retrain  100 :\n",
      "\ttrain: 1.0 0.005893072808291067 \ttest: 0.875 7.628320891284577\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        37\n",
      "           1    1.00000   1.00000   1.00000        37\n",
      "\n",
      "    accuracy                        1.00000        74\n",
      "   macro avg    1.00000   1.00000   1.00000        74\n",
      "weighted avg    1.00000   1.00000   1.00000        74\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.80000   1.00000   0.88889        16\n",
      "           1    1.00000   0.75000   0.85714        16\n",
      "\n",
      "    accuracy                        0.87500        32\n",
      "   macro avg    0.90000   0.87500   0.87302        32\n",
      "weighted avg    0.90000   0.87500   0.87302        32\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 151\n",
      "Average of depth: 1.086092715231788\n",
      "Number of nodes: 479\n",
      "18 72 1\n",
      "31 115 2\n",
      "37 135 3\n",
      "46 160 4\n",
      "49 171 5\n",
      "56 188 6\n",
      "58 196 7\n",
      "59 201 8\n",
      "65 225 9\n",
      "68 232 10\n",
      "71 243 11\n",
      "71 235 12\n",
      "75 247 13\n",
      "78 256 14\n",
      "78 254 15\n",
      "80 262 16\n",
      "80 262 17\n",
      "82 268 18\n",
      "84 276 19\n",
      "88 286 20\n",
      "89 289 21\n",
      "89 287 22\n",
      "91 295 23\n",
      "92 302 24\n",
      "95 307 25\n",
      "97 313 26\n",
      "100 322 27\n",
      "101 325 28\n",
      "104 334 29\n",
      "105 337 30\n",
      "107 345 31\n",
      "108 344 32\n",
      "111 355 33\n",
      "111 355 34\n",
      "114 364 35\n",
      "114 356 36\n",
      "114 356 37\n",
      "117 365 38\n",
      "118 368 39\n",
      "121 379 40\n",
      "121 379 41\n",
      "122 382 42\n",
      "125 393 43\n",
      "125 393 44\n",
      "127 401 45\n",
      "127 401 46\n",
      "130 414 47\n",
      "130 414 48\n",
      "131 417 49\n",
      "132 422 50\n",
      "134 436 51\n",
      "134 436 52\n",
      "136 444 53\n",
      "136 442 54\n",
      "137 447 55\n",
      "139 455 56\n",
      "141 455 57\n",
      "141 453 58\n",
      "141 453 59\n",
      "143 459 60\n",
      "143 459 61\n",
      "143 459 62\n",
      "143 459 63\n",
      "144 464 64\n",
      "144 462 65\n",
      "146 472 66\n",
      "148 480 67\n",
      "148 480 68\n",
      "148 480 69\n",
      "148 480 70\n",
      "149 485 71\n",
      "149 481 72\n",
      "149 481 73\n",
      "150 484 74\n",
      "150 484 75\n",
      "150 484 76\n",
      "150 484 77\n",
      "150 482 78\n",
      "150 482 79\n",
      "151 485 80\n",
      "151 485 81\n",
      "151 485 82\n",
      "151 485 83\n",
      "152 488 84\n",
      "152 488 85\n",
      "152 488 86\n",
      "153 491 87\n",
      "154 492 88\n",
      "154 492 89\n",
      "154 492 90\n",
      "154 492 91\n",
      "155 497 92\n",
      "156 500 93\n",
      "156 498 94\n",
      "157 501 95\n",
      "158 504 96\n",
      "159 511 97\n",
      "159 511 98\n",
      "159 511 99\n",
      "159 509 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 10.486715267795006 \ttest: 0.84375 10.219061141910599\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 5.00636454269069 \ttest: 0.84375 8.689192664613518\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 2.99594077562656 \ttest: 0.84375 7.986485156584703\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 2.0015973938472125 \ttest: 0.84375 7.5582404350861445\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.4287947181283074 \ttest: 0.84375 7.257862871093725\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 1.067566708769506 \ttest: 0.875 7.030030254620893\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 0.8254023659520162 \ttest: 0.875 6.848605145054735\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.6555601897549976 \ttest: 0.875 6.69927248185038\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.5321591463899288 \ttest: 0.875 6.573358494064584\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.4398910740811526 \ttest: 0.875 6.465215770966402\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.3692319983496524 \ttest: 0.875 6.370966626852374\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.31401157316799305 \ttest: 0.875 6.287837974666365\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.27009577418764913 \ttest: 0.875 6.213781950266856\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.23463494667028867 \ttest: 0.875 6.147246368988793\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.20561596425603917 \ttest: 0.875 6.0870290895659895\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.18158581907792012 \ttest: 0.875 6.032181954910502\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.16147571456356424 \ttest: 0.875 5.981945352323383\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.14448608795425896 \ttest: 0.875 5.935702399457279\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.13000966487610288 \ttest: 0.875 5.892946111622122\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.11757887175303729 \ttest: 0.875 5.853255390551787\n",
      "retrain  21 :\n",
      "\ttrain: 1.0 0.10682920987460223 \ttest: 0.875 5.81627714991277\n",
      "retrain  22 :\n",
      "\ttrain: 1.0 0.09747330666393106 \ttest: 0.875 5.781712798482877\n",
      "retrain  23 :\n",
      "\ttrain: 1.0 0.08928224351046167 \ttest: 0.875 5.7493078744045985\n",
      "retrain  24 :\n",
      "\ttrain: 1.0 0.08207192740545935 \ttest: 0.875 5.718843995208759\n",
      "retrain  25 :\n",
      "\ttrain: 1.0 0.07569301336401797 \ttest: 0.875 5.690132534659471\n",
      "retrain  26 :\n",
      "\ttrain: 1.0 0.07002336243201678 \ttest: 0.875 5.663009604288021\n",
      "retrain  27 :\n",
      "\ttrain: 1.0 0.06496233427703058 \ttest: 0.875 5.637332032523025\n",
      "retrain  28 :\n",
      "\ttrain: 1.0 0.060426423400517786 \ttest: 0.875 5.612974114978222\n",
      "retrain  29 :\n",
      "\ttrain: 1.0 0.05634589056486328 \ttest: 0.875 5.58982496685989\n",
      "retrain  30 :\n",
      "\ttrain: 1.0 0.052662139155228195 \ttest: 0.875 5.567786349870692\n",
      "retrain  31 :\n",
      "\ttrain: 1.0 0.04932565462930299 \ttest: 0.875 5.5467708762456915\n",
      "retrain  32 :\n",
      "\ttrain: 1.0 0.046294373518749495 \ttest: 0.875 5.5267005149215045\n",
      "retrain  33 :\n",
      "\ttrain: 1.0 0.04353238294221401 \ttest: 0.875 5.507505341548524\n",
      "retrain  34 :\n",
      "\ttrain: 1.0 0.041008876486039764 \ttest: 0.9375 5.489122486663522\n",
      "retrain  35 :\n",
      "\ttrain: 1.0 0.03869731045776381 \ttest: 0.9375 5.471495245941304\n",
      "retrain  36 :\n",
      "\ttrain: 1.0 0.036574717873144855 \ttest: 0.9375 5.454572323819163\n",
      "retrain  37 :\n",
      "\ttrain: 1.0 0.034621147453540474 \ttest: 0.9375 5.438307187499165\n",
      "retrain  38 :\n",
      "\ttrain: 1.0 0.03281920233480712 \ttest: 0.9375 5.422657512789421\n",
      "retrain  39 :\n",
      "\ttrain: 1.0 0.031153658791953358 \ttest: 0.9375 5.407584706747553\n",
      "retrain  40 :\n",
      "\ttrain: 1.0 0.029611149544230185 \ttest: 0.9375 5.3930534948599895\n",
      "retrain  41 :\n",
      "\ttrain: 1.0 0.028179899468090693 \ttest: 0.9375 5.379031562696655\n",
      "retrain  42 :\n",
      "\ttrain: 1.0 0.026849504061111494 \ttest: 0.9375 5.3654892437473345\n",
      "retrain  43 :\n",
      "\ttrain: 1.0 0.025610742952143307 \ttest: 0.9375 5.352399246569289\n",
      "retrain  44 :\n",
      "\ttrain: 1.0 0.02445542227717442 \ttest: 0.9375 5.339736415528252\n",
      "retrain  45 :\n",
      "\ttrain: 1.0 0.02337624093745204 \ttest: 0.9375 5.327477520353368\n",
      "retrain  46 :\n",
      "\ttrain: 1.0 0.022366676701787207 \ttest: 0.9375 5.315601070494082\n",
      "retrain  47 :\n",
      "\ttrain: 1.0 0.0214208888655755 \ttest: 0.9375 5.304087150897901\n",
      "retrain  48 :\n",
      "\ttrain: 1.0 0.020533634778074912 \ttest: 0.9375 5.292917276348678\n",
      "retrain  49 :\n",
      "\ttrain: 1.0 0.019700198029846863 \ttest: 0.9375 5.2820742619367\n",
      "retrain  50 :\n",
      "\ttrain: 1.0 0.01891632647929175 \ttest: 0.9375 5.271542107591324\n",
      "retrain  51 :\n",
      "\ttrain: 1.0 0.018178178610436288 \ttest: 0.9375 5.261305894907054\n",
      "retrain  52 :\n",
      "\ttrain: 1.0 0.017482276968718184 \ttest: 0.9375 5.251351694745832\n",
      "retrain  53 :\n",
      "\ttrain: 1.0 0.01682546762930187 \ttest: 0.9375 5.241666484310303\n",
      "retrain  54 :\n",
      "\ttrain: 1.0 0.016204884822722886 \ttest: 0.9375 5.232238072561827\n",
      "retrain  55 :\n",
      "\ttrain: 1.0 0.015617919982710579 \ttest: 0.9375 5.223055033008726\n",
      "retrain  56 :\n",
      "\ttrain: 1.0 0.015062194596663027 \ttest: 0.9375 5.214106643019235\n",
      "retrain  57 :\n",
      "\ttrain: 1.0 0.014535536335045144 \ttest: 0.9375 5.2053828289235415\n",
      "retrain  58 :\n",
      "\ttrain: 1.0 0.014035958015621897 \ttest: 0.9375 5.19687411626341\n",
      "retrain  59 :\n",
      "\ttrain: 1.0 0.013561639024867204 \ttest: 0.9375 5.1885715846284475\n",
      "retrain  60 :\n",
      "\ttrain: 1.0 0.01311090887447364 \ttest: 0.9375 5.1804668265874945\n",
      "retrain  61 :\n",
      "\ttrain: 1.0 0.012682232617541147 \ttest: 0.9375 5.172551910283318\n",
      "retrain  62 :\n",
      "\ttrain: 1.0 0.012274197888298291 \ttest: 0.9375 5.164819345310595\n",
      "retrain  63 :\n",
      "\ttrain: 1.0 0.011885503362366195 \ttest: 0.9375 5.1572620515418235\n",
      "retrain  64 :\n",
      "\ttrain: 1.0 0.01151494846264682 \ttest: 0.9375 5.149873330604793\n",
      "retrain  65 :\n",
      "\ttrain: 1.0 0.011161424159745324 \ttest: 0.9375 5.142646839749041\n",
      "retrain  66 :\n",
      "\ttrain: 1.0 0.010823904736117603 \ttest: 0.9375 5.135576567868327\n",
      "retrain  67 :\n",
      "\ttrain: 1.0 0.010501440400437323 \ttest: 0.9375 5.128656813471925\n",
      "retrain  68 :\n",
      "\ttrain: 1.0 0.010193150653478355 \ttest: 0.9375 5.121882164420231\n",
      "retrain  69 :\n",
      "\ttrain: 1.0 0.009898218319497089 \ttest: 0.9375 5.115247479259987\n",
      "retrain  70 :\n",
      "\ttrain: 1.0 0.009615884168005205 \ttest: 0.9375 5.1087478700119915\n",
      "retrain  71 :\n",
      "\ttrain: 1.0 0.009345442060213946 \ttest: 0.9375 5.102378686279464\n",
      "retrain  72 :\n",
      "\ttrain: 1.0 0.009086234562538077 \ttest: 0.9375 5.096135500558968\n",
      "retrain  73 :\n",
      "\ttrain: 1.0 0.008837648976559196 \ttest: 0.9375 5.090014094647682\n",
      "retrain  74 :\n",
      "\ttrain: 1.0 0.008599113740925313 \ttest: 0.9375 5.084010447051628\n",
      "retrain  75 :\n",
      "\ttrain: 1.0 0.008370095165941328 \ttest: 0.9375 5.078120721308798\n",
      "retrain  76 :\n",
      "\ttrain: 1.0 0.00815009446619767 \ttest: 0.9375 5.072341255149619\n",
      "retrain  77 :\n",
      "\ttrain: 1.0 0.007938645060587885 \ttest: 0.9375 5.066668550424675\n",
      "retrain  78 :\n",
      "\ttrain: 1.0 0.0077353101125626645 \ttest: 0.9375 5.061099263736252\n",
      "retrain  79 :\n",
      "\ttrain: 1.0 0.007539680286527885 \ttest: 0.9375 5.05563019771631\n",
      "retrain  80 :\n",
      "\ttrain: 1.0 0.007351371698974676 \ttest: 0.9375 5.050258292898745\n",
      "retrain  81 :\n",
      "\ttrain: 1.0 0.007170024045285165 \ttest: 0.9375 5.044980620138683\n",
      "retrain  82 :\n",
      "\ttrain: 1.0 0.006995298885226984 \ttest: 0.9375 5.0397943735357575\n",
      "retrain  83 :\n",
      "\ttrain: 1.0 0.006826878071974289 \ttest: 0.9375 5.034696863822221\n",
      "retrain  84 :\n",
      "\ttrain: 1.0 0.006664462311100691 \ttest: 0.9375 5.029685512180224\n",
      "retrain  85 :\n",
      "\ttrain: 1.0 0.006507769837413053 \ttest: 0.9375 5.0247578444556735\n",
      "retrain  86 :\n",
      "\ttrain: 1.0 0.006356535198751192 \ttest: 0.9375 5.019911485738947\n",
      "retrain  87 :\n",
      "\ttrain: 1.0 0.0062105081369947055 \ttest: 0.9375 5.0151441552852605\n",
      "retrain  88 :\n",
      "\ttrain: 1.0 0.006069452557507001 \ttest: 0.9375 5.010453661749789\n",
      "retrain  89 :\n",
      "\ttrain: 1.0 0.005933145579126028 \ttest: 0.9375 5.005837898714738\n",
      "retrain  90 :\n",
      "\ttrain: 1.0 0.005801376657593899 \ttest: 0.9375 5.001294840487422\n",
      "retrain  91 :\n",
      "\ttrain: 1.0 0.0056739467760143405 \ttest: 0.9375 4.996822538150155\n",
      "retrain  92 :\n",
      "\ttrain: 1.0 0.00555066769654999 \ttest: 0.9375 4.992419115844297\n",
      "retrain  93 :\n",
      "\ttrain: 1.0 0.00543136126812648 \ttest: 0.9375 4.988082767272185\n",
      "retrain  94 :\n",
      "\ttrain: 1.0 0.0053158587854080265 \ttest: 0.9375 4.983811752402029\n",
      "retrain  95 :\n",
      "\ttrain: 1.0 0.005204000394754552 \ttest: 0.9375 4.979604394361964\n",
      "retrain  96 :\n",
      "\ttrain: 1.0 0.005095634543269332 \ttest: 0.9375 4.975459076510544\n",
      "retrain  97 :\n",
      "\ttrain: 1.0 0.004990617467405093 \ttest: 0.9375 4.971374239671978\n",
      "retrain  98 :\n",
      "\ttrain: 1.0 0.004888812717918193 \ttest: 0.9375 4.967348379525184\n",
      "retrain  99 :\n",
      "\ttrain: 1.0 0.0047900907182507136 \ttest: 0.9375 4.9633800441367235\n",
      "retrain  100 :\n",
      "\ttrain: 1.0 0.004694328353681388 \ttest: 0.9375 4.95946783162827\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        37\n",
      "           1    1.00000   1.00000   1.00000        37\n",
      "\n",
      "    accuracy                        1.00000        74\n",
      "   macro avg    1.00000   1.00000   1.00000        74\n",
      "weighted avg    1.00000   1.00000   1.00000        74\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.93750   0.93750   0.93750        16\n",
      "           1    0.93750   0.93750   0.93750        16\n",
      "\n",
      "    accuracy                        0.93750        32\n",
      "   macro avg    0.93750   0.93750   0.93750        32\n",
      "weighted avg    0.93750   0.93750   0.93750        32\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 159\n",
      "Average of depth: 1.10062893081761\n",
      "Number of nodes: 509\n",
      "23 77 1\n",
      "38 132 2\n",
      "42 144 3\n",
      "49 161 4\n",
      "54 172 5\n",
      "57 181 6\n",
      "60 190 7\n",
      "61 191 8\n",
      "63 197 9\n",
      "63 197 10\n",
      "68 210 11\n",
      "70 220 12\n",
      "70 220 13\n",
      "71 223 14\n",
      "75 233 15\n",
      "79 247 16\n",
      "79 247 17\n",
      "81 253 18\n",
      "87 275 19\n",
      "90 286 20\n",
      "91 293 21\n",
      "92 296 22\n",
      "92 296 23\n",
      "94 310 24\n",
      "94 306 25\n",
      "94 306 26\n",
      "94 306 27\n",
      "94 304 28\n",
      "96 312 29\n",
      "97 311 30\n",
      "99 315 31\n",
      "100 318 32\n",
      "103 329 33\n",
      "103 327 34\n",
      "105 327 35\n",
      "106 332 36\n",
      "109 341 37\n",
      "109 341 38\n",
      "109 341 39\n",
      "109 341 40\n",
      "112 352 41\n",
      "114 362 42\n",
      "114 362 43\n",
      "115 365 44\n",
      "115 365 45\n",
      "116 370 46\n",
      "116 370 47\n",
      "119 383 48\n",
      "120 384 49\n",
      "122 390 50\n",
      "124 402 51\n",
      "124 402 52\n",
      "124 402 53\n",
      "126 406 54\n",
      "126 404 55\n",
      "127 409 56\n",
      "127 409 57\n",
      "127 409 58\n",
      "128 410 59\n",
      "128 404 60\n",
      "128 404 61\n",
      "130 414 62\n",
      "130 410 63\n",
      "130 408 64\n",
      "131 411 65\n",
      "131 411 66\n",
      "131 411 67\n",
      "131 409 68\n",
      "132 412 69\n",
      "133 413 70\n",
      "133 413 71\n",
      "133 413 72\n",
      "133 411 73\n",
      "133 411 74\n",
      "134 416 75\n",
      "137 427 76\n",
      "137 427 77\n",
      "138 428 78\n",
      "138 428 79\n",
      "139 435 80\n",
      "140 438 81\n",
      "141 441 82\n",
      "141 441 83\n",
      "141 441 84\n",
      "141 441 85\n",
      "141 439 86\n",
      "141 439 87\n",
      "142 442 88\n",
      "142 442 89\n",
      "142 442 90\n",
      "142 442 91\n",
      "142 442 92\n",
      "142 442 93\n",
      "142 442 94\n",
      "142 442 95\n",
      "142 442 96\n",
      "142 442 97\n",
      "142 442 98\n",
      "142 442 99\n",
      "142 442 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 13.089804501131109 \ttest: 1.0 9.183538465822622\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 6.638045535799366 \ttest: 1.0 6.709980549474344\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 4.048223288777526 \ttest: 1.0 5.462986223577836\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 2.7306533609227444 \ttest: 1.0 4.705469692793178\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.9635781394977319 \ttest: 1.0 4.1922609382776335\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 1.476928531007842 \ttest: 1.0 3.81915357160981\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 1.1490274447723812 \ttest: 1.0 3.5342126401566984\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.9178974531234319 \ttest: 1.0 3.3085623943542286\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.7491133952586634 \ttest: 1.0 3.1248189654770107\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.6222746522925416 \ttest: 1.0 2.9718649178521748\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.5246636430720968 \ttest: 1.0 2.8422444377174276\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.4480207505388679 \ttest: 1.0 2.730761838158233\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.38679604632475184 \ttest: 1.0 2.6336800692625753\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.33715136788586786 \ttest: 1.0 2.54823891060468\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.29636578502165034 \ttest: 1.0 2.4723530331660992\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.2624683247261585 \ttest: 1.0 2.4044159932690894\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.23400390242986618 \ttest: 1.0 2.3431690844108264\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.2098800387571138 \ttest: 1.0 2.2876112498533354\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.1892640477448383 \ttest: 1.0 2.236935758700617\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.17151259420554466 \ttest: 1.0 2.1904847789468636\n",
      "retrain  21 :\n",
      "\ttrain: 1.0 0.1561224998187855 \ttest: 1.0 2.1477161930754605\n",
      "retrain  22 :\n",
      "\ttrain: 1.0 0.14269579229865179 \ttest: 1.0 2.1081789596202674\n",
      "retrain  23 :\n",
      "\ttrain: 1.0 0.13091448336484054 \ttest: 1.0 2.071494549798966\n",
      "retrain  24 :\n",
      "\ttrain: 1.0 0.1205221066834466 \ttest: 1.0 2.0373427742956505\n",
      "retrain  25 :\n",
      "\ttrain: 1.0 0.11131002679942521 \ttest: 1.0 2.0054508302749157\n",
      "retrain  26 :\n",
      "\ttrain: 1.0 0.10310716381083962 \ttest: 1.0 1.9755847428411693\n",
      "retrain  27 :\n",
      "\ttrain: 1.0 0.09577219590991776 \ttest: 1.0 1.9475426092470822\n",
      "retrain  28 :\n",
      "\ttrain: 1.0 0.08918758141618438 \ttest: 1.0 1.9211492160100891\n",
      "retrain  29 :\n",
      "\ttrain: 1.0 0.08325493199157238 \ttest: 1.0 1.8962517126947183\n",
      "retrain  30 :\n",
      "\ttrain: 1.0 0.0778913998211127 \ttest: 1.0 1.8727161069566702\n",
      "retrain  31 :\n",
      "\ttrain: 1.0 0.07302683316030292 \ttest: 1.0 1.8504244037087163\n",
      "retrain  32 :\n",
      "\ttrain: 1.0 0.06860151946800093 \ttest: 1.0 1.8292722537623374\n",
      "retrain  33 :\n",
      "\ttrain: 1.0 0.0645643817281368 \ttest: 1.0 1.8091670086341876\n",
      "retrain  34 :\n",
      "\ttrain: 1.0 0.06087152711358884 \ttest: 1.0 1.7900261015515042\n",
      "retrain  35 :\n",
      "\ttrain: 1.0 0.057485071656878134 \ttest: 1.0 1.771775692250581\n",
      "retrain  36 :\n",
      "\ttrain: 1.0 0.05437218266947386 \ttest: 1.0 1.7543495264901403\n",
      "retrain  37 :\n",
      "\ttrain: 1.0 0.05150429410213556 \ttest: 1.0 1.7376879714026943\n",
      "retrain  38 :\n",
      "\ttrain: 1.0 0.04885646013096141 \ttest: 1.0 1.7217371956773664\n",
      "retrain  39 :\n",
      "\ttrain: 1.0 0.0464068198862589 \ttest: 1.0 1.706448469685326\n",
      "retrain  40 :\n",
      "\ttrain: 1.0 0.0441361520568554 \ttest: 1.0 1.6917775654479617\n",
      "retrain  41 :\n",
      "\ttrain: 1.0 0.0420275025650706 \ttest: 1.0 1.6776842401219225\n",
      "retrain  42 :\n",
      "\ttrain: 1.0 0.040065871955129985 \ttest: 1.0 1.6641317896680892\n",
      "retrain  43 :\n",
      "\ttrain: 1.0 0.038237951818268154 \ttest: 1.0 1.6510866617593947\n",
      "retrain  44 :\n",
      "\ttrain: 1.0 0.036531901674553266 \ttest: 1.0 1.6385181188983464\n",
      "retrain  45 :\n",
      "\ttrain: 1.0 0.03493715938119943 \ttest: 1.0 1.6263979442607681\n",
      "retrain  46 :\n",
      "\ttrain: 1.0 0.033444279442334336 \ttest: 1.0 1.6147001840356285\n",
      "retrain  47 :\n",
      "\ttrain: 1.0 0.03204479463327761 \ttest: 1.0 1.6034009210522129\n",
      "retrain  48 :\n",
      "\ttrain: 1.0 0.030731097182208816 \ttest: 1.0 1.592478075322088\n",
      "retrain  49 :\n",
      "\ttrain: 1.0 0.029496336418657038 \ttest: 1.0 1.5819112278110408\n",
      "retrain  50 :\n",
      "\ttrain: 1.0 0.028334330336136627 \ttest: 1.0 1.5716814643241541\n",
      "retrain  51 :\n",
      "\ttrain: 1.0 0.027239488952251124 \ttest: 1.0 1.5617712368582362\n",
      "retrain  52 :\n",
      "\ttrain: 1.0 0.026206747704500342 \ttest: 1.0 1.5521642401680489\n",
      "retrain  53 :\n",
      "\ttrain: 1.0 0.025231509410117745 \ttest: 1.0 1.542845301620519\n",
      "retrain  54 :\n",
      "\ttrain: 1.0 0.024309593556311578 \ttest: 1.0 1.5338002826860753\n",
      "retrain  55 :\n",
      "\ttrain: 1.0 0.023437191883357744 \ttest: 1.0 1.525015990647622\n",
      "retrain  56 :\n",
      "\ttrain: 1.0 0.022610829385089553 \ttest: 1.0 1.5164800993031229\n",
      "retrain  57 :\n",
      "\ttrain: 1.0 0.021827329985803064 \ttest: 1.0 1.5081810776032838\n",
      "retrain  58 :\n",
      "\ttrain: 1.0 0.021083786264536296 \ttest: 1.0 1.5001081253065633\n",
      "retrain  59 :\n",
      "\ttrain: 1.0 0.020377532691163266 \ttest: 1.0 1.492251114853667\n",
      "retrain  60 :\n",
      "\ttrain: 1.0 0.01970612191706073 \ttest: 1.0 1.4846005387661827\n",
      "retrain  61 :\n",
      "\ttrain: 1.0 0.019067303728917625 \ttest: 1.0 1.477147461961928\n",
      "retrain  62 :\n",
      "\ttrain: 1.0 0.018459006329721427 \ttest: 1.0 1.4698834784551056\n",
      "retrain  63 :\n",
      "\ttrain: 1.0 0.017879319657832973 \ttest: 1.0 1.4628006719744562\n",
      "retrain  64 :\n",
      "\ttrain: 1.0 0.017326480494793545 \ttest: 1.0 1.4558915800888395\n",
      "retrain  65 :\n",
      "\ttrain: 1.0 0.01679885914626659 \ttest: 1.0 1.449149161478364\n",
      "retrain  66 :\n",
      "\ttrain: 1.0 0.016294947509282426 \ttest: 1.0 1.4425667660314723\n",
      "retrain  67 :\n",
      "\ttrain: 1.0 0.015813348363519053 \ttest: 1.0 1.4361381074851423\n",
      "retrain  68 :\n",
      "\ttrain: 1.0 0.015352765745386753 \ttest: 1.0 1.4298572383574566\n",
      "retrain  69 :\n",
      "\ttrain: 1.0 0.014911996281733987 \ttest: 1.0 1.4237185269497785\n",
      "retrain  70 :\n",
      "\ttrain: 1.0 0.01448992137551724 \ttest: 1.0 1.4177166362203337\n",
      "retrain  71 :\n",
      "\ttrain: 1.0 0.014085500149162244 \ttest: 1.0 1.411846504352496\n",
      "retrain  72 :\n",
      "\ttrain: 1.0 0.013697763062905197 \ttest: 1.0 1.4061033268599985\n",
      "retrain  73 :\n",
      "\ttrain: 1.0 0.013325806135412581 \ttest: 1.0 1.4004825400879457\n",
      "retrain  74 :\n",
      "\ttrain: 1.0 0.012968785702660596 \ttest: 1.0 1.3949798059832297\n",
      "retrain  75 :\n",
      "\ttrain: 1.0 0.01262591365860212 \ttest: 1.0 1.3895909980208898\n",
      "retrain  76 :\n",
      "\ttrain: 1.0 0.012296453127720921 \ttest: 1.0 1.3843121881845197\n",
      "retrain  77 :\n",
      "\ttrain: 1.0 0.011979714525307307 \ttest: 1.0 1.3791396349089773\n",
      "retrain  78 :\n",
      "\ttrain: 1.0 0.011675051966299897 \ttest: 1.0 1.374069771902743\n",
      "retrain  79 :\n",
      "\ttrain: 1.0 0.011381859987928549 \ttest: 1.0 1.3690991977753366\n",
      "retrain  80 :\n",
      "\ttrain: 1.0 0.011099570555240098 \ttest: 1.0 1.364224666402356\n",
      "retrain  81 :\n",
      "\ttrain: 1.0 0.010827650321972684 \ttest: 1.0 1.3594430779671665\n",
      "retrain  82 :\n",
      "\ttrain: 1.0 0.010565598122218564 \ttest: 1.0 1.354751470623946\n",
      "retrain  83 :\n",
      "\ttrain: 1.0 0.010312942670940003 \ttest: 1.0 1.3501470127319646\n",
      "retrain  84 :\n",
      "\ttrain: 1.0 0.010069240453717637 \ttest: 1.0 1.3456269956155467\n",
      "retrain  85 :\n",
      "\ttrain: 1.0 0.009834073788158969 \ttest: 1.0 1.3411888268083119\n",
      "retrain  86 :\n",
      "\ttrain: 1.0 0.009607049041207273 \ttest: 1.0 1.3368300237439852\n",
      "retrain  87 :\n",
      "\ttrain: 1.0 0.009387794988199223 \ttest: 1.0 1.3325482078594106\n",
      "retrain  88 :\n",
      "\ttrain: 1.0 0.009175961300946884 \ttest: 1.0 1.3283410990784157\n",
      "retrain  89 :\n",
      "\ttrain: 1.0 0.008971217153389915 \ttest: 1.0 1.3242065106478724\n",
      "retrain  90 :\n",
      "\ttrain: 1.0 0.008773249934493507 \ttest: 1.0 1.320142344299783\n",
      "retrain  91 :\n",
      "\ttrain: 1.0 0.00858176405907616 \ttest: 1.0 1.3161465857153765\n",
      "retrain  92 :\n",
      "\ttrain: 1.0 0.008396479868151167 \ttest: 1.0 1.3122173002692912\n",
      "retrain  93 :\n",
      "\ttrain: 1.0 0.00821713261116951 \ttest: 1.0 1.3083526290336573\n",
      "retrain  94 :\n",
      "\ttrain: 1.0 0.008043471503272719 \ttest: 1.0 1.3045507850235956\n",
      "retrain  95 :\n",
      "\ttrain: 1.0 0.00787525885130876 \ttest: 1.0 1.3008100496671249\n",
      "retrain  96 :\n",
      "\ttrain: 1.0 0.007712269242942664 \ttest: 1.0 1.2971287694838503\n",
      "retrain  97 :\n",
      "\ttrain: 1.0 0.007554288793714229 \ttest: 1.0 1.293505352958019\n",
      "retrain  98 :\n",
      "\ttrain: 1.0 0.007401114447361225 \ttest: 1.0 1.2899382675926931\n",
      "retrain  99 :\n",
      "\ttrain: 1.0 0.007252553325149187 \ttest: 1.0 1.2864260371327976\n",
      "retrain  100 :\n",
      "\ttrain: 1.0 0.007108422120325892 \ttest: 1.0 1.2829672389457483\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        37\n",
      "           1    1.00000   1.00000   1.00000        37\n",
      "\n",
      "    accuracy                        1.00000        74\n",
      "   macro avg    1.00000   1.00000   1.00000        74\n",
      "weighted avg    1.00000   1.00000   1.00000        74\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        16\n",
      "           1    1.00000   1.00000   1.00000        16\n",
      "\n",
      "    accuracy                        1.00000        32\n",
      "   macro avg    1.00000   1.00000   1.00000        32\n",
      "weighted avg    1.00000   1.00000   1.00000        32\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 142\n",
      "Average of depth: 1.0492957746478873\n",
      "Number of nodes: 442\n",
      "18 66 1\n",
      "28 102 2\n",
      "38 138 3\n",
      "44 150 4\n",
      "49 167 5\n",
      "54 188 6\n",
      "61 221 7\n",
      "63 221 8\n",
      "68 242 9\n",
      "69 239 10\n",
      "72 244 11\n",
      "75 251 12\n",
      "75 249 13\n",
      "77 259 14\n",
      "78 262 15\n",
      "83 275 16\n",
      "86 278 17\n",
      "88 284 18\n",
      "92 292 19\n",
      "93 295 20\n",
      "93 295 21\n",
      "94 298 22\n",
      "96 306 23\n",
      "99 315 24\n",
      "100 318 25\n",
      "101 321 26\n",
      "102 324 27\n",
      "103 325 28\n",
      "103 325 29\n",
      "105 331 30\n",
      "108 342 31\n",
      "111 357 32\n",
      "113 359 33\n",
      "116 372 34\n",
      "117 375 35\n",
      "121 387 36\n",
      "123 395 37\n",
      "125 405 38\n",
      "126 408 39\n",
      "126 408 40\n",
      "127 417 41\n",
      "127 417 42\n",
      "127 415 43\n",
      "129 415 44\n",
      "130 418 45\n",
      "130 414 46\n",
      "132 420 47\n",
      "132 418 48\n",
      "134 422 49\n",
      "134 422 50\n",
      "134 422 51\n",
      "135 425 52\n",
      "136 428 53\n",
      "136 426 54\n",
      "138 432 55\n",
      "138 428 56\n",
      "139 431 57\n",
      "139 431 58\n",
      "140 434 59\n",
      "140 434 60\n",
      "140 434 61\n",
      "141 437 62\n",
      "142 440 63\n",
      "143 443 64\n",
      "144 448 65\n",
      "144 448 66\n",
      "145 453 67\n",
      "145 451 68\n",
      "146 454 69\n",
      "146 454 70\n",
      "146 454 71\n",
      "149 465 72\n",
      "149 465 73\n",
      "149 465 74\n",
      "149 465 75\n",
      "149 465 76\n",
      "149 465 77\n",
      "149 463 78\n",
      "150 468 79\n",
      "150 466 80\n",
      "150 466 81\n",
      "150 466 82\n",
      "150 466 83\n",
      "152 474 84\n",
      "153 479 85\n",
      "153 477 86\n",
      "153 477 87\n",
      "153 477 88\n",
      "154 480 89\n",
      "154 480 90\n",
      "154 480 91\n",
      "157 493 92\n",
      "157 493 93\n",
      "157 493 94\n",
      "157 493 95\n",
      "158 496 96\n",
      "159 497 97\n",
      "160 500 98\n",
      "161 507 99\n",
      "161 507 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 9.852868217847716 \ttest: 0.8125 10.335183374164549\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 4.401445197913287 \ttest: 0.8125 9.238801207651175\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 2.499873383133664 \ttest: 0.8125 8.89625827230604\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 1.6070341187242037 \ttest: 0.8125 8.758739317169859\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.1150779292768307 \ttest: 0.8125 8.6984202685703\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 0.8157352546551634 \ttest: 0.8125 8.6733554760627\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 0.6206600083720684 \ttest: 0.8125 8.666431799886379\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.48687991174173617 \ttest: 0.8125 8.669577962318924\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.3914080725602418 \ttest: 0.8125 8.678582312777229\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.3210497433338393 \ttest: 0.8125 8.691080813214079\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.26780308028185157 \ttest: 0.8125 8.705672925178309\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.22659511771166815 \ttest: 0.8125 8.72149470088832\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.1940890480941445 \ttest: 0.8125 8.737996860134484\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.1680205425869089 \ttest: 0.8125 8.754822415876426\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.14681131892532762 \ttest: 0.8125 8.771735873414348\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.12933533284331317 \ttest: 0.78125 8.788580609425317\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.1147725612720349 \ttest: 0.78125 8.805252348797275\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.10251488960954505 \ttest: 0.78125 8.821682189917503\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.09210397756978413 \ttest: 0.78125 8.837825478767254\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.08318930048409197 \ttest: 0.78125 8.853654366414018\n",
      "retrain  21 :\n",
      "\ttrain: 1.0 0.0754992356861103 \ttest: 0.78125 8.869152742789009\n",
      "retrain  22 :\n",
      "\ttrain: 1.0 0.0688207713354578 \ttest: 0.78125 8.88431273613675\n",
      "retrain  23 :\n",
      "\ttrain: 1.0 0.06298502880707246 \ttest: 0.78125 8.899132263319494\n",
      "retrain  24 :\n",
      "\ttrain: 1.0 0.057856776139822784 \ttest: 0.78125 8.91361329704251\n",
      "retrain  25 :\n",
      "\ttrain: 1.0 0.05332672683217757 \ttest: 0.78125 8.927760629281826\n",
      "retrain  26 :\n",
      "\ttrain: 1.0 0.04930581204740289 \ttest: 0.78125 8.941580982550612\n",
      "retrain  27 :\n",
      "\ttrain: 1.0 0.045720870493825894 \ttest: 0.78125 8.95508236775686\n",
      "retrain  28 :\n",
      "\ttrain: 1.0 0.04251136986441666 \ttest: 0.78125 8.968273618611914\n",
      "retrain  29 :\n",
      "\ttrain: 1.0 0.039626887829715254 \ttest: 0.78125 8.981164053538963\n",
      "retrain  30 :\n",
      "\ttrain: 1.0 0.03702515849073887 \ttest: 0.78125 8.99376323034754\n",
      "retrain  31 :\n",
      "\ttrain: 1.0 0.03467054413253885 \ttest: 0.78125 9.00608076883073\n",
      "retrain  32 :\n",
      "\ttrain: 1.0 0.032532829934831496 \ttest: 0.78125 9.018126223355305\n",
      "retrain  33 :\n",
      "\ttrain: 1.0 0.030586266128813443 \ttest: 0.78125 9.02990899239907\n",
      "retrain  34 :\n",
      "\ttrain: 1.0 0.028808801342387922 \ttest: 0.78125 9.041438255474313\n",
      "retrain  35 :\n",
      "\ttrain: 1.0 0.02718146483582671 \ttest: 0.78125 9.052722930384652\n",
      "retrain  36 :\n",
      "\ttrain: 1.0 0.02568786555158213 \ttest: 0.78125 9.063771645583305\n",
      "retrain  37 :\n",
      "\ttrain: 1.0 0.024313783456005128 \ttest: 0.78125 9.074592723732312\n",
      "retrain  38 :\n",
      "\ttrain: 1.0 0.02304683428218223 \ttest: 0.78125 9.085194173542666\n",
      "retrain  39 :\n",
      "\ttrain: 1.0 0.021876193015972815 \ttest: 0.78125 9.095583687701993\n",
      "retrain  40 :\n",
      "\ttrain: 1.0 0.02079236467381169 \ttest: 0.78125 9.105768645237776\n",
      "retrain  41 :\n",
      "\ttrain: 1.0 0.01978699336779467 \ttest: 0.78125 9.11575611706977\n",
      "retrain  42 :\n",
      "\ttrain: 1.0 0.018852702534001016 \ttest: 0.78125 9.125552873810564\n",
      "retrain  43 :\n",
      "\ttrain: 1.0 0.017982960654723944 \ttest: 0.78125 9.135165395103696\n",
      "retrain  44 :\n",
      "\ttrain: 1.0 0.01717196793778883 \ttest: 0.78125 9.144599879963826\n",
      "retrain  45 :\n",
      "\ttrain: 1.0 0.01641456030313051 \ttest: 0.78125 9.153862257716291\n",
      "retrain  46 :\n",
      "\ttrain: 1.0 0.015706127725498537 \ttest: 0.78125 9.162958199234845\n",
      "retrain  47 :\n",
      "\ttrain: 1.0 0.015042544535555463 \ttest: 0.78125 9.171893128253725\n",
      "retrain  48 :\n",
      "\ttrain: 1.0 0.014420109722248095 \ttest: 0.78125 9.18067223258948\n",
      "retrain  49 :\n",
      "\ttrain: 1.0 0.013835495631905772 \ttest: 0.78125 9.189300475153168\n",
      "retrain  50 :\n",
      "\ttrain: 1.0 0.013285703743004803 \ttest: 0.78125 9.197782604668182\n",
      "retrain  51 :\n",
      "\ttrain: 1.0 0.012768026424517123 \ttest: 0.78125 9.206123166035399\n",
      "retrain  52 :\n",
      "\ttrain: 1.0 0.012280013771533477 \ttest: 0.78125 9.214326510307421\n",
      "retrain  53 :\n",
      "\ttrain: 1.0 0.011819444763207558 \ttest: 0.78125 9.222396804248993\n",
      "retrain  54 :\n",
      "\ttrain: 1.0 0.01138430211188305 \ttest: 0.78125 9.23033803947219\n",
      "retrain  55 :\n",
      "\ttrain: 1.0 0.010972750273952156 \ttest: 0.78125 9.238154041143567\n",
      "retrain  56 :\n",
      "\ttrain: 1.0 0.010583116176816915 \ttest: 0.78125 9.245848476266817\n",
      "retrain  57 :\n",
      "\ttrain: 1.0 0.010213872285675253 \ttest: 0.78125 9.253424861549256\n",
      "retrain  58 :\n",
      "\ttrain: 1.0 0.009863621691428737 \ttest: 0.78125 9.260886570863644\n",
      "retrain  59 :\n",
      "\ttrain: 1.0 0.009531084948971686 \ttest: 0.78125 9.268236842319212\n",
      "retrain  60 :\n",
      "\ttrain: 1.0 0.009215088435202289 \ttest: 0.78125 9.275478784957267\n",
      "retrain  61 :\n",
      "\ttrain: 1.0 0.008914554029700207 \ttest: 0.78125 9.282615385087672\n",
      "retrain  62 :\n",
      "\ttrain: 1.0 0.008628489949270233 \ttest: 0.78125 9.289649512282903\n",
      "retrain  63 :\n",
      "\ttrain: 1.0 0.008355982591380656 \ttest: 0.78125 9.296583925046537\n",
      "retrain  64 :\n",
      "\ttrain: 1.0 0.008096189261678304 \ttest: 0.78125 9.30342127617286\n",
      "retrain  65 :\n",
      "\ttrain: 1.0 0.00784833167785196 \ttest: 0.78125 9.310164117813974\n",
      "retrain  66 :\n",
      "\ttrain: 1.0 0.007611690156648402 \ttest: 0.78125 9.31681490627024\n",
      "retrain  67 :\n",
      "\ttrain: 1.0 0.00738559840323264 \ttest: 0.78125 9.323376006519464\n",
      "retrain  68 :\n",
      "\ttrain: 1.0 0.007169438832670663 \ttest: 0.78125 9.329849696499465\n",
      "retrain  69 :\n",
      "\ttrain: 1.0 0.006962638362382313 \ttest: 0.78125 9.336238171158122\n",
      "retrain  70 :\n",
      "\ttrain: 1.0 0.006764664622198669 \ttest: 0.78125 9.342543546284233\n",
      "retrain  71 :\n",
      "\ttrain: 1.0 0.006575022535360141 \ttest: 0.78125 9.348767862131911\n",
      "retrain  72 :\n",
      "\ttrain: 1.0 0.006393251229572032 \ttest: 0.78125 9.354913086850498\n",
      "retrain  73 :\n",
      "\ttrain: 1.0 0.006218921242229761 \ttest: 0.78125 9.360981119731395\n",
      "retrain  74 :\n",
      "\ttrain: 1.0 0.00605163198825379 \ttest: 0.78125 9.36697379428244\n",
      "retrain  75 :\n",
      "\ttrain: 1.0 0.005891009462730038 \ttest: 0.78125 9.372892881140015\n",
      "retrain  76 :\n",
      "\ttrain: 1.0 0.005736704153817119 \ttest: 0.78125 9.378740090828316\n",
      "retrain  77 :\n",
      "\ttrain: 1.0 0.005588389144227664 \ttest: 0.78125 9.384517076374742\n",
      "retrain  78 :\n",
      "\ttrain: 1.0 0.0054457583820746456 \ttest: 0.78125 9.390225435789782\n",
      "retrain  79 :\n",
      "\ttrain: 1.0 0.005308525104045443 \ttest: 0.78125 9.395866714419293\n",
      "retrain  80 :\n",
      "\ttrain: 1.0 0.005176420395769682 \ttest: 0.78125 9.401442407176573\n",
      "retrain  81 :\n",
      "\ttrain: 1.0 0.00504919187591578 \ttest: 0.78125 9.406953960661149\n",
      "retrain  82 :\n",
      "\ttrain: 1.0 0.004926602492019372 \ttest: 0.78125 9.412402775170834\n",
      "retrain  83 :\n",
      "\ttrain: 1.0 0.004808429417338512 \ttest: 0.78125 9.417790206613146\n",
      "retrain  84 :\n",
      "\ttrain: 1.0 0.004694463039170272 \ttest: 0.78125 9.42311756832182\n",
      "retrain  85 :\n",
      "\ttrain: 1.0 0.004584506030069477 \ttest: 0.78125 9.428386132783817\n",
      "retrain  86 :\n",
      "\ttrain: 1.0 0.004478372494300272 \ttest: 0.78125 9.433597133281868\n",
      "retrain  87 :\n",
      "\ttrain: 1.0 0.004375887182640353 \ttest: 0.78125 9.438751765457269\n",
      "retrain  88 :\n",
      "\ttrain: 1.0 0.004276884769356415 \ttest: 0.78125 9.443851188797456\n",
      "retrain  89 :\n",
      "\ttrain: 1.0 0.004181209185791424 \ttest: 0.78125 9.448896528052394\n",
      "retrain  90 :\n",
      "\ttrain: 1.0 0.00408871300555666 \ttest: 0.78125 9.45388887458386\n",
      "retrain  91 :\n",
      "\ttrain: 1.0 0.003999256876814301 \ttest: 0.78125 9.458829287651163\n",
      "retrain  92 :\n",
      "\ttrain: 1.0 0.003912708997575147 \ttest: 0.78125 9.463718795636833\n",
      "retrain  93 :\n",
      "\ttrain: 1.0 0.003828944630328828 \ttest: 0.78125 9.468558397215523\n",
      "retrain  94 :\n",
      "\ttrain: 1.0 0.0037478456526741804 \ttest: 0.78125 9.473349062469124\n",
      "retrain  95 :\n",
      "\ttrain: 1.0 0.0036693001409318906 \ttest: 0.78125 9.478091733951034\n",
      "retrain  96 :\n",
      "\ttrain: 1.0 0.0035932019840027914 \ttest: 0.78125 9.482787327702214\n",
      "retrain  97 :\n",
      "\ttrain: 1.0 0.003519450524988136 \ttest: 0.78125 9.4874367342216\n",
      "retrain  98 :\n",
      "\ttrain: 1.0 0.00344795022831499 \ttest: 0.78125 9.492040819393246\n",
      "retrain  99 :\n",
      "\ttrain: 1.0 0.0033786103703139754 \ttest: 0.78125 9.496600425372486\n",
      "retrain  100 :\n",
      "\ttrain: 1.0 0.0033113447513810723 \ttest: 0.78125 9.501116371433131\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        37\n",
      "           1    1.00000   1.00000   1.00000        37\n",
      "\n",
      "    accuracy                        1.00000        74\n",
      "   macro avg    1.00000   1.00000   1.00000        74\n",
      "weighted avg    1.00000   1.00000   1.00000        74\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.76471   0.81250   0.78788        16\n",
      "           1    0.80000   0.75000   0.77419        16\n",
      "\n",
      "    accuracy                        0.78125        32\n",
      "   macro avg    0.78235   0.78125   0.78104        32\n",
      "weighted avg    0.78235   0.78125   0.78104        32\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 161\n",
      "Average of depth: 1.0683229813664596\n",
      "Number of nodes: 507\n",
      "19 77 1\n",
      "28 98 2\n",
      "31 101 3\n",
      "39 123 4\n",
      "43 143 5\n",
      "48 150 6\n",
      "50 158 7\n",
      "54 174 8\n",
      "55 177 9\n",
      "57 185 10\n",
      "60 196 11\n",
      "62 204 12\n",
      "65 213 13\n",
      "65 213 14\n",
      "65 213 15\n",
      "66 216 16\n",
      "66 216 17\n",
      "67 219 18\n",
      "68 226 19\n",
      "71 233 20\n",
      "74 242 21\n",
      "75 243 22\n",
      "79 263 23\n",
      "82 274 24\n",
      "83 275 25\n",
      "83 275 26\n",
      "84 278 27\n",
      "84 274 28\n",
      "88 290 29\n",
      "88 288 30\n",
      "88 288 31\n",
      "89 291 32\n",
      "91 301 33\n",
      "94 306 34\n",
      "96 312 35\n",
      "97 313 36\n",
      "98 316 37\n",
      "98 310 38\n",
      "98 310 39\n",
      "101 321 40\n",
      "102 324 41\n",
      "103 327 42\n",
      "103 325 43\n",
      "103 325 44\n",
      "104 324 45\n",
      "104 324 46\n",
      "106 332 47\n",
      "106 332 48\n",
      "107 335 49\n",
      "108 338 50\n",
      "109 341 51\n",
      "109 341 52\n",
      "109 341 53\n",
      "112 354 54\n",
      "112 354 55\n",
      "112 354 56\n",
      "113 355 57\n",
      "113 355 58\n",
      "114 358 59\n",
      "114 358 60\n",
      "114 354 61\n",
      "114 354 62\n",
      "114 354 63\n",
      "114 354 64\n",
      "114 354 65\n",
      "114 354 66\n",
      "116 358 67\n",
      "118 364 68\n",
      "119 367 69\n",
      "121 373 70\n",
      "121 371 71\n",
      "123 377 72\n",
      "124 380 73\n",
      "124 380 74\n",
      "125 383 75\n",
      "125 383 76\n",
      "125 383 77\n",
      "125 383 78\n",
      "125 383 79\n",
      "126 388 80\n",
      "126 388 81\n",
      "126 388 82\n",
      "126 388 83\n",
      "126 388 84\n",
      "126 388 85\n",
      "126 388 86\n",
      "126 388 87\n",
      "126 388 88\n",
      "126 388 89\n",
      "126 386 90\n",
      "126 386 91\n",
      "127 391 92\n",
      "129 401 93\n",
      "129 397 94\n",
      "129 397 95\n",
      "129 397 96\n",
      "129 397 97\n",
      "129 395 98\n",
      "129 395 99\n",
      "131 403 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 13.875152674682141 \ttest: 0.90625 8.944081351412137\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 6.9999045591319495 \ttest: 0.90625 6.564887594534174\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 4.235014474666003 \ttest: 0.9375 5.499848301962778\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 2.8467711071974637 \ttest: 0.9375 4.9143686052731255\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 2.045740980108314 \ttest: 0.9375 4.547316446686785\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 1.5395169528967572 \ttest: 0.9375 4.296379192463869\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 1.198679326159501 \ttest: 0.9375 4.114230330901922\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.9582368923006276 \ttest: 0.9375 3.9761555478394603\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.7824071431054963 \ttest: 0.9375 3.868024461400488\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.6500778161593685 \ttest: 0.9375 3.781176237472358\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.5481059019845012 \ttest: 0.9375 3.710004200152629\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.4679518403892697 \ttest: 0.9375 3.6507159570790892\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.40386952577070806 \ttest: 0.9375 3.6006525461027135\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.3518777594759952 \ttest: 0.9375 3.5578932220824315\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.3091486303763278 \ttest: 0.9375 3.5210151625283377\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.27362974466810186 \ttest: 0.9375 3.488941519847325\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.24380324257539576 \ttest: 0.9375 3.460842057666026\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.21852773782849283 \ttest: 0.9375 3.4360662600027303\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.1969320993877184 \ttest: 0.9375 3.414097146482209\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.17834252708533044 \ttest: 0.9375 3.394518666502067\n",
      "retrain  21 :\n",
      "\ttrain: 1.0 0.16223152168038882 \ttest: 0.9375 3.37699222192319\n",
      "retrain  22 :\n",
      "\ttrain: 1.0 0.1481815595312903 \ttest: 0.9375 3.3612394631619518\n",
      "retrain  23 :\n",
      "\ttrain: 1.0 0.13585883154907874 \ttest: 0.9375 3.347029482331176\n",
      "retrain  24 :\n",
      "\ttrain: 1.0 0.12499398906301216 \ttest: 0.9375 3.3341691433622547\n",
      "retrain  25 :\n",
      "\ttrain: 1.0 0.11536784430648248 \ttest: 0.9375 3.3224956862499786\n",
      "retrain  26 :\n",
      "\ttrain: 1.0 0.10680062438074757 \ttest: 0.9375 3.311871004031221\n",
      "retrain  27 :\n",
      "\ttrain: 1.0 0.09914380719988955 \ttest: 0.9375 3.302177166555737\n",
      "retrain  28 :\n",
      "\ttrain: 1.0 0.09227385618964684 \ttest: 0.9375 3.29331288490853\n",
      "retrain  29 :\n",
      "\ttrain: 1.0 0.08608736691458807 \ttest: 0.9375 3.2851906934667765\n",
      "retrain  30 :\n",
      "\ttrain: 1.0 0.08049727452405539 \ttest: 0.9375 3.2777346851030074\n",
      "retrain  31 :\n",
      "\ttrain: 1.0 0.07542986592330071 \ttest: 0.9375 3.270878676819257\n",
      "retrain  32 :\n",
      "\ttrain: 1.0 0.07082240791078265 \ttest: 0.9375 3.2645647132867666\n",
      "retrain  33 :\n",
      "\ttrain: 1.0 0.06662125078335093 \ttest: 0.9375 3.258741837839139\n",
      "retrain  34 :\n",
      "\ttrain: 1.0 0.06278030186876069 \ttest: 0.9375 3.2533650767808187\n",
      "retrain  35 :\n",
      "\ttrain: 1.0 0.059259789018729886 \ttest: 0.9375 3.248394595052121\n",
      "retrain  36 :\n",
      "\ttrain: 1.0 0.05602525297945265 \ttest: 0.9375 3.2437949904702985\n",
      "retrain  37 :\n",
      "\ttrain: 1.0 0.05304672162287806 \ttest: 0.9375 3.2395347007441195\n",
      "retrain  38 :\n",
      "\ttrain: 1.0 0.05029802958695451 \ttest: 0.9375 3.2355855028084206\n",
      "retrain  39 :\n",
      "\ttrain: 1.0 0.04775625487021204 \ttest: 0.9375 3.2319220881573916\n",
      "retrain  40 :\n",
      "\ttrain: 1.0 0.045401250024443354 \ttest: 0.9375 3.2285217010711165\n",
      "retrain  41 :\n",
      "\ttrain: 1.0 0.043215250272362754 \ttest: 0.9375 3.22536382914973\n",
      "retrain  42 :\n",
      "\ttrain: 1.0 0.04118254449739578 \ttest: 0.9375 3.2224299375569396\n",
      "retrain  43 :\n",
      "\ttrain: 1.0 0.03928919786914886 \ttest: 0.9375 3.219703239951919\n",
      "retrain  44 :\n",
      "\ttrain: 1.0 0.03752281707234541 \ttest: 0.9375 3.217168500347517\n",
      "retrain  45 :\n",
      "\ttrain: 1.0 0.03587235084207647 \ttest: 0.9375 3.2148118611433953\n",
      "retrain  46 :\n",
      "\ttrain: 1.0 0.03432791988145888 \ttest: 0.9375 3.2126206933981507\n",
      "retrain  47 :\n",
      "\ttrain: 1.0 0.03288067133037249 \ttest: 0.9375 3.2105834660659123\n",
      "retrain  48 :\n",
      "\ttrain: 1.0 0.031522653827583964 \ttest: 0.9375 3.2086896314618314\n",
      "retrain  49 :\n",
      "\ttrain: 1.0 0.030246709910480618 \ttest: 0.9375 3.206929524662134\n",
      "retrain  50 :\n",
      "\ttrain: 1.0 0.029046383063186826 \ttest: 0.9375 3.2052942749071818\n",
      "retrain  51 :\n",
      "\ttrain: 1.0 0.027915837183134187 \ttest: 0.9375 3.203775727375534\n",
      "retrain  52 :\n",
      "\ttrain: 1.0 0.02684978661008909 \ttest: 0.9375 3.2023663739453037\n",
      "retrain  53 :\n",
      "\ttrain: 1.0 0.02584343516731122 \ttest: 0.9375 3.2010592917657688\n",
      "retrain  54 :\n",
      "\ttrain: 1.0 0.024892422915360028 \ttest: 0.9375 3.199848088634746\n",
      "retrain  55 :\n",
      "\ttrain: 1.0 0.023992779525696357 \ttest: 0.9375 3.1987268543219347\n",
      "retrain  56 :\n",
      "\ttrain: 1.0 0.02314088335204842 \ttest: 0.9375 3.19769011710007\n",
      "retrain  57 :\n",
      "\ttrain: 1.0 0.022333425419227202 \ttest: 0.9375 3.196732804848378\n",
      "retrain  58 :\n",
      "\ttrain: 1.0 0.021567377667038617 \ttest: 0.9375 3.195850210179751\n",
      "retrain  59 :\n",
      "\ttrain: 1.0 0.020839964885451624 \ttest: 0.9375 3.1950379591167595\n",
      "retrain  60 :\n",
      "\ttrain: 1.0 0.020148639859704366 \ttest: 0.9375 3.194291982904493\n",
      "retrain  61 :\n",
      "\ttrain: 1.0 0.0194910613133727 \ttest: 0.9375 3.1936084926017934\n",
      "retrain  62 :\n",
      "\ttrain: 1.0 0.018865074295860134 \ttest: 0.9375 3.1929839561383906\n",
      "retrain  63 :\n",
      "\ttrain: 1.0 0.018268692710152756 \ttest: 0.9375 3.192415077564854\n",
      "retrain  64 :\n",
      "\ttrain: 1.0 0.017700083718530435 \ttest: 0.9375 3.191898778256175\n",
      "retrain  65 :\n",
      "\ttrain: 1.0 0.0171575537994841 \ttest: 0.9375 3.1914321798590644\n",
      "retrain  66 :\n",
      "\ttrain: 1.0 0.01663953625937839 \ttest: 0.9375 3.191012588798367\n",
      "retrain  67 :\n",
      "\ttrain: 1.0 0.016144580028266006 \ttest: 0.9375 3.1906374821798726\n",
      "retrain  68 :\n",
      "\ttrain: 1.0 0.015671339591402857 \ttest: 0.9375 3.1903044949459134\n",
      "retrain  69 :\n",
      "\ttrain: 1.0 0.015218565927013122 \ttest: 0.9375 3.190011408156651\n",
      "retrain  70 :\n",
      "\ttrain: 1.0 0.014785098337192774 \ttest: 0.9375 3.189756138284465\n",
      "retrain  71 :\n",
      "\ttrain: 1.0 0.014369857072923537 \ttest: 0.9375 3.189536727421492\n",
      "retrain  72 :\n",
      "\ttrain: 1.0 0.01397183666633289 \ttest: 0.9375 3.189351334311389\n",
      "retrain  73 :\n",
      "\ttrain: 1.0 0.013590099893865604 \ttest: 0.9375 3.189198226126165\n",
      "retrain  74 :\n",
      "\ttrain: 1.0 0.013223772303162264 \ttest: 0.9375 3.1890757709174338\n",
      "retrain  75 :\n",
      "\ttrain: 1.0 0.012872037244377209 \ttest: 0.9375 3.188982430678957\n",
      "retrain  76 :\n",
      "\ttrain: 1.0 0.012534131353576547 \ttest: 0.9375 3.1889167549639725\n",
      "retrain  77 :\n",
      "\ttrain: 1.0 0.012209340441883825 \ttest: 0.9375 3.188877375006717\n",
      "retrain  78 :\n",
      "\ttrain: 1.0 0.011896995749308314 \ttest: 0.9375 3.1888629983026417\n",
      "retrain  79 :\n",
      "\ttrain: 1.0 0.011596470526801047 \ttest: 0.9375 3.188872403606532\n",
      "retrain  80 :\n",
      "\ttrain: 1.0 0.01130717691412769 \ttest: 0.9375 3.1889044363117294\n",
      "retrain  81 :\n",
      "\ttrain: 1.0 0.01102856308469812 \ttest: 0.9375 3.188958004177332\n",
      "retrain  82 :\n",
      "\ttrain: 1.0 0.010760110631618806 \ttest: 0.9375 3.1890320733734905\n",
      "retrain  83 :\n",
      "\ttrain: 1.0 0.010501332171987267 \ttest: 0.9375 3.189125664817782\n",
      "retrain  84 :\n",
      "\ttrain: 1.0 0.010251769148878948 \ttest: 0.9375 3.189237850778209\n",
      "retrain  85 :\n",
      "\ttrain: 1.0 0.010010989812625187 \ttest: 0.9375 3.189367751720705\n",
      "retrain  86 :\n",
      "\ttrain: 1.0 0.009778587364883946 \ttest: 0.9375 3.189514533381075\n",
      "retrain  87 :\n",
      "\ttrain: 1.0 0.009554178250690814 \ttest: 0.9375 3.1896774040431417\n",
      "retrain  88 :\n",
      "\ttrain: 1.0 0.009337400585175196 \ttest: 0.9375 3.189855612006549\n",
      "retrain  89 :\n",
      "\ttrain: 1.0 0.009127912702958029 \ttest: 0.9375 3.1900484432291423\n",
      "retrain  90 :\n",
      "\ttrain: 1.0 0.008925391819432645 \ttest: 0.9375 3.1902552191302247\n",
      "retrain  91 :\n",
      "\ttrain: 1.0 0.008729532794185755 \ttest: 0.9375 3.190475294542149\n",
      "retrain  92 :\n",
      "\ttrain: 1.0 0.008540046987760168 \ttest: 0.9375 3.1907080557988445\n",
      "retrain  93 :\n",
      "\ttrain: 1.0 0.008356661203802199 \ttest: 0.9375 3.19095291895086\n",
      "retrain  94 :\n",
      "\ttrain: 1.0 0.008179116709391476 \ttest: 0.9375 3.1912093280973446\n",
      "retrain  95 :\n",
      "\ttrain: 1.0 0.008007168327026356 \ttest: 0.9375 3.1914767538262754\n",
      "retrain  96 :\n",
      "\ttrain: 1.0 0.007840583592343965 \ttest: 0.9375 3.1917546917549022\n",
      "retrain  97 :\n",
      "\ttrain: 1.0 0.007679141972198409 \ttest: 0.9375 3.192042661163091\n",
      "retrain  98 :\n",
      "\ttrain: 1.0 0.007522634138209411 \ttest: 0.9375 3.1923402037128232\n",
      "retrain  99 :\n",
      "\ttrain: 1.0 0.0073708612913344065 \ttest: 0.9375 3.1926468822476735\n",
      "retrain  100 :\n",
      "\ttrain: 1.0 0.007223634533413682 \ttest: 0.9375 3.192962279666565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        37\n",
      "           1    1.00000   1.00000   1.00000        37\n",
      "\n",
      "    accuracy                        1.00000        74\n",
      "   macro avg    1.00000   1.00000   1.00000        74\n",
      "weighted avg    1.00000   1.00000   1.00000        74\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   0.87500   0.93333        16\n",
      "           1    0.88889   1.00000   0.94118        16\n",
      "\n",
      "    accuracy                        0.93750        32\n",
      "   macro avg    0.94444   0.93750   0.93725        32\n",
      "weighted avg    0.94444   0.93750   0.93725        32\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 131\n",
      "Average of depth: 1.0381679389312977\n",
      "Number of nodes: 403\n",
      "19 71 1\n",
      "32 114 2\n",
      "35 125 3\n",
      "42 150 4\n",
      "46 158 5\n",
      "50 172 6\n",
      "55 189 7\n",
      "57 195 8\n",
      "61 211 9\n",
      "64 218 10\n",
      "66 222 11\n",
      "71 243 12\n",
      "74 254 13\n",
      "78 266 14\n",
      "80 274 15\n",
      "87 299 16\n",
      "89 303 17\n",
      "89 299 18\n",
      "92 308 19\n",
      "92 308 20\n",
      "98 326 21\n",
      "101 337 22\n",
      "101 335 23\n",
      "105 347 24\n",
      "109 359 25\n",
      "110 358 26\n",
      "112 362 27\n",
      "115 373 28\n",
      "116 380 29\n",
      "117 375 30\n",
      "119 381 31\n",
      "120 384 32\n",
      "120 384 33\n",
      "120 384 34\n",
      "122 388 35\n",
      "123 387 36\n",
      "126 396 37\n",
      "126 396 38\n",
      "127 399 39\n",
      "127 399 40\n",
      "127 399 41\n",
      "127 399 42\n",
      "127 399 43\n",
      "127 399 44\n",
      "127 399 45\n",
      "129 409 46\n",
      "129 407 47\n",
      "129 407 48\n",
      "129 407 49\n",
      "129 407 50\n",
      "131 415 51\n",
      "131 415 52\n",
      "133 421 53\n",
      "134 424 54\n",
      "134 424 55\n",
      "134 424 56\n",
      "134 422 57\n",
      "134 418 58\n",
      "134 418 59\n",
      "135 421 60\n",
      "136 424 61\n",
      "139 433 62\n",
      "140 436 63\n",
      "140 436 64\n",
      "143 453 65\n",
      "144 458 66\n",
      "144 458 67\n",
      "144 458 68\n",
      "145 461 69\n",
      "145 461 70\n",
      "146 466 71\n",
      "146 466 72\n",
      "147 471 73\n",
      "148 474 74\n",
      "148 474 75\n",
      "148 474 76\n",
      "148 474 77\n",
      "148 474 78\n",
      "148 474 79\n",
      "149 477 80\n",
      "149 477 81\n",
      "150 480 82\n",
      "151 483 83\n",
      "151 481 84\n",
      "151 481 85\n",
      "151 481 86\n",
      "152 486 87\n",
      "152 486 88\n",
      "154 494 89\n",
      "154 494 90\n",
      "154 494 91\n",
      "154 494 92\n",
      "154 494 93\n",
      "155 497 94\n",
      "156 502 95\n",
      "156 500 96\n",
      "156 500 97\n",
      "157 503 98\n",
      "157 503 99\n",
      "158 508 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 11.646399272662743 \ttest: 0.78125 10.104024134436411\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 5.729631334837634 \ttest: 0.8125 8.6205679267943\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 3.457200954749272 \ttest: 0.8125 8.029736662067858\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 2.3139541966586763 \ttest: 0.8125 7.718880018152149\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.650531917317704 \ttest: 0.8125 7.526414539487888\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 1.23088426130994 \ttest: 0.8125 7.394491290116585\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 0.9493551537527682 \ttest: 0.8125 7.297751832156278\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.7520300530743984 \ttest: 0.8125 7.223384646426268\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.608864253831672 \ttest: 0.8125 7.164207337602075\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.5020162159553709 \ttest: 0.8125 7.115864148606476\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.4203612886828047 \ttest: 0.8125 7.07554820126817\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.35668523279594966 \ttest: 0.8125 7.0413620483749035\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.30615431167534346 \ttest: 0.8125 7.011972729300127\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.26543836093411743 \ttest: 0.8125 6.98641391322219\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.23218705628972758 \ttest: 0.8125 6.963966492718973\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.20470610384511068 \ttest: 0.8125 6.9440833894830964\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.181750978265363 \ttest: 0.8125 6.926340466345618\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.16239206360642713 \ttest: 0.8125 6.910403480964105\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.14592441654270122 \ttest: 0.8125 6.896005240658569\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.13180612543267337 \ttest: 0.8125 6.8829294403258565\n",
      "retrain  21 :\n",
      "\ttrain: 1.0 0.11961541088636618 \ttest: 0.8125 6.870998994120969\n",
      "retrain  22 :\n",
      "\ttrain: 1.0 0.10902026046790596 \ttest: 0.8125 6.860067458898003\n",
      "retrain  23 :\n",
      "\ttrain: 1.0 0.09975660144189297 \ttest: 0.8125 6.850012628542161\n",
      "retrain  24 :\n",
      "\ttrain: 1.0 0.0916123877469443 \ttest: 0.8125 6.840731680550579\n",
      "retrain  25 :\n",
      "\ttrain: 1.0 0.08441584710444033 \ttest: 0.8125 6.832137450780884\n",
      "retrain  26 :\n",
      "\ttrain: 1.0 0.07802669607556292 \ttest: 0.8125 6.824155540327672\n",
      "retrain  27 :\n",
      "\ttrain: 1.0 0.07232950036248373 \ttest: 0.8125 6.8167220444441305\n",
      "retrain  28 :\n",
      "\ttrain: 1.0 0.06722860457987989 \ttest: 0.8125 6.809781752180017\n",
      "retrain  29 :\n",
      "\ttrain: 1.0 0.06264422324625471 \ttest: 0.8125 6.803286706231891\n",
      "retrain  30 :\n",
      "\ttrain: 1.0 0.05850939999122143 \ttest: 0.8125 6.797195041296529\n",
      "retrain  31 :\n",
      "\ttrain: 1.0 0.05476762229356013 \ttest: 0.8125 6.791470039810448\n",
      "retrain  32 :\n",
      "\ttrain: 1.0 0.05137093572329139 \ttest: 0.8125 6.786079358871822\n",
      "retrain  33 :\n",
      "\ttrain: 1.0 0.04827844208462853 \ttest: 0.8125 6.780994393069525\n",
      "retrain  34 :\n",
      "\ttrain: 1.0 0.045455095005592756 \ttest: 0.8125 6.776189746039422\n",
      "retrain  35 :\n",
      "\ttrain: 1.0 0.042870727750010884 \ttest: 0.8125 6.771642789626091\n",
      "retrain  36 :\n",
      "\ttrain: 1.0 0.04049926363608528 \ttest: 0.8125 6.767333294104295\n",
      "retrain  37 :\n",
      "\ttrain: 1.0 0.03831807102351062 \ttest: 0.8125 6.7632431164018225\n",
      "retrain  38 :\n",
      "\ttrain: 1.0 0.036307433491394245 \ttest: 0.8125 6.759355935945152\n",
      "retrain  39 :\n",
      "\ttrain: 1.0 0.034450112358790086 \ttest: 0.8125 6.755657029824343\n",
      "retrain  40 :\n",
      "\ttrain: 1.0 0.032730983659875756 \ttest: 0.8125 6.752133080592314\n",
      "retrain  41 :\n",
      "\ttrain: 1.0 0.03113673548083929 \ttest: 0.8125 6.748772011284982\n",
      "retrain  42 :\n",
      "\ttrain: 1.0 0.0296556144888637 \ttest: 0.8125 6.7455628432538735\n",
      "retrain  43 :\n",
      "\ttrain: 1.0 0.028277212750002282 \ttest: 0.8125 6.7424955732022145\n",
      "retrain  44 :\n",
      "\ttrain: 1.0 0.026992287700676982 \ttest: 0.8125 6.739561066455261\n",
      "retrain  45 :\n",
      "\ttrain: 1.0 0.025792609524740162 \ttest: 0.8125 6.736750964010172\n",
      "retrain  46 :\n",
      "\ttrain: 1.0 0.0246708312826144 \ttest: 0.8125 6.734057601327004\n",
      "retrain  47 :\n",
      "\ttrain: 1.0 0.02362037800732257 \ttest: 0.8125 6.731473937160672\n",
      "retrain  48 :\n",
      "\ttrain: 1.0 0.022635351674554126 \ttest: 0.8125 6.7289934910100735\n",
      "retrain  49 :\n",
      "\ttrain: 1.0 0.02171044950864672 \ttest: 0.8125 6.726610287987253\n",
      "retrain  50 :\n",
      "\ttrain: 1.0 0.020840893532936167 \ttest: 0.8125 6.7243188100962925\n",
      "retrain  51 :\n",
      "\ttrain: 1.0 0.020022369634050647 \ttest: 0.8125 6.722113953066244\n",
      "retrain  52 :\n",
      "\ttrain: 1.0 0.019250974703011084 \ttest: 0.8125 6.719990988010764\n",
      "retrain  53 :\n",
      "\ttrain: 1.0 0.018523170655184083 \ttest: 0.84375 6.717945527294287\n",
      "retrain  54 :\n",
      "\ttrain: 1.0 0.017835744326973144 \ttest: 0.84375 6.715973494074181\n",
      "retrain  55 :\n",
      "\ttrain: 1.0 0.01718577240810453 \ttest: 0.84375 6.714071095063652\n",
      "retrain  56 :\n",
      "\ttrain: 1.0 0.016570590701157652 \ttest: 0.84375 6.712234796123601\n",
      "retrain  57 :\n",
      "\ttrain: 1.0 0.015987767109936102 \ttest: 0.84375 6.7104613003453535\n",
      "retrain  58 :\n",
      "\ttrain: 1.0 0.015435077849613375 \ttest: 0.84375 6.7087475283316165\n",
      "retrain  59 :\n",
      "\ttrain: 1.0 0.01491048644771912 \ttest: 0.84375 6.707090600421864\n",
      "retrain  60 :\n",
      "\ttrain: 1.0 0.014412125168694636 \ttest: 0.84375 6.705487820641253\n",
      "retrain  61 :\n",
      "\ttrain: 1.0 0.013938278548143185 \ttest: 0.84375 6.703936662180578\n",
      "retrain  62 :\n",
      "\ttrain: 1.0 0.013487368767824002 \ttest: 0.84375 6.702434754238944\n",
      "retrain  63 :\n",
      "\ttrain: 1.0 0.013057942640340848 \ttest: 0.84375 6.700979870081756\n",
      "retrain  64 :\n",
      "\ttrain: 1.0 0.012648660004543583 \ttest: 0.84375 6.69956991618454\n",
      "retrain  65 :\n",
      "\ttrain: 1.0 0.012258283359866735 \ttest: 0.84375 6.698202922348802\n",
      "retrain  66 :\n",
      "\ttrain: 1.0 0.011885668590969498 \ttest: 0.84375 6.696877032689468\n",
      "retrain  67 :\n",
      "\ttrain: 1.0 0.011529756653774093 \ttest: 0.84375 6.695590497405248\n",
      "retrain  68 :\n",
      "\ttrain: 1.0 0.011189566110868843 \ttest: 0.84375 6.6943416652534244\n",
      "retrain  69 :\n",
      "\ttrain: 1.0 0.010864186418695219 \ttest: 0.84375 6.693128976659458\n",
      "retrain  70 :\n",
      "\ttrain: 1.0 0.010552771881354594 \ttest: 0.84375 6.691950957399589\n",
      "retrain  71 :\n",
      "\ttrain: 1.0 0.010254536196555376 \ttest: 0.84375 6.690806212801381\n",
      "retrain  72 :\n",
      "\ttrain: 1.0 0.009968747528440864 \ttest: 0.84375 6.689693422413187\n",
      "retrain  73 :\n",
      "\ttrain: 1.0 0.00969472405000796 \ttest: 0.84375 6.688611335098707\n",
      "retrain  74 :\n",
      "\ttrain: 1.0 0.009431829904731258 \ttest: 0.84375 6.687558764517479\n",
      "retrain  75 :\n",
      "\ttrain: 1.0 0.009179471543000342 \ttest: 0.84375 6.686534584956208\n",
      "retrain  76 :\n",
      "\ttrain: 1.0 0.008937094394190402 \ttest: 0.84375 6.685537727479444\n",
      "retrain  77 :\n",
      "\ttrain: 1.0 0.008704179839728111 \ttest: 0.84375 6.684567176371334\n",
      "retrain  78 :\n",
      "\ttrain: 1.0 0.008480242456480408 \ttest: 0.84375 6.683621965842988\n",
      "retrain  79 :\n",
      "\ttrain: 1.0 0.008264827503260805 \ttest: 0.84375 6.682701176982527\n",
      "retrain  80 :\n",
      "\ttrain: 1.0 0.008057508626286396 \ttest: 0.84375 6.681803934927133\n",
      "retrain  81 :\n",
      "\ttrain: 1.0 0.00785788576208457 \ttest: 0.84375 6.680929406238389\n",
      "retrain  82 :\n",
      "\ttrain: 1.0 0.00766558321869204 \ttest: 0.84375 6.680076796464013\n",
      "retrain  83 :\n",
      "\ttrain: 1.0 0.007480247918052865 \ttest: 0.84375 6.679245347870662\n",
      "retrain  84 :\n",
      "\ttrain: 1.0 0.007301547784340774 \ttest: 0.84375 6.6784343373339174\n",
      "retrain  85 :\n",
      "\ttrain: 1.0 0.007129170264539389 \ttest: 0.84375 6.677643074372814\n",
      "retrain  86 :\n",
      "\ttrain: 1.0 0.006962820969035411 \ttest: 0.84375 6.676870899317505\n",
      "retrain  87 :\n",
      "\ttrain: 1.0 0.00680222242123835 \ttest: 0.84375 6.67611718159954\n",
      "retrain  88 :\n",
      "\ttrain: 1.0 0.006647112906359318 \ttest: 0.84375 6.67538131815534\n",
      "retrain  89 :\n",
      "\ttrain: 1.0 0.006497245410472308 \ttest: 0.84375 6.67466273193411\n",
      "retrain  90 :\n",
      "\ttrain: 1.0 0.006352386641865042 \ttest: 0.84375 6.673960870502334\n",
      "retrain  91 :\n",
      "\ttrain: 1.0 0.006212316127473683 \ttest: 0.84375 6.673275204737585\n",
      "retrain  92 :\n",
      "\ttrain: 1.0 0.006076825377895723 \ttest: 0.84375 6.672605227605024\n",
      "retrain  93 :\n",
      "\ttrain: 1.0 0.005945717115103409 \ttest: 0.84375 6.671950453010529\n",
      "retrain  94 :\n",
      "\ttrain: 1.0 0.005818804557539396 \ttest: 0.84375 6.6713104147249\n",
      "retrain  95 :\n",
      "\ttrain: 1.0 0.005695910757778165 \ttest: 0.84375 6.670684665374003\n",
      "retrain  96 :\n",
      "\ttrain: 1.0 0.005576867988386839 \ttest: 0.84375 6.670072775490221\n",
      "retrain  97 :\n",
      "\ttrain: 1.0 0.005461517172021568 \ttest: 0.84375 6.669474332620842\n",
      "retrain  98 :\n",
      "\ttrain: 1.0 0.005349707352159295 \ttest: 0.84375 6.668888940489458\n",
      "retrain  99 :\n",
      "\ttrain: 1.0 0.00524129520118998 \ttest: 0.84375 6.66831621820671\n",
      "retrain  100 :\n",
      "\ttrain: 1.0 0.005136144562888415 \ttest: 0.84375 6.667755799527001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        37\n",
      "           1    1.00000   1.00000   1.00000        37\n",
      "\n",
      "    accuracy                        1.00000        74\n",
      "   macro avg    1.00000   1.00000   1.00000        74\n",
      "weighted avg    1.00000   1.00000   1.00000        74\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.78947   0.93750   0.85714        16\n",
      "           1    0.92308   0.75000   0.82759        16\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.85628   0.84375   0.84236        32\n",
      "weighted avg    0.85628   0.84375   0.84236        32\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 158\n",
      "Average of depth: 1.1012658227848102\n",
      "Number of nodes: 508\n",
      "19 67 1\n",
      "29 97 2\n",
      "35 117 3\n",
      "40 136 4\n",
      "47 153 5\n",
      "56 192 6\n",
      "60 206 7\n",
      "64 220 8\n",
      "67 231 9\n",
      "72 244 10\n",
      "73 245 11\n",
      "78 262 12\n",
      "79 263 13\n",
      "82 276 14\n",
      "85 287 15\n",
      "86 290 16\n",
      "88 294 17\n",
      "90 298 18\n",
      "90 298 19\n",
      "90 292 20\n",
      "92 292 21\n",
      "95 303 22\n",
      "95 301 23\n",
      "96 306 24\n",
      "98 308 25\n",
      "100 314 26\n",
      "100 314 27\n",
      "105 339 28\n",
      "106 344 29\n",
      "107 345 30\n",
      "108 344 31\n",
      "108 344 32\n",
      "108 344 33\n",
      "112 358 34\n",
      "113 361 35\n",
      "114 366 36\n",
      "115 371 37\n",
      "116 376 38\n",
      "116 376 39\n",
      "116 374 40\n",
      "116 372 41\n",
      "116 370 42\n",
      "117 373 43\n",
      "117 373 44\n",
      "118 376 45\n",
      "118 374 46\n",
      "118 374 47\n",
      "119 381 48\n",
      "119 381 49\n",
      "119 381 50\n",
      "120 384 51\n",
      "120 384 52\n",
      "120 384 53\n",
      "121 387 54\n",
      "123 395 55\n",
      "123 395 56\n",
      "124 398 57\n",
      "128 414 58\n",
      "128 412 59\n",
      "129 415 60\n",
      "129 415 61\n",
      "130 420 62\n",
      "131 423 63\n",
      "131 423 64\n",
      "131 423 65\n",
      "132 426 66\n",
      "132 426 67\n",
      "132 426 68\n",
      "134 432 69\n",
      "135 437 70\n",
      "136 442 71\n",
      "137 449 72\n",
      "137 449 73\n",
      "137 449 74\n",
      "137 447 75\n",
      "137 447 76\n",
      "137 447 77\n",
      "137 445 78\n",
      "138 450 79\n",
      "138 450 80\n",
      "138 448 81\n",
      "138 448 82\n",
      "139 455 83\n",
      "139 455 84\n",
      "139 455 85\n",
      "139 455 86\n",
      "139 451 87\n",
      "140 454 88\n",
      "140 454 89\n",
      "141 457 90\n",
      "141 457 91\n",
      "142 460 92\n",
      "142 460 93\n",
      "142 460 94\n",
      "142 460 95\n",
      "144 468 96\n",
      "144 468 97\n",
      "144 468 98\n",
      "145 473 99\n",
      "145 473 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.9864864864864865 13.165809550826769 \ttest: 0.9375 8.567422483308723\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 6.956420063093679 \ttest: 0.9375 6.302703793898909\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 4.389286064135527 \ttest: 0.9375 5.278332298248186\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 3.0273547085685384 \ttest: 0.9375 4.692742409021889\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 2.205652882829731 \ttest: 0.9375 4.3092677491505995\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 1.6705293151528577 \ttest: 0.9375 4.035643908409509\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 1.3034865593614948 \ttest: 0.9375 3.828702077322718\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 1.041779031624516 \ttest: 0.9375 3.6655368136237003\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.8493318175695717 \ttest: 0.96875 3.5328287034133266\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.7041586784191656 \ttest: 0.96875 3.4222748700352494\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.5922529950247877 \ttest: 0.96875 3.32841008808404\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.5043688083474303 \ttest: 0.96875 3.247476633793108\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.4342190212017302 \ttest: 0.96875 3.1767971669999695\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.37741847510381465 \ttest: 0.96875 3.1144069227235227\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.33083999239197476 \ttest: 0.96875 3.058827776614777\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.2922093413072111 \ttest: 0.96875 3.00892391893472\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.25984339976417625 \ttest: 0.96875 2.9638065186975036\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.23247676925871646 \ttest: 0.96875 2.9227688989764236\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.20914447534663314 \ttest: 0.96875 2.885241332312063\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.189101069813977 \ttest: 0.96875 2.850758811502536\n",
      "retrain  21 :\n",
      "\ttrain: 1.0 0.1717638565843009 \ttest: 0.96875 2.8189376164260826\n",
      "retrain  22 :\n",
      "\ttrain: 1.0 0.15667240936536336 \ttest: 0.96875 2.7894579762514153\n",
      "retrain  23 :\n",
      "\ttrain: 1.0 0.14345928272980493 \ttest: 0.96875 2.7620510393723117\n",
      "retrain  24 :\n",
      "\ttrain: 1.0 0.13182853601133124 \ttest: 0.96875 2.736488941904936\n",
      "retrain  25 :\n",
      "\ttrain: 1.0 0.1215397901424409 \ttest: 0.96875 2.7125771408034645\n",
      "retrain  26 :\n",
      "\ttrain: 1.0 0.11239625576863913 \ttest: 0.96875 2.690148426204353\n",
      "retrain  27 :\n",
      "\ttrain: 1.0 0.10423564741998556 \ttest: 0.96875 2.6690581954435713\n",
      "retrain  28 :\n",
      "\ttrain: 1.0 0.09692321946715249 \ttest: 0.96875 2.649180686515229\n",
      "retrain  29 :\n",
      "\ttrain: 1.0 0.09034637888439889 \ttest: 0.96875 2.6304059492589955\n",
      "retrain  30 :\n",
      "\ttrain: 1.0 0.08441048167940654 \ttest: 0.96875 2.612637389612491\n",
      "retrain  31 :\n",
      "\ttrain: 1.0 0.07903552628916516 \ttest: 0.96875 2.5957897632345617\n",
      "retrain  32 :\n",
      "\ttrain: 1.0 0.0741535327249781 \ttest: 0.96875 2.5797875245974824\n",
      "retrain  33 :\n",
      "\ttrain: 1.0 0.0697064503657126 \ttest: 0.96875 2.5645634595623608\n",
      "retrain  34 :\n",
      "\ttrain: 1.0 0.06564447649382615 \ttest: 0.96875 2.550057545748719\n",
      "retrain  35 :\n",
      "\ttrain: 1.0 0.06192469633183456 \ttest: 0.96875 2.536215997249253\n",
      "retrain  36 :\n",
      "\ttrain: 1.0 0.05850997648909642 \ttest: 0.96875 2.522990459520325\n",
      "retrain  37 :\n",
      "\ttrain: 1.0 0.055368059472781186 \ttest: 0.96875 2.5103373273758436\n",
      "retrain  38 :\n",
      "\ttrain: 1.0 0.052470818731003344 \ttest: 0.96875 2.498217164484643\n",
      "retrain  39 :\n",
      "\ttrain: 1.0 0.04979364262980719 \ttest: 0.96875 2.486594207024173\n",
      "retrain  40 :\n",
      "\ttrain: 1.0 0.04731492257078524 \ttest: 0.96875 2.475435937471966\n",
      "retrain  41 :\n",
      "\ttrain: 1.0 0.04501562567590797 \ttest: 0.96875 2.4647127171398537\n",
      "retrain  42 :\n",
      "\ttrain: 1.0 0.04287893649647863 \ttest: 0.96875 2.454397468136934\n",
      "retrain  43 :\n",
      "\ttrain: 1.0 0.040889955334694944 \ttest: 0.96875 2.4444653971082895\n",
      "retrain  44 :\n",
      "\ttrain: 1.0 0.039035443214174556 \ttest: 0.96875 2.43489375442981\n",
      "retrain  45 :\n",
      "\ttrain: 1.0 0.03730360546023632 \ttest: 0.96875 2.4256616236158095\n",
      "retrain  46 :\n",
      "\ttrain: 1.0 0.03568390737196068 \ttest: 0.96875 2.416749736569531\n",
      "retrain  47 :\n",
      "\ttrain: 1.0 0.03416691667686883 \ttest: 0.96875 2.4081403110189177\n",
      "retrain  48 :\n",
      "\ttrain: 1.0 0.03274416842444944 \ttest: 0.96875 2.399816907063628\n",
      "retrain  49 :\n",
      "\ttrain: 1.0 0.031408048749452945 \ttest: 0.96875 2.3917643002397346\n",
      "retrain  50 :\n",
      "\ttrain: 1.0 0.030151694560410326 \ttest: 0.96875 2.383968368905651\n",
      "retrain  51 :\n",
      "\ttrain: 1.0 0.028968906714543646 \ttest: 0.96875 2.376415994082545\n",
      "retrain  52 :\n",
      "\ttrain: 1.0 0.027854074651476067 \ttest: 0.96875 2.3690949701572825\n",
      "retrain  53 :\n",
      "\ttrain: 1.0 0.02680211079393007 \ttest: 0.96875 2.3619939250857733\n",
      "retrain  54 :\n",
      "\ttrain: 1.0 0.025808393298852143 \ttest: 0.96875 2.3551022489276505\n",
      "retrain  55 :\n",
      "\ttrain: 1.0 0.024868715968884236 \ttest: 0.96875 2.3484100297058057\n",
      "retrain  56 :\n",
      "\ttrain: 1.0 0.02397924432113823 \ttest: 0.96875 2.341907995721823\n",
      "retrain  57 :\n",
      "\ttrain: 1.0 0.023136476965233466 \ttest: 0.96875 2.3355874635749387\n",
      "retrain  58 :\n",
      "\ttrain: 1.0 0.022337211571447226 \ttest: 0.96875 2.3294402912313745\n",
      "retrain  59 :\n",
      "\ttrain: 1.0 0.021578514817359867 \ttest: 0.96875 2.32345883557557\n",
      "retrain  60 :\n",
      "\ttrain: 1.0 0.020857695791364792 \ttest: 0.96875 2.317635913947252\n",
      "retrain  61 :\n",
      "\ttrain: 1.0 0.020172282406960347 \ttest: 0.96875 2.3119647692304817\n",
      "retrain  62 :\n",
      "\ttrain: 1.0 0.019520000445341183 \ttest: 0.96875 2.3064390381143234\n",
      "retrain  63 :\n",
      "\ttrain: 1.0 0.018898754897509314 \ttest: 0.96875 2.301052722190916\n",
      "retrain  64 :\n",
      "\ttrain: 1.0 0.018306613322594 \ttest: 0.96875 2.295800161596635\n",
      "retrain  65 :\n",
      "\ttrain: 1.0 0.01774179097766765 \ttest: 0.96875 2.290676010936696\n",
      "retrain  66 :\n",
      "\ttrain: 1.0 0.017202637507199144 \ttest: 0.96875 2.285675217263534\n",
      "retrain  67 :\n",
      "\ttrain: 1.0 0.016687625008318406 \ttest: 0.96875 2.280792999905564\n",
      "retrain  68 :\n",
      "\ttrain: 1.0 0.016195337312043687 \ttest: 0.96875 2.276024831965735\n",
      "retrain  69 :\n",
      "\ttrain: 1.0 0.015724460341182127 \ttest: 0.96875 2.2713664233293187\n",
      "retrain  70 :\n",
      "\ttrain: 1.0 0.015273773423279428 \ttest: 0.96875 2.2668137050378707\n",
      "retrain  71 :\n",
      "\ttrain: 1.0 0.014842141452210404 \ttest: 0.96875 2.2623628149017208\n",
      "retrain  72 :\n",
      "\ttrain: 1.0 0.014428507805134369 \ttest: 0.96875 2.2580100842368793\n",
      "retrain  73 :\n",
      "\ttrain: 1.0 0.014031887932898272 \ttest: 0.96875 2.253752025624184\n",
      "retrain  74 :\n",
      "\ttrain: 1.0 0.013651363551815236 \ttest: 0.96875 2.2495853215990693\n",
      "retrain  75 :\n",
      "\ttrain: 1.0 0.013286077373295128 \ttest: 0.96875 2.245506814189662\n",
      "retrain  76 :\n",
      "\ttrain: 1.0 0.012935228315242773 \ttest: 0.96875 2.241513495229177\n",
      "retrain  77 :\n",
      "\ttrain: 1.0 0.012598067145624243 \ttest: 0.96875 2.2376024973759403\n",
      "retrain  78 :\n",
      "\ttrain: 1.0 0.012273892514264638 \ttest: 0.96875 2.233771085780866\n",
      "retrain  79 :\n",
      "\ttrain: 1.0 0.011962047333895595 \ttest: 0.96875 2.2300166503480687\n",
      "retrain  80 :\n",
      "\ttrain: 1.0 0.011661915475813703 \ttest: 0.96875 2.2263366985394444\n",
      "retrain  81 :\n",
      "\ttrain: 1.0 0.011372918749322546 \ttest: 0.96875 2.2227288486787047\n",
      "retrain  82 :\n",
      "\ttrain: 1.0 0.011094514137483812 \ttest: 0.96875 2.2191908237144844\n",
      "retrain  83 :\n",
      "\ttrain: 1.0 0.010826191264655637 \ttest: 0.96875 2.2157204454058657\n",
      "retrain  84 :\n",
      "\ttrain: 1.0 0.010567470073900648 \ttest: 0.96875 2.212315628896988\n",
      "retrain  85 :\n",
      "\ttrain: 1.0 0.010317898694647437 \ttest: 0.96875 2.208974377650399\n",
      "retrain  86 :\n",
      "\ttrain: 1.0 0.010077051483025805 \ttest: 0.96875 2.2056947787115133\n",
      "retrain  87 :\n",
      "\ttrain: 1.0 0.00984452721909973 \ttest: 0.96875 2.202474998278955\n",
      "retrain  88 :\n",
      "\ttrain: 1.0 0.009619947446823696 \ttest: 0.96875 2.199313277557741\n",
      "retrain  89 :\n",
      "\ttrain: 1.0 0.009402954943970376 \ttest: 0.96875 2.196207928874269\n",
      "retrain  90 :\n",
      "\ttrain: 1.0 0.009193212310544041 \ttest: 0.96875 2.1931573320338247\n",
      "retrain  91 :\n",
      "\ttrain: 1.0 0.00899040066532184 \ttest: 0.96875 2.190159930902947\n",
      "retrain  92 :\n",
      "\ttrain: 1.0 0.008794218441171533 \ttest: 0.96875 2.1872142302004765\n",
      "retrain  93 :\n",
      "\ttrain: 1.0 0.008604380270693546 \ttest: 0.96875 2.184318792482407\n",
      "retrain  94 :\n",
      "\ttrain: 1.0 0.008420615954539084 \ttest: 0.96875 2.1814722353069\n",
      "retrain  95 :\n",
      "\ttrain: 1.0 0.0082426695054761 \ttest: 0.96875 2.1786732285668853\n",
      "retrain  96 :\n",
      "\ttrain: 1.0 0.008070298261920909 \ttest: 0.96875 2.175920491978694\n",
      "retrain  97 :\n",
      "\ttrain: 1.0 0.007903272065232192 \ttest: 0.96875 2.1732127927160807\n",
      "retrain  98 :\n",
      "\ttrain: 1.0 0.007741372495585697 \ttest: 0.96875 2.1705489431797886\n",
      "retrain  99 :\n",
      "\ttrain: 1.0 0.007584392161715587 \ttest: 0.96875 2.1679277988936114\n",
      "retrain  100 :\n",
      "\ttrain: 1.0 0.00743213404023109 \ttest: 0.96875 2.165348256518568\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        37\n",
      "           1    1.00000   1.00000   1.00000        37\n",
      "\n",
      "    accuracy                        1.00000        74\n",
      "   macro avg    1.00000   1.00000   1.00000        74\n",
      "weighted avg    1.00000   1.00000   1.00000        74\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   0.93750   0.96774        16\n",
      "           1    0.94118   1.00000   0.96970        16\n",
      "\n",
      "    accuracy                        0.96875        32\n",
      "   macro avg    0.97059   0.96875   0.96872        32\n",
      "weighted avg    0.97059   0.96875   0.96872        32\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 145\n",
      "Average of depth: 1.110344827586207\n",
      "Number of nodes: 473\n",
      "17 55 1\n",
      "33 123 2\n",
      "43 149 3\n",
      "49 163 4\n",
      "54 178 5\n",
      "61 205 6\n",
      "63 209 7\n",
      "67 211 8\n",
      "72 228 9\n",
      "75 239 10\n",
      "79 251 11\n",
      "80 248 12\n",
      "82 254 13\n",
      "88 280 14\n",
      "90 284 15\n",
      "96 316 16\n",
      "99 325 17\n",
      "99 325 18\n",
      "101 335 19\n",
      "103 339 20\n",
      "104 342 21\n",
      "106 340 22\n",
      "107 347 23\n",
      "108 352 24\n",
      "108 346 25\n",
      "108 346 26\n",
      "109 349 27\n",
      "113 363 28\n",
      "114 366 29\n",
      "115 369 30\n",
      "115 363 31\n",
      "116 366 32\n",
      "117 369 33\n",
      "117 369 34\n",
      "118 372 35\n",
      "119 375 36\n",
      "121 389 37\n",
      "123 397 38\n",
      "126 414 39\n",
      "127 417 40\n",
      "127 417 41\n",
      "130 428 42\n",
      "132 436 43\n",
      "134 442 44\n",
      "135 445 45\n",
      "135 439 46\n",
      "137 445 47\n",
      "138 448 48\n",
      "139 451 49\n",
      "139 451 50\n",
      "139 449 51\n",
      "140 450 52\n",
      "141 457 53\n",
      "141 457 54\n",
      "141 453 55\n",
      "142 456 56\n",
      "142 456 57\n",
      "144 468 58\n",
      "145 475 59\n",
      "148 482 60\n",
      "149 487 61\n",
      "149 487 62\n",
      "150 490 63\n",
      "153 501 64\n",
      "153 501 65\n",
      "157 515 66\n",
      "157 515 67\n",
      "157 515 68\n",
      "157 515 69\n",
      "157 509 70\n",
      "159 521 71\n",
      "159 521 72\n",
      "159 521 73\n",
      "159 521 74\n",
      "160 524 75\n",
      "160 524 76\n",
      "161 527 77\n",
      "161 525 78\n",
      "161 525 79\n",
      "161 525 80\n",
      "162 528 81\n",
      "163 529 82\n",
      "163 529 83\n",
      "164 532 84\n",
      "164 532 85\n",
      "164 532 86\n",
      "164 532 87\n",
      "164 532 88\n",
      "165 533 89\n",
      "165 533 90\n",
      "165 533 91\n",
      "168 546 92\n",
      "169 553 93\n",
      "169 553 94\n",
      "170 558 95\n",
      "171 561 96\n",
      "172 564 97\n",
      "173 567 98\n",
      "173 563 99\n",
      "173 563 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 8.754351054491533 \ttest: 0.71875 11.240908805906589\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 3.8892875936545392 \ttest: 0.75 10.518255275380024\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 2.2308594015149934 \ttest: 0.75 10.326322333212968\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 1.4501378347320384 \ttest: 0.75 10.258071420230285\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.0163027732491035 \ttest: 0.78125 10.230493732516699\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 0.7498067357818836 \ttest: 0.78125 10.219374704812296\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 0.5745603496732361 \ttest: 0.78125 10.21585980574619\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.45339749829733067 \ttest: 0.78125 10.21617693681365\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.3663093063477637 \ttest: 0.78125 10.218535005833548\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.30172780132781696 \ttest: 0.78125 10.222012928218597\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.2525869722675089 \ttest: 0.78125 10.226107773377336\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.21437619850497147 \ttest: 0.78125 10.230532195028566\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.18410947020765106 \ttest: 0.78125 10.235116366080774\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.15974852981379115 \ttest: 0.78125 10.239757468966975\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.13986501431409504 \ttest: 0.78125 10.244392320627064\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.12343485107055131 \ttest: 0.78125 10.248981892361648\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.10970896266937949 \ttest: 0.78125 10.2535022370616\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.09812960666703222 \ttest: 0.78125 10.257939007574736\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.08827486874869876 \ttest: 0.78125 10.262284057724685\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.07982100619546983 \ttest: 0.78125 10.266533287485514\n",
      "retrain  21 :\n",
      "\ttrain: 1.0 0.0725163873661199 \ttest: 0.78125 10.27068525089466\n",
      "retrain  22 :\n",
      "\ttrain: 1.0 0.06616312982407338 \ttest: 0.78125 10.274740242307695\n",
      "retrain  23 :\n",
      "\ttrain: 1.0 0.060603950790229164 \ttest: 0.78125 10.278699688690153\n",
      "retrain  24 :\n",
      "\ttrain: 1.0 0.05571260985404274 \ttest: 0.78125 10.282565741178399\n",
      "retrain  25 :\n",
      "\ttrain: 1.0 0.051386867853529715 \ttest: 0.78125 10.28634099840695\n",
      "retrain  26 :\n",
      "\ttrain: 1.0 0.047543234530013634 \ttest: 0.78125 10.290028318148323\n",
      "retrain  27 :\n",
      "\ttrain: 1.0 0.04411300531238399 \ttest: 0.78125 10.293630688835698\n",
      "retrain  28 :\n",
      "\ttrain: 1.0 0.0410392389193307 \ttest: 0.78125 10.297151142096078\n",
      "retrain  29 :\n",
      "\ttrain: 1.0 0.03827442963054621 \ttest: 0.78125 10.300592693601306\n",
      "retrain  30 :\n",
      "\ttrain: 1.0 0.03577869806251657 \ttest: 0.78125 10.303958303600464\n",
      "retrain  31 :\n",
      "\ttrain: 1.0 0.03351837288121454 \ttest: 0.78125 10.307250851195638\n",
      "retrain  32 :\n",
      "\ttrain: 1.0 0.031464870057665545 \ttest: 0.78125 10.310473118240857\n",
      "retrain  33 :\n",
      "\ttrain: 1.0 0.02959380058813848 \ttest: 0.78125 10.31362777998243\n",
      "retrain  34 :\n",
      "\ttrain: 1.0 0.027884255093713978 \ttest: 0.78125 10.316717400411342\n",
      "retrain  35 :\n",
      "\ttrain: 1.0 0.0263182264290913 \ttest: 0.78125 10.319744430890491\n",
      "retrain  36 :\n",
      "\ttrain: 1.0 0.0248801407626679 \ttest: 0.78125 10.322711211034672\n",
      "retrain  37 :\n",
      "\ttrain: 1.0 0.02355647450194544 \ttest: 0.78125 10.325619971113877\n",
      "retrain  38 :\n",
      "\ttrain: 1.0 0.02233543960200143 \ttest: 0.8125 10.328472835458868\n",
      "retrain  39 :\n",
      "\ttrain: 1.0 0.021206723683793116 \ttest: 0.8125 10.33127182649664\n",
      "retrain  40 :\n",
      "\ttrain: 1.0 0.02016127434065465 \ttest: 0.8125 10.334018869150324\n",
      "retrain  41 :\n",
      "\ttrain: 1.0 0.01919111926784058 \ttest: 0.8125 10.336715795415202\n",
      "retrain  42 :\n",
      "\ttrain: 1.0 0.018289215587001875 \ttest: 0.8125 10.339364348978247\n",
      "retrain  43 :\n",
      "\ttrain: 1.0 0.01744932308344291 \ttest: 0.8125 10.34196618978914\n",
      "retrain  44 :\n",
      "\ttrain: 1.0 0.01666589712346978 \ttest: 0.8125 10.344522898519983\n",
      "retrain  45 :\n",
      "\ttrain: 1.0 0.01593399784229822 \ttest: 0.8125 10.347035980872256\n",
      "retrain  46 :\n",
      "\ttrain: 1.0 0.015249212842314758 \ttest: 0.8125 10.349506871705046\n",
      "retrain  47 :\n",
      "\ttrain: 1.0 0.014607591156463193 \ttest: 0.8125 10.351936938969617\n",
      "retrain  48 :\n",
      "\ttrain: 1.0 0.014005586642078762 \ttest: 0.8125 10.354327487443395\n",
      "retrain  49 :\n",
      "\ttrain: 1.0 0.013440009299412019 \ttest: 0.8125 10.356679762262106\n",
      "retrain  50 :\n",
      "\ttrain: 1.0 0.012907983273855079 \ttest: 0.8125 10.358994952252715\n",
      "retrain  51 :\n",
      "\ttrain: 1.0 0.012406910514988215 \ttest: 0.8125 10.361274193072592\n",
      "retrain  52 :\n",
      "\ttrain: 1.0 0.011934439239452779 \ttest: 0.8125 10.363518570162018\n",
      "retrain  53 :\n",
      "\ttrain: 1.0 0.011488436486475689 \ttest: 0.8125 10.365729121518346\n",
      "retrain  54 :\n",
      "\ttrain: 1.0 0.01106696417100043 \ttest: 0.8125 10.36790684030069\n",
      "retrain  55 :\n",
      "\ttrain: 1.0 0.010668258134839296 \ttest: 0.8125 10.370052677274394\n",
      "retrain  56 :\n",
      "\ttrain: 1.0 0.010290709775028606 \ttest: 0.8125 10.372167543104386\n",
      "retrain  57 :\n",
      "\ttrain: 1.0 0.009932849893786894 \ttest: 0.8125 10.374252310506625\n",
      "retrain  58 :\n",
      "\ttrain: 1.0 0.009593334468670688 \ttest: 0.8125 10.376307816266321\n",
      "retrain  59 :\n",
      "\ttrain: 1.0 0.009270932086701392 \ttest: 0.8125 10.378334863131446\n",
      "retrain  60 :\n",
      "\ttrain: 1.0 0.008964512824023715 \ttest: 0.8125 10.380334221589562\n",
      "retrain  61 :\n",
      "\ttrain: 1.0 0.008673038384358206 \ttest: 0.8125 10.38230663153564\n",
      "retrain  62 :\n",
      "\ttrain: 1.0 0.00839555333618614 \ttest: 0.8125 10.384252803838006\n",
      "retrain  63 :\n",
      "\ttrain: 1.0 0.008131177311118301 \ttest: 0.8125 10.386173421809264\n",
      "retrain  64 :\n",
      "\ttrain: 1.0 0.007879098044951328 \ttest: 0.8125 10.388069142588432\n",
      "retrain  65 :\n",
      "\ttrain: 1.0 0.007638565159082861 \ttest: 0.8125 10.38994059844033\n",
      "retrain  66 :\n",
      "\ttrain: 1.0 0.0074088845937119495 \ttest: 0.8125 10.391788397977649\n",
      "retrain  67 :\n",
      "\ttrain: 1.0 0.007189413615985236 \ttest: 0.8125 10.393613127310925\n",
      "retrain  68 :\n",
      "\ttrain: 1.0 0.0069795563362811544 \ttest: 0.8125 10.395415351131186\n",
      "retrain  69 :\n",
      "\ttrain: 1.0 0.006778759674425554 \ttest: 0.8125 10.397195613729746\n",
      "retrain  70 :\n",
      "\ttrain: 1.0 0.006586509725018665 \ttest: 0.8125 10.398954439959281\n",
      "retrain  71 :\n",
      "\ttrain: 1.0 0.00640232847741597 \ttest: 0.8125 10.400692336140086\n",
      "retrain  72 :\n",
      "\ttrain: 1.0 0.006225770851394834 \ttest: 0.8125 10.402409790915053\n",
      "retrain  73 :\n",
      "\ttrain: 1.0 0.006056422014286168 \ttest: 0.8125 10.404107276056722\n",
      "retrain  74 :\n",
      "\ttrain: 1.0 0.005893894949463891 \ttest: 0.8125 10.40578524722951\n",
      "retrain  75 :\n",
      "\ttrain: 1.0 0.005737828249657656 \ttest: 0.8125 10.40744414470997\n",
      "retrain  76 :\n",
      "\ttrain: 1.0 0.005587884111661317 \ttest: 0.8125 10.409084394067781\n",
      "retrain  77 :\n",
      "\ttrain: 1.0 0.005443746511718703 \ttest: 0.8125 10.41070640680991\n",
      "retrain  78 :\n",
      "\ttrain: 1.0 0.0053051195432339375 \ttest: 0.8125 10.412310580990333\n",
      "retrain  79 :\n",
      "\ttrain: 1.0 0.005171725900522201 \ttest: 0.8125 10.413897301787372\n",
      "retrain  80 :\n",
      "\ttrain: 1.0 0.005043305494131267 \ttest: 0.8125 10.415466942050706\n",
      "retrain  81 :\n",
      "\ttrain: 1.0 0.004919614184855328 \ttest: 0.8125 10.41701986281991\n",
      "retrain  82 :\n",
      "\ttrain: 1.0 0.004800422624963193 \ttest: 0.8125 10.418556413816237\n",
      "retrain  83 :\n",
      "\ttrain: 1.0 0.004685515196395287 \ttest: 0.8125 10.420076933909279\n",
      "retrain  84 :\n",
      "\ttrain: 1.0 0.004574689036772054 \ttest: 0.8125 10.421581751559975\n",
      "retrain  85 :\n",
      "\ttrain: 1.0 0.004467753145016829 \ttest: 0.8125 10.423071185241428\n",
      "retrain  86 :\n",
      "\ttrain: 1.0 0.0043645275592467765 \ttest: 0.8125 10.424545543838775\n",
      "retrain  87 :\n",
      "\ttrain: 1.0 0.004264842600338869 \ttest: 0.8125 10.426005127029377\n",
      "retrain  88 :\n",
      "\ttrain: 1.0 0.004168538175246429 \ttest: 0.8125 10.427450225644453\n",
      "retrain  89 :\n",
      "\ttrain: 1.0 0.004075463134735826 \ttest: 0.8125 10.428881122013212\n",
      "retrain  90 :\n",
      "\ttrain: 1.0 0.003985474680742056 \ttest: 0.8125 10.43029809029052\n",
      "retrain  91 :\n",
      "\ttrain: 1.0 0.0038984378190124163 \ttest: 0.8125 10.43170139676896\n",
      "retrain  92 :\n",
      "\ttrain: 1.0 0.0038142248531282175 \ttest: 0.8125 10.433091300176239\n",
      "retrain  93 :\n",
      "\ttrain: 1.0 0.0037327149163702304 \ttest: 0.8125 10.43446805195871\n",
      "retrain  94 :\n",
      "\ttrain: 1.0 0.003653793538228603 \ttest: 0.8125 10.435831896551775\n",
      "retrain  95 :\n",
      "\ttrain: 1.0 0.0035773522426598738 \ttest: 0.8125 10.43718307163789\n",
      "retrain  96 :\n",
      "\ttrain: 1.0 0.0035032881754625844 \ttest: 0.8125 10.438521808392869\n",
      "retrain  97 :\n",
      "\ttrain: 1.0 0.0034315037583855313 \ttest: 0.8125 10.439848331721063\n",
      "retrain  98 :\n",
      "\ttrain: 1.0 0.0033619063678002417 \ttest: 0.8125 10.441162860480055\n",
      "retrain  99 :\n",
      "\ttrain: 1.0 0.0032944080359650443 \ttest: 0.8125 10.442465607695414\n",
      "retrain  100 :\n",
      "\ttrain: 1.0 0.0032289251730843703 \ttest: 0.8125 10.443756780765987\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        37\n",
      "           1    1.00000   1.00000   1.00000        37\n",
      "\n",
      "    accuracy                        1.00000        74\n",
      "   macro avg    1.00000   1.00000   1.00000        74\n",
      "weighted avg    1.00000   1.00000   1.00000        74\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.81250   0.81250   0.81250        16\n",
      "           1    0.81250   0.81250   0.81250        16\n",
      "\n",
      "    accuracy                        0.81250        32\n",
      "   macro avg    0.81250   0.81250   0.81250        32\n",
      "weighted avg    0.81250   0.81250   0.81250        32\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 173\n",
      "Average of depth: 1.1098265895953756\n",
      "Number of nodes: 563\n",
      "16 58 1\n",
      "27 85 2\n",
      "38 122 3\n",
      "42 134 4\n",
      "49 157 5\n",
      "52 166 6\n",
      "53 169 7\n",
      "55 177 8\n",
      "57 183 9\n",
      "59 189 10\n",
      "61 195 11\n",
      "63 201 12\n",
      "66 212 13\n",
      "68 218 14\n",
      "69 225 15\n",
      "71 231 16\n",
      "76 252 17\n",
      "78 258 18\n",
      "80 260 19\n",
      "80 260 20\n",
      "82 272 21\n",
      "84 278 22\n",
      "85 279 23\n",
      "86 276 24\n",
      "88 282 25\n",
      "88 282 26\n",
      "88 282 27\n",
      "89 285 28\n",
      "91 291 29\n",
      "94 306 30\n",
      "94 306 31\n",
      "95 309 32\n",
      "97 319 33\n",
      "97 319 34\n",
      "97 319 35\n",
      "98 322 36\n",
      "98 322 37\n",
      "98 322 38\n",
      "101 335 39\n",
      "102 338 40\n",
      "104 344 41\n",
      "105 347 42\n",
      "108 360 43\n",
      "108 360 44\n",
      "108 360 45\n",
      "109 363 46\n",
      "110 364 47\n",
      "111 367 48\n",
      "111 367 49\n",
      "111 365 50\n",
      "111 365 51\n",
      "111 365 52\n",
      "114 374 53\n",
      "114 374 54\n",
      "114 374 55\n",
      "115 377 56\n",
      "115 377 57\n",
      "115 377 58\n",
      "116 382 59\n",
      "120 400 60\n",
      "120 400 61\n",
      "120 396 62\n",
      "123 405 63\n",
      "123 405 64\n",
      "123 405 65\n",
      "124 408 66\n",
      "125 413 67\n",
      "126 418 68\n",
      "126 418 69\n",
      "126 418 70\n",
      "126 418 71\n",
      "126 418 72\n",
      "126 418 73\n",
      "126 418 74\n",
      "126 418 75\n",
      "126 418 76\n",
      "126 418 77\n",
      "126 418 78\n",
      "126 418 79\n",
      "128 424 80\n",
      "130 434 81\n",
      "130 434 82\n",
      "132 444 83\n",
      "133 447 84\n",
      "133 445 85\n",
      "134 448 86\n",
      "135 451 87\n",
      "137 463 88\n",
      "138 468 89\n",
      "138 468 90\n",
      "139 473 91\n",
      "140 478 92\n",
      "141 481 93\n",
      "141 481 94\n",
      "141 481 95\n",
      "142 486 96\n",
      "142 484 97\n",
      "142 484 98\n",
      "142 484 99\n",
      "142 484 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.9864864864864865 13.076599026345903 \ttest: 0.90625 8.603341032166231\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 6.8238738838433814 \ttest: 0.90625 6.45690589979161\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 4.295721989566175 \ttest: 0.90625 5.549966386253488\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 2.978739752461202 \ttest: 0.90625 5.065367867135226\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 2.1891460035409493 \ttest: 0.90625 4.767336141954957\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 1.6735415816731058 \ttest: 0.90625 4.566745586690915\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 1.3172197145902227 \ttest: 0.90625 4.423169477469787\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 1.0607666140453236 \ttest: 0.90625 4.3157675110238305\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.870377547284626 \ttest: 0.90625 4.2327374173601635\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.7254754712798936 \ttest: 0.90625 4.166899222046746\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.6128905489896698 \ttest: 0.90625 4.113633170002606\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.5238609625004298 \ttest: 0.90625 4.069830602300918\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.45237394459120933 \ttest: 0.90625 4.033322022220529\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.3941959953630661 \ttest: 0.90625 4.002547064186933\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.3462806108014198 \ttest: 0.90625 3.9763547823448984\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.30639352459810576 \ttest: 0.90625 3.9538778420447125\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.2728685147930545 \ttest: 0.90625 3.93445049801715\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.24444427329888802 \ttest: 0.90625 3.917553514324452\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.22015305238305033 \ttest: 0.90625 3.902776214378223\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.199243196480377 \ttest: 0.90625 3.8897897395588124\n",
      "retrain  21 :\n",
      "\ttrain: 1.0 0.18112432586301636 \ttest: 0.90625 3.8783278293623606\n",
      "retrain  22 :\n",
      "\ttrain: 1.0 0.16532795022741725 \ttest: 0.90625 3.8681727628891824\n",
      "retrain  23 :\n",
      "\ttrain: 1.0 0.15147877166529605 \ttest: 0.90625 3.859144913221827\n",
      "retrain  24 :\n",
      "\ttrain: 1.0 0.1392735070781699 \ttest: 0.90625 3.8510948762023203\n",
      "retrain  25 :\n",
      "\ttrain: 1.0 0.12846507461262274 \ttest: 0.90625 3.8438974632344545\n",
      "retrain  26 :\n",
      "\ttrain: 1.0 0.11885065606389028 \ttest: 0.90625 3.837447063444782\n",
      "retrain  27 :\n",
      "\ttrain: 1.0 0.11026259350557349 \ttest: 0.90625 3.831654025135018\n",
      "retrain  28 :\n",
      "\ttrain: 1.0 0.10256138140709421 \ttest: 0.90625 3.8264418051208757\n",
      "retrain  29 :\n",
      "\ttrain: 1.0 0.09563022408247421 \ttest: 0.90625 3.82174470296672\n",
      "retrain  30 :\n",
      "\ttrain: 1.0 0.08937077375062931 \ttest: 0.90625 3.8175060452712546\n",
      "retrain  31 :\n",
      "\ttrain: 1.0 0.08369976711133187 \ttest: 0.90625 3.813676719504301\n",
      "retrain  32 :\n",
      "\ttrain: 1.0 0.07854635156586141 \ttest: 0.90625 3.8102139817028537\n",
      "retrain  33 :\n",
      "\ttrain: 1.0 0.0738499450069984 \ttest: 0.90625 3.80708048046243\n",
      "retrain  34 :\n",
      "\ttrain: 1.0 0.06955851154392745 \ttest: 0.90625 3.804243453048861\n",
      "retrain  35 :\n",
      "\ttrain: 1.0 0.0656271637763091 \ttest: 0.90625 3.801674059443889\n",
      "retrain  36 :\n",
      "\ttrain: 1.0 0.062017023172323923 \ttest: 0.90625 3.799346827658607\n",
      "retrain  37 :\n",
      "\ttrain: 1.0 0.05869428575703644 \ttest: 0.90625 3.7972391893610564\n",
      "retrain  38 :\n",
      "\ttrain: 1.0 0.05562945210754529 \ttest: 0.90625 3.7953310892383794\n",
      "retrain  39 :\n",
      "\ttrain: 1.0 0.052796689598810835 \ttest: 0.90625 3.7936046548890445\n",
      "retrain  40 :\n",
      "\ttrain: 1.0 0.050173301682162115 \ttest: 0.90625 3.7920439166639244\n",
      "retrain  41 :\n",
      "\ttrain: 1.0 0.047739284239691177 \ttest: 0.90625 3.7906345689275414\n",
      "retrain  42 :\n",
      "\ttrain: 1.0 0.04547695313161148 \ttest: 0.90625 3.7893637658273853\n",
      "retrain  43 :\n",
      "\ttrain: 1.0 0.04337063022741457 \ttest: 0.90625 3.788219945940037\n",
      "retrain  44 :\n",
      "\ttrain: 1.0 0.04140637769860345 \ttest: 0.90625 3.7871926811834755\n",
      "retrain  45 :\n",
      "\ttrain: 1.0 0.03957177231039903 \ttest: 0.90625 3.786272546202917\n",
      "retrain  46 :\n",
      "\ttrain: 1.0 0.037855713002160146 \ttest: 0.90625 3.785451005096234\n",
      "retrain  47 :\n",
      "\ttrain: 1.0 0.03624825628224086 \ttest: 0.90625 3.7847203128782905\n",
      "retrain  48 :\n",
      "\ttrain: 1.0 0.03474047495192875 \ttest: 0.90625 3.784073429517211\n",
      "retrain  49 :\n",
      "\ttrain: 1.0 0.03332433646805537 \ttest: 0.90625 3.783503944729907\n",
      "retrain  50 :\n",
      "\ttrain: 1.0 0.031992597895775604 \ttest: 0.90625 3.783006012014913\n",
      "retrain  51 :\n",
      "\ttrain: 1.0 0.030738714923579612 \ttest: 0.90625 3.7825742906401048\n",
      "retrain  52 :\n",
      "\ttrain: 1.0 0.02955676283652262 \ttest: 0.90625 3.782203894500954\n",
      "retrain  53 :\n",
      "\ttrain: 1.0 0.02844136769025927 \ttest: 0.90625 3.781890346929504\n",
      "retrain  54 :\n",
      "\ttrain: 1.0 0.02738764621294374 \ttest: 0.90625 3.7816295406713203\n",
      "retrain  55 :\n",
      "\ttrain: 1.0 0.026391153196408237 \ttest: 0.90625 3.781417702362271\n",
      "retrain  56 :\n",
      "\ttrain: 1.0 0.025447835331781295 \ttest: 0.90625 3.78125136093319\n",
      "retrain  57 :\n",
      "\ttrain: 1.0 0.024553990605444054 \ttest: 0.9375 3.7811273194514077\n",
      "retrain  58 :\n",
      "\ttrain: 1.0 0.023706232505011762 \ttest: 0.9375 3.7810426299765187\n",
      "retrain  59 :\n",
      "\ttrain: 1.0 0.022901458396751406 \ttest: 0.9375 3.780994571065611\n",
      "retrain  60 :\n",
      "\ttrain: 1.0 0.022136821529426087 \ttest: 0.9375 3.7809806276123634\n",
      "retrain  61 :\n",
      "\ttrain: 1.0 0.02140970619818334 \ttest: 0.9375 3.7809984727463126\n",
      "retrain  62 :\n",
      "\ttrain: 1.0 0.020717705668351467 \ttest: 0.9375 3.781045951554307\n",
      "retrain  63 :\n",
      "\ttrain: 1.0 0.020058602514987423 \ttest: 0.9375 3.7811210664168495\n",
      "retrain  64 :\n",
      "\ttrain: 1.0 0.019430351081447007 \ttest: 0.9375 3.7812219637782465\n",
      "retrain  65 :\n",
      "\ttrain: 1.0 0.018831061800541848 \ttest: 0.9375 3.781346922192154\n",
      "retrain  66 :\n",
      "\ttrain: 1.0 0.018258987156160728 \ttest: 0.9375 3.7814943415035875\n",
      "retrain  67 :\n",
      "\ttrain: 1.0 0.01771250909253263 \ttest: 0.9375 3.781662733045338\n",
      "retrain  68 :\n",
      "\ttrain: 1.0 0.01719012770338317 \ttest: 0.9375 3.7818507107413315\n",
      "retrain  69 :\n",
      "\ttrain: 1.0 0.016690451054747344 \ttest: 0.9375 3.782056983022172\n",
      "retrain  70 :\n",
      "\ttrain: 1.0 0.016212186013695236 \ttest: 0.9375 3.782280345469132\n",
      "retrain  71 :\n",
      "\ttrain: 1.0 0.015754129971164908 \ttest: 0.9375 3.782519674112472\n",
      "retrain  72 :\n",
      "\ttrain: 1.0 0.015315163360857965 \ttest: 0.9375 3.78277391931838\n",
      "retrain  73 :\n",
      "\ttrain: 1.0 0.014894242888061814 \ttest: 0.9375 3.783042100206177\n",
      "retrain  74 :\n",
      "\ttrain: 1.0 0.014490395392588569 \ttest: 0.9375 3.7833232995438775\n",
      "retrain  75 :\n",
      "\ttrain: 1.0 0.0141027122789909 \ttest: 0.9375 3.7836166590758444\n",
      "retrain  76 :\n",
      "\ttrain: 1.0 0.013730344455023712 \ttest: 0.9375 3.7839213752412926\n",
      "retrain  77 :\n",
      "\ttrain: 1.0 0.013372497726131034 \ttest: 0.9375 3.784236695246756\n",
      "retrain  78 :\n",
      "\ttrain: 1.0 0.013028428599685138 \ttest: 0.9375 3.784561913459515\n",
      "retrain  79 :\n",
      "\ttrain: 1.0 0.012697440457913902 \ttest: 0.9375 3.7848963680924226\n",
      "retrain  80 :\n",
      "\ttrain: 1.0 0.012378880063015336 \ttest: 0.9375 3.7852394381535843\n",
      "retrain  81 :\n",
      "\ttrain: 1.0 0.01207213436196844 \ttest: 0.9375 3.7855905406370556\n",
      "retrain  82 :\n",
      "\ttrain: 1.0 0.011776627562074996 \ttest: 0.9375 3.785949127933101\n",
      "retrain  83 :\n",
      "\ttrain: 1.0 0.01149181845137423 \ttest: 0.9375 3.7863146854386844\n",
      "retrain  84 :\n",
      "\ttrain: 1.0 0.011217197940813127 \ttest: 0.9375 3.7866867293507576\n",
      "retrain  85 :\n",
      "\ttrain: 1.0 0.010952286807478584 \ttest: 0.9375 3.7870648046266213\n",
      "retrain  86 :\n",
      "\ttrain: 1.0 0.010696633620340772 \ttest: 0.9375 3.7874484830971005\n",
      "retrain  87 :\n",
      "\ttrain: 1.0 0.010449812831858963 \ttest: 0.9375 3.7878373617196752\n",
      "retrain  88 :\n",
      "\ttrain: 1.0 0.010211423020486776 \ttest: 0.9375 3.7882310609598835\n",
      "retrain  89 :\n",
      "\ttrain: 1.0 0.00998108527061393 \ttest: 0.9375 3.788629223290399\n",
      "retrain  90 :\n",
      "\ttrain: 1.0 0.009758441677815964 \ttest: 0.9375 3.7890315117981825\n",
      "retrain  91 :\n",
      "\ttrain: 1.0 0.00954315396847211 \ttest: 0.9375 3.7894376088909545\n",
      "retrain  92 :\n",
      "\ttrain: 1.0 0.009334902223873773 \ttest: 0.9375 3.789847215095037\n",
      "retrain  93 :\n",
      "\ttrain: 1.0 0.009133383699893742 \ttest: 0.9375 3.790260047937318\n",
      "retrain  94 :\n",
      "\ttrain: 1.0 0.008938311734134381 \ttest: 0.9375 3.7906758409047314\n",
      "retrain  95 :\n",
      "\ttrain: 1.0 0.008749414733233474 \ttest: 0.9375 3.791094342475221\n",
      "retrain  96 :\n",
      "\ttrain: 1.0 0.008566435233687306 \ttest: 0.9375 3.7915153152146885\n",
      "retrain  97 :\n",
      "\ttrain: 1.0 0.008389129030162428 \ttest: 0.9375 3.7919385349348738\n",
      "retrain  98 :\n",
      "\ttrain: 1.0 0.008217264365817276 \ttest: 0.9375 3.792363789907577\n",
      "retrain  99 :\n",
      "\ttrain: 1.0 0.008050621179649718 \ttest: 0.9375 3.792790880130983\n",
      "retrain  100 :\n",
      "\ttrain: 1.0 0.00788899040633197 \ttest: 0.9375 3.7932196166442402\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        37\n",
      "           1    1.00000   1.00000   1.00000        37\n",
      "\n",
      "    accuracy                        1.00000        74\n",
      "   macro avg    1.00000   1.00000   1.00000        74\n",
      "weighted avg    1.00000   1.00000   1.00000        74\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.93750   0.93750   0.93750        16\n",
      "           1    0.93750   0.93750   0.93750        16\n",
      "\n",
      "    accuracy                        0.93750        32\n",
      "   macro avg    0.93750   0.93750   0.93750        32\n",
      "weighted avg    0.93750   0.93750   0.93750        32\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 142\n",
      "Average of depth: 1.176056338028169\n",
      "Number of nodes: 484\n",
      "16 54 1\n",
      "28 94 2\n",
      "36 120 3\n",
      "41 135 4\n",
      "48 156 5\n",
      "48 150 6\n",
      "54 172 7\n",
      "59 193 8\n",
      "64 214 9\n",
      "66 218 10\n",
      "68 226 11\n",
      "71 235 12\n",
      "75 253 13\n",
      "75 251 14\n",
      "79 263 15\n",
      "81 267 16\n",
      "83 277 17\n",
      "84 278 18\n",
      "84 276 19\n",
      "84 276 20\n",
      "85 279 21\n",
      "87 291 22\n",
      "89 295 23\n",
      "90 300 24\n",
      "91 303 25\n",
      "91 303 26\n",
      "92 304 27\n",
      "93 303 28\n",
      "96 312 29\n",
      "98 318 30\n",
      "102 330 31\n",
      "104 338 32\n",
      "106 344 33\n",
      "109 355 34\n",
      "110 358 35\n",
      "112 366 36\n",
      "112 366 37\n",
      "114 374 38\n",
      "117 385 39\n",
      "118 388 40\n",
      "119 393 41\n",
      "120 396 42\n",
      "120 396 43\n",
      "120 396 44\n",
      "121 405 45\n",
      "121 399 46\n",
      "122 402 47\n",
      "122 402 48\n",
      "123 407 49\n",
      "123 407 50\n",
      "125 417 51\n",
      "125 415 52\n",
      "127 425 53\n",
      "127 425 54\n",
      "128 428 55\n",
      "130 436 56\n",
      "131 441 57\n",
      "131 441 58\n",
      "132 444 59\n",
      "132 444 60\n",
      "133 447 61\n",
      "134 446 62\n",
      "136 452 63\n",
      "136 452 64\n",
      "136 452 65\n",
      "136 452 66\n",
      "136 452 67\n",
      "136 452 68\n",
      "136 452 69\n",
      "136 452 70\n",
      "136 452 71\n",
      "137 455 72\n",
      "138 460 73\n",
      "138 460 74\n",
      "139 465 75\n",
      "139 461 76\n",
      "139 461 77\n",
      "140 464 78\n",
      "140 462 79\n",
      "140 462 80\n",
      "140 462 81\n",
      "140 458 82\n",
      "141 461 83\n",
      "141 459 84\n",
      "141 457 85\n",
      "142 460 86\n",
      "142 458 87\n",
      "142 458 88\n",
      "142 458 89\n",
      "142 458 90\n",
      "143 461 91\n",
      "143 461 92\n",
      "143 459 93\n",
      "143 459 94\n",
      "143 459 95\n",
      "143 459 96\n",
      "144 462 97\n",
      "144 462 98\n",
      "144 462 99\n",
      "145 465 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 12.168622787984742 \ttest: 0.90625 9.773805533922514\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 5.939563681760221 \ttest: 0.90625 7.93726714549932\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 3.562251967678849 \ttest: 0.9375 7.113082268037557\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 2.3873087186239776 \ttest: 0.9375 6.638481018805116\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.7126426143543996 \ttest: 0.9375 6.324055230629897\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 1.2868378925032258 \ttest: 0.9375 6.097423569011317\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 1.000256441682174 \ttest: 0.9375 5.924893593984578\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.7981728355253368 \ttest: 0.9375 5.7884612419178\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.6505029533213949 \ttest: 0.9375 5.677505918422993\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.5394865113730553 \ttest: 0.9375 5.585292553456066\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.45405304666077423 \ttest: 0.9375 5.507312143479153\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.3870006824656521 \ttest: 0.9375 5.440417247478122\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.33347919067190696 \ttest: 0.9375 5.382336918127867\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.29012672910048176 \ttest: 0.9375 5.331387906280058\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.25455543827974403 \ttest: 0.9375 5.286294293235216\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.22503304188604226 \ttest: 0.9375 5.246070345530639\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.20027936145208514 \ttest: 0.9375 5.209941917736197\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.17933266036630074 \ttest: 0.9375 5.177292252392122\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.16145973835747707 \ttest: 0.9375 5.147623715836601\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.1460941731928162 \ttest: 0.9375 5.1205302280382705\n",
      "retrain  21 :\n",
      "\ttrain: 1.0 0.13279309723971516 \ttest: 0.9375 5.095677038670548\n",
      "retrain  22 :\n",
      "\ttrain: 1.0 0.12120643386565083 \ttest: 0.9375 5.072785654226027\n",
      "retrain  23 :\n",
      "\ttrain: 1.0 0.11105466634593036 \ttest: 0.9375 5.051622443110978\n",
      "retrain  24 :\n",
      "\ttrain: 1.0 0.10211254846121613 \ttest: 0.9375 5.031989909864978\n",
      "retrain  25 :\n",
      "\ttrain: 1.0 0.09419701616320691 \ttest: 0.9375 5.013719934882063\n",
      "retrain  26 :\n",
      "\ttrain: 1.0 0.0871581113265947 \ttest: 0.9375 4.996668480798908\n",
      "retrain  27 :\n",
      "\ttrain: 1.0 0.08087209300753823 \ttest: 0.9375 4.980711406624433\n",
      "retrain  28 :\n",
      "\ttrain: 1.0 0.07523615631910782 \ttest: 0.9375 4.965741127846022\n",
      "retrain  29 :\n",
      "\ttrain: 1.0 0.07016434582822771 \ttest: 0.9375 4.951663929233094\n",
      "retrain  30 :\n",
      "\ttrain: 1.0 0.06558436566249973 \ttest: 0.9375 4.938397785994114\n",
      "retrain  31 :\n",
      "\ttrain: 1.0 0.06143506922742101 \ttest: 0.9375 4.925870584349534\n",
      "retrain  32 :\n",
      "\ttrain: 1.0 0.057664468622118034 \ttest: 0.9375 4.914018658498753\n",
      "retrain  33 :\n",
      "\ttrain: 1.0 0.05422814481600528 \ttest: 0.9375 4.902785580132638\n",
      "retrain  34 :\n",
      "\ttrain: 1.0 0.05108796931464402 \ttest: 0.9375 4.892121150970478\n",
      "retrain  35 :\n",
      "\ttrain: 1.0 0.04821106973308014 \ttest: 0.9375 4.881980559606592\n",
      "retrain  36 :\n",
      "\ttrain: 1.0 0.04556898770032512 \ttest: 0.9375 4.872323672173691\n",
      "retrain  37 :\n",
      "\ttrain: 1.0 0.04313698943235888 \ttest: 0.9375 4.86311443263716\n",
      "retrain  38 :\n",
      "\ttrain: 1.0 0.040893498252162264 \ttest: 0.9375 4.854320353409726\n",
      "retrain  39 :\n",
      "\ttrain: 1.0 0.038819625097829866 \ttest: 0.9375 4.845912080772225\n",
      "retrain  40 :\n",
      "\ttrain: 1.0 0.036898778212376734 \ttest: 0.9375 4.837863022562323\n",
      "retrain  41 :\n",
      "\ttrain: 1.0 0.03511633716223637 \ttest: 0.9375 4.8301490279415455\n",
      "retrain  42 :\n",
      "\ttrain: 1.0 0.03345937938494291 \ttest: 0.9375 4.822748110915457\n",
      "retrain  43 :\n",
      "\ttrain: 1.0 0.031916449839875384 \ttest: 0.9375 4.815640210770959\n",
      "retrain  44 :\n",
      "\ttrain: 1.0 0.03047736619183324 \ttest: 0.9375 4.8088069837902765\n",
      "retrain  45 :\n",
      "\ttrain: 1.0 0.029133053416796974 \ttest: 0.9375 4.802231621566555\n",
      "retrain  46 :\n",
      "\ttrain: 1.0 0.027875402873445705 \ttest: 0.9375 4.79589869202912\n",
      "retrain  47 :\n",
      "\ttrain: 1.0 0.026697151801534973 \ttest: 0.9375 4.789793999924903\n",
      "retrain  48 :\n",
      "\ttrain: 1.0 0.025591779941283692 \ttest: 0.9375 4.783904464025458\n",
      "retrain  49 :\n",
      "\ttrain: 1.0 0.024553420556398697 \ttest: 0.9375 4.778218008759056\n",
      "retrain  50 :\n",
      "\ttrain: 1.0 0.02357678361796081 \ttest: 0.9375 4.7727234683227096\n",
      "retrain  51 :\n",
      "\ttrain: 1.0 0.02265708929084955 \ttest: 0.9375 4.7674105016235675\n",
      "retrain  52 :\n",
      "\ttrain: 1.0 0.02179001017713287 \ttest: 0.9375 4.762269516644474\n",
      "retrain  53 :\n",
      "\ttrain: 1.0 0.020971621026313017 \ttest: 0.9375 4.757291603033503\n",
      "retrain  54 :\n",
      "\ttrain: 1.0 0.02019835483180609 \ttest: 0.9375 4.752468471889177\n",
      "retrain  55 :\n",
      "\ttrain: 1.0 0.019466964405470737 \ttest: 0.9375 4.747792401857742\n",
      "retrain  56 :\n",
      "\ttrain: 1.0 0.01877448866445549 \ttest: 0.9375 4.743256190781032\n",
      "retrain  57 :\n",
      "\ttrain: 1.0 0.018118222982736697 \ttest: 0.9375 4.738853112236862\n",
      "retrain  58 :\n",
      "\ttrain: 1.0 0.017495693057956778 \ttest: 0.9375 4.734576876401812\n",
      "retrain  59 :\n",
      "\ttrain: 1.0 0.016904631826160886 \ttest: 0.9375 4.730421594741069\n",
      "retrain  60 :\n",
      "\ttrain: 1.0 0.016342959025668014 \ttest: 0.9375 4.726381748094034\n",
      "retrain  61 :\n",
      "\ttrain: 1.0 0.015808763068950807 \ttest: 0.9375 4.722452157779163\n",
      "retrain  62 :\n",
      "\ttrain: 1.0 0.015300284929941746 \ttest: 0.9375 4.718627959388636\n",
      "retrain  63 :\n",
      "\ttrain: 1.0 0.014815903795184295 \ttest: 0.9375 4.71490457898395\n",
      "retrain  64 :\n",
      "\ttrain: 1.0 0.014354124261972164 \ttest: 0.9375 4.711277711438595\n",
      "retrain  65 :\n",
      "\ttrain: 1.0 0.013913564896108527 \ttest: 0.9375 4.70774330070425\n",
      "retrain  66 :\n",
      "\ttrain: 1.0 0.01349294798702375 \ttest: 0.9375 4.704297521803218\n",
      "retrain  67 :\n",
      "\ttrain: 1.0 0.01309109035941845 \ttest: 0.9375 4.700936764372667\n",
      "retrain  68 :\n",
      "\ttrain: 1.0 0.012706895118934875 \ttest: 0.9375 4.6976576176061995\n",
      "retrain  69 :\n",
      "\ttrain: 1.0 0.012339344225083218 \ttest: 0.9375 4.694456856455568\n",
      "retrain  70 :\n",
      "\ttrain: 1.0 0.011987491798165963 \ttest: 0.9375 4.691331428970691\n",
      "retrain  71 :\n",
      "\ttrain: 1.0 0.011650458078588617 \ttest: 0.9375 4.688278444669333\n",
      "retrain  72 :\n",
      "\ttrain: 1.0 0.011327423966997548 \ttest: 0.9375 4.6852951638396085\n",
      "retrain  73 :\n",
      "\ttrain: 1.0 0.011017626082384265 \ttest: 0.9375 4.682378987688758\n",
      "retrain  74 :\n",
      "\ttrain: 1.0 0.010720352282835386 \ttest: 0.9375 4.679527449260705\n",
      "retrain  75 :\n",
      "\ttrain: 1.0 0.010434937600157287 \ttest: 0.9375 4.676738205052967\n",
      "retrain  76 :\n",
      "\ttrain: 1.0 0.010160760545306041 \ttest: 0.9375 4.674009027270569\n",
      "retrain  77 :\n",
      "\ttrain: 1.0 0.009897239746522728 \ttest: 0.9375 4.671337796660903\n",
      "retrain  78 :\n",
      "\ttrain: 1.0 0.009643830886417088 \ttest: 0.9375 4.668722495879091\n",
      "retrain  79 :\n",
      "\ttrain: 1.0 0.00940002390804227 \ttest: 0.9375 4.666161203338309\n",
      "retrain  80 :\n",
      "\ttrain: 1.0 0.009165340463334379 \ttest: 0.9375 4.66365208750403\n",
      "retrain  81 :\n",
      "\ttrain: 1.0 0.008939331580215499 \ttest: 0.9375 4.66119340159503\n",
      "retrain  82 :\n",
      "\ttrain: 1.0 0.008721575527231875 \ttest: 0.9375 4.658783478657551\n",
      "retrain  83 :\n",
      "\ttrain: 1.0 0.00851167585686514 \ttest: 0.9375 4.656420726982136\n",
      "retrain  84 :\n",
      "\ttrain: 1.0 0.008309259610654512 \ttest: 0.9375 4.6541036258355115\n",
      "retrain  85 :\n",
      "\ttrain: 1.0 0.008113975671035036 \ttest: 0.9375 4.651830721482387\n",
      "retrain  86 :\n",
      "\ttrain: 1.0 0.00792549324636107 \ttest: 0.9375 4.649600623474323\n",
      "retrain  87 :\n",
      "\ttrain: 1.0 0.00774350047697046 \ttest: 0.9375 4.64741200118487\n",
      "retrain  88 :\n",
      "\ttrain: 1.0 0.007567703151375088 \ttest: 0.9375 4.64526358057201\n",
      "retrain  89 :\n",
      "\ttrain: 1.0 0.0073978235227572745 \ttest: 0.9375 4.643154141150594\n",
      "retrain  90 :\n",
      "\ttrain: 1.0 0.007233599216924638 \ttest: 0.9375 4.641082513158959\n",
      "retrain  91 :\n",
      "\ttrain: 1.0 0.007074782223743471 \ttest: 0.9375 4.639047574905252\n",
      "retrain  92 :\n",
      "\ttrain: 1.0 0.0069211379648445835 \ttest: 0.9375 4.637048250280262\n",
      "retrain  93 :\n",
      "\ttrain: 1.0 0.006772444431087514 \ttest: 0.9375 4.635083506424575\n",
      "retrain  94 :\n",
      "\ttrain: 1.0 0.006628491383887091 \ttest: 0.9375 4.6331523515389685\n",
      "retrain  95 :\n",
      "\ttrain: 1.0 0.006489079615061067 \ttest: 0.9375 4.6312538328277935\n",
      "retrain  96 :\n",
      "\ttrain: 1.0 0.006354020260353928 \ttest: 0.9375 4.629387034565999\n",
      "retrain  97 :\n",
      "\ttrain: 1.0 0.0062231341622386045 \ttest: 0.9375 4.627551076281116\n",
      "retrain  98 :\n",
      "\ttrain: 1.0 0.00609625127799846 \ttest: 0.9375 4.625745111042264\n",
      "retrain  99 :\n",
      "\ttrain: 1.0 0.005973210129452785 \ttest: 0.9375 4.623968323848901\n",
      "retrain  100 :\n",
      "\ttrain: 1.0 0.005853857291014257 \ttest: 0.9375 4.62221993011248\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        37\n",
      "           1    1.00000   1.00000   1.00000        37\n",
      "\n",
      "    accuracy                        1.00000        74\n",
      "   macro avg    1.00000   1.00000   1.00000        74\n",
      "weighted avg    1.00000   1.00000   1.00000        74\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.93750   0.93750   0.93750        16\n",
      "           1    0.93750   0.93750   0.93750        16\n",
      "\n",
      "    accuracy                        0.93750        32\n",
      "   macro avg    0.93750   0.93750   0.93750        32\n",
      "weighted avg    0.93750   0.93750   0.93750        32\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 145\n",
      "Average of depth: 1.103448275862069\n",
      "Number of nodes: 465\n",
      "20 72 1\n",
      "31 113 2\n",
      "37 125 3\n",
      "39 129 4\n",
      "41 135 5\n",
      "42 136 6\n",
      "46 148 7\n",
      "49 163 8\n",
      "50 164 9\n",
      "56 184 10\n",
      "59 193 11\n",
      "62 200 12\n",
      "65 211 13\n",
      "67 217 14\n",
      "68 220 15\n",
      "71 229 16\n",
      "72 232 17\n",
      "73 233 18\n",
      "74 236 19\n",
      "79 255 20\n",
      "81 263 21\n",
      "85 277 22\n",
      "87 283 23\n",
      "90 294 24\n",
      "92 300 25\n",
      "92 300 26\n",
      "94 302 27\n",
      "96 316 28\n",
      "98 318 29\n",
      "100 326 30\n",
      "100 326 31\n",
      "101 327 32\n",
      "103 333 33\n",
      "104 334 34\n",
      "104 334 35\n",
      "104 334 36\n",
      "104 334 37\n",
      "106 340 38\n",
      "107 341 39\n",
      "107 341 40\n",
      "110 354 41\n",
      "110 352 42\n",
      "110 352 43\n",
      "111 355 44\n",
      "112 360 45\n",
      "112 360 46\n",
      "113 359 47\n",
      "114 362 48\n",
      "114 360 49\n",
      "115 363 50\n",
      "118 370 51\n",
      "118 368 52\n",
      "118 368 53\n",
      "118 368 54\n",
      "119 371 55\n",
      "119 371 56\n",
      "119 371 57\n",
      "121 383 58\n",
      "122 388 59\n",
      "122 388 60\n",
      "122 388 61\n",
      "122 388 62\n",
      "122 386 63\n",
      "121 377 64\n",
      "121 377 65\n",
      "121 377 66\n",
      "122 382 67\n",
      "122 382 68\n",
      "122 382 69\n",
      "123 385 70\n",
      "124 388 71\n",
      "126 402 72\n",
      "127 405 73\n",
      "127 405 74\n",
      "128 410 75\n",
      "128 410 76\n",
      "128 406 77\n",
      "130 414 78\n",
      "131 419 79\n",
      "131 419 80\n",
      "131 419 81\n",
      "131 419 82\n",
      "131 419 83\n",
      "132 426 84\n",
      "134 432 85\n",
      "134 432 86\n",
      "134 432 87\n",
      "135 437 88\n",
      "136 442 89\n",
      "136 442 90\n",
      "136 442 91\n",
      "136 442 92\n",
      "136 442 93\n",
      "137 445 94\n",
      "137 445 95\n",
      "137 445 96\n",
      "137 445 97\n",
      "139 453 98\n",
      "139 453 99\n",
      "139 453 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 13.4126344515929 \ttest: 0.90625 9.021910106677563\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 6.6397805763613835 \ttest: 0.90625 6.796707294161043\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 3.940647932493257 \ttest: 0.90625 5.809772109532901\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 2.597774425115163 \ttest: 0.90625 5.262427723079387\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.8335082489299948 \ttest: 0.90625 4.914089783760465\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 1.3583129567223604 \ttest: 0.90625 4.671750815190075\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 1.0436288836062828 \ttest: 0.9375 4.492508941143038\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.8250748331571149 \ttest: 0.9375 4.353929912242115\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.6674856148413377 \ttest: 0.9375 4.243150813995491\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.5503461744747565 \ttest: 0.9375 4.152262301945822\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.4610491438480101 \ttest: 0.9375 4.07612745832599\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.3915115183571036 \ttest: 0.9375 4.011260329185519\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.33636476515979746 \ttest: 0.9375 3.9552087690779394\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.29193475433569777 \ttest: 0.9375 3.9061954181945384\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.2556412324043768 \ttest: 0.9375 3.8628989715753743\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.2256309362289436 \ttest: 0.9375 3.8243156200657005\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.20054615991902097 \ttest: 0.9375 3.78966830049119\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.17937462711331306 \ttest: 0.9375 3.758345519068862\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.16134967225725033 \ttest: 0.9375 3.7298590586302027\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.14588239824557692 \ttest: 0.9375 3.7038140845928593\n",
      "retrain  21 :\n",
      "\ttrain: 1.0 0.13251465013723604 \ttest: 0.9375 3.679887594555499\n",
      "retrain  22 :\n",
      "\ttrain: 1.0 0.12088583377838749 \ttest: 0.9375 3.6578126069932697\n",
      "retrain  23 :\n",
      "\ttrain: 1.0 0.11070912301201852 \ttest: 0.9375 3.637366375761108\n",
      "retrain  24 :\n",
      "\ttrain: 1.0 0.10175414660035773 \ttest: 0.9375 3.6183614789334575\n",
      "retrain  25 :\n",
      "\ttrain: 1.0 0.09383421966772612 \ttest: 0.9375 3.6006389929630727\n",
      "retrain  26 :\n",
      "\ttrain: 1.0 0.08679680969830146 \ttest: 0.9375 3.584063201919557\n",
      "retrain  27 :\n",
      "\ttrain: 1.0 0.08051633612091845 \ttest: 0.9375 3.5685174518905054\n",
      "retrain  28 :\n",
      "\ttrain: 1.0 0.07488867466166865 \ttest: 0.9375 3.553900870157756\n",
      "retrain  29 :\n",
      "\ttrain: 1.0 0.0698269216010564 \ttest: 0.9375 3.5401257447903074\n",
      "retrain  30 :\n",
      "\ttrain: 1.0 0.06525809923539735 \ttest: 0.9375 3.5271154138483123\n",
      "retrain  31 :\n",
      "\ttrain: 1.0 0.06112057154310078 \ttest: 0.9375 3.514802551626942\n",
      "retrain  32 :\n",
      "\ttrain: 1.0 0.05736200079054822 \ttest: 0.9375 3.5031277670100485\n",
      "retrain  33 :\n",
      "\ttrain: 1.0 0.0539377197794438 \ttest: 0.9375 3.492038449219941\n",
      "retrain  34 :\n",
      "\ttrain: 1.0 0.0508094260957051 \ttest: 0.9375 3.4814878111963283\n",
      "retrain  35 :\n",
      "\ttrain: 1.0 0.047944127750293254 \ttest: 0.9375 3.4714340920002993\n",
      "retrain  36 :\n",
      "\ttrain: 1.0 0.0453132865184938 \ttest: 0.9375 3.461839888055098\n",
      "retrain  37 :\n",
      "\ttrain: 1.0 0.04289211782253112 \ttest: 0.9375 3.452671589436842\n",
      "retrain  38 :\n",
      "\ttrain: 1.0 0.040659015375799606 \ttest: 0.9375 3.443898902338065\n",
      "retrain  39 :\n",
      "\ttrain: 1.0 0.03859507587118383 \ttest: 0.9375 3.4354944426222094\n",
      "retrain  40 :\n",
      "\ttrain: 1.0 0.03668370436067345 \ttest: 0.9375 3.4274333883427195\n",
      "retrain  41 :\n",
      "\ttrain: 1.0 0.03491028507721272 \ttest: 0.9375 3.4196931814180296\n",
      "retrain  42 :\n",
      "\ttrain: 1.0 0.033261905610519046 \ttest: 0.9375 3.412253270483231\n",
      "retrain  43 :\n",
      "\ttrain: 1.0 0.03172712479907213 \ttest: 0.9375 3.405094888392425\n",
      "retrain  44 :\n",
      "\ttrain: 1.0 0.03029577661209006 \ttest: 0.9375 3.3982008590069137\n",
      "retrain  45 :\n",
      "\ttrain: 1.0 0.028958803795417144 \ttest: 0.9375 3.39155542883748\n",
      "retrain  46 :\n",
      "\ttrain: 1.0 0.027708116239095488 \ttest: 0.9375 3.3851441198627783\n",
      "retrain  47 :\n",
      "\ttrain: 1.0 0.026536469963703076 \ttest: 0.9375 3.3789536004579896\n",
      "retrain  48 :\n",
      "\ttrain: 1.0 0.025437363371675445 \ttest: 0.9375 3.3729715718672804\n",
      "retrain  49 :\n",
      "\ttrain: 1.0 0.0244049480102401 \ttest: 0.9375 3.367186668063123\n",
      "retrain  50 :\n",
      "\ttrain: 1.0 0.023433951576086163 \ttest: 0.9375 3.3615883671725806\n",
      "retrain  51 :\n",
      "\ttrain: 1.0 0.022519611282993093 \ttest: 0.9375 3.3561669129294978\n",
      "retrain  52 :\n",
      "\ttrain: 1.0 0.021657616031389562 \ttest: 0.9375 3.3509132448429844\n",
      "retrain  53 :\n",
      "\ttrain: 1.0 0.020844056078037465 \ttest: 0.9375 3.345818935965511\n",
      "retrain  54 :\n",
      "\ttrain: 1.0 0.020075379116364048 \ttest: 0.9375 3.340876137305364\n",
      "retrain  55 :\n",
      "\ttrain: 1.0 0.019348351852555196 \ttest: 0.9375 3.336077528063748\n",
      "retrain  56 :\n",
      "\ttrain: 1.0 0.018660026306610983 \ttest: 0.9375 3.3314162709910047\n",
      "retrain  57 :\n",
      "\ttrain: 1.0 0.018007710186906313 \ttest: 0.9375 3.326885972252965\n",
      "retrain  58 :\n",
      "\ttrain: 1.0 0.017388940785987163 \ttest: 0.9375 3.3224806452803333\n",
      "retrain  59 :\n",
      "\ttrain: 1.0 0.016801461928039045 \ttest: 0.9375 3.3181946781436045\n",
      "retrain  60 :\n",
      "\ttrain: 1.0 0.01624320356765408 \ttest: 0.9375 3.3140228040554915\n",
      "retrain  61 :\n",
      "\ttrain: 1.0 0.015712263697581098 \ttest: 0.9375 3.309960074653633\n",
      "retrain  62 :\n",
      "\ttrain: 1.0 0.015206892272005428 \ttest: 0.9375 3.3060018357599845\n",
      "retrain  63 :\n",
      "\ttrain: 1.0 0.01472547689315113 \ttest: 0.9375 3.302143705350841\n",
      "retrain  64 :\n",
      "\ttrain: 1.0 0.014266530043906803 \ttest: 0.9375 3.2983815535037735\n",
      "retrain  65 :\n",
      "\ttrain: 1.0 0.01382867767880624 \ttest: 0.9375 3.2947114841157688\n",
      "retrain  66 :\n",
      "\ttrain: 1.0 0.013410649010906876 \ttest: 0.9375 3.2911298182110973\n",
      "retrain  67 :\n",
      "\ttrain: 1.0 0.013011267353617276 \ttest: 0.9375 3.2876330786785206\n",
      "retrain  68 :\n",
      "\ttrain: 1.0 0.012629441894919623 \ttest: 0.9375 3.284217976295783\n",
      "retrain  69 :\n",
      "\ttrain: 1.0 0.012264160297200434 \ttest: 0.9375 3.280881396915338\n",
      "retrain  70 :\n",
      "\ttrain: 1.0 0.011914482029451202 \ttest: 0.9375 3.2776203896992824\n",
      "retrain  71 :\n",
      "\ttrain: 1.0 0.011579532350267412 \ttest: 0.9375 3.274432156303677\n",
      "retrain  72 :\n",
      "\ttrain: 1.0 0.011258496870143141 \ttest: 0.9375 3.271314040923286\n",
      "retrain  73 :\n",
      "\ttrain: 1.0 0.010950616630266405 \ttest: 0.9375 3.268263521117157\n",
      "retrain  74 :\n",
      "\ttrain: 1.0 0.010655183642567519 \ttest: 0.9375 3.2652781993438627\n",
      "retrain  75 :\n",
      "\ttrain: 1.0 0.010371536842324976 \ttest: 0.9375 3.262355795142586\n",
      "retrain  76 :\n",
      "\ttrain: 1.0 0.010099058410336127 \ttest: 0.9375 3.259494137902729\n",
      "retrain  77 :\n",
      "\ttrain: 1.0 0.009837170426629079 \ttest: 0.9375 3.2566911601705284\n",
      "retrain  78 :\n",
      "\ttrain: 1.0 0.009585331822033702 \ttest: 0.9375 3.2539448914462743\n",
      "retrain  79 :\n",
      "\ttrain: 1.0 0.009343035597725868 \ttest: 0.9375 3.2512534524302827\n",
      "retrain  80 :\n",
      "\ttrain: 1.0 0.009109806286188238 \ttest: 0.9375 3.248615049679832\n",
      "retrain  81 :\n",
      "\ttrain: 1.0 0.008885197629951463 \ttest: 0.9375 3.2460279706429054\n",
      "retrain  82 :\n",
      "\ttrain: 1.0 0.008668790457049992 \ttest: 0.9375 3.243490579037778\n",
      "retrain  83 :\n",
      "\ttrain: 1.0 0.008460190734388032 \ttest: 0.9375 3.24100131055041\n",
      "retrain  84 :\n",
      "\ttrain: 1.0 0.00825902778220949 \ttest: 0.9375 3.2385586688241963\n",
      "retrain  85 :\n",
      "\ttrain: 1.0 0.008064952634627004 \ttest: 0.9375 3.2361612217188944\n",
      "retrain  86 :\n",
      "\ttrain: 1.0 0.007877636532727989 \ttest: 0.9375 3.233807597817717\n",
      "retrain  87 :\n",
      "\ttrain: 1.0 0.007696769538157157 \ttest: 0.9375 3.231496483163373\n",
      "retrain  88 :\n",
      "\ttrain: 1.0 0.007522059256302634 \ttest: 0.9375 3.229226618205571\n",
      "retrain  89 :\n",
      "\ttrain: 1.0 0.007353229659303673 \ttest: 0.9375 3.2269967949440304\n",
      "retrain  90 :\n",
      "\ttrain: 1.0 0.007190020000067894 \ttest: 0.9375 3.224805854252375\n",
      "retrain  91 :\n",
      "\ttrain: 1.0 0.007032183809351302 \ttest: 0.9375 3.222652683369568\n",
      "retrain  92 :\n",
      "\ttrain: 1.0 0.006879487968725433 \ttest: 0.9375 3.2205362135466484\n",
      "retrain  93 :\n",
      "\ttrain: 1.0 0.0067317118529457275 \ttest: 0.9375 3.218455417837549\n",
      "retrain  94 :\n",
      "\ttrain: 1.0 0.006588646535851245 \ttest: 0.9375 3.21640930902372\n",
      "retrain  95 :\n",
      "\ttrain: 1.0 0.006450094054478574 \ttest: 0.9375 3.2143969376630754\n",
      "retrain  96 :\n",
      "\ttrain: 1.0 0.006315866726567247 \ttest: 0.9375 3.2124173902545916\n",
      "retrain  97 :\n",
      "\ttrain: 1.0 0.006185786517079113 \ttest: 0.9375 3.2104697875105495\n",
      "retrain  98 :\n",
      "\ttrain: 1.0 0.006059684449752974 \ttest: 0.9375 3.2085532827290364\n",
      "retrain  99 :\n",
      "\ttrain: 1.0 0.0059374000600753395 \ttest: 0.9375 3.2066670602599445\n",
      "retrain  100 :\n",
      "\ttrain: 1.0 0.005818780886371946 \ttest: 0.9375 3.204810334058159\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        37\n",
      "           1    1.00000   1.00000   1.00000        37\n",
      "\n",
      "    accuracy                        1.00000        74\n",
      "   macro avg    1.00000   1.00000   1.00000        74\n",
      "weighted avg    1.00000   1.00000   1.00000        74\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.93750   0.93750   0.93750        16\n",
      "           1    0.93750   0.93750   0.93750        16\n",
      "\n",
      "    accuracy                        0.93750        32\n",
      "   macro avg    0.93750   0.93750   0.93750        32\n",
      "weighted avg    0.93750   0.93750   0.93750        32\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 139\n",
      "Average of depth: 1.1079136690647482\n",
      "Number of nodes: 453\n",
      "20 72 1\n",
      "33 109 2\n",
      "39 133 3\n",
      "46 150 4\n",
      "50 160 5\n",
      "56 178 6\n",
      "60 188 7\n",
      "65 203 8\n",
      "67 211 9\n",
      "72 226 10\n",
      "75 237 11\n",
      "80 256 12\n",
      "83 269 13\n",
      "83 269 14\n",
      "84 272 15\n",
      "85 275 16\n",
      "88 286 17\n",
      "90 292 18\n",
      "91 295 19\n",
      "93 301 20\n",
      "95 307 21\n",
      "98 318 22\n",
      "99 321 23\n",
      "102 332 24\n",
      "102 332 25\n",
      "108 356 26\n",
      "110 356 27\n",
      "112 366 28\n",
      "113 369 29\n",
      "117 387 30\n",
      "119 393 31\n",
      "122 402 32\n",
      "124 408 33\n",
      "124 406 34\n",
      "125 411 35\n",
      "127 419 36\n",
      "127 417 37\n",
      "127 417 38\n",
      "127 415 39\n",
      "128 418 40\n",
      "130 424 41\n",
      "131 421 42\n",
      "132 424 43\n",
      "132 424 44\n",
      "133 427 45\n",
      "136 434 46\n",
      "139 449 47\n",
      "139 449 48\n",
      "140 452 49\n",
      "140 452 50\n",
      "140 452 51\n",
      "141 455 52\n",
      "141 455 53\n",
      "142 460 54\n",
      "142 460 55\n",
      "142 460 56\n",
      "143 465 57\n",
      "144 470 58\n",
      "145 473 59\n",
      "145 469 60\n",
      "146 472 61\n",
      "148 478 62\n",
      "149 479 63\n",
      "149 479 64\n",
      "149 479 65\n",
      "149 479 66\n",
      "151 485 67\n",
      "152 488 68\n",
      "155 497 69\n",
      "156 498 70\n",
      "156 494 71\n",
      "157 493 72\n",
      "159 499 73\n",
      "159 499 74\n",
      "160 504 75\n",
      "162 510 76\n",
      "163 511 77\n",
      "163 511 78\n",
      "163 511 79\n",
      "163 511 80\n",
      "163 511 81\n",
      "164 514 82\n",
      "165 519 83\n",
      "166 522 84\n",
      "166 518 85\n",
      "166 518 86\n",
      "166 518 87\n",
      "167 521 88\n",
      "168 522 89\n",
      "169 525 90\n",
      "169 525 91\n",
      "170 530 92\n",
      "171 533 93\n",
      "171 533 94\n",
      "172 536 95\n",
      "173 545 96\n",
      "173 541 97\n",
      "174 540 98\n",
      "175 543 99\n",
      "175 543 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 8.749746400506536 \ttest: 0.65625 12.688237570284937\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 3.9873828506863145 \ttest: 0.65625 12.67235332685981\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 2.3119834116077493 \ttest: 0.65625 12.924176795961955\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 1.5075379717504676 \ttest: 0.65625 13.180794512901146\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.0565124532111145 \ttest: 0.65625 13.409567518444547\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 0.7785726481843123 \ttest: 0.65625 13.609711276430335\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 0.5957220207791892 \ttest: 0.65625 13.78537298230473\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.4694047425786763 \ttest: 0.65625 13.940825417747778\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.37873172167574376 \ttest: 0.65625 14.07963031500669\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.31159072086546513 \ttest: 0.65625 14.204618358874203\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.26057642917971063 \ttest: 0.65625 14.318021594825368\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.2209626292003436 \ttest: 0.65625 14.421608933289608\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.18962318821504176 \ttest: 0.65625 14.516795621275023\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.1644266470849325 \ttest: 0.65625 14.604726237245606\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.1438812446143519 \ttest: 0.65625 14.686336527763036\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.1269188595099626 \ttest: 0.65625 14.762399456365586\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.11275919878481183 \ttest: 0.65625 14.833559717155893\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.10082198998503747 \ttest: 0.65625 14.900359845435691\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.09066878040929652 \ttest: 0.65625 14.96326017782631\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.08196349646515771 \ttest: 0.65625 15.022654273142049\n",
      "retrain  21 :\n",
      "\ttrain: 1.0 0.07444517968748221 \ttest: 0.65625 15.078880950311454\n",
      "retrain  22 :\n",
      "\ttrain: 1.0 0.06790879893648927 \ttest: 0.65625 15.132233779107565\n",
      "retrain  23 :\n",
      "\ttrain: 1.0 0.06219152477656738 \ttest: 0.65625 15.182968633239902\n",
      "retrain  24 :\n",
      "\ttrain: 1.0 0.057162764257202 \ttest: 0.65625 15.231309754746865\n",
      "retrain  25 :\n",
      "\ttrain: 1.0 0.05271682681382983 \ttest: 0.65625 15.27745466364453\n",
      "retrain  26 :\n",
      "\ttrain: 1.0 0.04876745870134323 \ttest: 0.65625 15.321578163708983\n",
      "retrain  27 :\n",
      "\ttrain: 1.0 0.04524372267154232 \ttest: 0.65625 15.36383563466365\n",
      "retrain  28 :\n",
      "\ttrain: 1.0 0.042086858467558136 \ttest: 0.65625 15.404365756404786\n",
      "retrain  29 :\n",
      "\ttrain: 1.0 0.03924786685110828 \ttest: 0.65625 15.443292777709328\n",
      "retrain  30 :\n",
      "\ttrain: 1.0 0.03668563320469728 \ttest: 0.65625 15.480728416967338\n",
      "retrain  31 :\n",
      "\ttrain: 1.0 0.03436545761979269 \ttest: 0.65625 15.516773463632378\n",
      "retrain  32 :\n",
      "\ttrain: 1.0 0.03225789412038503 \ttest: 0.65625 15.551519134696111\n",
      "retrain  33 :\n",
      "\ttrain: 1.0 0.03033782707757362 \ttest: 0.65625 15.585048229423698\n",
      "retrain  34 :\n",
      "\ttrain: 1.0 0.02858373113242799 \ttest: 0.65625 15.617436117004441\n",
      "retrain  35 :\n",
      "\ttrain: 1.0 0.026977074207058235 \ttest: 0.65625 15.648751585070054\n",
      "retrain  36 :\n",
      "\ttrain: 1.0 0.025501832910109656 \ttest: 0.65625 15.679057571762815\n",
      "retrain  37 :\n",
      "\ttrain: 1.0 0.02414409684130543 \ttest: 0.65625 15.708411799864805\n",
      "retrain  38 :\n",
      "\ttrain: 1.0 0.022891743673383355 \ttest: 0.65625 15.736867328177345\n",
      "retrain  39 :\n",
      "\ttrain: 1.0 0.02173417093417488 \ttest: 0.65625 15.76447303267807\n",
      "retrain  40 :\n",
      "\ttrain: 1.0 0.02066207347907221 \ttest: 0.65625 15.791274027838785\n",
      "retrain  41 :\n",
      "\ttrain: 1.0 0.019667257987754743 \ttest: 0.65625 15.817312036749938\n",
      "retrain  42 :\n",
      "\ttrain: 1.0 0.01874248762208343 \ttest: 0.65625 15.84262571728316\n",
      "retrain  43 :\n",
      "\ttrain: 1.0 0.017881351378386534 \ttest: 0.65625 15.867250950366016\n",
      "retrain  44 :\n",
      "\ttrain: 1.0 0.017078153755499585 \ttest: 0.65625 15.891221095491545\n",
      "retrain  45 :\n",
      "\ttrain: 1.0 0.016327821212983686 \ttest: 0.65625 15.914567217799743\n",
      "retrain  46 :\n",
      "\ttrain: 1.0 0.015625822566533214 \ttest: 0.65625 15.937318290416355\n",
      "retrain  47 :\n",
      "\ttrain: 1.0 0.014968101000768681 \ttest: 0.65625 15.959501375191993\n",
      "retrain  48 :\n",
      "\ttrain: 1.0 0.014351015804488677 \ttest: 0.65625 15.98114178453092\n",
      "retrain  49 :\n",
      "\ttrain: 1.0 0.01377129227371255 \ttest: 0.65625 16.002263226618354\n",
      "retrain  50 :\n",
      "\ttrain: 1.0 0.013225978501637278 \ttest: 0.65625 16.022887936034433\n",
      "retrain  51 :\n",
      "\ttrain: 1.0 0.012712407995947115 \ttest: 0.65625 16.043036791472332\n",
      "retrain  52 :\n",
      "\ttrain: 1.0 0.012228167243596315 \ttest: 0.65625 16.062729422048122\n",
      "retrain  53 :\n",
      "\ttrain: 1.0 0.011771067489678794 \ttest: 0.65625 16.081984303494707\n",
      "retrain  54 :\n",
      "\ttrain: 1.0 0.011339120116918327 \ttest: 0.65625 16.10081884536533\n",
      "retrain  55 :\n",
      "\ttrain: 1.0 0.010930515110858841 \ttest: 0.65625 16.119249470229605\n",
      "retrain  56 :\n",
      "\ttrain: 1.0 0.0105436021771203 \ttest: 0.65625 16.13729168572241\n",
      "retrain  57 :\n",
      "\ttrain: 1.0 0.010176874144377155 \ttest: 0.65625 16.154960150200644\n",
      "retrain  58 :\n",
      "\ttrain: 1.0 0.00982895234261276 \ttest: 0.65625 16.17226873267191\n",
      "retrain  59 :\n",
      "\ttrain: 1.0 0.009498573692793475 \ttest: 0.65625 16.18923056758039\n",
      "retrain  60 :\n",
      "\ttrain: 1.0 0.009184579283061595 \ttest: 0.65625 16.20585810496709\n",
      "retrain  61 :\n",
      "\ttrain: 1.0 0.008885904239222569 \ttest: 0.65625 16.22216315646206\n",
      "retrain  62 :\n",
      "\ttrain: 1.0 0.00860156872479094 \ttest: 0.65625 16.238156937514688\n",
      "retrain  63 :\n",
      "\ttrain: 1.0 0.008330669929054315 \ttest: 0.65625 16.253850106222835\n",
      "retrain  64 :\n",
      "\ttrain: 1.0 0.00807237492123905 \ttest: 0.65625 16.269252799082135\n",
      "retrain  65 :\n",
      "\ttrain: 1.0 0.00782591426551274 \ttest: 0.65625 16.28437466394208\n",
      "retrain  66 :\n",
      "\ttrain: 1.0 0.007590576305721617 \ttest: 0.65625 16.299224890424977\n",
      "retrain  67 :\n",
      "\ttrain: 1.0 0.0073657020408409435 \ttest: 0.65625 16.313812238037027\n",
      "retrain  68 :\n",
      "\ttrain: 1.0 0.007150680522443192 \ttest: 0.65625 16.32814506217719\n",
      "retrain  69 :\n",
      "\ttrain: 1.0 0.006944944714339817 \ttest: 0.65625 16.342231338228345\n",
      "retrain  70 :\n",
      "\ttrain: 1.0 0.006747967762154226 \ttest: 0.65625 16.35607868389691\n",
      "retrain  71 :\n",
      "\ttrain: 1.0 0.0065592596271288875 \ttest: 0.65625 16.369694379950538\n",
      "retrain  72 :\n",
      "\ttrain: 1.0 0.006378364044117022 \ttest: 0.65625 16.383085389488755\n",
      "retrain  73 :\n",
      "\ttrain: 1.0 0.006204855768591786 \ttest: 0.65625 16.39625837586875\n",
      "retrain  74 :\n",
      "\ttrain: 1.0 0.00603833808173726 \ttest: 0.65625 16.40921971939637\n",
      "retrain  75 :\n",
      "\ttrain: 1.0 0.005878440526358037 \ttest: 0.65625 16.421975532882556\n",
      "retrain  76 :\n",
      "\ttrain: 1.0 0.005724816849540114 \ttest: 0.65625 16.434531676155835\n",
      "retrain  77 :\n",
      "\ttrain: 1.0 0.005577143130779994 \ttest: 0.65625 16.446893769613197\n",
      "retrain  78 :\n",
      "\ttrain: 1.0 0.005435116076730992 \ttest: 0.65625 16.459067206884423\n",
      "retrain  79 :\n",
      "\ttrain: 1.0 0.005298451465842299 \ttest: 0.65625 16.471057166678108\n",
      "retrain  80 :\n",
      "\ttrain: 1.0 0.005166882728030442 \ttest: 0.65625 16.4828686238715\n",
      "retrain  81 :\n",
      "\ttrain: 1.0 0.005040159646158569 \ttest: 0.65625 16.49450635990104\n",
      "retrain  82 :\n",
      "\ttrain: 1.0 0.004918047167537814 \ttest: 0.65625 16.505974972505573\n",
      "retrain  83 :\n",
      "\ttrain: 1.0 0.004800324314931161 \ttest: 0.65625 16.51727888486956\n",
      "retrain  84 :\n",
      "\ttrain: 1.0 0.004686783187658134 \ttest: 0.65625 16.52842235420998\n",
      "retrain  85 :\n",
      "\ttrain: 1.0 0.004577228044385575 \ttest: 0.65625 16.539409479846597\n",
      "retrain  86 :\n",
      "\ttrain: 1.0 0.004471474460063041 \ttest: 0.65625 16.550244210792386\n",
      "retrain  87 :\n",
      "\ttrain: 1.0 0.004369348550235259 \ttest: 0.65625 16.560930352897596\n",
      "retrain  88 :\n",
      "\ttrain: 1.0 0.004270686256650929 \ttest: 0.65625 16.571471575578435\n",
      "retrain  89 :\n",
      "\ttrain: 1.0 0.004175332688696999 \ttest: 0.65625 16.58187141815886\n",
      "retrain  90 :\n",
      "\ttrain: 1.0 0.004083141515730613 \ttest: 0.65625 16.592133295851585\n",
      "retrain  91 :\n",
      "\ttrain: 1.0 0.00399397440586491 \ttest: 0.65625 16.60226050540267\n",
      "retrain  92 :\n",
      "\ttrain: 1.0 0.003907700507195934 \ttest: 0.65625 16.612256230421806\n",
      "retrain  93 :\n",
      "\ttrain: 1.0 0.003824195967843827 \ttest: 0.65625 16.6221235464191\n",
      "retrain  94 :\n",
      "\ttrain: 1.0 0.0037433434915262707 \ttest: 0.65625 16.631865425567284\n",
      "retrain  95 :\n",
      "\ttrain: 1.0 0.0036650319256906873 \ttest: 0.65625 16.641484741207094\n",
      "retrain  96 :\n",
      "\ttrain: 1.0 0.003589155879508899 \ttest: 0.65625 16.65098427211208\n",
      "retrain  97 :\n",
      "\ttrain: 1.0 0.0035156153692862575 \ttest: 0.65625 16.660366706528073\n",
      "retrain  98 :\n",
      "\ttrain: 1.0 0.0034443154890606864 \ttest: 0.65625 16.6696346460013\n",
      "retrain  99 :\n",
      "\ttrain: 1.0 0.0033751661043680044 \ttest: 0.65625 16.678790609008168\n",
      "retrain  100 :\n",
      "\ttrain: 1.0 0.003308081567330899 \ttest: 0.65625 16.687837034398992\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        37\n",
      "           1    1.00000   1.00000   1.00000        37\n",
      "\n",
      "    accuracy                        1.00000        74\n",
      "   macro avg    1.00000   1.00000   1.00000        74\n",
      "weighted avg    1.00000   1.00000   1.00000        74\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.66667   0.62500   0.64516        16\n",
      "           1    0.64706   0.68750   0.66667        16\n",
      "\n",
      "    accuracy                        0.65625        32\n",
      "   macro avg    0.65686   0.65625   0.65591        32\n",
      "weighted avg    0.65686   0.65625   0.65591        32\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 175\n",
      "Average of depth: 1.0514285714285714\n",
      "Number of nodes: 543\n",
      "18 66 1\n",
      "32 118 2\n",
      "41 151 3\n",
      "45 161 4\n",
      "53 183 5\n",
      "60 200 6\n",
      "63 209 7\n",
      "65 213 8\n",
      "67 219 9\n",
      "69 225 10\n",
      "71 233 11\n",
      "72 236 12\n",
      "77 251 13\n",
      "80 262 14\n",
      "81 267 15\n",
      "83 271 16\n",
      "86 282 17\n",
      "87 287 18\n",
      "88 286 19\n",
      "88 286 20\n",
      "89 289 21\n",
      "92 298 22\n",
      "93 301 23\n",
      "95 311 24\n",
      "96 312 25\n",
      "99 319 26\n",
      "101 325 27\n",
      "105 337 28\n",
      "107 343 29\n",
      "107 341 30\n",
      "108 344 31\n",
      "108 344 32\n",
      "109 349 33\n",
      "109 349 34\n",
      "109 349 35\n",
      "109 347 36\n",
      "110 352 37\n",
      "112 358 38\n",
      "115 369 39\n",
      "118 382 40\n",
      "119 383 41\n",
      "120 388 42\n",
      "121 389 43\n",
      "122 394 44\n",
      "122 394 45\n",
      "122 394 46\n",
      "126 410 47\n",
      "126 410 48\n",
      "126 410 49\n",
      "126 410 50\n",
      "127 413 51\n",
      "128 412 52\n",
      "129 417 53\n",
      "130 420 54\n",
      "130 420 55\n",
      "130 420 56\n",
      "131 423 57\n",
      "131 423 58\n",
      "131 423 59\n",
      "131 423 60\n",
      "132 426 61\n",
      "134 434 62\n",
      "137 449 63\n",
      "137 445 64\n",
      "137 443 65\n",
      "137 443 66\n",
      "137 443 67\n",
      "137 443 68\n",
      "139 451 69\n",
      "139 451 70\n",
      "139 451 71\n",
      "139 451 72\n",
      "139 451 73\n",
      "140 456 74\n",
      "140 454 75\n",
      "141 457 76\n",
      "141 457 77\n",
      "142 460 78\n",
      "142 460 79\n",
      "143 463 80\n",
      "143 461 81\n",
      "143 461 82\n",
      "145 469 83\n",
      "145 469 84\n",
      "145 467 85\n",
      "145 465 86\n",
      "145 463 87\n",
      "145 463 88\n",
      "145 463 89\n",
      "146 468 90\n",
      "146 466 91\n",
      "146 466 92\n",
      "146 466 93\n",
      "147 471 94\n",
      "147 471 95\n",
      "147 471 96\n",
      "147 469 97\n",
      "147 469 98\n",
      "147 469 99\n",
      "147 469 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.9864864864864865 12.185456483113125 \ttest: 0.9375 9.40221300767779\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 5.857582949455355 \ttest: 0.9375 7.33701048893402\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 3.4695980096845593 \ttest: 0.9375 6.398111540469506\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 2.3019339062117616 \ttest: 0.9375 5.86014798140307\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.6370231070438708 \ttest: 0.9375 5.507122939680224\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 1.2205311796173792 \ttest: 0.9375 5.254998905347144\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 0.9422648524796431 \ttest: 0.9375 5.064441650425378\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.7474286921792582 \ttest: 0.9375 4.914492211867296\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.6059990798510965 \ttest: 0.9375 4.792887437236354\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.5003213369058589 \ttest: 0.9375 4.691934652621551\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.41944337761922723 \ttest: 0.9375 4.60654326582432\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.3562784952492718 \ttest: 0.9375 4.533199288794979\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.30608076670818574 \ttest: 0.9375 4.469392621757786\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.2655789925547063 \ttest: 0.9375 4.413278770070791\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.2324621675187043 \ttest: 0.9375 4.363469637711054\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.2050622430567995 \ttest: 0.9375 4.318899090301166\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.1821522910129489 \ttest: 0.9375 4.27873371284049\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.16281456115657855 \ttest: 0.9375 4.242311892205016\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.14635215630777348 \ttest: 0.9375 4.20910121339742\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.13222864736632445 \ttest: 0.9375 4.178668022479774\n",
      "retrain  21 :\n",
      "\ttrain: 1.0 0.1200260038180968 \ttest: 0.9375 4.150655267604877\n",
      "retrain  22 :\n",
      "\ttrain: 1.0 0.10941478106016439 \ttest: 0.9375 4.124766092882214\n",
      "retrain  23 :\n",
      "\ttrain: 1.0 0.10013266418150105 \ttest: 0.9375 4.100751506504373\n",
      "retrain  24 :\n",
      "\ttrain: 1.0 0.09196880614075587 \ttest: 0.9375 4.078400983859396\n",
      "retrain  25 :\n",
      "\ttrain: 1.0 0.08475224632416728 \ttest: 0.9375 4.057535217729579\n",
      "retrain  26 :\n",
      "\ttrain: 1.0 0.0783432435020685 \ttest: 0.9375 4.03800046133436\n",
      "retrain  27 :\n",
      "\ttrain: 1.0 0.07262671776323176 \ttest: 0.9375 4.019664068255237\n",
      "retrain  28 :\n",
      "\ttrain: 1.0 0.06750723715401127 \ttest: 0.9375 4.002410942324793\n",
      "retrain  29 :\n",
      "\ttrain: 1.0 0.0629051484927909 \ttest: 0.9375 3.9861406868550264\n",
      "retrain  30 :\n",
      "\ttrain: 1.0 0.05875356458433262 \ttest: 0.9375 3.9707652967221514\n",
      "retrain  31 :\n",
      "\ttrain: 1.0 0.05499599871879781 \ttest: 0.9375 3.956207275753793\n",
      "retrain  32 :\n",
      "\ttrain: 1.0 0.051584492885440966 \ttest: 0.9375 3.942398090196235\n",
      "retrain  33 :\n",
      "\ttrain: 1.0 0.048478125801012656 \ttest: 0.9375 3.929276889892038\n",
      "retrain  34 :\n",
      "\ttrain: 1.0 0.045641815487525425 \ttest: 0.9375 3.9167894443080686\n",
      "retrain  35 :\n",
      "\ttrain: 1.0 0.04304535201024055 \ttest: 0.9375 3.904887252203049\n",
      "retrain  36 :\n",
      "\ttrain: 1.0 0.04066261135012084 \ttest: 0.9375 3.893526792553592\n",
      "retrain  37 :\n",
      "\ttrain: 1.0 0.03847091279180564 \ttest: 0.9375 3.8826688911083354\n",
      "retrain  38 :\n",
      "\ttrain: 1.0 0.036450490748397874 \ttest: 0.9375 3.8722781821425407\n",
      "retrain  39 :\n",
      "\ttrain: 1.0 0.034584058389112535 \ttest: 0.9375 3.8623226490259266\n",
      "retrain  40 :\n",
      "\ttrain: 1.0 0.03285644533582737 \ttest: 0.9375 3.852773230376739\n",
      "retrain  41 :\n",
      "\ttrain: 1.0 0.031254295446623226 \ttest: 0.9375 3.8436034810636226\n",
      "retrain  42 :\n",
      "\ttrain: 1.0 0.029765813596885817 \ttest: 0.9375 3.8347892792892004\n",
      "retrain  43 :\n",
      "\ttrain: 1.0 0.02838055261274701 \ttest: 0.9375 3.826308572561802\n",
      "retrain  44 :\n",
      "\ttrain: 1.0 0.02708923326353308 \ttest: 0.9375 3.8181411566229437\n",
      "retrain  45 :\n",
      "\ttrain: 1.0 0.02588359159546587 \ttest: 0.9375 3.810268482415084\n",
      "retrain  46 :\n",
      "\ttrain: 1.0 0.02475624897497953 \ttest: 0.9375 3.802673486998461\n",
      "retrain  47 :\n",
      "\ttrain: 1.0 0.023700601072160155 \ttest: 0.9375 3.7953404449972425\n",
      "retrain  48 :\n",
      "\ttrain: 1.0 0.02271072270265747 \ttest: 0.9375 3.7882548377047796\n",
      "retrain  49 :\n",
      "\ttrain: 1.0 0.021781285997878992 \ttest: 0.9375 3.781403237429561\n",
      "retrain  50 :\n",
      "\ttrain: 1.0 0.02090748981746205 \ttest: 0.9375 3.7747732050365297\n",
      "retrain  51 :\n",
      "\ttrain: 1.0 0.02008499867740378 \ttest: 0.9375 3.768353198947749\n",
      "retrain  52 :\n",
      "\ttrain: 1.0 0.019309889759251707 \ttest: 0.9375 3.7621324941238745\n",
      "retrain  53 :\n",
      "\ttrain: 1.0 0.018578606804029084 \ttest: 0.9375 3.7561011097630668\n",
      "retrain  54 :\n",
      "\ttrain: 1.0 0.01788791988975122 \ttest: 0.9375 3.75024974463438\n",
      "retrain  55 :\n",
      "\ttrain: 1.0 0.01723489025189101 \ttest: 0.9375 3.7445697191145264\n",
      "retrain  56 :\n",
      "\ttrain: 1.0 0.01661683943861693 \ttest: 0.9375 3.7390529231251293\n",
      "retrain  57 :\n",
      "\ttrain: 1.0 0.01603132220234303 \ttest: 0.9375 3.733691769276188\n",
      "retrain  58 :\n",
      "\ttrain: 1.0 0.015476102620315423 \ttest: 0.9375 3.7284791506137838\n",
      "retrain  59 :\n",
      "\ttrain: 1.0 0.014949133012991264 \ttest: 0.9375 3.723408402448722\n",
      "retrain  60 :\n",
      "\ttrain: 1.0 0.014448535292568 \ttest: 0.9375 3.718473267810053\n",
      "retrain  61 :\n",
      "\ttrain: 1.0 0.013972584427384574 \ttest: 0.9375 3.7136678661250517\n",
      "retrain  62 :\n",
      "\ttrain: 1.0 0.013519693752826176 \ttest: 0.9375 3.7089866647767784\n",
      "retrain  63 :\n",
      "\ttrain: 1.0 0.01308840189726733 \ttest: 0.9375 3.7044244532330213\n",
      "retrain  64 :\n",
      "\ttrain: 1.0 0.01267736112366569 \ttest: 0.9375 3.699976319477327\n",
      "retrain  65 :\n",
      "\ttrain: 1.0 0.012285326914640814 \ttest: 0.9375 3.6956376285047323\n",
      "retrain  66 :\n",
      "\ttrain: 1.0 0.011911148652032692 \ttest: 0.9375 3.691404002672543\n",
      "retrain  67 :\n",
      "\ttrain: 1.0 0.011553761261690415 \ttest: 0.9375 3.6872713037206277\n",
      "retrain  68 :\n",
      "\ttrain: 1.0 0.01121217771113275 \ttest: 0.9375 3.683235616296713\n",
      "retrain  69 :\n",
      "\ttrain: 1.0 0.010885482262201086 \ttest: 0.9375 3.679293232840539\n",
      "retrain  70 :\n",
      "\ttrain: 1.0 0.010572824393262095 \ttest: 0.9375 3.6754406396968378\n",
      "retrain  71 :\n",
      "\ttrain: 1.0 0.010273413316226276 \ttest: 0.9375 3.671674504341179\n",
      "retrain  72 :\n",
      "\ttrain: 1.0 0.009986513022888669 \ttest: 0.9375 3.667991663615166\n",
      "retrain  73 :\n",
      "\ttrain: 1.0 0.009711437803087631 \ttest: 0.9375 3.6643891128783737\n",
      "retrain  74 :\n",
      "\ttrain: 1.0 0.009447548184100455 \ttest: 0.9375 3.6608639959940663\n",
      "retrain  75 :\n",
      "\ttrain: 1.0 0.009194247246704673 \ttest: 0.9375 3.657413596074242\n",
      "retrain  76 :\n",
      "\ttrain: 1.0 0.008950977278562599 \ttest: 0.9375 3.6540353269171293\n",
      "retrain  77 :\n",
      "\ttrain: 1.0 0.008717216730142512 \ttest: 0.9375 3.6507267250768933\n",
      "retrain  78 :\n",
      "\ttrain: 1.0 0.008492477442368852 \ttest: 0.9375 3.6474854425113317\n",
      "retrain  79 :\n",
      "\ttrain: 1.0 0.008276302118673673 \ttest: 0.9375 3.6443092397585493\n",
      "retrain  80 :\n",
      "\ttrain: 1.0 0.008068262017170051 \ttest: 0.9375 3.641195979598381\n",
      "retrain  81 :\n",
      "\ttrain: 1.0 0.007867954841345306 \ttest: 0.9375 3.6381436211585023\n",
      "retrain  82 :\n",
      "\ttrain: 1.0 0.007675002810023943 \ttest: 0.9375 3.63515021442893\n",
      "retrain  83 :\n",
      "\ttrain: 1.0 0.0074890508894227305 \ttest: 0.9375 3.6322138951520007\n",
      "retrain  84 :\n",
      "\ttrain: 1.0 0.007309765171947096 \ttest: 0.9375 3.6293328800579063\n",
      "retrain  85 :\n",
      "\ttrain: 1.0 0.007136831387992728 \ttest: 0.9375 3.6265054624186126\n",
      "retrain  86 :\n",
      "\ttrain: 1.0 0.0069699535384437445 \ttest: 0.9375 3.6237300078953694\n",
      "retrain  87 :\n",
      "\ttrain: 1.0 0.006808852636824087 \ttest: 0.9375 3.6210049506572495\n",
      "retrain  88 :\n",
      "\ttrain: 1.0 0.006653265551181441 \ttest: 0.9375 3.6183287897501293\n",
      "retrain  89 :\n",
      "\ttrain: 1.0 0.006502943936779748 \ttest: 0.9375 3.6157000856972723\n",
      "retrain  90 :\n",
      "\ttrain: 1.0 0.006357653251563976 \ttest: 0.9375 3.613117457314326\n",
      "retrain  91 :\n",
      "\ttrain: 1.0 0.006217171847151085 \ttest: 0.9375 3.610579578722962\n",
      "retrain  92 :\n",
      "\ttrain: 1.0 0.006081290128806111 \ttest: 0.9375 3.608085176548739\n",
      "retrain  93 :\n",
      "\ttrain: 1.0 0.005949809778491955 \ttest: 0.9375 3.6056330272899286\n",
      "retrain  94 :\n",
      "\ttrain: 1.0 0.005822543035644912 \ttest: 0.9375 3.6032219548451705\n",
      "retrain  95 :\n",
      "\ttrain: 1.0 0.005699312030831882 \ttest: 0.9375 3.6008508281887566\n",
      "retrain  96 :\n",
      "\ttrain: 1.0 0.005579948167897263 \ttest: 0.9375 3.5985185591832733\n",
      "retrain  97 :\n",
      "\ttrain: 1.0 0.0054642915506133635 \ttest: 0.9375 3.596224100520165\n",
      "retrain  98 :\n",
      "\ttrain: 1.0 0.00535219045021253 \ttest: 0.9375 3.5939664437794483\n",
      "retrain  99 :\n",
      "\ttrain: 1.0 0.005243500810507149 \ttest: 0.9375 3.5917446176005816\n",
      "retrain  100 :\n",
      "\ttrain: 1.0 0.005138085787598926 \ttest: 0.9375 3.5895576859570317\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        37\n",
      "           1    1.00000   1.00000   1.00000        37\n",
      "\n",
      "    accuracy                        1.00000        74\n",
      "   macro avg    1.00000   1.00000   1.00000        74\n",
      "weighted avg    1.00000   1.00000   1.00000        74\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   0.87500   0.93333        16\n",
      "           1    0.88889   1.00000   0.94118        16\n",
      "\n",
      "    accuracy                        0.93750        32\n",
      "   macro avg    0.94444   0.93750   0.93725        32\n",
      "weighted avg    0.94444   0.93750   0.93725        32\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 147\n",
      "Average of depth: 1.0952380952380953\n",
      "Number of nodes: 469\n",
      "21 69 1\n",
      "33 113 2\n",
      "37 123 3\n",
      "43 141 4\n",
      "48 160 5\n",
      "51 165 6\n",
      "57 189 7\n",
      "60 196 8\n",
      "61 197 9\n",
      "62 198 10\n",
      "65 205 11\n",
      "69 219 12\n",
      "71 223 13\n",
      "74 234 14\n",
      "74 234 15\n",
      "76 240 16\n",
      "77 243 17\n",
      "77 241 18\n",
      "78 242 19\n",
      "78 240 20\n",
      "79 243 21\n",
      "80 246 22\n",
      "83 257 23\n",
      "85 271 24\n",
      "86 274 25\n",
      "87 277 26\n",
      "89 283 27\n",
      "90 284 28\n",
      "94 298 29\n",
      "94 298 30\n",
      "95 305 31\n",
      "96 308 32\n",
      "99 319 33\n",
      "99 313 34\n",
      "99 313 35\n",
      "101 317 36\n",
      "101 317 37\n",
      "103 325 38\n",
      "103 325 39\n",
      "103 325 40\n",
      "105 333 41\n",
      "108 338 42\n",
      "108 338 43\n",
      "109 341 44\n",
      "110 344 45\n",
      "112 352 46\n",
      "113 355 47\n",
      "114 358 48\n",
      "114 358 49\n",
      "115 361 50\n",
      "118 370 51\n",
      "119 371 52\n",
      "121 379 53\n",
      "121 377 54\n",
      "122 384 55\n",
      "122 384 56\n",
      "122 382 57\n",
      "122 378 58\n",
      "124 388 59\n",
      "126 396 60\n",
      "126 396 61\n",
      "126 396 62\n",
      "126 396 63\n",
      "128 400 64\n",
      "129 403 65\n",
      "129 403 66\n",
      "131 409 67\n",
      "131 407 68\n",
      "132 410 69\n",
      "132 410 70\n",
      "133 415 71\n",
      "134 418 72\n",
      "134 418 73\n",
      "134 418 74\n",
      "135 419 75\n",
      "135 419 76\n",
      "136 424 77\n",
      "136 424 78\n",
      "136 424 79\n",
      "137 427 80\n",
      "138 430 81\n",
      "138 428 82\n",
      "138 426 83\n",
      "139 429 84\n",
      "139 427 85\n",
      "139 427 86\n",
      "139 427 87\n",
      "139 427 88\n",
      "139 427 89\n",
      "139 427 90\n",
      "140 432 91\n",
      "140 432 92\n",
      "142 440 93\n",
      "142 440 94\n",
      "142 440 95\n",
      "142 440 96\n",
      "146 458 97\n",
      "146 458 98\n",
      "147 461 99\n",
      "147 461 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 12.749406591517204 \ttest: 0.875 10.002234254873489\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 6.522739781687189 \ttest: 0.875 8.005798304847676\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 4.0403005652698685 \ttest: 0.875 7.064319136764635\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 2.762672805756856 \ttest: 0.875 6.515736427508491\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 2.0067679517834525 \ttest: 0.875 6.1538927403653165\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 1.5198781910684427 \ttest: 0.875 5.895845653444827\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 1.1876919126695735 \ttest: 0.875 5.701863477890508\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.9512717199794845 \ttest: 0.875 5.550441694011727\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.7773834453801249 \ttest: 0.875 5.428861113665767\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.6460336896115904 \ttest: 0.875 5.329079914429628\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.5445878026155738 \ttest: 0.875 5.245744240251767\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.4647433341315876 \ttest: 0.875 5.175140679053497\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.40086675754746154 \ttest: 0.875 5.114606557884834\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.3490307793562133 \ttest: 0.875 5.062179409595538\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.30643322517389415 \ttest: 0.875 5.016379020821901\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.27103376788787825 \ttest: 0.875 4.9760667032964\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.24131997278973033 \ttest: 0.875 4.940351466078803\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.21615269014606597 \ttest: 0.875 4.908525709727238\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.19466154344721937 \ttest: 0.875 4.880020086054358\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.17617284527933771 \ttest: 0.875 4.854371139695295\n",
      "retrain  21 :\n",
      "\ttrain: 1.0 0.16015897387103642 \ttest: 0.875 4.831197678226413\n",
      "retrain  22 :\n",
      "\ttrain: 1.0 0.14620223658252582 \ttest: 0.875 4.810183229205199\n",
      "retrain  23 :\n",
      "\ttrain: 1.0 0.13396868920002158 \ttest: 0.875 4.791062822104873\n",
      "retrain  24 :\n",
      "\ttrain: 1.0 0.12318890921195913 \ttest: 0.875 4.773612895207414\n",
      "retrain  25 :\n",
      "\ttrain: 1.0 0.11364369902161009 \ttest: 0.875 4.757643494920863\n",
      "retrain  26 :\n",
      "\ttrain: 1.0 0.10515333218459519 \ttest: 0.875 4.742992180075087\n",
      "retrain  27 :\n",
      "\ttrain: 1.0 0.0975693781802483 \ttest: 0.875 4.729519210289089\n",
      "retrain  28 :\n",
      "\ttrain: 1.0 0.0907684257780326 \ttest: 0.875 4.717103712582189\n",
      "retrain  29 :\n",
      "\ttrain: 1.0 0.08464721957059396 \ttest: 0.875 4.705640601151096\n",
      "retrain  30 :\n",
      "\ttrain: 1.0 0.0791188590217187 \ttest: 0.875 4.695038082699011\n",
      "retrain  31 :\n",
      "\ttrain: 1.0 0.0741098039489866 \ttest: 0.875 4.685215621129466\n",
      "retrain  32 :\n",
      "\ttrain: 1.0 0.06955749750508382 \ttest: 0.875 4.676102265642578\n",
      "retrain  33 :\n",
      "\ttrain: 1.0 0.06540846591939627 \ttest: 0.875 4.667635268569552\n",
      "retrain  34 :\n",
      "\ttrain: 1.0 0.06161678921687137 \ttest: 0.875 4.659758935902339\n",
      "retrain  35 :\n",
      "\ttrain: 1.0 0.0581428627288636 \ttest: 0.875 4.6524236659842995\n",
      "retrain  36 :\n",
      "\ttrain: 1.0 0.05495238812724957 \ttest: 0.875 4.645585141327205\n",
      "retrain  37 :\n",
      "\ttrain: 1.0 0.05201554681290255 \ttest: 0.875 4.639203645794572\n",
      "retrain  38 :\n",
      "\ttrain: 1.0 0.04930631908477118 \ttest: 0.875 4.633243485006954\n",
      "retrain  39 :\n",
      "\ttrain: 1.0 0.04680192053882668 \ttest: 0.875 4.627672492191673\n",
      "retrain  40 :\n",
      "\ttrain: 1.0 0.04448233326584384 \ttest: 0.875 4.62246160511949\n",
      "retrain  41 :\n",
      "\ttrain: 1.0 0.042329914117279946 \ttest: 0.875 4.617584502466799\n",
      "retrain  42 :\n",
      "\ttrain: 1.0 0.040329065942426086 \ttest: 0.875 4.6130172900807445\n",
      "retrain  43 :\n",
      "\ttrain: 1.0 0.038465960527102015 \ttest: 0.875 4.608738229331529\n",
      "retrain  44 :\n",
      "\ttrain: 1.0 0.03672830417673447 \ttest: 0.875 4.604727501105867\n",
      "retrain  45 :\n",
      "\ttrain: 1.0 0.03510513862815324 \ttest: 0.875 4.600967000100837\n",
      "retrain  46 :\n",
      "\ttrain: 1.0 0.03358667135263089 \ttest: 0.875 4.597440154973549\n",
      "retrain  47 :\n",
      "\ttrain: 1.0 0.032164130409050334 \ttest: 0.875 4.5941317706324405\n",
      "retrain  48 :\n",
      "\ttrain: 1.0 0.030829639882590007 \ttest: 0.875 4.591027889553935\n",
      "retrain  49 :\n",
      "\ttrain: 1.0 0.029576112648405036 \ttest: 0.875 4.5881156694998895\n",
      "retrain  50 :\n",
      "\ttrain: 1.0 0.028397157767960243 \ttest: 0.875 4.585383275417225\n",
      "retrain  51 :\n",
      "\ttrain: 1.0 0.02728700028618334 \ttest: 0.875 4.5828197836378575\n",
      "retrain  52 :\n",
      "\ttrain: 1.0 0.026240411572437016 \ttest: 0.875 4.580415096777161\n",
      "retrain  53 :\n",
      "\ttrain: 1.0 0.025252648654629062 \ttest: 0.875 4.578159867963376\n",
      "retrain  54 :\n",
      "\ttrain: 1.0 0.02431940124709494 \ttest: 0.875 4.576045433226582\n",
      "retrain  55 :\n",
      "\ttrain: 1.0 0.02343674537984461 \ttest: 0.875 4.5740637510410025\n",
      "retrain  56 :\n",
      "\ttrain: 1.0 0.022601102707812494 \ttest: 0.875 4.5722073481538015\n",
      "retrain  57 :\n",
      "\ttrain: 1.0 0.021809204720609994 \ttest: 0.875 4.570469270951509\n",
      "retrain  58 :\n",
      "\ttrain: 1.0 0.02105806119132987 \ttest: 0.875 4.5688430417155\n",
      "retrain  59 :\n",
      "\ttrain: 1.0 0.020344932301505175 \ttest: 0.875 4.567322619203272\n",
      "retrain  60 :\n",
      "\ttrain: 1.0 0.01966730396186282 \ttest: 0.875 4.565902363065279\n",
      "retrain  61 :\n",
      "\ttrain: 1.0 0.01902286591784292 \ttest: 0.875 4.564577001669505\n",
      "retrain  62 :\n",
      "\ttrain: 1.0 0.018409492287263452 \ttest: 0.875 4.563341602959618\n",
      "retrain  63 :\n",
      "\ttrain: 1.0 0.017825224226859136 \ttest: 0.875 4.562191548018802\n",
      "retrain  64 :\n",
      "\ttrain: 1.0 0.01726825446622726 \ttest: 0.875 4.561122507051204\n",
      "retrain  65 :\n",
      "\ttrain: 1.0 0.016736913483225247 \ttest: 0.875 4.560130417527404\n",
      "retrain  66 :\n",
      "\ttrain: 1.0 0.01622965712510538 \ttest: 0.875 4.559211464270352\n",
      "retrain  67 :\n",
      "\ttrain: 1.0 0.015745055505489977 \ttest: 0.875 4.558362061284089\n",
      "retrain  68 :\n",
      "\ttrain: 1.0 0.015281783029385093 \ttest: 0.875 4.557578835150334\n",
      "retrain  69 :\n",
      "\ttrain: 1.0 0.014838609417383769 \ttest: 0.875 4.556858609837729\n",
      "retrain  70 :\n",
      "\ttrain: 1.0 0.014414391616504561 \ttest: 0.875 4.556198392785837\n",
      "retrain  71 :\n",
      "\ttrain: 1.0 0.014008066499152243 \ttest: 0.875 4.555595362141199\n",
      "retrain  72 :\n",
      "\ttrain: 1.0 0.013618644263811165 \ttest: 0.875 4.555046855035961\n",
      "retrain  73 :\n",
      "\ttrain: 1.0 0.013245202461573301 \ttest: 0.875 4.554550356811409\n",
      "retrain  74 :\n",
      "\ttrain: 1.0 0.012886880581699987 \ttest: 0.875 4.554103491098972\n",
      "retrain  75 :\n",
      "\ttrain: 1.0 0.012542875137318464 \ttest: 0.875 4.553704010680406\n",
      "retrain  76 :\n",
      "\ttrain: 1.0 0.01221243519923476 \ttest: 0.875 4.553349789056924\n",
      "retrain  77 :\n",
      "\ttrain: 1.0 0.011894858331842026 \ttest: 0.875 4.553038812664168\n",
      "retrain  78 :\n",
      "\ttrain: 1.0 0.011589486890346522 \ttest: 0.875 4.552769173676227\n",
      "retrain  79 :\n",
      "\ttrain: 1.0 0.011295704643118909 \ttest: 0.875 4.552539063347565\n",
      "retrain  80 :\n",
      "\ttrain: 1.0 0.011012933687001687 \ttest: 0.875 4.552346765846732\n",
      "retrain  81 :\n",
      "\ttrain: 1.0 0.01074063162693464 \ttest: 0.875 4.55219065254012\n",
      "retrain  82 :\n",
      "\ttrain: 1.0 0.01047828899436739 \ttest: 0.875 4.552069176688117\n",
      "retrain  83 :\n",
      "\ttrain: 1.0 0.010225426881665493 \ttest: 0.875 4.551980868519493\n",
      "retrain  84 :\n",
      "\ttrain: 1.0 0.00998159477213171 \ttest: 0.875 4.551924330653064\n",
      "retrain  85 :\n",
      "\ttrain: 1.0 0.00974636854739898 \ttest: 0.875 4.551898233838536\n",
      "retrain  86 :\n",
      "\ttrain: 1.0 0.009519348655841357 \ttest: 0.875 4.551901312990997\n",
      "retrain  87 :\n",
      "\ttrain: 1.0 0.009300158427323174 \ttest: 0.84375 4.551932363495819\n",
      "retrain  88 :\n",
      "\ttrain: 1.0 0.009088442521094307 \ttest: 0.84375 4.551990237762821\n",
      "retrain  89 :\n",
      "\ttrain: 1.0 0.008883865494959687 \ttest: 0.84375 4.552073842010373\n",
      "retrain  90 :\n",
      "\ttrain: 1.0 0.008686110485028414 \ttest: 0.84375 4.552182133261878\n",
      "retrain  91 :\n",
      "\ttrain: 1.0 0.008494877986394825 \ttest: 0.84375 4.552314116538492\n",
      "retrain  92 :\n",
      "\ttrain: 1.0 0.008309884726040552 \ttest: 0.84375 4.5524688422334005\n",
      "retrain  93 :\n",
      "\ttrain: 1.0 0.00813086262008143 \ttest: 0.84375 4.552645403654182\n",
      "retrain  94 :\n",
      "\ttrain: 1.0 0.0079575578082315 \ttest: 0.84375 4.552842934720889\n",
      "retrain  95 :\n",
      "\ttrain: 1.0 0.00778972975902574 \ttest: 0.84375 4.5530606078085585\n",
      "retrain  96 :\n",
      "\ttrain: 1.0 0.007627150439944155 \ttest: 0.84375 4.553297631723732\n",
      "retrain  97 :\n",
      "\ttrain: 1.0 0.007469603547118932 \ttest: 0.84375 4.553553249805452\n",
      "retrain  98 :\n",
      "\ttrain: 1.0 0.007316883789791123 \ttest: 0.84375 4.553826738141952\n",
      "retrain  99 :\n",
      "\ttrain: 1.0 0.0071687962251197335 \ttest: 0.84375 4.55411740389495\n",
      "retrain  100 :\n",
      "\ttrain: 1.0 0.007025155639338473 \ttest: 0.84375 4.554424583724099\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        37\n",
      "           1    1.00000   1.00000   1.00000        37\n",
      "\n",
      "    accuracy                        1.00000        74\n",
      "   macro avg    1.00000   1.00000   1.00000        74\n",
      "weighted avg    1.00000   1.00000   1.00000        74\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.82353   0.87500   0.84848        16\n",
      "           1    0.86667   0.81250   0.83871        16\n",
      "\n",
      "    accuracy                        0.84375        32\n",
      "   macro avg    0.84510   0.84375   0.84360        32\n",
      "weighted avg    0.84510   0.84375   0.84360        32\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 147\n",
      "Average of depth: 1.0680272108843538\n",
      "Number of nodes: 461\n",
      "18 60 1\n",
      "30 94 2\n",
      "34 114 3\n",
      "43 137 4\n",
      "49 161 5\n",
      "56 184 6\n",
      "59 193 7\n",
      "63 209 8\n",
      "66 216 9\n",
      "70 230 10\n",
      "75 247 11\n",
      "78 266 12\n",
      "80 272 13\n",
      "82 278 14\n",
      "83 281 15\n",
      "84 284 16\n",
      "85 287 17\n",
      "86 288 18\n",
      "89 303 19\n",
      "91 311 20\n",
      "93 319 21\n",
      "94 316 22\n",
      "96 324 23\n",
      "98 326 24\n",
      "98 326 25\n",
      "98 326 26\n",
      "99 327 27\n",
      "103 341 28\n",
      "104 342 29\n",
      "106 344 30\n",
      "108 350 31\n",
      "110 356 32\n",
      "112 364 33\n",
      "113 367 34\n",
      "114 370 35\n",
      "115 375 36\n",
      "117 379 37\n",
      "118 382 38\n",
      "118 382 39\n",
      "120 388 40\n",
      "121 393 41\n",
      "123 397 42\n",
      "123 397 43\n",
      "124 400 44\n",
      "126 408 45\n",
      "126 408 46\n",
      "126 406 47\n",
      "126 402 48\n",
      "127 407 49\n",
      "129 419 50\n",
      "130 424 51\n",
      "133 435 52\n",
      "133 435 53\n",
      "135 435 54\n",
      "135 433 55\n",
      "136 436 56\n",
      "137 439 57\n",
      "139 447 58\n",
      "140 450 59\n",
      "140 450 60\n",
      "140 448 61\n",
      "140 448 62\n",
      "140 448 63\n",
      "140 446 64\n",
      "140 446 65\n",
      "142 452 66\n",
      "142 452 67\n",
      "142 452 68\n",
      "143 455 69\n",
      "143 455 70\n",
      "143 455 71\n",
      "145 459 72\n",
      "145 459 73\n",
      "147 467 74\n",
      "147 467 75\n",
      "148 468 76\n",
      "149 473 77\n",
      "150 478 78\n",
      "151 481 79\n",
      "151 481 80\n",
      "151 479 81\n",
      "151 479 82\n",
      "151 479 83\n",
      "153 485 84\n",
      "153 485 85\n",
      "153 485 86\n",
      "153 483 87\n",
      "153 483 88\n",
      "153 481 89\n",
      "153 481 90\n",
      "153 479 91\n",
      "153 479 92\n",
      "153 479 93\n",
      "153 479 94\n",
      "153 479 95\n",
      "153 477 96\n",
      "153 477 97\n",
      "154 482 98\n",
      "155 485 99\n",
      "156 490 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 11.477388411917001 \ttest: 0.9375 9.22442019422031\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 5.643431525051005 \ttest: 0.9375 7.305657080822469\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 3.4135546273057185 \ttest: 0.9375 6.484749389139443\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 2.2927960791192685 \ttest: 0.9375 6.043980994284722\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.6422626280554113 \ttest: 0.9375 5.774012149620669\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 1.2301639369106718 \ttest: 0.9375 5.59409969682885\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 0.9530049615955024 \ttest: 0.9375 5.467002651425836\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.7581209751118834 \ttest: 0.9375 5.373308964102851\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.6162228471354173 \ttest: 0.9375 5.301963526102505\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.5099315091937591 \ttest: 0.9375 5.246234973942153\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.42840660926921037 \ttest: 0.9375 5.201804553284796\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.3646091627448955 \ttest: 0.9375 5.165782451150239\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.3138136753244406 \ttest: 0.9375 5.136167048911658\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.27275684252119736 \ttest: 0.9375 5.111531278823198\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.23912950202784536 \ttest: 0.9375 5.090832414026086\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.2112624758518928 \ttest: 0.9375 5.073292291486322\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.18792628963069455 \ttest: 0.9375 5.058319417824379\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.16820004810568362 \ttest: 0.9375 5.045456879257021\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.15138354771543847 \ttest: 0.9375 5.034346646534953\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.13693712355283758 \ttest: 0.9375 5.0247045817960405\n",
      "retrain  21 :\n",
      "\ttrain: 1.0 0.12443969741704587 \ttest: 0.9375 5.0163026000396975\n",
      "retrain  22 :\n",
      "\ttrain: 1.0 0.11355901813189369 \ttest: 0.9375 5.008955716658457\n",
      "retrain  23 :\n",
      "\ttrain: 1.0 0.104030221947208 \ttest: 0.90625 5.00251249612344\n",
      "retrain  24 :\n",
      "\ttrain: 1.0 0.0956401672517798 \ttest: 0.90625 4.996847909357672\n",
      "retrain  25 :\n",
      "\ttrain: 1.0 0.0882158391006517 \ttest: 0.90625 4.991857923821638\n",
      "retrain  26 :\n",
      "\ttrain: 1.0 0.08161566314637139 \ttest: 0.90625 4.987455357935956\n",
      "retrain  27 :\n",
      "\ttrain: 1.0 0.07572292678286213 \ttest: 0.90625 4.983566670190781\n",
      "retrain  28 :\n",
      "\ttrain: 1.0 0.07044074505652911 \ttest: 0.90625 4.980129447576426\n",
      "retrain  29 :\n",
      "\ttrain: 1.0 0.06568817180151885 \ttest: 0.90625 4.977090423055396\n",
      "retrain  30 :\n",
      "\ttrain: 1.0 0.06139716870740469 \ttest: 0.90625 4.974403897373543\n",
      "retrain  31 :\n",
      "\ttrain: 1.0 0.057510223391096654 \ttest: 0.90625 4.9720304728499665\n",
      "retrain  32 :\n",
      "\ttrain: 1.0 0.05397846291921389 \ttest: 0.90625 4.969936030018422\n",
      "retrain  33 :\n",
      "\ttrain: 1.0 0.050760148803192046 \ttest: 0.90625 4.968090894874448\n",
      "retrain  34 :\n",
      "\ttrain: 1.0 0.047819468076541645 \ttest: 0.90625 4.966469156879661\n",
      "retrain  35 :\n",
      "\ttrain: 1.0 0.045125555920206444 \ttest: 0.90625 4.9650481070698405\n",
      "retrain  36 :\n",
      "\ttrain: 1.0 0.04265170066191892 \ttest: 0.90625 4.963807772497353\n",
      "retrain  37 :\n",
      "\ttrain: 1.0 0.04037469338789403 \ttest: 0.90625 4.9627305284373495\n",
      "retrain  38 :\n",
      "\ttrain: 1.0 0.038274292955765066 \ttest: 0.90625 4.961800773745785\n",
      "retrain  39 :\n",
      "\ttrain: 1.0 0.0363327836548117 \ttest: 0.90625 4.961004657795106\n",
      "retrain  40 :\n",
      "\ttrain: 1.0 0.03453460767240211 \ttest: 0.90625 4.960329849761552\n",
      "retrain  41 :\n",
      "\ttrain: 1.0 0.032866058290107955 \ttest: 0.90625 4.959765342865793\n",
      "retrain  42 :\n",
      "\ttrain: 1.0 0.031315022637073975 \ttest: 0.90625 4.959301287600533\n",
      "retrain  43 :\n",
      "\ttrain: 1.0 0.029870765082991642 \ttest: 0.90625 4.958928849107591\n",
      "retrain  44 :\n",
      "\ttrain: 1.0 0.028523744114353593 \ttest: 0.90625 4.958640084762166\n",
      "retrain  45 :\n",
      "\ttrain: 1.0 0.027265456921564284 \ttest: 0.90625 4.958427838735901\n",
      "retrain  46 :\n",
      "\ttrain: 1.0 0.026088307017890437 \ttest: 0.90625 4.958285650882679\n",
      "retrain  47 :\n",
      "\ttrain: 1.0 0.024985491079722227 \ttest: 0.90625 4.958207677752299\n",
      "retrain  48 :\n",
      "\ttrain: 1.0 0.02395090189095778 \ttest: 0.90625 4.958188623910651\n",
      "retrain  49 :\n",
      "\ttrain: 1.0 0.022979044830543468 \ttest: 0.90625 4.95822368204878\n",
      "retrain  50 :\n",
      "\ttrain: 1.0 0.022064965790491442 \ttest: 0.90625 4.958308480611514\n",
      "retrain  51 :\n",
      "\ttrain: 1.0 0.021204188774622414 \ttest: 0.90625 4.958439037880015\n",
      "retrain  52 :\n",
      "\ttrain: 1.0 0.020392661723357065 \ttest: 0.90625 4.958611721610469\n",
      "retrain  53 :\n",
      "\ttrain: 1.0 0.019626709350779772 \ttest: 0.90625 4.9588232134699535\n",
      "retrain  54 :\n",
      "\ttrain: 1.0 0.018902991977650472 \ttest: 0.90625 4.95907047762581\n",
      "retrain  55 :\n",
      "\ttrain: 1.0 0.01821846950649755 \ttest: 0.90625 4.9593507329408535\n",
      "retrain  56 :\n",
      "\ttrain: 1.0 0.017570369819078932 \ttest: 0.90625 4.959661428307137\n",
      "retrain  57 :\n",
      "\ttrain: 1.0 0.016956160987675134 \ttest: 0.90625 4.960000220718271\n",
      "retrain  58 :\n",
      "\ttrain: 1.0 0.016373526784123477 \ttest: 0.90625 4.960364955737074\n",
      "retrain  59 :\n",
      "\ttrain: 1.0 0.01582034504762942 \ttest: 0.90625 4.960753650063163\n",
      "retrain  60 :\n",
      "\ttrain: 1.0 0.015294668536938658 \ttest: 0.90625 4.961164475945639\n",
      "retrain  61 :\n",
      "\ttrain: 1.0 0.014794707946641209 \ttest: 0.90625 4.961595747220425\n",
      "retrain  62 :\n",
      "\ttrain: 1.0 0.014318816813003954 \ttest: 0.90625 4.962045906781165\n",
      "retrain  63 :\n",
      "\ttrain: 1.0 0.013865478073253074 \ttest: 0.90625 4.962513515317549\n",
      "retrain  64 :\n",
      "\ttrain: 1.0 0.013433292074848422 \ttest: 0.90625 4.962997241176428\n",
      "retrain  65 :\n",
      "\ttrain: 1.0 0.013020965858987769 \ttest: 0.90625 4.963495851219388\n",
      "retrain  66 :\n",
      "\ttrain: 1.0 0.012627303566152697 \ttest: 0.90625 4.9640082025663395\n",
      "retrain  67 :\n",
      "\ttrain: 1.0 0.012251197831626216 \ttest: 0.90625 4.964533235128257\n",
      "retrain  68 :\n",
      "\ttrain: 1.0 0.011891622056121287 \ttest: 0.90625 4.9650699648440035\n",
      "retrain  69 :\n",
      "\ttrain: 1.0 0.011547623451416989 \ttest: 0.90625 4.965617477546418\n",
      "retrain  70 :\n",
      "\ttrain: 1.0 0.011218316773580395 \ttest: 0.90625 4.966174923391636\n",
      "retrain  71 :\n",
      "\ttrain: 1.0 0.01090287866727795 \ttest: 0.90625 4.966741511793373\n",
      "retrain  72 :\n",
      "\ttrain: 1.0 0.010600542554109289 \ttest: 0.90625 4.967316506810587\n",
      "retrain  73 :\n",
      "\ttrain: 1.0 0.010310594006054278 \ttest: 0.90625 4.967899222942821\n",
      "retrain  74 :\n",
      "\ttrain: 1.0 0.010032366552195655 \ttest: 0.90625 4.968489021292632\n",
      "retrain  75 :\n",
      "\ttrain: 1.0 0.009765237873020196 \ttest: 0.90625 4.969085306059034\n",
      "retrain  76 :\n",
      "\ttrain: 1.0 0.009508626341947156 \ttest: 0.90625 4.969687521329801\n",
      "retrain  77 :\n",
      "\ttrain: 1.0 0.009261987878391196 \ttest: 0.90625 4.970295148143978\n",
      "retrain  78 :\n",
      "\ttrain: 1.0 0.009024813080738022 \ttest: 0.90625 4.970907701799\n",
      "retrain  79 :\n",
      "\ttrain: 1.0 0.008796624611171928 \ttest: 0.90625 4.971524729379497\n",
      "retrain  80 :\n",
      "\ttrain: 1.0 0.008576974807416421 \ttest: 0.90625 4.972145807487282\n",
      "retrain  81 :\n",
      "\ttrain: 1.0 0.00836544349918975 \ttest: 0.90625 4.972770540154102\n",
      "retrain  82 :\n",
      "\ttrain: 1.0 0.008161636009588455 \ttest: 0.90625 4.973398556920633\n",
      "retrain  83 :\n",
      "\ttrain: 1.0 0.007965181323734806 \ttest: 0.90625 4.974029511066847\n",
      "retrain  84 :\n",
      "\ttrain: 1.0 0.00777573040889855 \ttest: 0.90625 4.974663077980345\n",
      "retrain  85 :\n",
      "\ttrain: 1.0 0.0075929546719576465 \ttest: 0.90625 4.975298953650611\n",
      "retrain  86 :\n",
      "\ttrain: 1.0 0.007416544541529358 \ttest: 0.90625 4.975936853278258\n",
      "retrain  87 :\n",
      "\ttrain: 1.0 0.00724620816340019 \ttest: 0.90625 4.976576509989444\n",
      "retrain  88 :\n",
      "\ttrain: 1.0 0.007081670199036275 \ttest: 0.90625 4.977217673646531\n",
      "retrain  89 :\n",
      "\ttrain: 1.0 0.0069226707179797144 \ttest: 0.90625 4.9778601097469135\n",
      "retrain  90 :\n",
      "\ttrain: 1.0 0.0067689641758483104 \ttest: 0.90625 4.9785035984027\n",
      "retrain  91 :\n",
      "\ttrain: 1.0 0.006620318470467755 \ttest: 0.90625 4.979147933394611\n",
      "retrain  92 :\n",
      "\ttrain: 1.0 0.006476514069390664 \ttest: 0.90625 4.979792921294034\n",
      "retrain  93 :\n",
      "\ttrain: 1.0 0.006337343202704548 \ttest: 0.90625 4.980438380647764\n",
      "retrain  94 :\n",
      "\ttrain: 1.0 0.006202609115609329 \ttest: 0.90625 4.981084141220425\n",
      "retrain  95 :\n",
      "\ttrain: 1.0 0.006072125375764871 \ttest: 0.90625 4.981730043289991\n",
      "retrain  96 :\n",
      "\ttrain: 1.0 0.005945715230873428 \ttest: 0.90625 4.982375936992282\n",
      "retrain  97 :\n",
      "\ttrain: 1.0 0.005823211012380089 \ttest: 0.90625 4.983021681710625\n",
      "retrain  98 :\n",
      "\ttrain: 1.0 0.005704453581549537 \ttest: 0.90625 4.983667145507187\n",
      "retrain  99 :\n",
      "\ttrain: 1.0 0.005589291814515139 \ttest: 0.90625 4.984312204592846\n",
      "retrain  100 :\n",
      "\ttrain: 1.0 0.005477582123200831 \ttest: 0.90625 4.984956742832669\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        37\n",
      "           1    1.00000   1.00000   1.00000        37\n",
      "\n",
      "    accuracy                        1.00000        74\n",
      "   macro avg    1.00000   1.00000   1.00000        74\n",
      "weighted avg    1.00000   1.00000   1.00000        74\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.93333   0.87500   0.90323        16\n",
      "           1    0.88235   0.93750   0.90909        16\n",
      "\n",
      "    accuracy                        0.90625        32\n",
      "   macro avg    0.90784   0.90625   0.90616        32\n",
      "weighted avg    0.90784   0.90625   0.90616        32\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 156\n",
      "Average of depth: 1.0705128205128205\n",
      "Number of nodes: 490\n",
      "19 63 1\n",
      "26 90 2\n",
      "36 130 3\n",
      "38 132 4\n",
      "43 145 5\n",
      "48 160 6\n",
      "52 170 7\n",
      "57 185 8\n",
      "59 193 9\n",
      "63 211 10\n",
      "65 213 11\n",
      "66 216 12\n",
      "66 208 13\n",
      "71 229 14\n",
      "73 237 15\n",
      "74 240 16\n",
      "76 248 17\n",
      "77 251 18\n",
      "79 257 19\n",
      "81 263 20\n",
      "84 270 21\n",
      "87 279 22\n",
      "87 279 23\n",
      "90 294 24\n",
      "94 304 25\n",
      "95 311 26\n",
      "95 301 27\n",
      "97 305 28\n",
      "98 306 29\n",
      "101 315 30\n",
      "101 313 31\n",
      "103 323 32\n",
      "106 332 33\n",
      "106 332 34\n",
      "106 332 35\n",
      "107 335 36\n",
      "107 335 37\n",
      "108 340 38\n",
      "108 336 39\n",
      "108 334 40\n",
      "108 334 41\n",
      "109 337 42\n",
      "109 337 43\n",
      "109 337 44\n",
      "112 348 45\n",
      "112 348 46\n",
      "113 351 47\n",
      "113 351 48\n",
      "114 358 49\n",
      "115 361 50\n",
      "117 369 51\n",
      "118 374 52\n",
      "119 377 53\n",
      "120 382 54\n",
      "120 380 55\n",
      "120 380 56\n",
      "120 380 57\n",
      "120 380 58\n",
      "120 380 59\n",
      "120 380 60\n",
      "120 380 61\n",
      "120 380 62\n",
      "121 383 63\n",
      "121 383 64\n",
      "123 391 65\n",
      "124 392 66\n",
      "126 402 67\n",
      "126 402 68\n",
      "126 402 69\n",
      "126 402 70\n",
      "126 402 71\n",
      "126 402 72\n",
      "127 405 73\n",
      "128 408 74\n",
      "128 408 75\n",
      "128 408 76\n",
      "128 406 77\n",
      "129 411 78\n",
      "131 417 79\n",
      "131 417 80\n",
      "132 420 81\n",
      "133 423 82\n",
      "134 426 83\n",
      "134 422 84\n",
      "134 422 85\n",
      "134 422 86\n",
      "134 422 87\n",
      "134 420 88\n",
      "134 420 89\n",
      "134 420 90\n",
      "134 420 91\n",
      "135 425 92\n",
      "136 430 93\n",
      "137 431 94\n",
      "138 434 95\n",
      "138 434 96\n",
      "138 430 97\n",
      "139 433 98\n",
      "139 433 99\n",
      "140 436 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 13.298845443941618 \ttest: 0.9375 9.17371085139174\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 6.598934170751978 \ttest: 0.9375 6.896858106311473\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 3.9304881629061974 \ttest: 0.9375 5.862810455998357\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 2.597613015723211 \ttest: 0.9375 5.284995538174047\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.8358097119942238 \ttest: 0.9375 4.917610612457528\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 1.3605433211910753 \ttest: 0.9375 4.663373191277489\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 1.045076067601477 \ttest: 0.9375 4.476774945911828\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.8256680185687384 \ttest: 0.9375 4.333819130753883\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.6673552251901336 \ttest: 0.9375 4.22067861413098\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.5496625534019617 \ttest: 0.9375 4.12882711150129\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.4599677004617131 \ttest: 0.9375 4.052719340434671\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.3901582407417016 \ttest: 0.9375 3.988590936561\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.33483628639473284 \ttest: 0.9375 3.9337951145991434\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.29030291049515744 \ttest: 0.9375 3.88641552311393\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.25395832374759275 \ttest: 0.9375 3.84502981204646\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.22393440262068004 \ttest: 0.9375 3.808559596565078\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.1988623551589 \ttest: 0.9375 3.776172068927546\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.17772173066659364 \ttest: 0.9375 3.7472136200640596\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.15973988278374707 \ttest: 0.9375 3.721163931593072\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.14432356476634195 \ttest: 0.9375 3.6976035236627283\n",
      "retrain  21 :\n",
      "\ttrain: 1.0 0.1310114763662137 \ttest: 0.9375 3.676190365196018\n",
      "retrain  22 :\n",
      "\ttrain: 1.0 0.11944076383624969 \ttest: 0.9375 3.6566427209915844\n",
      "retrain  23 :\n",
      "\ttrain: 1.0 0.10932299140590994 \ttest: 0.9375 3.6387263750321557\n",
      "retrain  24 :\n",
      "\ttrain: 1.0 0.10042665456436839 \ttest: 0.9375 3.622244978479671\n",
      "retrain  25 :\n",
      "\ttrain: 1.0 0.09256428383501056 \ttest: 0.9375 3.60703266427661\n",
      "retrain  26 :\n",
      "\ttrain: 1.0 0.08558281693210004 \ttest: 0.9375 3.592948329718119\n",
      "retrain  27 :\n",
      "\ttrain: 1.0 0.07935632933055609 \ttest: 0.9375 3.5798711626952806\n",
      "retrain  28 :\n",
      "\ttrain: 1.0 0.07378048781426552 \ttest: 0.9375 3.567697106486164\n",
      "retrain  29 :\n",
      "\ttrain: 1.0 0.06876827729765152 \ttest: 0.9375 3.556336040733357\n",
      "retrain  30 :\n",
      "\ttrain: 1.0 0.0642466786809163 \ttest: 0.9375 3.5457095145594897\n",
      "retrain  31 :\n",
      "\ttrain: 1.0 0.06015406415161727 \ttest: 0.9375 3.5357489094114447\n",
      "retrain  32 :\n",
      "\ttrain: 1.0 0.05643813877212393 \ttest: 0.9375 3.5263939393274413\n",
      "retrain  33 :\n",
      "\ttrain: 1.0 0.053054301664033736 \ttest: 0.9375 3.517591418336445\n",
      "retrain  34 :\n",
      "\ttrain: 1.0 0.049964332126348765 \ttest: 0.9375 3.509294240972725\n",
      "retrain  35 :\n",
      "\ttrain: 1.0 0.047135329322893306 \ttest: 0.9375 3.5014605340382916\n",
      "retrain  36 :\n",
      "\ttrain: 1.0 0.04453885128697844 \ttest: 0.9375 3.494052946902326\n",
      "retrain  37 :\n",
      "\ttrain: 1.0 0.04215021167387143 \ttest: 0.9375 3.487038054587943\n",
      "retrain  38 :\n",
      "\ttrain: 1.0 0.039947902171192345 \ttest: 0.9375 3.480385853232685\n",
      "retrain  39 :\n",
      "\ttrain: 1.0 0.03791311561996514 \ttest: 0.9375 3.474069331631268\n",
      "retrain  40 :\n",
      "\ttrain: 1.0 0.036029350321889586 \ttest: 0.9375 3.4680641057769153\n",
      "retrain  41 :\n",
      "\ttrain: 1.0 0.03428208015531915 \ttest: 0.9375 3.4623481058310794\n",
      "retrain  42 :\n",
      "\ttrain: 1.0 0.03265847831541594 \ttest: 0.9375 3.45690130693377\n",
      "retrain  43 :\n",
      "\ttrain: 1.0 0.031147184968483815 \ttest: 0.9375 3.451705496840012\n",
      "retrain  44 :\n",
      "\ttrain: 1.0 0.029738111040126025 \ttest: 0.9375 3.4467440746238314\n",
      "retrain  45 :\n",
      "\ttrain: 1.0 0.028422271870526712 \ttest: 0.9375 3.4420018756993818\n",
      "retrain  46 :\n",
      "\ttrain: 1.0 0.02719164566419279 \ttest: 0.9375 3.4374650192224445\n",
      "retrain  47 :\n",
      "\ttrain: 1.0 0.02603905260848858 \ttest: 0.9375 3.433120774595546\n",
      "retrain  48 :\n",
      "\ttrain: 1.0 0.024958051290226498 \ttest: 0.9375 3.428957444337798\n",
      "retrain  49 :\n",
      "\ttrain: 1.0 0.02394284964437249 \ttest: 0.9375 3.4249642610210578\n",
      "retrain  50 :\n",
      "\ttrain: 1.0 0.022988228155725272 \ttest: 0.9375 3.421131296336223\n",
      "retrain  51 :\n",
      "\ttrain: 1.0 0.02208947342803426 \ttest: 0.9375 3.4174493806526685\n",
      "retrain  52 :\n",
      "\ttrain: 1.0 0.021242320554654227 \ttest: 0.9375 3.413910031681932\n",
      "retrain  53 :\n",
      "\ttrain: 1.0 0.02044290298548278 \ttest: 0.9375 3.4105053910632686\n",
      "retrain  54 :\n",
      "\ttrain: 1.0 0.019687708798324148 \ttest: 0.9375 3.407228167861279\n",
      "retrain  55 :\n",
      "\ttrain: 1.0 0.01897354245821478 \ttest: 0.9375 3.4040715881105235\n",
      "retrain  56 :\n",
      "\ttrain: 1.0 0.018297491292930422 \ttest: 0.9375 3.4010293496637862\n",
      "retrain  57 :\n",
      "\ttrain: 1.0 0.01765689603267885 \ttest: 0.9375 3.398095581703454\n",
      "retrain  58 :\n",
      "\ttrain: 1.0 0.017049324861492708 \ttest: 0.9375 3.3952648083625045\n",
      "retrain  59 :\n",
      "\ttrain: 1.0 0.016472550510778596 \ttest: 0.9375 3.392531915975593\n",
      "retrain  60 :\n",
      "\ttrain: 1.0 0.015924529994832765 \ttest: 0.9375 3.3898921235436754\n",
      "retrain  61 :\n",
      "\ttrain: 1.0 0.01540338664630857 \ttest: 0.9375 3.3873409560494587\n",
      "retrain  62 :\n",
      "\ttrain: 1.0 0.014907394158558185 \ttest: 0.9375 3.3848742203071094\n",
      "retrain  63 :\n",
      "\ttrain: 1.0 0.01443496238306555 \ttest: 0.9375 3.382487983069221\n",
      "retrain  64 :\n",
      "\ttrain: 1.0 0.013984624665121785 \ttest: 0.9375 3.3801785511481963\n",
      "retrain  65 :\n",
      "\ttrain: 1.0 0.013555026530534801 \ttest: 0.9375 3.377942453338652\n",
      "retrain  66 :\n",
      "\ttrain: 1.0 0.013144915561375776 \ttest: 0.9375 3.375776423952918\n",
      "retrain  67 :\n",
      "\ttrain: 1.0 0.012753132320264184 \ttest: 0.9375 3.37367738780385\n",
      "retrain  68 :\n",
      "\ttrain: 1.0 0.012378602201073351 \ttest: 0.9375 3.371642446488384\n",
      "retrain  69 :\n",
      "\ttrain: 1.0 0.01202032809968663 \ttest: 0.9375 3.3696688658419927\n",
      "retrain  70 :\n",
      "\ttrain: 1.0 0.011677383811962774 \ttest: 0.9375 3.3677540644488686\n",
      "retrain  71 :\n",
      "\ttrain: 1.0 0.01134890807771304 \ttest: 0.9375 3.3658956031053955\n",
      "retrain  72 :\n",
      "\ttrain: 1.0 0.011034099199539196 \ttest: 0.9375 3.364091175145745\n",
      "retrain  73 :\n",
      "\ttrain: 1.0 0.010732210174066595 \ttest: 0.9375 3.3623385975482494\n",
      "retrain  74 :\n",
      "\ttrain: 1.0 0.010442544280631747 \ttest: 0.9375 3.360635802749858\n",
      "retrain  75 :\n",
      "\ttrain: 1.0 0.010164451079014711 \ttest: 0.9375 3.358980831103672\n",
      "retrain  76 :\n",
      "\ttrain: 1.0 0.009897322773488489 \ttest: 0.9375 3.357371823921256\n",
      "retrain  77 :\n",
      "\ttrain: 1.0 0.00964059090540835 \ttest: 0.9375 3.3558070170474203\n",
      "retrain  78 :\n",
      "\ttrain: 1.0 0.009393723340885637 \ttest: 0.9375 3.354284734920431\n",
      "retrain  79 :\n",
      "\ttrain: 1.0 0.009156221523871185 \ttest: 0.9375 3.3528033850753447\n",
      "retrain  80 :\n",
      "\ttrain: 1.0 0.008927617968285704 \ttest: 0.9375 3.3513614530522786\n",
      "retrain  81 :\n",
      "\ttrain: 1.0 0.008707473965740488 \ttest: 0.9375 3.349957497675201\n",
      "retrain  82 :\n",
      "\ttrain: 1.0 0.008495377487947396 \ttest: 0.9375 3.3485901466700843\n",
      "retrain  83 :\n",
      "\ttrain: 1.0 0.008290941265167304 \ttest: 0.9375 3.347258092594267\n",
      "retrain  84 :\n",
      "\ttrain: 1.0 0.008093801024030244 \ttest: 0.9375 3.345960089051504\n",
      "retrain  85 :\n",
      "\ttrain: 1.0 0.007903613869812833 \ttest: 0.9375 3.3446949471695175\n",
      "retrain  86 :\n",
      "\ttrain: 1.0 0.007720056799809848 \ttest: 0.9375 3.3434615323190484\n",
      "retrain  87 :\n",
      "\ttrain: 1.0 0.007542825335809541 \ttest: 0.9375 3.3422587610552545\n",
      "retrain  88 :\n",
      "\ttrain: 1.0 0.007371632264901262 \ttest: 0.9375 3.341085598264062\n",
      "retrain  89 :\n",
      "\ttrain: 1.0 0.00720620647892695 \ttest: 0.9375 3.339941054497589\n",
      "retrain  90 :\n",
      "\ttrain: 1.0 0.007046291903850305 \ttest: 0.9375 3.3388241834841663\n",
      "retrain  91 :\n",
      "\ttrain: 1.0 0.006891646511176722 \ttest: 0.9375 3.337734079799733\n",
      "retrain  92 :\n",
      "\ttrain: 1.0 0.006742041404321268 \ttest: 0.9375 3.3366698766885188\n",
      "retrain  93 :\n",
      "\ttrain: 1.0 0.006597259973506426 \ttest: 0.9375 3.335630744021941\n",
      "retrain  94 :\n",
      "\ttrain: 1.0 0.006457097113382295 \ttest: 0.9375 3.3346158863855972\n",
      "retrain  95 :\n",
      "\ttrain: 1.0 0.006321358498109365 \ttest: 0.9375 3.3336245412850407\n",
      "retrain  96 :\n",
      "\ttrain: 1.0 0.00618985990913457 \ttest: 0.9375 3.332655977461817\n",
      "retrain  97 :\n",
      "\ttrain: 1.0 0.0060624266113319895 \ttest: 0.9375 3.331709493311938\n",
      "retrain  98 :\n",
      "\ttrain: 1.0 0.005938892773574846 \ttest: 0.9375 3.3307844153995614\n",
      "retrain  99 :\n",
      "\ttrain: 1.0 0.005819100930161717 \ttest: 0.9375 3.32988009705927\n",
      "retrain  100 :\n",
      "\ttrain: 1.0 0.005702901479840328 \ttest: 0.9375 3.32899591708083\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        37\n",
      "           1    1.00000   1.00000   1.00000        37\n",
      "\n",
      "    accuracy                        1.00000        74\n",
      "   macro avg    1.00000   1.00000   1.00000        74\n",
      "weighted avg    1.00000   1.00000   1.00000        74\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.93750   0.93750   0.93750        16\n",
      "           1    0.93750   0.93750   0.93750        16\n",
      "\n",
      "    accuracy                        0.93750        32\n",
      "   macro avg    0.93750   0.93750   0.93750        32\n",
      "weighted avg    0.93750   0.93750   0.93750        32\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 140\n",
      "Average of depth: 1.05\n",
      "Number of nodes: 436\n",
      "16 52 1\n",
      "28 92 2\n",
      "38 132 3\n",
      "45 151 4\n",
      "49 169 5\n",
      "55 199 6\n",
      "61 221 7\n",
      "65 229 8\n",
      "69 243 9\n",
      "71 245 10\n",
      "76 260 11\n",
      "80 276 12\n",
      "84 286 13\n",
      "86 292 14\n",
      "89 293 15\n",
      "91 297 16\n",
      "93 301 17\n",
      "95 305 18\n",
      "97 311 19\n",
      "101 333 20\n",
      "102 336 21\n",
      "103 335 22\n",
      "104 336 23\n",
      "104 336 24\n",
      "107 349 25\n",
      "109 357 26\n",
      "110 362 27\n",
      "113 371 28\n",
      "114 374 29\n",
      "115 377 30\n",
      "115 375 31\n",
      "117 381 32\n",
      "118 384 33\n",
      "119 387 34\n",
      "120 392 35\n",
      "121 395 36\n",
      "123 409 37\n",
      "123 407 38\n",
      "126 418 39\n",
      "128 426 40\n",
      "128 426 41\n",
      "128 424 42\n",
      "129 427 43\n",
      "130 430 44\n",
      "131 433 45\n",
      "133 437 46\n",
      "134 440 47\n",
      "135 443 48\n",
      "137 453 49\n",
      "138 460 50\n",
      "139 463 51\n",
      "139 457 52\n",
      "139 457 53\n",
      "142 468 54\n",
      "143 473 55\n",
      "144 476 56\n",
      "144 476 57\n",
      "144 474 58\n",
      "144 472 59\n",
      "146 480 60\n",
      "146 478 61\n",
      "146 478 62\n",
      "147 479 63\n",
      "147 479 64\n",
      "147 477 65\n",
      "148 480 66\n",
      "148 480 67\n",
      "149 483 68\n",
      "149 483 69\n",
      "149 483 70\n",
      "149 483 71\n",
      "151 491 72\n",
      "152 494 73\n",
      "154 502 74\n",
      "155 505 75\n",
      "155 505 76\n",
      "156 508 77\n",
      "156 508 78\n",
      "156 504 79\n",
      "157 507 80\n",
      "158 510 81\n",
      "158 510 82\n",
      "158 510 83\n",
      "160 520 84\n",
      "161 523 85\n",
      "161 523 86\n",
      "161 521 87\n",
      "161 521 88\n",
      "161 521 89\n",
      "161 521 90\n",
      "162 524 91\n",
      "162 522 92\n",
      "163 529 93\n",
      "163 529 94\n",
      "163 529 95\n",
      "163 529 96\n",
      "163 529 97\n",
      "163 529 98\n",
      "163 527 99\n",
      "164 530 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 10.694128352309178 \ttest: 0.875 9.292699988403694\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 4.9773003382081775 \ttest: 0.875 7.547062294401947\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 2.8759313390021433 \ttest: 0.875 6.841545852232191\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 1.8626329138080087 \ttest: 0.875 6.483066004065297\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.296911596751959 \ttest: 0.875 6.2758981717850535\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 0.950361562956389 \ttest: 0.875 6.146195620464956\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 0.723699793591474 \ttest: 0.875 6.060592631951321\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.5679342160701555 \ttest: 0.875 6.002051885846068\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.4566330850928904 \ttest: 0.875 5.961069457235188\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.37454505419551143 \ttest: 0.875 5.931977163765978\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.31239052745825474 \ttest: 0.875 5.911212944276012\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.2642736604155211 \ttest: 0.875 5.896442255991633\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.22631057440679092 \ttest: 0.875 5.886081446256071\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.19586287709652989 \ttest: 0.875 5.879024937212784\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.17109009725835625 \ttest: 0.875 5.874481939991153\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.1506783361279615 \ttest: 0.875 5.871874965124112\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.1336703202293588 \ttest: 0.875 5.87077466902898\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.119355890646477 \ttest: 0.875 5.870856839005432\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.10719963921469242 \ttest: 0.875 5.871873289917087\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.0967920074220214 \ttest: 0.875 5.873631743209404\n",
      "retrain  21 :\n",
      "\ttrain: 1.0 0.08781556946222076 \ttest: 0.875 5.875981646391569\n",
      "retrain  22 :\n",
      "\ttrain: 1.0 0.08002135887049279 \ttest: 0.875 5.878804006153407\n",
      "retrain  23 :\n",
      "\ttrain: 1.0 0.07321197097069493 \ttest: 0.875 5.882003985765694\n",
      "retrain  24 :\n",
      "\ttrain: 1.0 0.0672293193151493 \ttest: 0.875 5.8855054395088535\n",
      "retrain  25 :\n",
      "\ttrain: 1.0 0.061945641526277025 \ttest: 0.875 5.889246825878705\n",
      "retrain  26 :\n",
      "\ttrain: 1.0 0.05725680818247831 \ttest: 0.875 5.893178116303851\n",
      "retrain  27 :\n",
      "\ttrain: 1.0 0.05307728671856664 \ttest: 0.875 5.897258432079122\n",
      "retrain  28 :\n",
      "\ttrain: 1.0 0.04933630992369827 \ttest: 0.875 5.901454220397207\n",
      "retrain  29 :\n",
      "\ttrain: 1.0 0.04597493162362662 \ttest: 0.875 5.9057378338919735\n",
      "retrain  30 :\n",
      "\ttrain: 1.0 0.042943742984122464 \ttest: 0.875 5.910086415292893\n",
      "retrain  31 :\n",
      "\ttrain: 1.0 0.040201085784730944 \ttest: 0.875 5.914481014967142\n",
      "retrain  32 :\n",
      "\ttrain: 1.0 0.0377116431369966 \ttest: 0.875 5.918905887781448\n",
      "retrain  33 :\n",
      "\ttrain: 1.0 0.035445319439747575 \ttest: 0.875 5.923347929163841\n",
      "retrain  34 :\n",
      "\ttrain: 1.0 0.033376343841606385 \ttest: 0.875 5.927796220043598\n",
      "retrain  35 :\n",
      "\ttrain: 1.0 0.031482547782467105 \ttest: 0.875 5.932241657557556\n",
      "retrain  36 :\n",
      "\ttrain: 1.0 0.029744779124596964 \ttest: 0.875 5.936676653766289\n",
      "retrain  37 :\n",
      "\ttrain: 1.0 0.028146424208842155 \ttest: 0.875 5.941094888635849\n",
      "retrain  38 :\n",
      "\ttrain: 1.0 0.026673015751375706 \ttest: 0.875 5.94549110657186\n",
      "retrain  39 :\n",
      "\ttrain: 1.0 0.02531190944302305 \ttest: 0.875 5.949860948100038\n",
      "retrain  40 :\n",
      "\ttrain: 1.0 0.024052015860894352 \ttest: 0.875 5.954200810056589\n",
      "retrain  41 :\n",
      "\ttrain: 1.0 0.022883577162387248 \ttest: 0.875 5.958507729017981\n",
      "retrain  42 :\n",
      "\ttrain: 1.0 0.021797980230003552 \ttest: 0.875 5.962779283761224\n",
      "retrain  43 :\n",
      "\ttrain: 1.0 0.020787599636280952 \ttest: 0.875 5.967013513375887\n",
      "retrain  44 :\n",
      "\ttrain: 1.0 0.01984566512240244 \ttest: 0.875 5.971208848301918\n",
      "retrain  45 :\n",
      "\ttrain: 1.0 0.01896614932130867 \ttest: 0.875 5.9753640520836395\n",
      "retrain  46 :\n",
      "\ttrain: 1.0 0.01814367227326892 \ttest: 0.875 5.9794781720408015\n",
      "retrain  47 :\n",
      "\ttrain: 1.0 0.01737341992911283 \ttest: 0.875 5.9835504973854565\n",
      "retrain  48 :\n",
      "\ttrain: 1.0 0.016651074351688767 \ttest: 0.875 5.987580523576826\n",
      "retrain  49 :\n",
      "\ttrain: 1.0 0.015972753738530073 \ttest: 0.875 5.991567921918539\n",
      "retrain  50 :\n",
      "\ttrain: 1.0 0.015334960720318412 \ttest: 0.875 5.995512513574729\n",
      "retrain  51 :\n",
      "\ttrain: 1.0 0.014734537657597666 \ttest: 0.875 5.999414247321286\n",
      "retrain  52 :\n",
      "\ttrain: 1.0 0.014168627875514988 \ttest: 0.875 6.003273180462788\n",
      "retrain  53 :\n",
      "\ttrain: 1.0 0.013634641953433706 \ttest: 0.875 6.00708946243929\n",
      "retrain  54 :\n",
      "\ttrain: 1.0 0.013130228331114494 \ttest: 0.875 6.0108633207241295\n",
      "retrain  55 :\n",
      "\ttrain: 1.0 0.012653247612124007 \ttest: 0.875 6.014595048677507\n",
      "retrain  56 :\n",
      "\ttrain: 1.0 0.012201750043197783 \ttest: 0.875 6.018284995073194\n",
      "retrain  57 :\n",
      "\ttrain: 1.0 0.011773955729416249 \ttest: 0.875 6.021933555059615\n",
      "retrain  58 :\n",
      "\ttrain: 1.0 0.011368237212414343 \ttest: 0.875 6.025541162352761\n",
      "retrain  59 :\n",
      "\ttrain: 1.0 0.010983104094953417 \ttest: 0.875 6.029108282489178\n",
      "retrain  60 :\n",
      "\ttrain: 1.0 0.010617189442078245 \ttest: 0.875 6.032635406992528\n",
      "retrain  61 :\n",
      "\ttrain: 1.0 0.010269237728391722 \ttest: 0.875 6.0361230483289185\n",
      "retrain  62 :\n",
      "\ttrain: 1.0 0.009938094134035947 \ttest: 0.875 6.039571735544122\n",
      "retrain  63 :\n",
      "\ttrain: 1.0 0.009622695019843735 \ttest: 0.875 6.042982010491214\n",
      "retrain  64 :\n",
      "\ttrain: 1.0 0.00932205943569998 \ttest: 0.875 6.04635442457006\n",
      "retrain  65 :\n",
      "\ttrain: 1.0 0.009035281536143969 \ttest: 0.875 6.0496895359110106\n",
      "retrain  66 :\n",
      "\ttrain: 1.0 0.008761523794241851 \ttest: 0.875 6.052987906944646\n",
      "retrain  67 :\n",
      "\ttrain: 1.0 0.008500010919248992 \ttest: 0.875 6.05625010230723\n",
      "retrain  68 :\n",
      "\ttrain: 1.0 0.008250024395963932 \ttest: 0.875 6.059476687038469\n",
      "retrain  69 :\n",
      "\ttrain: 1.0 0.008010897574283436 \ttest: 0.875 6.062668225033901\n",
      "retrain  70 :\n",
      "\ttrain: 1.0 0.007782011246575052 \ttest: 0.875 6.065825277719338\n",
      "retrain  71 :\n",
      "\ttrain: 1.0 0.007562789658321986 \ttest: 0.875 6.068948402918946\n",
      "retrain  72 :\n",
      "\ttrain: 1.0 0.007352696904253674 \ttest: 0.875 6.0720381538923975\n",
      "retrain  73 :\n",
      "\ttrain: 1.0 0.007151233668019069 \ttest: 0.875 6.075095078519601\n",
      "retrain  74 :\n",
      "\ttrain: 1.0 0.006957934268518909 \ttest: 0.875 6.078119718614328\n",
      "retrain  75 :\n",
      "\ttrain: 1.0 0.006772363980404918 \ttest: 0.875 6.081112609350388\n",
      "retrain  76 :\n",
      "\ttrain: 1.0 0.0065941166000728635 \ttest: 0.875 6.084074278786153\n",
      "retrain  77 :\n",
      "\ttrain: 1.0 0.00642281223180249 \ttest: 0.875 6.087005247474898\n",
      "retrain  78 :\n",
      "\ttrain: 1.0 0.006258095271601946 \ttest: 0.875 6.089906028150116\n",
      "retrain  79 :\n",
      "\ttrain: 1.0 0.006099632568852829 \ttest: 0.875 6.092777125476191\n",
      "retrain  80 :\n",
      "\ttrain: 1.0 0.005947111748076451 \ttest: 0.875 6.095619035856096\n",
      "retrain  81 :\n",
      "\ttrain: 1.0 0.0058002396750936325 \ttest: 0.875 6.098432247288747\n",
      "retrain  82 :\n",
      "\ttrain: 1.0 0.005658741053565163 \ttest: 0.875 6.101217239269557\n",
      "retrain  83 :\n",
      "\ttrain: 1.0 0.005522357139411098 \ttest: 0.875 6.10397448272855\n",
      "retrain  84 :\n",
      "\ttrain: 1.0 0.005390844561937653 \ttest: 0.875 6.10670444000102\n",
      "retrain  85 :\n",
      "\ttrain: 1.0 0.005263974241677286 \ttest: 0.875 6.109407564826379\n",
      "retrain  86 :\n",
      "\ttrain: 1.0 0.005141530395987054 \ttest: 0.875 6.112084302371349\n",
      "retrain  87 :\n",
      "\ttrain: 1.0 0.005023309624372101 \ttest: 0.875 6.1147350892741095\n",
      "retrain  88 :\n",
      "\ttrain: 1.0 0.004909120066317993 \ttest: 0.875 6.117360353706388\n",
      "retrain  89 :\n",
      "\ttrain: 1.0 0.004798780625142018 \ttest: 0.875 6.119960515450947\n",
      "retrain  90 :\n",
      "\ttrain: 1.0 0.004692120252019117 \ttest: 0.875 6.122535985992072\n",
      "retrain  91 :\n",
      "\ttrain: 1.0 0.004588977284913143 \ttest: 0.875 6.1250871686171084\n",
      "retrain  92 :\n",
      "\ttrain: 1.0 0.004489198837657699 \ttest: 0.875 6.127614458527221\n",
      "retrain  93 :\n",
      "\ttrain: 1.0 0.0043926402348885025 \ttest: 0.875 6.130118242955824\n",
      "retrain  94 :\n",
      "\ttrain: 1.0 0.004299164488939183 \ttest: 0.875 6.1325989012932896\n",
      "retrain  95 :\n",
      "\ttrain: 1.0 0.004208641815178957 \ttest: 0.875 6.13505680521675\n",
      "retrain  96 :\n",
      "\ttrain: 1.0 0.004120949182599681 \ttest: 0.875 6.1374923188239165\n",
      "retrain  97 :\n",
      "\ttrain: 1.0 0.0040359698967545685 \ttest: 0.875 6.1399057987699655\n",
      "retrain  98 :\n",
      "\ttrain: 1.0 0.003953593212415948 \ttest: 0.875 6.14229759440673\n",
      "retrain  99 :\n",
      "\ttrain: 1.0 0.0038737139735580584 \ttest: 0.875 6.144668047923432\n",
      "retrain  100 :\n",
      "\ttrain: 1.0 0.0037962322784851612 \ttest: 0.875 6.147017494488361\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        37\n",
      "           1    1.00000   1.00000   1.00000        37\n",
      "\n",
      "    accuracy                        1.00000        74\n",
      "   macro avg    1.00000   1.00000   1.00000        74\n",
      "weighted avg    1.00000   1.00000   1.00000        74\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.87500   0.87500   0.87500        16\n",
      "           1    0.87500   0.87500   0.87500        16\n",
      "\n",
      "    accuracy                        0.87500        32\n",
      "   macro avg    0.87500   0.87500   0.87500        32\n",
      "weighted avg    0.87500   0.87500   0.87500        32\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 164\n",
      "Average of depth: 1.103658536585366\n",
      "Number of nodes: 530\n",
      "23 71 1\n",
      "30 102 2\n",
      "38 132 3\n",
      "42 148 4\n",
      "49 171 5\n",
      "54 186 6\n",
      "57 193 7\n",
      "58 200 8\n",
      "58 200 9\n",
      "62 216 10\n",
      "66 226 11\n",
      "72 240 12\n",
      "75 243 13\n",
      "76 246 14\n",
      "79 257 15\n",
      "80 256 16\n",
      "83 275 17\n",
      "86 288 18\n",
      "86 288 19\n",
      "87 291 20\n",
      "88 294 21\n",
      "90 302 22\n",
      "93 307 23\n",
      "93 307 24\n",
      "94 310 25\n",
      "95 315 26\n",
      "96 320 27\n",
      "97 323 28\n",
      "97 317 29\n",
      "99 325 30\n",
      "102 342 31\n",
      "107 359 32\n",
      "108 362 33\n",
      "111 371 34\n",
      "111 369 35\n",
      "113 371 36\n",
      "115 377 37\n",
      "115 377 38\n",
      "115 377 39\n",
      "116 382 40\n",
      "116 382 41\n",
      "116 382 42\n",
      "116 382 43\n",
      "116 382 44\n",
      "116 382 45\n",
      "118 388 46\n",
      "120 396 47\n",
      "121 399 48\n",
      "122 404 49\n",
      "123 407 50\n",
      "123 407 51\n",
      "123 401 52\n",
      "123 399 53\n",
      "125 405 54\n",
      "127 417 55\n",
      "128 424 56\n",
      "129 427 57\n",
      "131 435 58\n",
      "132 438 59\n",
      "133 441 60\n",
      "134 446 61\n",
      "135 449 62\n",
      "135 447 63\n",
      "135 447 64\n",
      "136 452 65\n",
      "136 450 66\n",
      "137 453 67\n",
      "137 453 68\n",
      "137 453 69\n",
      "138 454 70\n",
      "138 454 71\n",
      "139 457 72\n",
      "140 460 73\n",
      "141 465 74\n",
      "141 461 75\n",
      "142 464 76\n",
      "143 467 77\n",
      "144 468 78\n",
      "145 469 79\n",
      "147 479 80\n",
      "148 484 81\n",
      "148 480 82\n",
      "148 480 83\n",
      "149 483 84\n",
      "149 483 85\n",
      "151 489 86\n",
      "151 489 87\n",
      "151 489 88\n",
      "151 489 89\n",
      "152 492 90\n",
      "153 497 91\n",
      "153 497 92\n",
      "154 500 93\n",
      "154 498 94\n",
      "154 498 95\n",
      "156 504 96\n",
      "156 504 97\n",
      "156 502 98\n",
      "156 502 99\n",
      "156 502 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 11.536830960515081 \ttest: 0.84375 8.937029566027377\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 5.576143334668652 \ttest: 0.84375 7.1591518488308505\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 3.314555156001166 \ttest: 0.875 6.429895883943562\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 2.1956340358949773 \ttest: 0.875 6.035634042246514\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 1.5559190352178365 \ttest: 0.875 5.787124671571016\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 1.1558437443780438 \ttest: 0.90625 5.614930819614509\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 0.8896178952691995 \ttest: 0.9375 5.48775415977099\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.7040602547627997 \ttest: 0.9375 5.389417316912552\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.5699344274188746 \ttest: 0.9375 5.310710498101931\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.4700735372602579 \ttest: 0.9375 5.246000475348479\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.3938691714404081 \ttest: 0.9375 5.191644843730732\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.3344896846231171 \ttest: 0.9375 5.145181553615821\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.2873821362435977 \ttest: 0.9375 5.104884786439081\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.24942256657407633 \ttest: 0.9375 5.069507507874984\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.21841294493194663 \ttest: 0.9375 5.038125141598908\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.19277238526798662 \ttest: 0.9375 5.010036862825359\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.17134161230784395 \ttest: 0.9375 4.984701156853042\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.15325572786757213 \ttest: 0.9375 4.96169251346026\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.13785940607989122 \ttest: 0.9375 4.940671579151608\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.12464914413044946 \ttest: 0.9375 4.9213641203434655\n",
      "retrain  21 :\n",
      "\ttrain: 1.0 0.11323317228115948 \ttest: 0.9375 4.903545898987854\n",
      "retrain  22 :\n",
      "\ttrain: 1.0 0.10330313425547663 \ttest: 0.9375 4.8870316037441714\n",
      "retrain  23 :\n",
      "\ttrain: 1.0 0.09461376301264081 \ttest: 0.9375 4.871666618373091\n",
      "retrain  24 :\n",
      "\ttrain: 1.0 0.08696808214217333 \ttest: 0.9375 4.857320810659612\n",
      "retrain  25 :\n",
      "\ttrain: 1.0 0.08020648673102933 \ttest: 0.9375 4.843883783676675\n",
      "retrain  26 :\n",
      "\ttrain: 1.0 0.07419858770092568 \ttest: 0.9375 4.831261201094013\n",
      "retrain  27 :\n",
      "\ttrain: 1.0 0.0688370511097583 \ttest: 0.9375 4.819371912036098\n",
      "retrain  28 :\n",
      "\ttrain: 1.0 0.06403289552175742 \ttest: 0.9375 4.808145678554936\n",
      "retrain  29 :\n",
      "\ttrain: 1.0 0.059711867320776275 \ttest: 0.9375 4.797521362497424\n",
      "retrain  30 :\n",
      "\ttrain: 1.0 0.055811621479679 \ttest: 0.9375 4.787445466296216\n",
      "retrain  31 :\n",
      "\ttrain: 1.0 0.05227951019105493 \ttest: 0.9375 4.777870949105637\n",
      "retrain  32 :\n",
      "\ttrain: 1.0 0.049070834521090595 \ttest: 0.9375 4.768756259105061\n",
      "retrain  33 :\n",
      "\ttrain: 1.0 0.04614745184382152 \ttest: 0.9375 4.760064536953711\n",
      "retrain  34 :\n",
      "\ttrain: 1.0 0.04347665889567089 \ttest: 0.9375 4.751762955831033\n",
      "retrain  35 :\n",
      "\ttrain: 1.0 0.04103028999893079 \ttest: 0.9375 4.743822171287581\n",
      "retrain  36 :\n",
      "\ttrain: 1.0 0.03878398448303139 \ttest: 0.9375 4.736215859995184\n",
      "retrain  37 :\n",
      "\ttrain: 1.0 0.03671658806731176 \ttest: 0.9375 4.728920330938412\n",
      "retrain  38 :\n",
      "\ttrain: 1.0 0.03480966099517041 \ttest: 0.9375 4.721914195999905\n",
      "retrain  39 :\n",
      "\ttrain: 1.0 0.03304707175877638 \ttest: 0.9375 4.715178089524965\n",
      "retrain  40 :\n",
      "\ttrain: 1.0 0.0314146598476657 \ttest: 0.9375 4.708694428498592\n",
      "retrain  41 :\n",
      "\ttrain: 1.0 0.029899954468805296 \ttest: 0.9375 4.702447206572094\n",
      "retrain  42 :\n",
      "\ttrain: 1.0 0.028491938892375557 \ttest: 0.9375 4.696421816441197\n",
      "retrain  43 :\n",
      "\ttrain: 1.0 0.027180852175795675 \ttest: 0.9375 4.690604896081316\n",
      "retrain  44 :\n",
      "\ttrain: 1.0 0.02595802165525495 \ttest: 0.9375 4.684984195146951\n",
      "retrain  45 :\n",
      "\ttrain: 1.0 0.024815720878291026 \ttest: 0.9375 4.679548458485597\n",
      "retrain  46 :\n",
      "\ttrain: 1.0 0.0237470486643698 \ttest: 0.9375 4.674287324235959\n",
      "retrain  47 :\n",
      "\ttrain: 1.0 0.022745825784404032 \ttest: 0.9375 4.669191234401835\n",
      "retrain  48 :\n",
      "\ttrain: 1.0 0.021806506391275626 \ttest: 0.9375 4.664251356136771\n",
      "retrain  49 :\n",
      "\ttrain: 1.0 0.020924101847203967 \ttest: 0.9375 4.659459512256249\n",
      "retrain  50 :\n",
      "\ttrain: 1.0 0.0200941150074749 \ttest: 0.9375 4.654808119726109\n",
      "retrain  51 :\n",
      "\ttrain: 1.0 0.019312483354624654 \ttest: 0.9375 4.6502901350674355\n",
      "retrain  52 :\n",
      "\ttrain: 1.0 0.018575529648956993 \ttest: 0.9375 4.645899005777327\n",
      "retrain  53 :\n",
      "\ttrain: 1.0 0.01787991898296938 \ttest: 0.9375 4.641628626997503\n",
      "retrain  54 :\n",
      "\ttrain: 1.0 0.017222621308829348 \ttest: 0.9375 4.6374733027736035\n",
      "retrain  55 :\n",
      "\ttrain: 1.0 0.016600878657314785 \ttest: 0.9375 4.633427711341139\n",
      "retrain  56 :\n",
      "\ttrain: 1.0 0.01601217638980934 \ttest: 0.9375 4.62948687395255\n",
      "retrain  57 :\n",
      "\ttrain: 1.0 0.015454217926953763 \ttest: 0.9375 4.625646126826052\n",
      "retrain  58 :\n",
      "\ttrain: 1.0 0.014924902482322906 \ttest: 0.9375 4.6219010958532785\n",
      "retrain  59 :\n",
      "\ttrain: 1.0 0.014422305400175046 \ttest: 0.9375 4.618247673750529\n",
      "retrain  60 :\n",
      "\ttrain: 1.0 0.013944660755436456 \ttest: 0.9375 4.6146819993792505\n",
      "retrain  61 :\n",
      "\ttrain: 1.0 0.013490345923685072 \ttest: 0.9375 4.611200438996356\n",
      "retrain  62 :\n",
      "\ttrain: 1.0 0.01305786787063673 \ttest: 0.9375 4.607799569224916\n",
      "retrain  63 :\n",
      "\ttrain: 1.0 0.012645850945864862 \ttest: 0.9375 4.604476161561604\n",
      "retrain  64 :\n",
      "\ttrain: 1.0 0.012253025995298903 \ttest: 0.9375 4.6012271682595\n",
      "retrain  65 :\n",
      "\ttrain: 1.0 0.011878220632348096 \ttest: 0.9375 4.5980497094441075\n",
      "retrain  66 :\n",
      "\ttrain: 1.0 0.011520350529023064 \ttest: 0.9375 4.594941061337137\n",
      "retrain  67 :\n",
      "\ttrain: 1.0 0.01117841160679293 \ttest: 0.9375 4.591898645477123\n",
      "retrain  68 :\n",
      "\ttrain: 1.0 0.010851473022615566 \ttest: 0.9375 4.588920018838527\n",
      "retrain  69 :\n",
      "\ttrain: 1.0 0.010538670859040061 \ttest: 0.9375 4.586002864762066\n",
      "retrain  70 :\n",
      "\ttrain: 1.0 0.010239202438842932 \ttest: 0.9375 4.583144984618596\n",
      "retrain  71 :\n",
      "\ttrain: 1.0 0.009952321194616497 \ttest: 0.9375 4.5803442901373685\n",
      "retrain  72 :\n",
      "\ttrain: 1.0 0.009677332032321056 \ttest: 0.9375 4.577598796336893\n",
      "retrain  73 :\n",
      "\ttrain: 1.0 0.009413587135242315 \ttest: 0.9375 4.574906615003185\n",
      "retrain  74 :\n",
      "\ttrain: 1.0 0.00916048216123472 \ttest: 0.9375 4.572265948665908\n",
      "retrain  75 :\n",
      "\ttrain: 1.0 0.008917452791722895 \ttest: 0.9375 4.569675085028065\n",
      "retrain  76 :\n",
      "\ttrain: 1.0 0.008683971595796954 \ttest: 0.9375 4.567132391809333\n",
      "retrain  77 :\n",
      "\ttrain: 1.0 0.008459545176977638 \ttest: 0.9375 4.564636311967204\n",
      "retrain  78 :\n",
      "\ttrain: 1.0 0.008243711573929783 \ttest: 0.9375 4.562185359263557\n",
      "retrain  79 :\n",
      "\ttrain: 1.0 0.008036037889641322 \ttest: 0.9375 4.559778114147511\n",
      "retrain  80 :\n",
      "\ttrain: 1.0 0.007836118126423663 \ttest: 0.9375 4.557413219928179\n",
      "retrain  81 :\n",
      "\ttrain: 1.0 0.007643571206581391 \ttest: 0.9375 4.555089379213467\n",
      "retrain  82 :\n",
      "\ttrain: 1.0 0.007458039160789739 \ttest: 0.9375 4.552805350593289\n",
      "retrain  83 :\n",
      "\ttrain: 1.0 0.0072791854681484025 \ttest: 0.9375 4.55055994554758\n",
      "retrain  84 :\n",
      "\ttrain: 1.0 0.007106693533582516 \ttest: 0.9375 4.548352025561288\n",
      "retrain  85 :\n",
      "\ttrain: 1.0 0.00694026528976531 \ttest: 0.9375 4.546180499430147\n",
      "retrain  86 :\n",
      "\ttrain: 1.0 0.006779619912068008 \ttest: 0.9375 4.544044320742447\n",
      "retrain  87 :\n",
      "\ttrain: 1.0 0.006624492636221205 \ttest: 0.9375 4.541942485523358\n",
      "retrain  88 :\n",
      "\ttrain: 1.0 0.0064746336694191985 \ttest: 0.9375 4.539874030029529\n",
      "retrain  89 :\n",
      "\ttrain: 1.0 0.0063298071865272275 \ttest: 0.9375 4.537838028682739\n",
      "retrain  90 :\n",
      "\ttrain: 1.0 0.006189790403880497 \ttest: 0.9375 4.53583359213231\n",
      "retrain  91 :\n",
      "\ttrain: 1.0 0.006054372723900039 \ttest: 0.9375 4.533859865436929\n",
      "retrain  92 :\n",
      "\ttrain: 1.0 0.005923354944408569 \ttest: 0.9375 4.531916026357217\n",
      "retrain  93 :\n",
      "\ttrain: 1.0 0.005796548527117362 \ttest: 0.9375 4.5300012837511625\n",
      "retrain  94 :\n",
      "\ttrain: 1.0 0.0056737749202803184 \ttest: 0.9375 4.528114876065164\n",
      "retrain  95 :\n",
      "\ttrain: 1.0 0.005554864930982618 \ttest: 0.9375 4.5262560699139875\n",
      "retrain  96 :\n",
      "\ttrain: 1.0 0.0054396581429526705 \ttest: 0.9375 4.524424158743511\n",
      "retrain  97 :\n",
      "\ttrain: 1.0 0.00532800237616595 \ttest: 0.9375 4.522618461570594\n",
      "retrain  98 :\n",
      "\ttrain: 1.0 0.005219753184848635 \ttest: 0.9375 4.520838321794857\n",
      "retrain  99 :\n",
      "\ttrain: 1.0 0.005114773390796353 \ttest: 0.9375 4.519083106077562\n",
      "retrain  100 :\n",
      "\ttrain: 1.0 0.0050129326491983525 \ttest: 0.9375 4.5173522032831475\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        37\n",
      "           1    1.00000   1.00000   1.00000        37\n",
      "\n",
      "    accuracy                        1.00000        74\n",
      "   macro avg    1.00000   1.00000   1.00000        74\n",
      "weighted avg    1.00000   1.00000   1.00000        74\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.93750   0.93750   0.93750        16\n",
      "           1    0.93750   0.93750   0.93750        16\n",
      "\n",
      "    accuracy                        0.93750        32\n",
      "   macro avg    0.93750   0.93750   0.93750        32\n",
      "weighted avg    0.93750   0.93750   0.93750        32\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 156\n",
      "Average of depth: 1.1025641025641026\n",
      "Number of nodes: 502\n"
     ]
    }
   ],
   "source": [
    "def fit_trees():\n",
    "    learning_rate=0.1\n",
    "    max_depth=3\n",
    "    bins=8\n",
    "    lam=100\n",
    "\n",
    "    gtgp = GTGP(learning_rate=learning_rate,max_depth=max_depth,bins=bins,lam=lam)\n",
    "\n",
    "    total_size=10\n",
    "    elite_size = 10\n",
    "    epoch= 100\n",
    "    gp_epoch= 3\n",
    "    verbose = 1\n",
    "    tolerance=0.01\n",
    "\n",
    "    gtgp.fit(X_train,y_train,total_size=total_size,elite_size = elite_size,epoch=epoch,gp_epoch=gp_epoch,tolerance=tolerance,verbose=verbose)\n",
    "\n",
    "    retrain_epoch= 100\n",
    "    alpha=0\n",
    "    beta=1\n",
    "    gammer=0\n",
    "\n",
    "    verbose=1\n",
    "    gtgp.lam = 10\n",
    "    gtgp.retrain_estimators(X_test,y_test,retrain_epoch=retrain_epoch,alpha=alpha,beta=beta,gammer=gammer,verbose=verbose)\n",
    "\n",
    "    return gtgp\n",
    "\n",
    "with open('./benchmark/'+dataset+'.csv','w') as f:\n",
    "        f.writelines(\"\")\n",
    "\n",
    "for i in range(30):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size,stratify=y, random_state=seeds[i])\n",
    "    y_train,y_test,y_train_one_hot,y_test_one_hot = to_one_hot(y_train,y_test)\n",
    "    gtgp = fit_trees()\n",
    "\n",
    "    print(classification_report(y_train,np.argmax(gtgp.train_p,axis=1),digits=5))\n",
    "    print(classification_report(y_test,np.argmax(gtgp.test_p,axis=1),digits=5))\n",
    "\n",
    "    num_trees,depth,num_nodes = gtgp.print_model()\n",
    "\n",
    "    train_acc = accuracy_score(y_train,np.argmax(gtgp.train_p,axis=1))\n",
    "    test_acc = accuracy_score(y_test,np.argmax(gtgp.test_p,axis=1))\n",
    "    # train_f1 = f1_score(y_train,np.argmax(gtgp.train_p,axis=1),average='macro')\n",
    "    # test_f1 = f1_score(y_test,np.argmax(gtgp.test_p,axis=1),average='macro')\n",
    "\n",
    "    # train_f1 = roc_auc_score(gtgp.y_one_hot.toarray(),(gtgp.train_p.T/np.sum(gtgp.train_p,axis=1)).T)\n",
    "    # test_f1 = roc_auc_score(y_test_one_hot.toarray(),(gtgp.test_p.T/np.sum(gtgp.test_p,axis=1)).T)\n",
    "\n",
    "    train_f1 = roc_auc_score(gtgp.y_one_hot.toarray(),gtgp.train_p)\n",
    "    test_f1 = roc_auc_score(y_test_one_hot.toarray(),gtgp.test_p)\n",
    "\n",
    "\n",
    "    with open('./benchmark/'+dataset+'.csv','a') as f:\n",
    "        s = str(train_acc)+\",\"+str(test_acc)+\",\"+str(train_f1)+\",\"+str(test_f1)+\",\"+str(num_trees)+\",\"+str(depth)+\",\"+str(num_nodes)+\"\\n\"\n",
    "        f.writelines(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662e91a5",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ed15d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "661630ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size,stratify=y, random_state=seeds[i])\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_train,y_test,y_train_one_hot,y_test_one_hot = to_one_hot(y_train,y_test)\n",
    "\n",
    "    num_trees = 1\n",
    "    depth = clf.tree_.max_depth\n",
    "    num_nodes = clf.tree_.node_count\n",
    "\n",
    "    train_acc = accuracy_score(y_train,clf.predict(X_train))\n",
    "    test_acc = accuracy_score(y_test,clf.predict(X_test))\n",
    "    train_f1 = f1_score(y_train,clf.predict(X_train),average='macro')\n",
    "    test_f1 = f1_score(y_test,clf.predict(X_test),average='macro')\n",
    "\n",
    "    train_roc = roc_auc_score(y_train_one_hot.toarray(),clf.predict_proba(X_train))\n",
    "    test_roc = roc_auc_score(y_test_one_hot.toarray(),clf.predict_proba(X_test))\n",
    "\n",
    "    with open('./benchmark_DC/'+dataset+'.csv','a') as f:\n",
    "        s = str(train_acc)+\",\"+str(test_acc)+\",\"+str(train_f1)+\",\"+str(test_f1)+\",\"+str(num_trees)+\",\"+str(depth)+\",\"+str(num_nodes)+\"\\n\"\n",
    "        f.writelines(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63afbae1",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28fa8541",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "acfdd7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./benchmark_xgb/'+dataset+'.csv','w') as f:\n",
    "    for i in range(30):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size,stratify=y, random_state=seeds[i])\n",
    "        y_train,y_test,y_train_one_hot,y_test_one_hot = to_one_hot(y_train,y_test)\n",
    "        # xgb = xgboost.XGBClassifier(n_estimators=100,max_depth=6)\n",
    "        # xgb = xgboost.XGBClassifier(min_child_weight=0,max_depth=4)\n",
    "        xgb = xgboost.XGBClassifier(n_estimators=1000)\n",
    "        xgb.fit(X_train,y_train)\n",
    "\n",
    "        import json\n",
    "\n",
    "        def item_generator(json_input, lookup_key):\n",
    "            if isinstance(json_input, dict):\n",
    "                for k, v in json_input.items():\n",
    "                    if k == lookup_key:\n",
    "                        yield v\n",
    "                    else:\n",
    "                        yield from item_generator(v, lookup_key)\n",
    "            elif isinstance(json_input, list):\n",
    "                for item in json_input:\n",
    "                    yield from item_generator(item, lookup_key)\n",
    "\n",
    "        def tree_depth(json_text):\n",
    "            json_input = json.loads(json_text)\n",
    "            depths = list(item_generator(json_input, 'depth'))\n",
    "            return max(depths) + 1 if len(depths) != 0 else 1\n",
    "\n",
    "        train_acc = accuracy_score(y_train,xgb.predict(X_train))\n",
    "        test_acc = accuracy_score(y_test,xgb.predict(X_test))\n",
    "\n",
    "        # train_f1 = f1_score(y_train,xgb.predict(X_train),average='macro')\n",
    "        # test_f1 = f1_score(y_test,xgb.predict(X_test),average='macro')\n",
    "        train_f1 = roc_auc_score(y_train_one_hot.toarray(),xgb.predict_proba(X_train))\n",
    "        test_f1 = roc_auc_score(y_test_one_hot.toarray(),xgb.predict_proba(X_test))\n",
    "\n",
    "        booster = xgb.get_booster()\n",
    "\n",
    "        tree_df = booster.trees_to_dataframe()\n",
    "        depths = [tree_depth(x) for x in booster.get_dump(dump_format = \"json\")]\n",
    "        num_trees = len(depths)\n",
    "        depth = np.average(depths)\n",
    "        num_nodes = len(tree_df)\n",
    "\n",
    "        s = str(train_acc)+\",\"+str(test_acc)+\",\"+str(train_f1)+\",\"+str(test_f1)+\",\"+str(num_trees)+\",\"+str(depth)+\",\"+str(num_nodes)+\"\\n\"\n",
    "        f.writelines(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc363f99",
   "metadata": {},
   "source": [
    "# GDBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e6d3435",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef69c1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./benchmark_GBDT/'+dataset+'.csv','w') as f:\n",
    "    for i in range(30):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size,stratify=y, random_state=seeds[i])\n",
    "        y_train,y_test,y_train_one_hot,y_test_one_hot = to_one_hot(y_train,y_test)\n",
    "        # clf = GradientBoostingClassifier(n_estimators=1000)\n",
    "        clf = GradientBoostingClassifier()\n",
    "        clf.fit(X_train,y_train)\n",
    "\n",
    "        train_acc = accuracy_score(y_train,clf.predict(X_train))\n",
    "        test_acc = accuracy_score(y_test,clf.predict(X_test))\n",
    "        # train_f1 = f1_score(y_train,clf.predict(X_train),average='macro')\n",
    "        # test_f1 = f1_score(y_test,clf.predict(X_test),average='macro')\n",
    "        train_f1 = roc_auc_score(y_train_one_hot.toarray(),clf.predict_proba(X_train))\n",
    "        test_f1 = roc_auc_score(y_test_one_hot.toarray(),clf.predict_proba(X_test))\n",
    "\n",
    "\n",
    "        num_trees = len([ est for ests in clf.estimators_ for est in ests])\n",
    "        depth = np.average([ max(1,est.tree_.max_depth) for ests in clf.estimators_ for est in ests])\n",
    "        num_nodes = sum([ est.tree_.node_count for ests in clf.estimators_ for est in ests])\n",
    "\n",
    "        s = str(train_acc)+\",\"+str(test_acc)+\",\"+str(train_f1)+\",\"+str(test_f1)+\",\"+str(num_trees)+\",\"+str(depth)+\",\"+str(num_nodes)+\"\\n\"\n",
    "        f.writelines(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0ef54f",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8623bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3edfc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./benchmark_RF/'+dataset+'.csv','w') as f:\n",
    "    for i in range(30):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size,stratify=y, random_state=seeds[i])\n",
    "        y_train,y_test,y_train_one_hot,y_test_one_hot = to_one_hot(y_train,y_test)\n",
    "        # rfc = RandomForestClassifier(n_estimators=100)\n",
    "        rfc = RandomForestClassifier()\n",
    "        rfc.fit(X_train,y_train)\n",
    "\n",
    "        train_acc = accuracy_score(y_train,rfc.predict(X_train))\n",
    "        test_acc = accuracy_score(y_test,rfc.predict(X_test))\n",
    "        # train_f1 = f1_score(y_train,rfc.predict(X_train),average='macro')\n",
    "        # test_f1 = f1_score(y_test,rfc.predict(X_test),average='macro')\n",
    "        \n",
    "        train_f1 = roc_auc_score(y_train_one_hot.toarray(),rfc.predict_proba(X_train))\n",
    "        test_f1 = roc_auc_score(y_test_one_hot.toarray(),rfc.predict_proba(X_test))\n",
    "\n",
    "        num_trees = len(rfc.estimators_)\n",
    "        depth = np.average([est.tree_.max_depth for est in rfc.estimators_])\n",
    "        num_nodes = sum([est.tree_.node_count for est in rfc.estimators_])\n",
    "\n",
    "        s = str(train_acc)+\",\"+str(test_acc)+\",\"+str(train_f1)+\",\"+str(test_f1)+\",\"+str(num_trees)+\",\"+str(depth)+\",\"+str(num_nodes)+\"\\n\"\n",
    "        f.writelines(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49b66a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb3fc4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BStackGP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc-autonumbering": true,
  "toc-showcode": true,
  "toc-showmarkdowntxt": true,
  "vscode": {
   "interpreter": {
    "hash": "598cefc26d6e5a65b2978c65314d0610ea9dfe34c7d989c4b6d2528d500ccb7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
