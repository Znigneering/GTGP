{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a8bc990-ebc5-46bd-bab4-f4091ce5b834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../script/\")\n",
    "\n",
    "import Functions\n",
    "from Engine import Engine\n",
    "from GTGP import GTGP\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report,accuracy_score,confusion_matrix,f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import importlib\n",
    "from time import time\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbad47da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.utils import shuffle\n",
    "def plot_roc_curve(true_y, y_prob):\n",
    "    \"\"\"\n",
    "    plots the roc curve based of the probabilities\n",
    "    \"\"\"\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(true_y, y_prob)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    print(roc_auc_score(true_y,prob[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c114de92",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "feedaa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/labor.tsv\",delimiter='\\t')\n",
    "X = df.iloc[:,:-1].to_numpy().astype(\"float\")\n",
    "y = df.iloc[:,-1].to_numpy().astype(\"int\")\n",
    "\n",
    "seeds = [10086, 200,500,30506,30405,30420,10056,7059,40965,5398,869543,83491,823190,\n",
    "         48392,2810,48392,3498210,483902,859032,12890,538920,86954,54309,6504,9840,\n",
    "         219805,548,2981,432890,5438908,219094,5843902,60854,979,12890,2108,4093]\n",
    "train_size = 0.7\n",
    "dataset = 'labor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a2341bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(y,yt):\n",
    "    le = LabelEncoder()\n",
    "    ohe = OneHotEncoder()\n",
    "    y_train = le.fit_transform(y)\n",
    "    y_one_hot = ohe.fit_transform(y_train.reshape(-1,1))\n",
    "    \n",
    "    y_test = le.transform(yt)\n",
    "    yt_one_hot = ohe.transform(y_test.reshape(-1,1))\n",
    "    \n",
    "    return y_train,y_test,y_one_hot,yt_one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdd30c5",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f418f618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 30 1\n",
      "19 57 2\n",
      "28 84 3\n",
      "37 111 4\n",
      "46 138 5\n",
      "54 162 6\n",
      "64 192 7\n",
      "73 219 8\n",
      "82 246 9\n",
      "90 270 10\n",
      "98 294 11\n",
      "105 315 12\n",
      "114 342 13\n",
      "122 366 14\n",
      "131 393 15\n",
      "140 420 16\n",
      "145 435 17\n",
      "152 456 18\n",
      "159 477 19\n",
      "168 504 20\n",
      "172 516 21\n",
      "177 531 22\n",
      "185 555 23\n",
      "190 570 24\n",
      "196 588 25\n",
      "202 606 26\n",
      "209 627 27\n",
      "215 645 28\n",
      "222 666 29\n",
      "227 681 30\n",
      "229 687 31\n",
      "235 705 32\n",
      "240 720 33\n",
      "244 732 34\n",
      "249 747 35\n",
      "254 762 36\n",
      "259 777 37\n",
      "265 795 38\n",
      "272 816 39\n",
      "276 828 40\n",
      "282 846 41\n",
      "286 858 42\n",
      "289 867 43\n",
      "292 876 44\n",
      "295 885 45\n",
      "303 909 46\n",
      "310 930 47\n",
      "311 933 48\n",
      "315 945 49\n",
      "318 954 50\n",
      "324 972 51\n",
      "326 978 52\n",
      "330 990 53\n",
      "331 993 54\n",
      "335 1005 55\n",
      "339 1017 56\n",
      "343 1029 57\n",
      "347 1041 58\n",
      "353 1059 59\n",
      "356 1068 60\n",
      "357 1071 61\n",
      "359 1077 62\n",
      "364 1092 63\n",
      "365 1095 64\n",
      "368 1104 65\n",
      "371 1113 66\n",
      "374 1122 67\n",
      "376 1128 68\n",
      "377 1131 69\n",
      "378 1134 70\n",
      "380 1140 71\n",
      "382 1146 72\n",
      "384 1152 73\n",
      "385 1155 74\n",
      "388 1164 75\n",
      "390 1170 76\n",
      "391 1173 77\n",
      "392 1176 78\n",
      "395 1185 79\n",
      "396 1188 80\n",
      "398 1194 81\n",
      "400 1200 82\n",
      "403 1209 83\n",
      "406 1218 84\n",
      "406 1218 85\n",
      "409 1227 86\n",
      "409 1227 87\n",
      "410 1230 88\n",
      "412 1236 89\n",
      "414 1242 90\n",
      "416 1248 91\n",
      "417 1251 92\n",
      "421 1263 93\n",
      "423 1269 94\n",
      "426 1278 95\n",
      "426 1278 96\n",
      "428 1284 97\n",
      "429 1287 98\n",
      "431 1293 99\n",
      "433 1299 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 1.933906611096769 \ttest: 0.8888888888888888 2.8742054635230563\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 0.6238979166008491 \ttest: 0.8888888888888888 2.2649854948245896\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 0.2995435726530212 \ttest: 0.8888888888888888 2.0541657460822784\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 0.1741665673945659 \ttest: 0.8888888888888888 1.9470463776814535\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 0.11336450531935093 \ttest: 0.9444444444444444 1.882074103684496\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 0.07948601672587706 \ttest: 0.9444444444444444 1.838498497488929\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 0.05874557059288154 \ttest: 0.9444444444444444 1.8073240259158367\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.04515304781016048 \ttest: 0.9444444444444444 1.7839974621859682\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.03577326922976776 \ttest: 0.9444444444444444 1.7659583901440423\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.029033471670424166 \ttest: 0.9444444444444444 1.7516529180960572\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.02403045366013411 \ttest: 0.9444444444444444 1.7400818040991062\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.02021600884164492 \ttest: 0.9444444444444444 1.730572574679066\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.01724199066544484 \ttest: 0.9444444444444444 1.7226557423381794\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.01487880364965624 \ttest: 0.9444444444444444 1.7159934605380103\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.012970121614587668 \ttest: 0.9444444444444444 1.710336358945786\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.011406551102318859 \ttest: 0.9444444444444444 1.7054963505777934\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.01010970194275449 \ttest: 0.9444444444444444 1.7013289039777748\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.009022220902821537 \ttest: 0.9444444444444444 1.6977211410870747\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.00810136922087872 \ttest: 0.9444444444444444 1.6945836397941927\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.007314774761539078 \ttest: 0.9444444444444444 1.691844660299922\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        14\n",
      "           1    1.00000   1.00000   1.00000        25\n",
      "\n",
      "    accuracy                        1.00000        39\n",
      "   macro avg    1.00000   1.00000   1.00000        39\n",
      "weighted avg    1.00000   1.00000   1.00000        39\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   0.83333   0.90909         6\n",
      "           1    0.92308   1.00000   0.96000        12\n",
      "\n",
      "    accuracy                        0.94444        18\n",
      "   macro avg    0.96154   0.91667   0.93455        18\n",
      "weighted avg    0.94872   0.94444   0.94303        18\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 433\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 1299\n",
      "10 30 1\n",
      "20 60 2\n",
      "29 87 3\n",
      "36 108 4\n",
      "46 138 5\n",
      "54 162 6\n",
      "63 189 7\n",
      "73 219 8\n",
      "81 243 9\n",
      "88 264 10\n",
      "98 294 11\n",
      "107 321 12\n",
      "114 342 13\n",
      "119 357 14\n",
      "126 378 15\n",
      "131 393 16\n",
      "138 414 17\n",
      "143 429 18\n",
      "151 453 19\n",
      "157 471 20\n",
      "164 492 21\n",
      "171 513 22\n",
      "177 531 23\n",
      "182 546 24\n",
      "187 561 25\n",
      "194 582 26\n",
      "196 588 27\n",
      "204 612 28\n",
      "208 624 29\n",
      "212 636 30\n",
      "215 645 31\n",
      "220 660 32\n",
      "228 684 33\n",
      "234 702 34\n",
      "240 720 35\n",
      "248 744 36\n",
      "258 774 37\n",
      "265 795 38\n",
      "269 807 39\n",
      "277 831 40\n",
      "279 837 41\n",
      "286 858 42\n",
      "289 867 43\n",
      "297 891 44\n",
      "301 903 45\n",
      "305 915 46\n",
      "308 924 47\n",
      "314 942 48\n",
      "318 954 49\n",
      "322 966 50\n",
      "324 972 51\n",
      "329 987 52\n",
      "337 1011 53\n",
      "339 1017 54\n",
      "343 1029 55\n",
      "347 1041 56\n",
      "351 1053 57\n",
      "353 1059 58\n",
      "356 1068 59\n",
      "358 1074 60\n",
      "361 1083 61\n",
      "363 1089 62\n",
      "365 1095 63\n",
      "368 1104 64\n",
      "369 1107 65\n",
      "371 1113 66\n",
      "373 1119 67\n",
      "375 1125 68\n",
      "381 1143 69\n",
      "384 1152 70\n",
      "384 1152 71\n",
      "388 1164 72\n",
      "390 1170 73\n",
      "391 1173 74\n",
      "394 1182 75\n",
      "399 1197 76\n",
      "400 1200 77\n",
      "400 1200 78\n",
      "400 1200 79\n",
      "401 1203 80\n",
      "402 1206 81\n",
      "405 1215 82\n",
      "406 1218 83\n",
      "407 1221 84\n",
      "407 1221 85\n",
      "409 1227 86\n",
      "409 1227 87\n",
      "412 1236 88\n",
      "414 1242 89\n",
      "416 1248 90\n",
      "420 1260 91\n",
      "420 1260 92\n",
      "420 1260 93\n",
      "422 1266 94\n",
      "424 1272 95\n",
      "426 1278 96\n",
      "427 1281 97\n",
      "430 1290 98\n",
      "431 1293 99\n",
      "431 1293 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 2.377586651586267 \ttest: 0.9444444444444444 2.6529841471700903\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 0.8327028705800001 \ttest: 0.9444444444444444 2.01712225184339\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 0.41714981430195397 \ttest: 0.9444444444444444 1.8334964126458315\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 0.24897044911700728 \ttest: 0.9444444444444444 1.7606636197384242\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 0.1649204993462013 \ttest: 0.9444444444444444 1.7278934609030372\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 0.11708236310116321 \ttest: 0.9444444444444444 1.712778342502877\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 0.08733146672705944 \ttest: 0.9444444444444444 1.706413986847678\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.0675976985750155 \ttest: 0.9444444444444444 1.70472080977304\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.05385066217455945 \ttest: 0.9444444444444444 1.7056383073979202\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.04389756742950104 \ttest: 0.9444444444444444 1.7080501177873628\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.03646337303476335 \ttest: 0.9444444444444444 1.711319216305011\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.030766147800316203 \ttest: 0.9444444444444444 1.7150678067586829\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.02630498445154666 \ttest: 0.9444444444444444 1.7190654311915017\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.022747096625608868 \ttest: 0.9444444444444444 1.7231687691638322\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.019864456068803556 \ttest: 0.9444444444444444 1.7272877106728184\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.017496614339659305 \ttest: 0.9444444444444444 1.7313654871567288\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.015528042542180768 \ttest: 0.9444444444444444 1.735366655064902\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.013873857729281975 \ttest: 0.9444444444444444 1.739269628765896\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.012470569643339176 \ttest: 0.9444444444444444 1.743061932825321\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.011269927919939303 \ttest: 0.9444444444444444 1.7467371242825855\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        14\n",
      "           1    1.00000   1.00000   1.00000        25\n",
      "\n",
      "    accuracy                        1.00000        39\n",
      "   macro avg    1.00000   1.00000   1.00000        39\n",
      "weighted avg    1.00000   1.00000   1.00000        39\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.85714   1.00000   0.92308         6\n",
      "           1    1.00000   0.91667   0.95652        12\n",
      "\n",
      "    accuracy                        0.94444        18\n",
      "   macro avg    0.92857   0.95833   0.93980        18\n",
      "weighted avg    0.95238   0.94444   0.94537        18\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 431\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 1293\n",
      "9 27 1\n",
      "19 57 2\n",
      "28 84 3\n",
      "38 114 4\n",
      "48 144 5\n",
      "56 168 6\n",
      "64 192 7\n",
      "73 219 8\n",
      "83 249 9\n",
      "90 270 10\n",
      "98 294 11\n",
      "106 318 12\n",
      "112 336 13\n",
      "119 357 14\n",
      "126 378 15\n",
      "131 393 16\n",
      "140 420 17\n",
      "143 429 18\n",
      "150 450 19\n",
      "155 465 20\n",
      "161 483 21\n",
      "169 507 22\n",
      "174 522 23\n",
      "181 543 24\n",
      "186 558 25\n",
      "193 579 26\n",
      "199 597 27\n",
      "205 615 28\n",
      "209 627 29\n",
      "214 642 30\n",
      "220 660 31\n",
      "224 672 32\n",
      "228 684 33\n",
      "232 696 34\n",
      "238 714 35\n",
      "245 735 36\n",
      "247 741 37\n",
      "250 750 38\n",
      "253 759 39\n",
      "261 783 40\n",
      "266 798 41\n",
      "269 807 42\n",
      "271 813 43\n",
      "276 828 44\n",
      "279 837 45\n",
      "282 846 46\n",
      "287 861 47\n",
      "289 867 48\n",
      "291 873 49\n",
      "294 882 50\n",
      "297 891 51\n",
      "299 897 52\n",
      "301 903 53\n",
      "306 918 54\n",
      "314 942 55\n",
      "315 945 56\n",
      "318 954 57\n",
      "323 969 58\n",
      "327 981 59\n",
      "330 990 60\n",
      "332 996 61\n",
      "334 1002 62\n",
      "335 1005 63\n",
      "338 1014 64\n",
      "341 1023 65\n",
      "346 1038 66\n",
      "350 1050 67\n",
      "350 1050 68\n",
      "352 1056 69\n",
      "354 1062 70\n",
      "358 1074 71\n",
      "362 1086 72\n",
      "366 1098 73\n",
      "367 1101 74\n",
      "367 1101 75\n",
      "372 1116 76\n",
      "373 1119 77\n",
      "373 1119 78\n",
      "375 1125 79\n",
      "378 1134 80\n",
      "380 1140 81\n",
      "382 1146 82\n",
      "384 1152 83\n",
      "386 1158 84\n",
      "387 1161 85\n",
      "389 1167 86\n",
      "390 1170 87\n",
      "394 1182 88\n",
      "398 1194 89\n",
      "401 1203 90\n",
      "402 1206 91\n",
      "405 1215 92\n",
      "405 1215 93\n",
      "409 1227 94\n",
      "409 1227 95\n",
      "410 1230 96\n",
      "410 1230 97\n",
      "410 1230 98\n",
      "411 1233 99\n",
      "413 1239 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 1.9998377313920341 \ttest: 0.8333333333333334 3.6760105565844676\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 0.6781144718487989 \ttest: 0.8333333333333334 3.07262032804316\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 0.33792833519689164 \ttest: 0.8333333333333334 2.8434679463929413\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 0.2018746206651742 \ttest: 0.8333333333333334 2.7181197274188804\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 0.13408852538776836 \ttest: 0.8333333333333334 2.63692002457086\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 0.09550432964749085 \ttest: 0.8333333333333334 2.5790562928504457\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 0.07147497727368195 \ttest: 0.8333333333333334 2.5352348505628197\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.055504518899504966 \ttest: 0.8333333333333334 2.500618770026341\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.044353998322988114 \ttest: 0.8888888888888888 2.472414795495158\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.03626185626478423 \ttest: 0.8888888888888888 2.448884016100637\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.03020341604985587 \ttest: 0.8888888888888888 2.428880618180849\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.025549768538454545 \ttest: 0.8888888888888888 2.4116152608808266\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.021897589523906805 \ttest: 0.8888888888888888 2.396524366884816\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.018978582382747394 \ttest: 0.8888888888888888 2.383193536127655\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.016608654320903162 \ttest: 0.8888888888888888 2.371310460584012\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.014658084951071218 \ttest: 0.8888888888888888 2.360634794471097\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.013033333511460804 \ttest: 0.8888888888888888 2.3509782108883814\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.01166557089268832 \ttest: 0.8888888888888888 2.3421908128365536\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.010503238884536706 \ttest: 0.9444444444444444 2.334151638468607\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.009507097966630563 \ttest: 0.9444444444444444 2.3267618795652067\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        14\n",
      "           1    1.00000   1.00000   1.00000        25\n",
      "\n",
      "    accuracy                        1.00000        39\n",
      "   macro avg    1.00000   1.00000   1.00000        39\n",
      "weighted avg    1.00000   1.00000   1.00000        39\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.85714   1.00000   0.92308         6\n",
      "           1    1.00000   0.91667   0.95652        12\n",
      "\n",
      "    accuracy                        0.94444        18\n",
      "   macro avg    0.92857   0.95833   0.93980        18\n",
      "weighted avg    0.95238   0.94444   0.94537        18\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 413\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 1239\n",
      "10 30 1\n",
      "20 60 2\n",
      "30 90 3\n",
      "38 114 4\n",
      "47 141 5\n",
      "56 168 6\n",
      "62 186 7\n",
      "71 213 8\n",
      "78 234 9\n",
      "88 264 10\n",
      "96 288 11\n",
      "105 315 12\n",
      "114 342 13\n",
      "120 360 14\n",
      "128 384 15\n",
      "135 405 16\n",
      "143 429 17\n",
      "150 450 18\n",
      "155 465 19\n",
      "159 477 20\n",
      "165 495 21\n",
      "169 507 22\n",
      "175 525 23\n",
      "179 537 24\n",
      "185 555 25\n",
      "192 576 26\n",
      "197 591 27\n",
      "201 603 28\n",
      "206 618 29\n",
      "208 624 30\n",
      "213 639 31\n",
      "218 654 32\n",
      "224 672 33\n",
      "230 690 34\n",
      "234 702 35\n",
      "239 717 36\n",
      "245 735 37\n",
      "252 756 38\n",
      "259 777 39\n",
      "263 789 40\n",
      "267 801 41\n",
      "273 819 42\n",
      "277 831 43\n",
      "280 840 44\n",
      "283 849 45\n",
      "288 864 46\n",
      "291 873 47\n",
      "298 894 48\n",
      "302 906 49\n",
      "306 918 50\n",
      "309 927 51\n",
      "314 942 52\n",
      "317 951 53\n",
      "323 969 54\n",
      "329 987 55\n",
      "333 999 56\n",
      "338 1014 57\n",
      "340 1020 58\n",
      "345 1035 59\n",
      "348 1044 60\n",
      "351 1053 61\n",
      "356 1068 62\n",
      "359 1077 63\n",
      "361 1083 64\n",
      "362 1086 65\n",
      "366 1098 66\n",
      "369 1107 67\n",
      "369 1107 68\n",
      "369 1107 69\n",
      "371 1113 70\n",
      "373 1119 71\n",
      "376 1128 72\n",
      "378 1134 73\n",
      "381 1143 74\n",
      "384 1152 75\n",
      "385 1155 76\n",
      "389 1167 77\n",
      "389 1167 78\n",
      "393 1179 79\n",
      "397 1191 80\n",
      "400 1200 81\n",
      "400 1200 82\n",
      "401 1203 83\n",
      "402 1206 84\n",
      "404 1212 85\n",
      "409 1227 86\n",
      "409 1227 87\n",
      "412 1236 88\n",
      "413 1239 89\n",
      "414 1242 90\n",
      "415 1245 91\n",
      "416 1248 92\n",
      "418 1254 93\n",
      "421 1263 94\n",
      "424 1272 95\n",
      "427 1281 96\n",
      "428 1284 97\n",
      "429 1287 98\n",
      "432 1296 99\n",
      "433 1299 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 2.167646093464805 \ttest: 0.8888888888888888 2.797234087331636\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 0.7975177128597849 \ttest: 0.8888888888888888 1.9592762713073628\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 0.4137823247719472 \ttest: 0.9444444444444444 1.6068980912871158\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 0.2529439371742239 \ttest: 0.9444444444444444 1.4033058686898512\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 0.17046971227467686 \ttest: 1.0 1.2669185587563685\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 0.12261063729363113 \ttest: 1.0 1.167395343723569\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 0.09239440864460309 \ttest: 1.0 1.0906042914890475\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.0721082625822383 \ttest: 1.0 1.0289784873004635\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.057835606212517786 \ttest: 1.0 0.9780602993946529\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.04741591115547707 \ttest: 1.0 0.935033791612936\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.03957816931574857 \ttest: 1.0 0.898022378896539\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.033535118730622024 \ttest: 1.0 0.8657213808464629\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.02877807131071388 \ttest: 1.0 0.8371919880631082\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.02496651467642402 \ttest: 1.0 0.8117391278504641\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.02186556967732506 \ttest: 1.0 0.7888356775571777\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.019308986557445087 \ttest: 1.0 0.7680736013150757\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.017176422879776044 \ttest: 1.0 0.749131402017144\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.015379035228907283 \ttest: 1.0 0.7317518235132972\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.013850082193758637 \ttest: 1.0 0.7157261967275221\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.012538641707187331 \ttest: 1.0 0.7008832112019283\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        14\n",
      "           1    1.00000   1.00000   1.00000        25\n",
      "\n",
      "    accuracy                        1.00000        39\n",
      "   macro avg    1.00000   1.00000   1.00000        39\n",
      "weighted avg    1.00000   1.00000   1.00000        39\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000         6\n",
      "           1    1.00000   1.00000   1.00000        12\n",
      "\n",
      "    accuracy                        1.00000        18\n",
      "   macro avg    1.00000   1.00000   1.00000        18\n",
      "weighted avg    1.00000   1.00000   1.00000        18\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 433\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 1299\n",
      "10 30 1\n",
      "20 60 2\n",
      "29 87 3\n",
      "39 117 4\n",
      "47 141 5\n",
      "57 171 6\n",
      "67 201 7\n",
      "74 222 8\n",
      "84 252 9\n",
      "94 282 10\n",
      "103 309 11\n",
      "109 327 12\n",
      "116 348 13\n",
      "123 369 14\n",
      "131 393 15\n",
      "139 417 16\n",
      "144 432 17\n",
      "151 453 18\n",
      "158 474 19\n",
      "165 495 20\n",
      "171 513 21\n",
      "178 534 22\n",
      "184 552 23\n",
      "191 573 24\n",
      "197 591 25\n",
      "204 612 26\n",
      "210 630 27\n",
      "217 651 28\n",
      "223 669 29\n",
      "226 678 30\n",
      "230 690 31\n",
      "238 714 32\n",
      "243 729 33\n",
      "248 744 34\n",
      "251 753 35\n",
      "255 765 36\n",
      "260 780 37\n",
      "263 789 38\n",
      "269 807 39\n",
      "272 816 40\n",
      "276 828 41\n",
      "281 843 42\n",
      "284 852 43\n",
      "290 870 44\n",
      "294 882 45\n",
      "302 906 46\n",
      "306 918 47\n",
      "307 921 48\n",
      "312 936 49\n",
      "315 945 50\n",
      "318 954 51\n",
      "323 969 52\n",
      "328 984 53\n",
      "334 1002 54\n",
      "337 1011 55\n",
      "343 1029 56\n",
      "347 1041 57\n",
      "352 1056 58\n",
      "354 1062 59\n",
      "354 1062 60\n",
      "357 1071 61\n",
      "358 1074 62\n",
      "361 1083 63\n",
      "363 1089 64\n",
      "365 1095 65\n",
      "369 1107 66\n",
      "372 1116 67\n",
      "373 1119 68\n",
      "375 1125 69\n",
      "380 1140 70\n",
      "381 1143 71\n",
      "384 1152 72\n",
      "385 1155 73\n",
      "389 1167 74\n",
      "391 1173 75\n",
      "393 1179 76\n",
      "394 1182 77\n",
      "397 1191 78\n",
      "401 1203 79\n",
      "403 1209 80\n",
      "404 1212 81\n",
      "407 1221 82\n",
      "408 1224 83\n",
      "412 1236 84\n",
      "416 1248 85\n",
      "417 1251 86\n",
      "419 1257 87\n",
      "421 1263 88\n",
      "421 1263 89\n",
      "422 1266 90\n",
      "423 1269 91\n",
      "426 1278 92\n",
      "429 1287 93\n",
      "430 1290 94\n",
      "432 1296 95\n",
      "433 1299 96\n",
      "435 1305 97\n",
      "438 1314 98\n",
      "439 1317 99\n",
      "441 1323 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 1.9818111185133074 \ttest: 0.9444444444444444 2.8443311850047093\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 0.6621185561378844 \ttest: 0.9444444444444444 2.010163826204222\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 0.3248552457194203 \ttest: 0.9444444444444444 1.7007780581350536\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 0.19186773847787514 \ttest: 0.9444444444444444 1.541979277383254\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 0.12639891958687394 \ttest: 0.9444444444444444 1.4457672916763509\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 0.08947720454818668 \ttest: 0.9444444444444444 1.381360922418439\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 0.0666473221620117 \ttest: 0.9444444444444444 1.335294380749759\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.051559629932323686 \ttest: 0.9444444444444444 1.3007605754823381\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.04107348592465998 \ttest: 0.9444444444444444 1.2739512695502555\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.03349215693957084 \ttest: 0.9444444444444444 1.252569762596499\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.027834149654254372 \ttest: 0.9444444444444444 1.2351484108882034\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.023499876477553888 \ttest: 0.9444444444444444 1.2207052451593068\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.020106351111461113 \ttest: 0.9444444444444444 1.2085582304187397\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.017399682731073878 \ttest: 0.9444444444444444 1.1982187477124415\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.015206185942036479 \ttest: 0.9444444444444444 1.1893274897097097\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.013403797336094085 \ttest: 0.9444444444444444 1.1816142878128273\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.011904704227910802 \ttest: 0.9444444444444444 1.1748720537156911\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.010644428203693502 \ttest: 0.9444444444444444 1.168939366705727\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.009574761660117536 \ttest: 0.9444444444444444 1.163688533242915\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.008659078304256043 \ttest: 0.9444444444444444 1.159017210772585\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        14\n",
      "           1    1.00000   1.00000   1.00000        25\n",
      "\n",
      "    accuracy                        1.00000        39\n",
      "   macro avg    1.00000   1.00000   1.00000        39\n",
      "weighted avg    1.00000   1.00000   1.00000        39\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.85714   1.00000   0.92308         6\n",
      "           1    1.00000   0.91667   0.95652        12\n",
      "\n",
      "    accuracy                        0.94444        18\n",
      "   macro avg    0.92857   0.95833   0.93980        18\n",
      "weighted avg    0.95238   0.94444   0.94537        18\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 441\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 1323\n",
      "10 30 1\n",
      "20 60 2\n",
      "29 87 3\n",
      "38 114 4\n",
      "46 138 5\n",
      "56 168 6\n",
      "63 189 7\n",
      "71 213 8\n",
      "80 240 9\n",
      "88 264 10\n",
      "96 288 11\n",
      "104 312 12\n",
      "111 333 13\n",
      "120 360 14\n",
      "125 375 15\n",
      "134 402 16\n",
      "142 426 17\n",
      "149 447 18\n",
      "154 462 19\n",
      "162 486 20\n",
      "167 501 21\n",
      "174 522 22\n",
      "180 540 23\n",
      "188 564 24\n",
      "193 579 25\n",
      "199 597 26\n",
      "204 612 27\n",
      "208 624 28\n",
      "214 642 29\n",
      "220 660 30\n",
      "224 672 31\n",
      "231 693 32\n",
      "234 702 33\n",
      "238 714 34\n",
      "242 726 35\n",
      "249 747 36\n",
      "255 765 37\n",
      "262 786 38\n",
      "267 801 39\n",
      "270 810 40\n",
      "275 825 41\n",
      "279 837 42\n",
      "284 852 43\n",
      "289 867 44\n",
      "293 879 45\n",
      "296 888 46\n",
      "300 900 47\n",
      "301 903 48\n",
      "307 921 49\n",
      "309 927 50\n",
      "313 939 51\n",
      "317 951 52\n",
      "319 957 53\n",
      "323 969 54\n",
      "327 981 55\n",
      "330 990 56\n",
      "335 1005 57\n",
      "337 1011 58\n",
      "342 1026 59\n",
      "344 1032 60\n",
      "345 1035 61\n",
      "348 1044 62\n",
      "348 1044 63\n",
      "350 1050 64\n",
      "354 1062 65\n",
      "356 1068 66\n",
      "361 1083 67\n",
      "363 1089 68\n",
      "365 1095 69\n",
      "367 1101 70\n",
      "367 1101 71\n",
      "369 1107 72\n",
      "371 1113 73\n",
      "375 1125 74\n",
      "377 1131 75\n",
      "381 1143 76\n",
      "384 1152 77\n",
      "384 1152 78\n",
      "387 1161 79\n",
      "389 1167 80\n",
      "393 1179 81\n",
      "394 1182 82\n",
      "395 1185 83\n",
      "397 1191 84\n",
      "399 1197 85\n",
      "402 1206 86\n",
      "404 1212 87\n",
      "404 1212 88\n",
      "405 1215 89\n",
      "407 1221 90\n",
      "408 1224 91\n",
      "410 1230 92\n",
      "410 1230 93\n",
      "412 1236 94\n",
      "416 1248 95\n",
      "419 1257 96\n",
      "422 1266 97\n",
      "423 1269 98\n",
      "425 1275 99\n",
      "427 1281 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 2.5450389990147704 \ttest: 0.9444444444444444 2.5998590520901494\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 0.9202046786008384 \ttest: 1.0 1.7120773879927202\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 0.46345183279175123 \ttest: 1.0 1.37437681277409\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 0.275597948000051 \ttest: 1.0 1.1965223024711367\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 0.1814945144908649 \ttest: 1.0 1.0860497166712433\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 0.12808631808080528 \ttest: 1.0 1.0101935461369629\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 0.09502246623633907 \ttest: 1.0 0.9544811873733235\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.07319892404980831 \ttest: 1.0 0.9115467916972181\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.05806840241800348 \ttest: 1.0 0.8772478881031882\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.04716202778913631 \ttest: 1.0 0.8490747121330855\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.03904864543595104 \ttest: 1.0 0.825416290869446\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.03285363988382768 \ttest: 1.0 0.8051897622857007\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.028018730743219086 \ttest: 1.0 0.7876393029709452\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.024174314886888697 \ttest: 1.0 0.7722205593826873\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.02106798827856177 \ttest: 1.0 0.7585309618171283\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.01852271630520967 \ttest: 1.0 0.7462659737064816\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.01641140911144072 \ttest: 1.0 0.7351906601191034\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.014640951534582192 \ttest: 1.0 0.7251206526614917\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.01314187864130452 \ttest: 1.0 0.7159090695585403\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.011861529080239318 \ttest: 1.0 0.7074373196569307\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        14\n",
      "           1    1.00000   1.00000   1.00000        25\n",
      "\n",
      "    accuracy                        1.00000        39\n",
      "   macro avg    1.00000   1.00000   1.00000        39\n",
      "weighted avg    1.00000   1.00000   1.00000        39\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000         6\n",
      "           1    1.00000   1.00000   1.00000        12\n",
      "\n",
      "    accuracy                        1.00000        18\n",
      "   macro avg    1.00000   1.00000   1.00000        18\n",
      "weighted avg    1.00000   1.00000   1.00000        18\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 427\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 1281\n",
      "10 30 1\n",
      "18 54 2\n",
      "28 84 3\n",
      "36 108 4\n",
      "46 138 5\n",
      "56 168 6\n",
      "64 192 7\n",
      "73 219 8\n",
      "83 249 9\n",
      "92 276 10\n",
      "101 303 11\n",
      "108 324 12\n",
      "113 339 13\n",
      "120 360 14\n",
      "128 384 15\n",
      "135 405 16\n",
      "143 429 17\n",
      "150 450 18\n",
      "158 474 19\n",
      "163 489 20\n",
      "169 507 21\n",
      "177 531 22\n",
      "184 552 23\n",
      "191 573 24\n",
      "197 591 25\n",
      "200 600 26\n",
      "204 612 27\n",
      "211 633 28\n",
      "221 663 29\n",
      "228 684 30\n",
      "233 699 31\n",
      "238 714 32\n",
      "243 729 33\n",
      "250 750 34\n",
      "253 759 35\n",
      "256 768 36\n",
      "260 780 37\n",
      "264 792 38\n",
      "270 810 39\n",
      "275 825 40\n",
      "279 837 41\n",
      "284 852 42\n",
      "290 870 43\n",
      "294 882 44\n",
      "298 894 45\n",
      "303 909 46\n",
      "307 921 47\n",
      "308 924 48\n",
      "315 945 49\n",
      "319 957 50\n",
      "323 969 51\n",
      "324 972 52\n",
      "327 981 53\n",
      "329 987 54\n",
      "332 996 55\n",
      "337 1011 56\n",
      "341 1023 57\n",
      "342 1026 58\n",
      "344 1032 59\n",
      "348 1044 60\n",
      "350 1050 61\n",
      "353 1059 62\n",
      "356 1068 63\n",
      "358 1074 64\n",
      "361 1083 65\n",
      "364 1092 66\n",
      "366 1098 67\n",
      "368 1104 68\n",
      "368 1104 69\n",
      "369 1107 70\n",
      "371 1113 71\n",
      "372 1116 72\n",
      "375 1125 73\n",
      "379 1137 74\n",
      "382 1146 75\n",
      "382 1146 76\n",
      "384 1152 77\n",
      "389 1167 78\n",
      "395 1185 79\n",
      "396 1188 80\n",
      "400 1200 81\n",
      "402 1206 82\n",
      "405 1215 83\n",
      "405 1215 84\n",
      "407 1221 85\n",
      "407 1221 86\n",
      "409 1227 87\n",
      "409 1227 88\n",
      "410 1230 89\n",
      "411 1233 90\n",
      "414 1242 91\n",
      "416 1248 92\n",
      "417 1251 93\n",
      "419 1257 94\n",
      "421 1263 95\n",
      "422 1266 96\n",
      "424 1272 97\n",
      "425 1275 98\n",
      "425 1275 99\n",
      "425 1275 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 2.389320438533798 \ttest: 0.9444444444444444 2.7673559909016827\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 0.8695458040596203 \ttest: 0.9444444444444444 1.8789430109399199\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 0.44319143005063555 \ttest: 0.9444444444444444 1.5678663275304667\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 0.26624551050569756 \ttest: 0.9444444444444444 1.4239563574120924\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 0.1766902712920828 \ttest: 0.9444444444444444 1.3475958319833126\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 0.125409668181884 \ttest: 0.9444444444444444 1.3038643859445753\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 0.09343442861910578 \ttest: 0.9444444444444444 1.277774734801787\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.07220877618917564 \ttest: 0.9444444444444444 1.2619941892248159\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.057425837622733004 \ttest: 0.9444444444444444 1.2525868193098448\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.04673111464000314 \ttest: 0.9444444444444444 1.247288519202542\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.03875164635292098 \ttest: 0.9444444444444444 1.2447250888873331\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.03264413256164944 \ttest: 0.9444444444444444 1.2440260748823662\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.027867960068540566 \ttest: 0.9444444444444444 1.2446206828918687\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.024063903191116932 \ttest: 0.9444444444444444 1.2461238066025073\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.020985868856114365 \ttest: 0.9444444444444444 1.2482694044999973\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.01846077798584617 \ttest: 0.9444444444444444 1.2508700242372648\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.016364086325085986 \ttest: 0.9444444444444444 1.2537913892488861\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.014604355559811023 \ttest: 0.9444444444444444 1.2569359821334511\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.013113248409343714 \ttest: 0.9444444444444444 1.2602321735870954\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.011838875964601788 \ttest: 0.9444444444444444 1.2636268650939086\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        14\n",
      "           1    1.00000   1.00000   1.00000        25\n",
      "\n",
      "    accuracy                        1.00000        39\n",
      "   macro avg    1.00000   1.00000   1.00000        39\n",
      "weighted avg    1.00000   1.00000   1.00000        39\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   0.83333   0.90909         6\n",
      "           1    0.92308   1.00000   0.96000        12\n",
      "\n",
      "    accuracy                        0.94444        18\n",
      "   macro avg    0.96154   0.91667   0.93455        18\n",
      "weighted avg    0.94872   0.94444   0.94303        18\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 425\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 1275\n",
      "10 30 1\n",
      "19 57 2\n",
      "28 84 3\n",
      "38 114 4\n",
      "48 144 5\n",
      "56 168 6\n",
      "66 198 7\n",
      "73 219 8\n",
      "79 237 9\n",
      "86 258 10\n",
      "93 279 11\n",
      "101 303 12\n",
      "110 330 13\n",
      "118 354 14\n",
      "125 375 15\n",
      "133 399 16\n",
      "140 420 17\n",
      "146 438 18\n",
      "152 456 19\n",
      "157 471 20\n",
      "164 492 21\n",
      "169 507 22\n",
      "177 531 23\n",
      "187 561 24\n",
      "191 573 25\n",
      "198 594 26\n",
      "204 612 27\n",
      "212 636 28\n",
      "220 660 29\n",
      "228 684 30\n",
      "234 702 31\n",
      "235 705 32\n",
      "239 717 33\n",
      "245 735 34\n",
      "247 741 35\n",
      "254 762 36\n",
      "261 783 37\n",
      "264 792 38\n",
      "270 810 39\n",
      "275 825 40\n",
      "278 834 41\n",
      "281 843 42\n",
      "285 855 43\n",
      "289 867 44\n",
      "291 873 45\n",
      "294 882 46\n",
      "298 894 47\n",
      "303 909 48\n",
      "308 924 49\n",
      "311 933 50\n",
      "318 954 51\n",
      "320 960 52\n",
      "323 969 53\n",
      "324 972 54\n",
      "326 978 55\n",
      "327 981 56\n",
      "335 1005 57\n",
      "336 1008 58\n",
      "339 1017 59\n",
      "344 1032 60\n",
      "348 1044 61\n",
      "351 1053 62\n",
      "356 1068 63\n",
      "362 1086 64\n",
      "366 1098 65\n",
      "368 1104 66\n",
      "370 1110 67\n",
      "373 1119 68\n",
      "375 1125 69\n",
      "378 1134 70\n",
      "379 1137 71\n",
      "381 1143 72\n",
      "383 1149 73\n",
      "385 1155 74\n",
      "389 1167 75\n",
      "390 1170 76\n",
      "391 1173 77\n",
      "394 1182 78\n",
      "396 1188 79\n",
      "399 1197 80\n",
      "399 1197 81\n",
      "399 1197 82\n",
      "400 1200 83\n",
      "404 1212 84\n",
      "406 1218 85\n",
      "410 1230 86\n",
      "412 1236 87\n",
      "413 1239 88\n",
      "415 1245 89\n",
      "416 1248 90\n",
      "419 1257 91\n",
      "421 1263 92\n",
      "423 1269 93\n",
      "426 1278 94\n",
      "426 1278 95\n",
      "427 1281 96\n",
      "428 1284 97\n",
      "431 1293 98\n",
      "431 1293 99\n",
      "434 1302 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 1.9297918415006654 \ttest: 0.9444444444444444 2.8386644889911\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 0.6527060580881946 \ttest: 0.9444444444444444 2.32995076498831\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 0.3249333677647901 \ttest: 0.9444444444444444 2.176209243407143\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 0.19373035832892627 \ttest: 0.9444444444444444 2.1043459253749646\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 0.12834960431653625 \ttest: 0.9444444444444444 2.0631949988562828\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 0.09116533558756787 \ttest: 0.9444444444444444 2.0368008348321074\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 0.06804249481721433 \ttest: 0.9444444444444444 2.0186222321264764\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.05270310457902827 \ttest: 0.9444444444444444 2.0054823608526857\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.04201481536123048 \ttest: 0.9444444444444444 1.9956507643991905\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.0342740660466063 \ttest: 0.9444444444444444 1.9881036670669376\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.02849042198670977 \ttest: 0.9444444444444444 1.9821964984737819\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.024056510700567135 \ttest: 0.9444444444444444 1.977503267788178\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.02058324199300582 \ttest: 0.9444444444444444 1.9737312887711356\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.017812105781825283 \ttest: 0.9444444444444444 1.9706729660828315\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.015565957016261145 \ttest: 0.9444444444444444 1.9681771013614866\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.013720139909088854 \ttest: 0.9444444444444444 1.9661310735529705\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.012184888467458884 \ttest: 0.9444444444444444 1.9644493677604682\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.010894240767400433 \ttest: 0.9444444444444444 1.9630659606080914\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.009798852319845858 \ttest: 0.9444444444444444 1.9619291295733847\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.00886121740219128 \ttest: 0.9444444444444444 1.9609978316491563\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        14\n",
      "           1    1.00000   1.00000   1.00000        25\n",
      "\n",
      "    accuracy                        1.00000        39\n",
      "   macro avg    1.00000   1.00000   1.00000        39\n",
      "weighted avg    1.00000   1.00000   1.00000        39\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.85714   1.00000   0.92308         6\n",
      "           1    1.00000   0.91667   0.95652        12\n",
      "\n",
      "    accuracy                        0.94444        18\n",
      "   macro avg    0.92857   0.95833   0.93980        18\n",
      "weighted avg    0.95238   0.94444   0.94537        18\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 434\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 1302\n",
      "9 27 1\n",
      "19 57 2\n",
      "28 84 3\n",
      "38 114 4\n",
      "47 141 5\n",
      "56 168 6\n",
      "64 192 7\n",
      "72 216 8\n",
      "80 240 9\n",
      "88 264 10\n",
      "95 285 11\n",
      "103 309 12\n",
      "112 336 13\n",
      "116 348 14\n",
      "124 372 15\n",
      "133 399 16\n",
      "139 417 17\n",
      "148 444 18\n",
      "154 462 19\n",
      "159 477 20\n",
      "164 492 21\n",
      "171 513 22\n",
      "176 528 23\n",
      "180 540 24\n",
      "184 552 25\n",
      "190 570 26\n",
      "194 582 27\n",
      "199 597 28\n",
      "205 615 29\n",
      "210 630 30\n",
      "215 645 31\n",
      "218 654 32\n",
      "226 678 33\n",
      "231 693 34\n",
      "239 717 35\n",
      "246 738 36\n",
      "255 765 37\n",
      "260 780 38\n",
      "266 798 39\n",
      "268 804 40\n",
      "274 822 41\n",
      "278 834 42\n",
      "278 834 43\n",
      "284 852 44\n",
      "291 873 45\n",
      "295 885 46\n",
      "296 888 47\n",
      "300 900 48\n",
      "304 912 49\n",
      "306 918 50\n",
      "311 933 51\n",
      "314 942 52\n",
      "316 948 53\n",
      "321 963 54\n",
      "324 972 55\n",
      "326 978 56\n",
      "329 987 57\n",
      "332 996 58\n",
      "333 999 59\n",
      "335 1005 60\n",
      "338 1014 61\n",
      "340 1020 62\n",
      "347 1041 63\n",
      "349 1047 64\n",
      "351 1053 65\n",
      "353 1059 66\n",
      "360 1080 67\n",
      "362 1086 68\n",
      "364 1092 69\n",
      "366 1098 70\n",
      "367 1101 71\n",
      "370 1110 72\n",
      "376 1128 73\n",
      "377 1131 74\n",
      "380 1140 75\n",
      "382 1146 76\n",
      "384 1152 77\n",
      "387 1161 78\n",
      "390 1170 79\n",
      "393 1179 80\n",
      "394 1182 81\n",
      "397 1191 82\n",
      "397 1191 83\n",
      "401 1203 84\n",
      "403 1209 85\n",
      "404 1212 86\n",
      "404 1212 87\n",
      "405 1215 88\n",
      "407 1221 89\n",
      "409 1227 90\n",
      "412 1236 91\n",
      "414 1242 92\n",
      "418 1254 93\n",
      "420 1260 94\n",
      "421 1263 95\n",
      "422 1266 96\n",
      "425 1275 97\n",
      "428 1284 98\n",
      "430 1290 99\n",
      "430 1290 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 2.6604157479794353 \ttest: 0.9444444444444444 2.3270036455321352\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 0.9841361099225248 \ttest: 0.9444444444444444 1.529784675211227\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 0.5042620038719018 \ttest: 0.9444444444444444 1.2567577964622567\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 0.30423153759750987 \ttest: 0.9444444444444444 1.1180141162270667\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 0.20274491513699205 \ttest: 0.9444444444444444 1.0320226710161888\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 0.14448190256769555 \ttest: 0.9444444444444444 0.972189699980826\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 0.10804976290101678 \ttest: 0.9444444444444444 0.9273496906294776\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.08379433852051567 \ttest: 0.9444444444444444 0.8919887776302263\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.06685182639233607 \ttest: 0.9444444444444444 0.8630585394699208\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.0545600220516503 \ttest: 0.9444444444444444 0.8387277631757364\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.045364163429181426 \ttest: 0.9444444444444444 0.8178243103475484\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.038307633493698014 \ttest: 0.9444444444444444 0.7995593738423944\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.03277604487424876 \ttest: 0.9444444444444444 0.7833801917836867\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.028360377200691282 \ttest: 0.9444444444444444 0.76888628096123\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.024779891810903065 \ttest: 0.9444444444444444 0.7557792740950383\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.02183677174653312 \ttest: 0.9444444444444444 0.743831555647906\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.019388409783150297 \ttest: 0.9444444444444444 0.7328659195076704\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.01732991867133282 \ttest: 0.9444444444444444 0.7227419530887774\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.015582774172593196 \ttest: 0.9444444444444444 0.713346670869758\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.01408725274330321 \ttest: 0.9444444444444444 0.7045879147227317\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        14\n",
      "           1    1.00000   1.00000   1.00000        25\n",
      "\n",
      "    accuracy                        1.00000        39\n",
      "   macro avg    1.00000   1.00000   1.00000        39\n",
      "weighted avg    1.00000   1.00000   1.00000        39\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   0.83333   0.90909         6\n",
      "           1    0.92308   1.00000   0.96000        12\n",
      "\n",
      "    accuracy                        0.94444        18\n",
      "   macro avg    0.96154   0.91667   0.93455        18\n",
      "weighted avg    0.94872   0.94444   0.94303        18\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 430\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 1290\n",
      "10 30 1\n",
      "20 60 2\n",
      "28 84 3\n",
      "38 114 4\n",
      "48 144 5\n",
      "56 168 6\n",
      "65 195 7\n",
      "74 222 8\n",
      "84 252 9\n",
      "92 276 10\n",
      "101 303 11\n",
      "111 333 12\n",
      "118 354 13\n",
      "126 378 14\n",
      "134 402 15\n",
      "140 420 16\n",
      "149 447 17\n",
      "158 474 18\n",
      "167 501 19\n",
      "173 519 20\n",
      "181 543 21\n",
      "185 555 22\n",
      "193 579 23\n",
      "202 606 24\n",
      "207 621 25\n",
      "214 642 26\n",
      "222 666 27\n",
      "226 678 28\n",
      "230 690 29\n",
      "235 705 30\n",
      "240 720 31\n",
      "246 738 32\n",
      "250 750 33\n",
      "256 768 34\n",
      "260 780 35\n",
      "265 795 36\n",
      "270 810 37\n",
      "273 819 38\n",
      "279 837 39\n",
      "284 852 40\n",
      "291 873 41\n",
      "295 885 42\n",
      "300 900 43\n",
      "306 918 44\n",
      "310 930 45\n",
      "313 939 46\n",
      "316 948 47\n",
      "319 957 48\n",
      "322 966 49\n",
      "323 969 50\n",
      "327 981 51\n",
      "333 999 52\n",
      "336 1008 53\n",
      "340 1020 54\n",
      "342 1026 55\n",
      "347 1041 56\n",
      "352 1056 57\n",
      "353 1059 58\n",
      "357 1071 59\n",
      "359 1077 60\n",
      "363 1089 61\n",
      "365 1095 62\n",
      "366 1098 63\n",
      "370 1110 64\n",
      "373 1119 65\n",
      "376 1128 66\n",
      "378 1134 67\n",
      "383 1149 68\n",
      "387 1161 69\n",
      "389 1167 70\n",
      "393 1179 71\n",
      "395 1185 72\n",
      "399 1197 73\n",
      "403 1209 74\n",
      "403 1209 75\n",
      "406 1218 76\n",
      "408 1224 77\n",
      "409 1227 78\n",
      "411 1233 79\n",
      "413 1239 80\n",
      "415 1245 81\n",
      "416 1248 82\n",
      "419 1257 83\n",
      "421 1263 84\n",
      "422 1266 85\n",
      "424 1272 86\n",
      "424 1272 87\n",
      "425 1275 88\n",
      "427 1281 89\n",
      "427 1281 90\n",
      "428 1284 91\n",
      "429 1287 92\n",
      "430 1290 93\n",
      "430 1290 94\n",
      "433 1299 95\n",
      "434 1302 96\n",
      "437 1311 97\n",
      "439 1317 98\n",
      "441 1323 99\n",
      "441 1323 100\n",
      "retrain  1 :\n",
      "\ttrain: 0.9743589743589743 2.5561883857231678 \ttest: 0.9444444444444444 3.3372648850209172\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 1.0849331352732876 \ttest: 1.0 2.1694223129196324\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 0.5959494621895204 \ttest: 1.0 1.614101599256287\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 0.3729273313283314 \ttest: 1.0 1.297626651049801\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 0.253930352668235 \ttest: 1.0 1.094918176043402\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 0.18349009832523297 \ttest: 1.0 0.9540218117614954\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 0.13854463290039606 \ttest: 1.0 0.8501594245436577\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.10819365801064716 \ttest: 1.0 0.7701855400338575\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.08677070686168808 \ttest: 1.0 0.7065210929667936\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.07110390909405764 \ttest: 1.0 0.6544995449543313\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.05930954534920385 \ttest: 1.0 0.6110921300747758\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.050213472419268816 \ttest: 1.0 0.5742467582083822\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.04305378412901074 \ttest: 1.0 0.5425227367999558\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.037318985814311964 \ttest: 1.0 0.5148779715474133\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.03265556362003952 \ttest: 1.0 0.49053932835881076\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.028812968607617766 \ttest: 1.0 0.4689205849288779\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.025609684201769907 \ttest: 1.0 0.44956876468023055\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.0229116376885872 \ttest: 1.0 0.43212801546257606\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.020618085139718103 \ttest: 1.0 0.41631467888752605\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.018652156627840023 \ttest: 1.0 0.4018996972383059\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        14\n",
      "           1    1.00000   1.00000   1.00000        25\n",
      "\n",
      "    accuracy                        1.00000        39\n",
      "   macro avg    1.00000   1.00000   1.00000        39\n",
      "weighted avg    1.00000   1.00000   1.00000        39\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000         6\n",
      "           1    1.00000   1.00000   1.00000        12\n",
      "\n",
      "    accuracy                        1.00000        18\n",
      "   macro avg    1.00000   1.00000   1.00000        18\n",
      "weighted avg    1.00000   1.00000   1.00000        18\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 441\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 1323\n",
      "9 27 1\n",
      "19 57 2\n",
      "28 84 3\n",
      "37 111 4\n",
      "47 141 5\n",
      "55 165 6\n",
      "64 192 7\n",
      "74 222 8\n",
      "83 249 9\n",
      "90 270 10\n",
      "98 294 11\n",
      "107 321 12\n",
      "115 345 13\n",
      "124 372 14\n",
      "130 390 15\n",
      "139 417 16\n",
      "144 432 17\n",
      "152 456 18\n",
      "159 477 19\n",
      "168 504 20\n",
      "173 519 21\n",
      "177 531 22\n",
      "182 546 23\n",
      "188 564 24\n",
      "194 582 25\n",
      "199 597 26\n",
      "205 615 27\n",
      "210 630 28\n",
      "217 651 29\n",
      "225 675 30\n",
      "229 687 31\n",
      "236 708 32\n",
      "238 714 33\n",
      "243 729 34\n",
      "246 738 35\n",
      "250 750 36\n",
      "257 771 37\n",
      "260 780 38\n",
      "264 792 39\n",
      "267 801 40\n",
      "273 819 41\n",
      "275 825 42\n",
      "281 843 43\n",
      "286 858 44\n",
      "288 864 45\n",
      "291 873 46\n",
      "298 894 47\n",
      "303 909 48\n",
      "308 924 49\n",
      "308 924 50\n",
      "311 933 51\n",
      "313 939 52\n",
      "316 948 53\n",
      "319 957 54\n",
      "320 960 55\n",
      "324 972 56\n",
      "329 987 57\n",
      "332 996 58\n",
      "336 1008 59\n",
      "341 1023 60\n",
      "344 1032 61\n",
      "345 1035 62\n",
      "347 1041 63\n",
      "348 1044 64\n",
      "351 1053 65\n",
      "354 1062 66\n",
      "358 1074 67\n",
      "361 1083 68\n",
      "364 1092 69\n",
      "366 1098 70\n",
      "370 1110 71\n",
      "371 1113 72\n",
      "372 1116 73\n",
      "374 1122 74\n",
      "377 1131 75\n",
      "381 1143 76\n",
      "384 1152 77\n",
      "385 1155 78\n",
      "388 1164 79\n",
      "389 1167 80\n",
      "393 1179 81\n",
      "396 1188 82\n",
      "399 1197 83\n",
      "400 1200 84\n",
      "400 1200 85\n",
      "403 1209 86\n",
      "405 1215 87\n",
      "408 1224 88\n",
      "410 1230 89\n",
      "413 1239 90\n",
      "416 1248 91\n",
      "419 1257 92\n",
      "422 1266 93\n",
      "422 1266 94\n",
      "427 1281 95\n",
      "429 1287 96\n",
      "431 1293 97\n",
      "433 1299 98\n",
      "434 1302 99\n",
      "437 1311 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 1.9751796731789724 \ttest: 0.8333333333333334 4.404892062309159\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 0.6935359081101106 \ttest: 0.8333333333333334 4.081525122711404\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 0.3511842616734876 \ttest: 0.8333333333333334 4.018210287715194\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 0.21193338986249802 \ttest: 0.8333333333333334 4.014471969123814\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 0.14181580973747399 \ttest: 0.8333333333333334 4.029547776967925\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 0.10158633523254092 \ttest: 0.8333333333333334 4.051071971289377\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 0.0763720568647811 \ttest: 0.8333333333333334 4.07449418977183\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.05952548047437726 \ttest: 0.8333333333333334 4.097966333221106\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.047711041473235356 \ttest: 0.8333333333333334 4.120713365588137\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.03910475244900021 \ttest: 0.8333333333333334 4.142425478125666\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.032640551254139824 \ttest: 0.8333333333333334 4.163005427039838\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.02766135564815645 \ttest: 0.8333333333333334 4.182455160330191\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.023744181844459273 \ttest: 0.8333333333333334 4.200822138739076\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.020606703427003215 \ttest: 0.8333333333333334 4.218173014586252\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.01805461185323365 \ttest: 0.8333333333333334 4.234580504303747\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.015950612648581837 \ttest: 0.8333333333333334 4.250116869803727\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.014195457644954227 \ttest: 0.8333333333333334 4.264850798707775\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.012715953536334049 \ttest: 0.8333333333333334 4.278846058664356\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.011457160490758367 \ttest: 0.8333333333333334 4.292161079015201\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.010377186971778356 \ttest: 0.8333333333333334 4.304849009026058\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        14\n",
      "           1    1.00000   1.00000   1.00000        25\n",
      "\n",
      "    accuracy                        1.00000        39\n",
      "   macro avg    1.00000   1.00000   1.00000        39\n",
      "weighted avg    1.00000   1.00000   1.00000        39\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.80000   0.66667   0.72727         6\n",
      "           1    0.84615   0.91667   0.88000        12\n",
      "\n",
      "    accuracy                        0.83333        18\n",
      "   macro avg    0.82308   0.79167   0.80364        18\n",
      "weighted avg    0.83077   0.83333   0.82909        18\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 437\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 1311\n",
      "10 30 1\n",
      "20 60 2\n",
      "29 87 3\n",
      "39 117 4\n",
      "47 141 5\n",
      "55 165 6\n",
      "63 189 7\n",
      "72 216 8\n",
      "81 243 9\n",
      "89 267 10\n",
      "96 288 11\n",
      "103 309 12\n",
      "112 336 13\n",
      "121 363 14\n",
      "130 390 15\n",
      "138 414 16\n",
      "145 435 17\n",
      "151 453 18\n",
      "157 471 19\n",
      "159 477 20\n",
      "168 504 21\n",
      "176 528 22\n",
      "182 546 23\n",
      "188 564 24\n",
      "194 582 25\n",
      "196 588 26\n",
      "202 606 27\n",
      "207 621 28\n",
      "213 639 29\n",
      "217 651 30\n",
      "226 678 31\n",
      "232 696 32\n",
      "237 711 33\n",
      "242 726 34\n",
      "247 741 35\n",
      "255 765 36\n",
      "262 786 37\n",
      "266 798 38\n",
      "270 810 39\n",
      "273 819 40\n",
      "279 837 41\n",
      "283 849 42\n",
      "291 873 43\n",
      "297 891 44\n",
      "302 906 45\n",
      "309 927 46\n",
      "310 930 47\n",
      "315 945 48\n",
      "317 951 49\n",
      "319 957 50\n",
      "326 978 51\n",
      "330 990 52\n",
      "336 1008 53\n",
      "339 1017 54\n",
      "340 1020 55\n",
      "346 1038 56\n",
      "349 1047 57\n",
      "351 1053 58\n",
      "352 1056 59\n",
      "354 1062 60\n",
      "356 1068 61\n",
      "361 1083 62\n",
      "367 1101 63\n",
      "370 1110 64\n",
      "372 1116 65\n",
      "374 1122 66\n",
      "379 1137 67\n",
      "382 1146 68\n",
      "385 1155 69\n",
      "388 1164 70\n",
      "391 1173 71\n",
      "391 1173 72\n",
      "393 1179 73\n",
      "395 1185 74\n",
      "396 1188 75\n",
      "398 1194 76\n",
      "399 1197 77\n",
      "400 1200 78\n",
      "403 1209 79\n",
      "406 1218 80\n",
      "408 1224 81\n",
      "410 1230 82\n",
      "412 1236 83\n",
      "413 1239 84\n",
      "417 1251 85\n",
      "420 1260 86\n",
      "422 1266 87\n",
      "424 1272 88\n",
      "426 1278 89\n",
      "429 1287 90\n",
      "433 1299 91\n",
      "435 1305 92\n",
      "437 1311 93\n",
      "439 1317 94\n",
      "442 1326 95\n",
      "445 1335 96\n",
      "445 1335 97\n",
      "448 1344 98\n",
      "448 1344 99\n",
      "448 1344 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 2.081406238389066 \ttest: 0.8333333333333334 3.774487564317689\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 0.8170512602261015 \ttest: 0.8333333333333334 3.128431390784855\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 0.4383936599262457 \ttest: 0.8333333333333334 2.8628875232739497\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 0.2729009108147194 \ttest: 0.8333333333333334 2.7155217461995185\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 0.18593079858948708 \ttest: 0.8333333333333334 2.62084675113333\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 0.13468137736265157 \ttest: 0.8888888888888888 2.5544333920101274\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 0.1019903166061879 \ttest: 0.8888888888888888 2.505015406142544\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.07988258609323849 \ttest: 0.8888888888888888 2.4666506666213883\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.06424461271883636 \ttest: 0.8888888888888888 2.4358983028697034\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.052781213489696104 \ttest: 0.8888888888888888 2.4106233411087534\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.04413051278483839 \ttest: 0.8888888888888888 2.3894285371822934\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.0374433143728918 \ttest: 0.8888888888888888 2.371359762889188\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.032167985691620916 \ttest: 0.8888888888888888 2.355742462429407\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.027933667346788336 \ttest: 0.9444444444444444 2.3420857377558533\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.024483630340592047 \ttest: 0.9444444444444444 2.3300234874445436\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.02163561245913407 \ttest: 0.9444444444444444 2.3192768819564518\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.019257342743913042 \ttest: 0.9444444444444444 2.3096296509945438\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.017250956638118355 \ttest: 0.9444444444444444 2.300911345240082\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.015542795434951255 \ttest: 0.9444444444444444 2.2929857180288704\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.014076565422437909 \ttest: 0.9444444444444444 2.2857424848686847\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        14\n",
      "           1    1.00000   1.00000   1.00000        25\n",
      "\n",
      "    accuracy                        1.00000        39\n",
      "   macro avg    1.00000   1.00000   1.00000        39\n",
      "weighted avg    1.00000   1.00000   1.00000        39\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   0.83333   0.90909         6\n",
      "           1    0.92308   1.00000   0.96000        12\n",
      "\n",
      "    accuracy                        0.94444        18\n",
      "   macro avg    0.96154   0.91667   0.93455        18\n",
      "weighted avg    0.94872   0.94444   0.94303        18\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 448\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 1344\n",
      "10 30 1\n",
      "20 60 2\n",
      "29 87 3\n",
      "36 108 4\n",
      "46 138 5\n",
      "56 168 6\n",
      "64 192 7\n",
      "74 222 8\n",
      "83 249 9\n",
      "89 267 10\n",
      "97 291 11\n",
      "104 312 12\n",
      "109 327 13\n",
      "117 351 14\n",
      "123 369 15\n",
      "132 396 16\n",
      "141 423 17\n",
      "145 435 18\n",
      "153 459 19\n",
      "159 477 20\n",
      "165 495 21\n",
      "175 525 22\n",
      "181 543 23\n",
      "184 552 24\n",
      "190 570 25\n",
      "196 588 26\n",
      "202 606 27\n",
      "207 621 28\n",
      "213 639 29\n",
      "219 657 30\n",
      "227 681 31\n",
      "232 696 32\n",
      "236 708 33\n",
      "241 723 34\n",
      "249 747 35\n",
      "253 759 36\n",
      "256 768 37\n",
      "259 777 38\n",
      "262 786 39\n",
      "268 804 40\n",
      "273 819 41\n",
      "277 831 42\n",
      "281 843 43\n",
      "285 855 44\n",
      "289 867 45\n",
      "294 882 46\n",
      "296 888 47\n",
      "302 906 48\n",
      "307 921 49\n",
      "312 936 50\n",
      "316 948 51\n",
      "319 957 52\n",
      "322 966 53\n",
      "325 975 54\n",
      "328 984 55\n",
      "332 996 56\n",
      "338 1014 57\n",
      "341 1023 58\n",
      "345 1035 59\n",
      "348 1044 60\n",
      "353 1059 61\n",
      "355 1065 62\n",
      "356 1068 63\n",
      "358 1074 64\n",
      "361 1083 65\n",
      "365 1095 66\n",
      "367 1101 67\n",
      "372 1116 68\n",
      "374 1122 69\n",
      "376 1128 70\n",
      "379 1137 71\n",
      "380 1140 72\n",
      "384 1152 73\n",
      "386 1158 74\n",
      "388 1164 75\n",
      "390 1170 76\n",
      "395 1185 77\n",
      "397 1191 78\n",
      "399 1197 79\n",
      "400 1200 80\n",
      "402 1206 81\n",
      "404 1212 82\n",
      "406 1218 83\n",
      "407 1221 84\n",
      "409 1227 85\n",
      "412 1236 86\n",
      "414 1242 87\n",
      "418 1254 88\n",
      "419 1257 89\n",
      "422 1266 90\n",
      "426 1278 91\n",
      "426 1278 92\n",
      "427 1281 93\n",
      "429 1287 94\n",
      "430 1290 95\n",
      "433 1299 96\n",
      "435 1305 97\n",
      "439 1317 98\n",
      "439 1317 99\n",
      "440 1320 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 2.7636976093827372 \ttest: 0.9444444444444444 2.2079120559508865\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 1.0800690881432435 \ttest: 1.0 1.2520349337209669\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 0.5726442629167955 \ttest: 1.0 0.888710459812526\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 0.3526938888378323 \ttest: 1.0 0.699408850919157\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 0.23817432116229437 \ttest: 1.0 0.5840514720717387\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 0.17127245080633466 \ttest: 1.0 0.5066740866096994\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 0.1289223755977627 \ttest: 1.0 0.4512574869601788\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.10047255415247776 \ttest: 1.0 0.409629358985004\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.08046419950120919 \ttest: 1.0 0.3772032751303502\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.06587040215627829 \ttest: 1.0 0.35121473401545417\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.05490545701257303 \ttest: 1.0 0.32990194933666844\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.046461780816734514 \ttest: 1.0 0.3120907576468715\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.039823368203955246 \ttest: 1.0 0.29696930687177614\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.03451096950262382 \ttest: 1.0 0.28395871852698235\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.03019415093565152 \ttest: 1.0 0.2726353089975311\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.026639181470695033 \ttest: 1.0 0.2626819419157921\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.023677004861471937 \ttest: 1.0 0.2538565590313262\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.0211829226876118 \ttest: 1.0 0.2459712206705622\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.019063343336751547 \ttest: 1.0 0.2388777847816644\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.01724692454808831 \ttest: 1.0 0.23245789876991538\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        14\n",
      "           1    1.00000   1.00000   1.00000        25\n",
      "\n",
      "    accuracy                        1.00000        39\n",
      "   macro avg    1.00000   1.00000   1.00000        39\n",
      "weighted avg    1.00000   1.00000   1.00000        39\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000         6\n",
      "           1    1.00000   1.00000   1.00000        12\n",
      "\n",
      "    accuracy                        1.00000        18\n",
      "   macro avg    1.00000   1.00000   1.00000        18\n",
      "weighted avg    1.00000   1.00000   1.00000        18\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 440\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 1320\n",
      "10 30 1\n",
      "20 60 2\n",
      "30 90 3\n",
      "40 120 4\n",
      "50 150 5\n",
      "57 171 6\n",
      "67 201 7\n",
      "76 228 8\n",
      "84 252 9\n",
      "92 276 10\n",
      "100 300 11\n",
      "107 321 12\n",
      "115 345 13\n",
      "125 375 14\n",
      "133 399 15\n",
      "142 426 16\n",
      "148 444 17\n",
      "154 462 18\n",
      "159 477 19\n",
      "166 498 20\n",
      "170 510 21\n",
      "176 528 22\n",
      "181 543 23\n",
      "186 558 24\n",
      "189 567 25\n",
      "195 585 26\n",
      "201 603 27\n",
      "209 627 28\n",
      "216 648 29\n",
      "222 666 30\n",
      "227 681 31\n",
      "231 693 32\n",
      "234 702 33\n",
      "238 714 34\n",
      "244 732 35\n",
      "250 750 36\n",
      "255 765 37\n",
      "260 780 38\n",
      "265 795 39\n",
      "271 813 40\n",
      "277 831 41\n",
      "280 840 42\n",
      "282 846 43\n",
      "287 861 44\n",
      "292 876 45\n",
      "299 897 46\n",
      "302 906 47\n",
      "306 918 48\n",
      "309 927 49\n",
      "312 936 50\n",
      "316 948 51\n",
      "319 957 52\n",
      "322 966 53\n",
      "325 975 54\n",
      "330 990 55\n",
      "333 999 56\n",
      "335 1005 57\n",
      "337 1011 58\n",
      "338 1014 59\n",
      "342 1026 60\n",
      "345 1035 61\n",
      "348 1044 62\n",
      "352 1056 63\n",
      "356 1068 64\n",
      "357 1071 65\n",
      "361 1083 66\n",
      "366 1098 67\n",
      "368 1104 68\n",
      "373 1119 69\n",
      "377 1131 70\n",
      "384 1152 71\n",
      "388 1164 72\n",
      "392 1176 73\n",
      "394 1182 74\n",
      "395 1185 75\n",
      "397 1191 76\n",
      "402 1206 77\n",
      "403 1209 78\n",
      "406 1218 79\n",
      "409 1227 80\n",
      "412 1236 81\n",
      "414 1242 82\n",
      "415 1245 83\n",
      "416 1248 84\n",
      "417 1251 85\n",
      "418 1254 86\n",
      "419 1257 87\n",
      "419 1257 88\n",
      "423 1269 89\n",
      "424 1272 90\n",
      "424 1272 91\n",
      "425 1275 92\n",
      "426 1278 93\n",
      "427 1281 94\n",
      "427 1281 95\n",
      "428 1284 96\n",
      "430 1290 97\n",
      "432 1296 98\n",
      "433 1299 99\n",
      "433 1299 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 2.303761413111016 \ttest: 0.8333333333333334 4.197940683756836\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 0.8296561883653566 \ttest: 0.8333333333333334 3.725846431167776\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 0.4249277907180422 \ttest: 0.8333333333333334 3.589286643701549\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 0.25763061646505986 \ttest: 0.8333333333333334 3.533979690101566\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 0.17264528954769887 \ttest: 0.8333333333333334 3.5082653361214207\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 0.1236650950928127 \ttest: 0.8333333333333334 3.495910050952912\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 0.09290170160090638 \ttest: 0.8333333333333334 3.4904092693604567\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.0723322609766977 \ttest: 0.8333333333333334 3.488725738947212\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.05790734376271864 \ttest: 0.8333333333333334 3.4892852318723127\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.047404288655645645 \ttest: 0.8333333333333334 3.4912082152327817\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.03952100263094564 \ttest: 0.8333333333333334 3.493975022042631\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.03345382678775583 \ttest: 0.8333333333333334 3.497265249658976\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.02868505070928412 \ttest: 0.8333333333333334 3.5008747749865963\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.02486902667485266 \ttest: 0.8333333333333334 3.504670251605677\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.021767872961352082 \ttest: 0.8333333333333334 3.5085629213337532\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.01921354737358984 \ttest: 0.8333333333333334 3.512492924202119\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.017084621180959488 \ttest: 0.8333333333333334 3.516419575404616\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.015291586460102733 \ttest: 0.8333333333333334 3.5203151645585504\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.01376729411096325 \ttest: 0.8333333333333334 3.524160902837094\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.012460573174570385 \ttest: 0.8333333333333334 3.5279442172218207\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        14\n",
      "           1    1.00000   1.00000   1.00000        25\n",
      "\n",
      "    accuracy                        1.00000        39\n",
      "   macro avg    1.00000   1.00000   1.00000        39\n",
      "weighted avg    1.00000   1.00000   1.00000        39\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.80000   0.66667   0.72727         6\n",
      "           1    0.84615   0.91667   0.88000        12\n",
      "\n",
      "    accuracy                        0.83333        18\n",
      "   macro avg    0.82308   0.79167   0.80364        18\n",
      "weighted avg    0.83077   0.83333   0.82909        18\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 433\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 1299\n",
      "10 30 1\n",
      "20 60 2\n",
      "29 87 3\n",
      "38 114 4\n",
      "47 141 5\n",
      "55 165 6\n",
      "65 195 7\n",
      "73 219 8\n",
      "80 240 9\n",
      "88 264 10\n",
      "98 294 11\n",
      "106 318 12\n",
      "113 339 13\n",
      "121 363 14\n",
      "129 387 15\n",
      "137 411 16\n",
      "141 423 17\n",
      "150 450 18\n",
      "158 474 19\n",
      "166 498 20\n",
      "174 522 21\n",
      "180 540 22\n",
      "186 558 23\n",
      "190 570 24\n",
      "195 585 25\n",
      "202 606 26\n",
      "208 624 27\n",
      "216 648 28\n",
      "223 669 29\n",
      "226 678 30\n",
      "229 687 31\n",
      "230 690 32\n",
      "233 699 33\n",
      "238 714 34\n",
      "244 732 35\n",
      "252 756 36\n",
      "255 765 37\n",
      "257 771 38\n",
      "263 789 39\n",
      "269 807 40\n",
      "271 813 41\n",
      "275 825 42\n",
      "281 843 43\n",
      "288 864 44\n",
      "292 876 45\n",
      "297 891 46\n",
      "300 900 47\n",
      "305 915 48\n",
      "310 930 49\n",
      "315 945 50\n",
      "317 951 51\n",
      "321 963 52\n",
      "323 969 53\n",
      "325 975 54\n",
      "330 990 55\n",
      "334 1002 56\n",
      "336 1008 57\n",
      "342 1026 58\n",
      "342 1026 59\n",
      "345 1035 60\n",
      "349 1047 61\n",
      "351 1053 62\n",
      "353 1059 63\n",
      "357 1071 64\n",
      "361 1083 65\n",
      "363 1089 66\n",
      "367 1101 67\n",
      "371 1113 68\n",
      "372 1116 69\n",
      "376 1128 70\n",
      "379 1137 71\n",
      "380 1140 72\n",
      "383 1149 73\n",
      "385 1155 74\n",
      "387 1161 75\n",
      "389 1167 76\n",
      "390 1170 77\n",
      "394 1182 78\n",
      "396 1188 79\n",
      "400 1200 80\n",
      "403 1209 81\n",
      "406 1218 82\n",
      "406 1218 83\n",
      "407 1221 84\n",
      "409 1227 85\n",
      "412 1236 86\n",
      "413 1239 87\n",
      "418 1254 88\n",
      "422 1266 89\n",
      "422 1266 90\n",
      "424 1272 91\n",
      "425 1275 92\n",
      "429 1287 93\n",
      "430 1290 94\n",
      "431 1293 95\n",
      "434 1302 96\n",
      "436 1308 97\n",
      "437 1311 98\n",
      "439 1317 99\n",
      "440 1320 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 2.6050490196583125 \ttest: 0.9444444444444444 2.5331224452861276\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 1.0263222533731813 \ttest: 0.9444444444444444 1.519514413095798\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 0.5454048688387338 \ttest: 1.0 1.1283676203734527\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 0.33589261457059527 \ttest: 1.0 0.9283742995596234\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 0.22662085238896335 \ttest: 1.0 0.8088376233236334\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 0.16276544356967598 \ttest: 1.0 0.7298910115080943\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 0.12235812092834943 \ttest: 1.0 0.6740275237253056\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.09523177580812328 \ttest: 1.0 0.6324586146918499\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.07617018026949156 \ttest: 1.0 0.6003232630662485\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.06227960738091398 \ttest: 1.0 0.574727585938546\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.051852810483201554 \ttest: 1.0 0.5538464716961862\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.043831062019541164 \ttest: 1.0 0.5364741557136066\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.03753017273688179 \ttest: 1.0 0.5217830714806646\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.032492391985001916 \ttest: 1.0 0.5091868266676781\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.02840227033992677 \ttest: 1.0 0.49825853714418533\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.025036799220272663 \ttest: 1.0 0.48868014780557634\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.022234771058399095 \ttest: 1.0 0.4802098748149957\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.019877347016170825 \ttest: 1.0 0.4726606525154145\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.01787538651682708 \ttest: 1.0 0.465885485938873\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.016160980645599763 \ttest: 1.0 0.4597672632154764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        14\n",
      "           1    1.00000   1.00000   1.00000        25\n",
      "\n",
      "    accuracy                        1.00000        39\n",
      "   macro avg    1.00000   1.00000   1.00000        39\n",
      "weighted avg    1.00000   1.00000   1.00000        39\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000         6\n",
      "           1    1.00000   1.00000   1.00000        12\n",
      "\n",
      "    accuracy                        1.00000        18\n",
      "   macro avg    1.00000   1.00000   1.00000        18\n",
      "weighted avg    1.00000   1.00000   1.00000        18\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 440\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 1320\n",
      "10 30 1\n",
      "20 60 2\n",
      "29 87 3\n",
      "38 114 4\n",
      "47 141 5\n",
      "56 168 6\n",
      "65 195 7\n",
      "74 222 8\n",
      "81 243 9\n",
      "90 270 10\n",
      "95 285 11\n",
      "102 306 12\n",
      "108 324 13\n",
      "115 345 14\n",
      "123 369 15\n",
      "131 393 16\n",
      "137 411 17\n",
      "145 435 18\n",
      "152 456 19\n",
      "155 465 20\n",
      "163 489 21\n",
      "170 510 22\n",
      "179 537 23\n",
      "183 549 24\n",
      "187 561 25\n",
      "193 579 26\n",
      "198 594 27\n",
      "205 615 28\n",
      "209 627 29\n",
      "217 651 30\n",
      "223 669 31\n",
      "230 690 32\n",
      "236 708 33\n",
      "238 714 34\n",
      "242 726 35\n",
      "245 735 36\n",
      "250 750 37\n",
      "256 768 38\n",
      "257 771 39\n",
      "258 774 40\n",
      "262 786 41\n",
      "267 801 42\n",
      "273 819 43\n",
      "276 828 44\n",
      "281 843 45\n",
      "286 858 46\n",
      "289 867 47\n",
      "292 876 48\n",
      "295 885 49\n",
      "299 897 50\n",
      "303 909 51\n",
      "308 924 52\n",
      "310 930 53\n",
      "312 936 54\n",
      "316 948 55\n",
      "321 963 56\n",
      "323 969 57\n",
      "325 975 58\n",
      "329 987 59\n",
      "330 990 60\n",
      "333 999 61\n",
      "336 1008 62\n",
      "340 1020 63\n",
      "343 1029 64\n",
      "346 1038 65\n",
      "348 1044 66\n",
      "349 1047 67\n",
      "351 1053 68\n",
      "353 1059 69\n",
      "354 1062 70\n",
      "356 1068 71\n",
      "359 1077 72\n",
      "362 1086 73\n",
      "367 1101 74\n",
      "368 1104 75\n",
      "370 1110 76\n",
      "371 1113 77\n",
      "375 1125 78\n",
      "379 1137 79\n",
      "383 1149 80\n",
      "385 1155 81\n",
      "387 1161 82\n",
      "389 1167 83\n",
      "391 1173 84\n",
      "392 1176 85\n",
      "396 1188 86\n",
      "400 1200 87\n",
      "400 1200 88\n",
      "403 1209 89\n",
      "406 1218 90\n",
      "411 1233 91\n",
      "413 1239 92\n",
      "413 1239 93\n",
      "414 1242 94\n",
      "415 1245 95\n",
      "416 1248 96\n",
      "418 1254 97\n",
      "419 1257 98\n",
      "422 1266 99\n",
      "422 1266 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 2.455913452860676 \ttest: 0.8333333333333334 4.3246310371235985\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 0.8680296242897522 \ttest: 0.8333333333333334 3.773498358267841\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 0.4371967798762844 \ttest: 0.8333333333333334 3.5918692517401576\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 0.2620317953842388 \ttest: 0.8333333333333334 3.5072247318949277\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 0.17418571477762207 \ttest: 0.8333333333333334 3.4603314285078595\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 0.12403790534165013 \ttest: 0.8333333333333334 3.4316548054353593\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 0.09276771332769487 \ttest: 0.8333333333333334 3.4130162938117046\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.0719762720616812 \ttest: 0.8333333333333334 3.4004261723395204\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.05746062527857379 \ttest: 0.8333333333333334 3.3917207939180867\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.04692988348070847 \ttest: 0.8333333333333334 3.3856322745028313\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.03904965813645509 \ttest: 0.8333333333333334 3.3813724361601754\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.03300028448242234 \ttest: 0.8333333333333334 3.3784280114767746\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.028255869175768365 \ttest: 0.8888888888888888 3.3764520050878866\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.02446651200057254 \ttest: 0.8888888888888888 3.375202498562162\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.021392123152566635 \ttest: 0.8888888888888888 3.3745064400945486\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.01886354291561413 \ttest: 0.8888888888888888 3.3742373188821118\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.016758816082531602 \ttest: 0.8888888888888888 3.3743009119843035\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.014988230327995768 \ttest: 0.8888888888888888 3.374625908496301\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.0134846062671517 \ttest: 0.8888888888888888 3.375157579876227\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.012196834155671462 \ttest: 0.8888888888888888 3.3758534085024903\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        14\n",
      "           1    1.00000   1.00000   1.00000        25\n",
      "\n",
      "    accuracy                        1.00000        39\n",
      "   macro avg    1.00000   1.00000   1.00000        39\n",
      "weighted avg    1.00000   1.00000   1.00000        39\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.83333   0.83333   0.83333         6\n",
      "           1    0.91667   0.91667   0.91667        12\n",
      "\n",
      "    accuracy                        0.88889        18\n",
      "   macro avg    0.87500   0.87500   0.87500        18\n",
      "weighted avg    0.88889   0.88889   0.88889        18\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 422\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 1266\n",
      "9 27 1\n",
      "19 57 2\n",
      "29 87 3\n",
      "38 114 4\n",
      "48 144 5\n",
      "58 174 6\n",
      "67 201 7\n",
      "76 228 8\n",
      "84 252 9\n",
      "94 282 10\n",
      "103 309 11\n",
      "113 339 12\n",
      "121 363 13\n",
      "128 384 14\n",
      "137 411 15\n",
      "143 429 16\n",
      "149 447 17\n",
      "155 465 18\n",
      "162 486 19\n",
      "167 501 20\n",
      "176 528 21\n",
      "182 546 22\n",
      "187 561 23\n",
      "194 582 24\n",
      "199 597 25\n",
      "204 612 26\n",
      "211 633 27\n",
      "217 651 28\n",
      "220 660 29\n",
      "224 672 30\n",
      "229 687 31\n",
      "234 702 32\n",
      "237 711 33\n",
      "241 723 34\n",
      "245 735 35\n",
      "247 741 36\n",
      "253 759 37\n",
      "261 783 38\n",
      "266 798 39\n",
      "272 816 40\n",
      "278 834 41\n",
      "283 849 42\n",
      "286 858 43\n",
      "287 861 44\n",
      "290 870 45\n",
      "295 885 46\n",
      "300 900 47\n",
      "303 909 48\n",
      "307 921 49\n",
      "308 924 50\n",
      "313 939 51\n",
      "316 948 52\n",
      "321 963 53\n",
      "324 972 54\n",
      "327 981 55\n",
      "332 996 56\n",
      "335 1005 57\n",
      "337 1011 58\n",
      "340 1020 59\n",
      "344 1032 60\n",
      "347 1041 61\n",
      "350 1050 62\n",
      "352 1056 63\n",
      "354 1062 64\n",
      "356 1068 65\n",
      "357 1071 66\n",
      "360 1080 67\n",
      "364 1092 68\n",
      "367 1101 69\n",
      "372 1116 70\n",
      "374 1122 71\n",
      "378 1134 72\n",
      "378 1134 73\n",
      "380 1140 74\n",
      "382 1146 75\n",
      "385 1155 76\n",
      "389 1167 77\n",
      "392 1176 78\n",
      "393 1179 79\n",
      "395 1185 80\n",
      "398 1194 81\n",
      "401 1203 82\n",
      "403 1209 83\n",
      "405 1215 84\n",
      "407 1221 85\n",
      "410 1230 86\n",
      "412 1236 87\n",
      "414 1242 88\n",
      "414 1242 89\n",
      "416 1248 90\n",
      "418 1254 91\n",
      "421 1263 92\n",
      "422 1266 93\n",
      "423 1269 94\n",
      "425 1275 95\n",
      "426 1278 96\n",
      "429 1287 97\n",
      "431 1293 98\n",
      "432 1296 99\n",
      "433 1299 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 2.3284219338290857 \ttest: 0.9444444444444444 2.5603306676040893\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 0.8260753903982081 \ttest: 0.9444444444444444 1.7891867744545058\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 0.41760757768880274 \ttest: 0.9444444444444444 1.5024077506181348\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 0.25106464135733836 \ttest: 0.9444444444444444 1.3472165290638105\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 0.1673485314810665 \ttest: 0.9444444444444444 1.2467625285677935\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 0.11945517493677345 \ttest: 0.9444444444444444 1.1747571804047667\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 0.08952915032131298 \ttest: 0.9444444444444444 1.1196827436932497\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.06959259544252702 \ttest: 0.9444444444444444 1.0756397389767094\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.05564843443907849 \ttest: 0.9444444444444444 1.0392634052562737\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.045515267801491684 \ttest: 1.0 1.0084780981511676\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.03792083695153764 \ttest: 1.0 0.9819247008934427\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.03208261705023892 \ttest: 1.0 0.9586705995730578\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.02749789076785541 \ttest: 1.0 0.9380512474067535\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.023831753003311345 \ttest: 1.0 0.9195782078319394\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.02085412103777793 \ttest: 1.0 0.9028830648170824\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.01840269510692275 \ttest: 1.0 0.8876817628990025\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.016360334435704057 \ttest: 1.0 0.8737511256828595\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.014640776497563457 \ttest: 1.0 0.860912920909278\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.013179360049528955 \ttest: 1.0 0.8490227606283998\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.011926844191500254 \ttest: 1.0 0.837962190609386\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        14\n",
      "           1    1.00000   1.00000   1.00000        25\n",
      "\n",
      "    accuracy                        1.00000        39\n",
      "   macro avg    1.00000   1.00000   1.00000        39\n",
      "weighted avg    1.00000   1.00000   1.00000        39\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000         6\n",
      "           1    1.00000   1.00000   1.00000        12\n",
      "\n",
      "    accuracy                        1.00000        18\n",
      "   macro avg    1.00000   1.00000   1.00000        18\n",
      "weighted avg    1.00000   1.00000   1.00000        18\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 433\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 1299\n",
      "10 30 1\n",
      "20 60 2\n",
      "30 90 3\n",
      "40 120 4\n",
      "49 147 5\n",
      "58 174 6\n",
      "67 201 7\n",
      "76 228 8\n",
      "85 255 9\n",
      "94 282 10\n",
      "103 309 11\n",
      "110 330 12\n",
      "118 354 13\n",
      "125 375 14\n",
      "132 396 15\n",
      "141 423 16\n",
      "149 447 17\n",
      "152 456 18\n",
      "159 477 19\n",
      "166 498 20\n",
      "172 516 21\n",
      "179 537 22\n",
      "188 564 23\n",
      "195 585 24\n",
      "199 597 25\n",
      "208 624 26\n",
      "215 645 27\n",
      "221 663 28\n",
      "225 675 29\n",
      "231 693 30\n",
      "239 717 31\n",
      "244 732 32\n",
      "249 747 33\n",
      "253 759 34\n",
      "259 777 35\n",
      "265 795 36\n",
      "268 804 37\n",
      "275 825 38\n",
      "277 831 39\n",
      "282 846 40\n",
      "289 867 41\n",
      "296 888 42\n",
      "302 906 43\n",
      "309 927 44\n",
      "315 945 45\n",
      "319 957 46\n",
      "325 975 47\n",
      "327 981 48\n",
      "330 990 49\n",
      "333 999 50\n",
      "334 1002 51\n",
      "337 1011 52\n",
      "340 1020 53\n",
      "345 1035 54\n",
      "349 1047 55\n",
      "351 1053 56\n",
      "354 1062 57\n",
      "359 1077 58\n",
      "363 1089 59\n",
      "366 1098 60\n",
      "369 1107 61\n",
      "375 1125 62\n",
      "379 1137 63\n",
      "385 1155 64\n",
      "386 1158 65\n",
      "391 1173 66\n",
      "392 1176 67\n",
      "397 1191 68\n",
      "398 1194 69\n",
      "399 1197 70\n",
      "403 1209 71\n",
      "407 1221 72\n",
      "409 1227 73\n",
      "410 1230 74\n",
      "413 1239 75\n",
      "414 1242 76\n",
      "415 1245 77\n",
      "418 1254 78\n",
      "419 1257 79\n",
      "421 1263 80\n",
      "421 1263 81\n",
      "423 1269 82\n",
      "427 1281 83\n",
      "428 1284 84\n",
      "430 1290 85\n",
      "432 1296 86\n",
      "433 1299 87\n",
      "435 1305 88\n",
      "435 1305 89\n",
      "436 1308 90\n",
      "437 1311 91\n",
      "438 1314 92\n",
      "439 1317 93\n",
      "439 1317 94\n",
      "440 1320 95\n",
      "441 1323 96\n",
      "442 1326 97\n",
      "442 1326 98\n",
      "445 1335 99\n",
      "446 1338 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 2.2612491768485494 \ttest: 0.8888888888888888 3.239625289824211\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 0.8427004132810377 \ttest: 0.8888888888888888 2.417994209940659\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 0.4339134626616079 \ttest: 0.8888888888888888 2.0865492838485933\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 0.2628197491516665 \ttest: 0.9444444444444444 1.9064611804001177\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 0.17575775649188988 \ttest: 0.9444444444444444 1.7925584992236037\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 0.12564174129027572 \ttest: 1.0 1.7135396776094953\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 0.09422449355542688 \ttest: 1.0 1.6552053320519513\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.0732577794762958 \ttest: 1.0 1.6101756766124136\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.05857955737476847 \ttest: 1.0 1.5742300277982904\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.04790814285553541 \ttest: 1.0 1.5447763131002148\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.039908906524362325 \ttest: 1.0 1.5201324200078772\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.03375939857104448 \ttest: 1.0 1.4991576650043479\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.02893059683083926 \ttest: 1.0 1.4810502276371529\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.025069790947365722 \ttest: 1.0 1.4652293764532256\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.021934545579840575 \ttest: 1.0 1.4512637388088838\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.01935379814564518 \ttest: 1.0 1.4388258728558383\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.017204065485362408 \ttest: 1.0 1.4276625215292467\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.01539441059780904 \ttest: 1.0 1.417574565763902\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.013856670132183741 \ttest: 1.0 1.408403170353873\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.012538940148480851 \ttest: 1.0 1.4000199951633951\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        14\n",
      "           1    1.00000   1.00000   1.00000        25\n",
      "\n",
      "    accuracy                        1.00000        39\n",
      "   macro avg    1.00000   1.00000   1.00000        39\n",
      "weighted avg    1.00000   1.00000   1.00000        39\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000         6\n",
      "           1    1.00000   1.00000   1.00000        12\n",
      "\n",
      "    accuracy                        1.00000        18\n",
      "   macro avg    1.00000   1.00000   1.00000        18\n",
      "weighted avg    1.00000   1.00000   1.00000        18\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 446\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 1338\n",
      "10 30 1\n",
      "20 60 2\n",
      "30 90 3\n",
      "40 120 4\n",
      "50 150 5\n",
      "60 180 6\n",
      "70 210 7\n",
      "79 237 8\n",
      "88 264 9\n",
      "98 294 10\n",
      "105 315 11\n",
      "111 333 12\n",
      "120 360 13\n",
      "128 384 14\n",
      "137 411 15\n",
      "144 432 16\n",
      "153 459 17\n",
      "157 471 18\n",
      "165 495 19\n",
      "171 513 20\n",
      "175 525 21\n",
      "181 543 22\n",
      "187 561 23\n",
      "192 576 24\n",
      "198 594 25\n",
      "206 618 26\n",
      "212 636 27\n",
      "220 660 28\n",
      "226 678 29\n",
      "231 693 30\n",
      "237 711 31\n",
      "240 720 32\n",
      "245 735 33\n",
      "249 747 34\n",
      "254 762 35\n",
      "258 774 36\n",
      "262 786 37\n",
      "264 792 38\n",
      "271 813 39\n",
      "276 828 40\n",
      "279 837 41\n",
      "282 846 42\n",
      "285 855 43\n",
      "288 864 44\n",
      "292 876 45\n",
      "297 891 46\n",
      "300 900 47\n",
      "301 903 48\n",
      "305 915 49\n",
      "309 927 50\n",
      "312 936 51\n",
      "315 945 52\n",
      "322 966 53\n",
      "325 975 54\n",
      "329 987 55\n",
      "333 999 56\n",
      "337 1011 57\n",
      "342 1026 58\n",
      "343 1029 59\n",
      "346 1038 60\n",
      "351 1053 61\n",
      "353 1059 62\n",
      "353 1059 63\n",
      "356 1068 64\n",
      "360 1080 65\n",
      "362 1086 66\n",
      "364 1092 67\n",
      "365 1095 68\n",
      "367 1101 69\n",
      "371 1113 70\n",
      "373 1119 71\n",
      "377 1131 72\n",
      "381 1143 73\n",
      "381 1143 74\n",
      "383 1149 75\n",
      "384 1152 76\n",
      "388 1164 77\n",
      "390 1170 78\n",
      "395 1185 79\n",
      "399 1197 80\n",
      "402 1206 81\n",
      "407 1221 82\n",
      "410 1230 83\n",
      "411 1233 84\n",
      "414 1242 85\n",
      "417 1251 86\n",
      "417 1251 87\n",
      "418 1254 88\n",
      "422 1266 89\n",
      "423 1269 90\n",
      "423 1269 91\n",
      "426 1278 92\n",
      "427 1281 93\n",
      "431 1293 94\n",
      "435 1305 95\n",
      "436 1308 96\n",
      "436 1308 97\n",
      "438 1314 98\n",
      "439 1317 99\n",
      "439 1317 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 1.871238218369606 \ttest: 0.7777777777777778 4.551153024900503\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 0.7063706146458767 \ttest: 0.8333333333333334 3.816071893209713\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 0.3716377622482552 \ttest: 0.8333333333333334 3.45309045919047\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 0.2274310072220594 \ttest: 0.8333333333333334 3.23422353859216\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 0.1525984926867523 \ttest: 0.8333333333333334 3.088032371256258\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 0.10906206911662202 \ttest: 0.8333333333333334 2.9834848125050466\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 0.08163161013727442 \ttest: 0.8333333333333334 2.9049221665556035\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.06329289191769684 \ttest: 0.8333333333333334 2.8436314679031325\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.050455778458047995 \ttest: 0.8333333333333334 2.7943981133737505\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.04113399739880934 \ttest: 0.8333333333333334 2.7539173386498947\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.03415908042922408 \ttest: 0.8333333333333334 2.7199955235459243\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.028808557488252673 \ttest: 0.8333333333333334 2.691119952920043\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.02461690042706769 \ttest: 0.8333333333333334 2.666213583185142\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.021273526291303038 \ttest: 0.8333333333333334 2.6444884880489754\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.01856497544322474 \ttest: 0.8333333333333334 2.6253546816438265\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.01634072267288323 \ttest: 0.8888888888888888 2.6083613970502446\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.014492215396185821 \ttest: 0.8888888888888888 2.593158113241114\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.012939609268356956 \ttest: 0.8888888888888888 2.579467998448359\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.011623138421007673 \ttest: 0.8888888888888888 2.567069388306383\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.010497361217118431 \ttest: 0.8888888888888888 2.5557825978814503\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        14\n",
      "           1    1.00000   1.00000   1.00000        25\n",
      "\n",
      "    accuracy                        1.00000        39\n",
      "   macro avg    1.00000   1.00000   1.00000        39\n",
      "weighted avg    1.00000   1.00000   1.00000        39\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   0.66667   0.80000         6\n",
      "           1    0.85714   1.00000   0.92308        12\n",
      "\n",
      "    accuracy                        0.88889        18\n",
      "   macro avg    0.92857   0.83333   0.86154        18\n",
      "weighted avg    0.90476   0.88889   0.88205        18\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 439\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 1317\n",
      "10 30 1\n",
      "20 60 2\n",
      "29 87 3\n",
      "38 114 4\n",
      "46 138 5\n",
      "55 165 6\n",
      "65 195 7\n",
      "74 222 8\n",
      "82 246 9\n",
      "88 264 10\n",
      "97 291 11\n",
      "103 309 12\n",
      "113 339 13\n",
      "120 360 14\n",
      "127 381 15\n",
      "134 402 16\n",
      "142 426 17\n",
      "149 447 18\n",
      "156 468 19\n",
      "159 477 20\n",
      "165 495 21\n",
      "173 519 22\n",
      "180 540 23\n",
      "188 564 24\n",
      "192 576 25\n",
      "198 594 26\n",
      "205 615 27\n",
      "208 624 28\n",
      "212 636 29\n",
      "218 654 30\n",
      "225 675 31\n",
      "229 687 32\n",
      "236 708 33\n",
      "240 720 34\n",
      "243 729 35\n",
      "247 741 36\n",
      "251 753 37\n",
      "258 774 38\n",
      "265 795 39\n",
      "269 807 40\n",
      "273 819 41\n",
      "278 834 42\n",
      "283 849 43\n",
      "284 852 44\n",
      "288 864 45\n",
      "294 882 46\n",
      "297 891 47\n",
      "300 900 48\n",
      "303 909 49\n",
      "307 921 50\n",
      "310 930 51\n",
      "316 948 52\n",
      "319 957 53\n",
      "323 969 54\n",
      "325 975 55\n",
      "330 990 56\n",
      "333 999 57\n",
      "337 1011 58\n",
      "341 1023 59\n",
      "343 1029 60\n",
      "346 1038 61\n",
      "348 1044 62\n",
      "354 1062 63\n",
      "359 1077 64\n",
      "362 1086 65\n",
      "363 1089 66\n",
      "365 1095 67\n",
      "367 1101 68\n",
      "369 1107 69\n",
      "372 1116 70\n",
      "376 1128 71\n",
      "380 1140 72\n",
      "383 1149 73\n",
      "384 1152 74\n",
      "385 1155 75\n",
      "387 1161 76\n",
      "391 1173 77\n",
      "392 1176 78\n",
      "392 1176 79\n",
      "393 1179 80\n",
      "397 1191 81\n",
      "398 1194 82\n",
      "400 1200 83\n",
      "401 1203 84\n",
      "403 1209 85\n",
      "406 1218 86\n",
      "407 1221 87\n",
      "408 1224 88\n",
      "408 1224 89\n",
      "412 1236 90\n",
      "414 1242 91\n",
      "417 1251 92\n",
      "418 1254 93\n",
      "422 1266 94\n",
      "422 1266 95\n",
      "423 1269 96\n",
      "423 1269 97\n",
      "426 1278 98\n",
      "429 1287 99\n",
      "430 1290 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 2.5001195899700424 \ttest: 0.9444444444444444 2.5522618122190535\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 0.9620898474499298 \ttest: 0.9444444444444444 1.7122686729775636\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 0.5049094780867653 \ttest: 0.9444444444444444 1.3932795229547632\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 0.309039551736524 \ttest: 0.9444444444444444 1.2219597865680827\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 0.20781904441713095 \ttest: 0.9444444444444444 1.112631290131202\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 0.14897490582295797 \ttest: 0.9444444444444444 1.0354000779421049\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 0.11185465555609983 \ttest: 0.9444444444444444 0.9770996209789843\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.08698475826607759 \ttest: 0.9444444444444444 0.9309999190505118\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.06953246351531416 \ttest: 0.9444444444444444 0.8932851674129272\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.05682693047952796 \ttest: 0.9444444444444444 0.8616198713487246\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.04729653861810457 \ttest: 0.9444444444444444 0.8344879808817767\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.039968498888057306 \ttest: 0.9444444444444444 0.8108583986982772\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.034215034936973684 \ttest: 0.9444444444444444 0.7900027894653606\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.029616585798292884 \ttest: 0.9444444444444444 0.7713902976378776\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.025884260977163814 \ttest: 0.9444444444444444 0.7546236687648\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.02281396455811594 \ttest: 0.9444444444444444 0.7393988737410934\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.02025824128015047 \ttest: 0.9444444444444444 0.7254786842537564\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.018108439777764173 \ttest: 0.9444444444444444 0.7126748519881521\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.016283092472966724 \ttest: 0.9444444444444444 0.7008357720571791\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.014720156375724993 \ttest: 0.9444444444444444 0.689837744599886\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        14\n",
      "           1    1.00000   1.00000   1.00000        25\n",
      "\n",
      "    accuracy                        1.00000        39\n",
      "   macro avg    1.00000   1.00000   1.00000        39\n",
      "weighted avg    1.00000   1.00000   1.00000        39\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   0.83333   0.90909         6\n",
      "           1    0.92308   1.00000   0.96000        12\n",
      "\n",
      "    accuracy                        0.94444        18\n",
      "   macro avg    0.96154   0.91667   0.93455        18\n",
      "weighted avg    0.94872   0.94444   0.94303        18\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 430\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 1290\n",
      "10 30 1\n",
      "18 54 2\n",
      "27 81 3\n",
      "37 111 4\n",
      "46 138 5\n",
      "55 165 6\n",
      "63 189 7\n",
      "71 213 8\n",
      "80 240 9\n",
      "87 261 10\n",
      "95 285 11\n",
      "102 306 12\n",
      "111 333 13\n",
      "120 360 14\n",
      "130 390 15\n",
      "138 414 16\n",
      "143 429 17\n",
      "150 450 18\n",
      "158 474 19\n",
      "165 495 20\n",
      "171 513 21\n",
      "179 537 22\n",
      "187 561 23\n",
      "192 576 24\n",
      "197 591 25\n",
      "204 612 26\n",
      "211 633 27\n",
      "217 651 28\n",
      "223 669 29\n",
      "229 687 30\n",
      "236 708 31\n",
      "242 726 32\n",
      "247 741 33\n",
      "250 750 34\n",
      "256 768 35\n",
      "261 783 36\n",
      "266 798 37\n",
      "272 816 38\n",
      "274 822 39\n",
      "279 837 40\n",
      "283 849 41\n",
      "286 858 42\n",
      "293 879 43\n",
      "298 894 44\n",
      "301 903 45\n",
      "305 915 46\n",
      "308 924 47\n",
      "310 930 48\n",
      "316 948 49\n",
      "317 951 50\n",
      "319 957 51\n",
      "323 969 52\n",
      "327 981 53\n",
      "331 993 54\n",
      "336 1008 55\n",
      "337 1011 56\n",
      "339 1017 57\n",
      "342 1026 58\n",
      "347 1041 59\n",
      "351 1053 60\n",
      "352 1056 61\n",
      "354 1062 62\n",
      "355 1065 63\n",
      "359 1077 64\n",
      "363 1089 65\n",
      "366 1098 66\n",
      "366 1098 67\n",
      "369 1107 68\n",
      "375 1125 69\n",
      "378 1134 70\n",
      "379 1137 71\n",
      "382 1146 72\n",
      "384 1152 73\n",
      "387 1161 74\n",
      "388 1164 75\n",
      "391 1173 76\n",
      "393 1179 77\n",
      "397 1191 78\n",
      "399 1197 79\n",
      "400 1200 80\n",
      "402 1206 81\n",
      "404 1212 82\n",
      "407 1221 83\n",
      "408 1224 84\n",
      "410 1230 85\n",
      "413 1239 86\n",
      "414 1242 87\n",
      "414 1242 88\n",
      "414 1242 89\n",
      "416 1248 90\n",
      "417 1251 91\n",
      "418 1254 92\n",
      "420 1260 93\n",
      "423 1269 94\n",
      "424 1272 95\n",
      "425 1275 96\n",
      "425 1275 97\n",
      "426 1278 98\n",
      "427 1281 99\n",
      "430 1290 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 2.5306627070242 \ttest: 0.9444444444444444 2.4434113066843612\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 0.8889269528126518 \ttest: 0.9444444444444444 1.795494575583078\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 0.4452186362598098 \ttest: 0.9444444444444444 1.6265817047274744\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 0.2659619043571566 \ttest: 0.9444444444444444 1.5648701057314884\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 0.17645398260329595 \ttest: 0.9444444444444444 1.5393805491461556\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 0.12550172313874006 \ttest: 0.9444444444444444 1.5290902326239102\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 0.09378974434584554 \ttest: 0.9444444444444444 1.526045836332263\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.07273200132688218 \ttest: 0.9444444444444444 1.5267353348691595\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.058044078427985105 \ttest: 0.9444444444444444 1.5294357415751776\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.04739558793842795 \ttest: 0.9444444444444444 1.533236068384747\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.03943128466228552 \ttest: 0.9444444444444444 1.537627774088522\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.03331970861305623 \ttest: 0.9444444444444444 1.5423156256243338\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.02852791030064407 \ttest: 0.9444444444444444 1.5471235237693715\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.02470156641794236 \ttest: 0.9444444444444444 1.5519447152022574\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.021597703132469573 \ttest: 0.9444444444444444 1.556714157527214\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.01904521590914919 \ttest: 0.9444444444444444 1.5613925532110398\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.016920799474896765 \ttest: 0.9444444444444444 1.5659568129533428\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.015133780347046611 \ttest: 0.9444444444444444 1.5703941988602035\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.013616279531730526 \ttest: 0.9444444444444444 1.574698643089518\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.012316667980824925 \ttest: 0.9444444444444444 1.5788683889099198\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        14\n",
      "           1    1.00000   1.00000   1.00000        25\n",
      "\n",
      "    accuracy                        1.00000        39\n",
      "   macro avg    1.00000   1.00000   1.00000        39\n",
      "weighted avg    1.00000   1.00000   1.00000        39\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.85714   1.00000   0.92308         6\n",
      "           1    1.00000   0.91667   0.95652        12\n",
      "\n",
      "    accuracy                        0.94444        18\n",
      "   macro avg    0.92857   0.95833   0.93980        18\n",
      "weighted avg    0.95238   0.94444   0.94537        18\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 430\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 1290\n",
      "10 30 1\n",
      "19 57 2\n",
      "29 87 3\n",
      "37 111 4\n",
      "47 141 5\n",
      "56 168 6\n",
      "64 192 7\n",
      "73 219 8\n",
      "82 246 9\n",
      "91 273 10\n",
      "99 297 11\n",
      "108 324 12\n",
      "118 354 13\n",
      "127 381 14\n",
      "136 408 15\n",
      "143 429 16\n",
      "152 456 17\n",
      "160 480 18\n",
      "167 501 19\n",
      "173 519 20\n",
      "179 537 21\n",
      "185 555 22\n",
      "190 570 23\n",
      "195 585 24\n",
      "201 603 25\n",
      "208 624 26\n",
      "213 639 27\n",
      "219 657 28\n",
      "222 666 29\n",
      "227 681 30\n",
      "233 699 31\n",
      "238 714 32\n",
      "244 732 33\n",
      "247 741 34\n",
      "253 759 35\n",
      "257 771 36\n",
      "263 789 37\n",
      "267 801 38\n",
      "271 813 39\n",
      "276 828 40\n",
      "280 840 41\n",
      "285 855 42\n",
      "291 873 43\n",
      "294 882 44\n",
      "298 894 45\n",
      "301 903 46\n",
      "308 924 47\n",
      "313 939 48\n",
      "321 963 49\n",
      "323 969 50\n",
      "329 987 51\n",
      "332 996 52\n",
      "336 1008 53\n",
      "339 1017 54\n",
      "342 1026 55\n",
      "344 1032 56\n",
      "346 1038 57\n",
      "348 1044 58\n",
      "352 1056 59\n",
      "353 1059 60\n",
      "356 1068 61\n",
      "358 1074 62\n",
      "362 1086 63\n",
      "365 1095 64\n",
      "366 1098 65\n",
      "369 1107 66\n",
      "373 1119 67\n",
      "375 1125 68\n",
      "378 1134 69\n",
      "381 1143 70\n",
      "385 1155 71\n",
      "386 1158 72\n",
      "389 1167 73\n",
      "392 1176 74\n",
      "392 1176 75\n",
      "394 1182 76\n",
      "396 1188 77\n",
      "398 1194 78\n",
      "402 1206 79\n",
      "404 1212 80\n",
      "407 1221 81\n",
      "412 1236 82\n",
      "413 1239 83\n",
      "414 1242 84\n",
      "416 1248 85\n",
      "417 1251 86\n",
      "418 1254 87\n",
      "421 1263 88\n",
      "422 1266 89\n",
      "423 1269 90\n",
      "424 1272 91\n",
      "428 1284 92\n",
      "428 1284 93\n",
      "430 1290 94\n",
      "430 1290 95\n",
      "433 1299 96\n",
      "434 1302 97\n",
      "435 1305 98\n",
      "435 1305 99\n",
      "437 1311 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 2.2923200997360524 \ttest: 0.9444444444444444 2.789997900954022\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 0.7829581755236045 \ttest: 0.9444444444444444 2.1025898759832056\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 0.3849715081953781 \ttest: 0.9444444444444444 1.8901635139399249\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 0.22682599603037992 \ttest: 0.9444444444444444 1.8006051251393178\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 0.14891831200273925 \ttest: 0.9444444444444444 1.757327261112709\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 0.10505670641765232 \ttest: 0.9444444444444444 1.7352306001542115\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 0.07800368514991025 \ttest: 0.9444444444444444 1.7240446687865072\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.06017320308179577 \ttest: 0.9444444444444444 1.7189320995930826\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.04781348160869869 \ttest: 0.9444444444444444 1.7173817951562473\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.03889982616207964 \ttest: 0.9444444444444444 1.71799442776953\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.03226286082846854 \ttest: 0.9444444444444444 1.7199473518643322\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.027189489372240513 \ttest: 0.9444444444444444 1.7227366050229007\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.023225062390477523 \ttest: 0.9444444444444444 1.7260434157342546\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.020068736322892633 \ttest: 0.9444444444444444 1.7296611008129368\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.017515074629662643 \ttest: 0.9444444444444444 1.7334531249718017\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.015419948706012366 \ttest: 0.9444444444444444 1.7373280857677633\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.013679842862792094 \ttest: 0.9444444444444444 1.741224295934722\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.01221886739138282 \ttest: 0.9444444444444444 1.7451000112238015\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.01098036720396285 \ttest: 0.9444444444444444 1.7489270857375663\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.009921358451945658 \ttest: 0.9444444444444444 1.7526867660893237\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        14\n",
      "           1    1.00000   1.00000   1.00000        25\n",
      "\n",
      "    accuracy                        1.00000        39\n",
      "   macro avg    1.00000   1.00000   1.00000        39\n",
      "weighted avg    1.00000   1.00000   1.00000        39\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   0.83333   0.90909         6\n",
      "           1    0.92308   1.00000   0.96000        12\n",
      "\n",
      "    accuracy                        0.94444        18\n",
      "   macro avg    0.96154   0.91667   0.93455        18\n",
      "weighted avg    0.94872   0.94444   0.94303        18\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 437\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 1311\n",
      "10 30 1\n",
      "18 54 2\n",
      "27 81 3\n",
      "36 108 4\n",
      "45 135 5\n",
      "54 162 6\n",
      "62 186 7\n",
      "71 213 8\n",
      "79 237 9\n",
      "88 264 10\n",
      "97 291 11\n",
      "106 318 12\n",
      "112 336 13\n",
      "120 360 14\n",
      "125 375 15\n",
      "132 396 16\n",
      "140 420 17\n",
      "147 441 18\n",
      "154 462 19\n",
      "163 489 20\n",
      "168 504 21\n",
      "176 528 22\n",
      "180 540 23\n",
      "184 552 24\n",
      "192 576 25\n",
      "199 597 26\n",
      "207 621 27\n",
      "211 633 28\n",
      "218 654 29\n",
      "221 663 30\n",
      "226 678 31\n",
      "232 696 32\n",
      "236 708 33\n",
      "243 729 34\n",
      "247 741 35\n",
      "254 762 36\n",
      "261 783 37\n",
      "265 795 38\n",
      "270 810 39\n",
      "274 822 40\n",
      "281 843 41\n",
      "287 861 42\n",
      "293 879 43\n",
      "297 891 44\n",
      "301 903 45\n",
      "306 918 46\n",
      "312 936 47\n",
      "316 948 48\n",
      "321 963 49\n",
      "323 969 50\n",
      "324 972 51\n",
      "326 978 52\n",
      "329 987 53\n",
      "333 999 54\n",
      "338 1014 55\n",
      "341 1023 56\n",
      "346 1038 57\n",
      "348 1044 58\n",
      "350 1050 59\n",
      "353 1059 60\n",
      "359 1077 61\n",
      "362 1086 62\n",
      "364 1092 63\n",
      "367 1101 64\n",
      "370 1110 65\n",
      "372 1116 66\n",
      "374 1122 67\n",
      "377 1131 68\n",
      "379 1137 69\n",
      "382 1146 70\n",
      "383 1149 71\n",
      "383 1149 72\n",
      "385 1155 73\n",
      "387 1161 74\n",
      "390 1170 75\n",
      "391 1173 76\n",
      "395 1185 77\n",
      "397 1191 78\n",
      "398 1194 79\n",
      "403 1209 80\n",
      "404 1212 81\n",
      "405 1215 82\n",
      "410 1230 83\n",
      "413 1239 84\n",
      "415 1245 85\n",
      "416 1248 86\n",
      "418 1254 87\n",
      "418 1254 88\n",
      "419 1257 89\n",
      "423 1269 90\n",
      "426 1278 91\n",
      "428 1284 92\n",
      "429 1287 93\n",
      "431 1293 94\n",
      "431 1293 95\n",
      "433 1299 96\n",
      "437 1311 97\n",
      "439 1317 98\n",
      "439 1317 99\n",
      "442 1326 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 2.2170283672257196 \ttest: 0.8333333333333334 3.7724665529722885\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 0.7709350616120082 \ttest: 0.8888888888888888 3.1444576344573796\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 0.38249844289628665 \ttest: 0.8888888888888888 2.910263803880902\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 0.22649978394280662 \ttest: 0.8888888888888888 2.7915643898929967\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 0.14919084859055864 \ttest: 0.8888888888888888 2.722016680240943\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 0.10550095441120783 \ttest: 0.8888888888888888 2.677751260624278\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 0.0784811889796364 \ttest: 0.8888888888888888 2.6480837135045165\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.06063577797454838 \ttest: 0.8888888888888888 2.6275303953350018\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.048244961781624816 \ttest: 0.8888888888888888 2.6129980636528627\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.03929626010297758 \ttest: 0.8888888888888888 2.6026163720129074\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.032625056292004455 \ttest: 0.8888888888888888 2.595192462555146\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.027520011135940096 \ttest: 0.8888888888888888 2.5899327216465413\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.023526978275978622 \ttest: 0.8888888888888888 2.586290721851665\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.02034509303639547 \ttest: 0.8888888888888888 2.5838793924511108\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.017768690812570587 \ttest: 0.8888888888888888 2.582417921728856\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.01565334847791274 \ttest: 0.8888888888888888 2.581698405028692\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.01389525105094589 \ttest: 0.8888888888888888 2.581564202343289\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.012418230390132803 \ttest: 0.8888888888888888 2.58189549469379\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.01116538281470426 \ttest: 0.8888888888888888 2.582599406341727\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.010093507116555527 \ttest: 0.8888888888888888 2.5836031028625293\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        14\n",
      "           1    1.00000   1.00000   1.00000        25\n",
      "\n",
      "    accuracy                        1.00000        39\n",
      "   macro avg    1.00000   1.00000   1.00000        39\n",
      "weighted avg    1.00000   1.00000   1.00000        39\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   0.66667   0.80000         6\n",
      "           1    0.85714   1.00000   0.92308        12\n",
      "\n",
      "    accuracy                        0.88889        18\n",
      "   macro avg    0.92857   0.83333   0.86154        18\n",
      "weighted avg    0.90476   0.88889   0.88205        18\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 442\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 1326\n",
      "10 30 1\n",
      "20 60 2\n",
      "29 87 3\n",
      "38 114 4\n",
      "47 141 5\n",
      "55 165 6\n",
      "63 189 7\n",
      "70 210 8\n",
      "78 234 9\n",
      "87 261 10\n",
      "96 288 11\n",
      "104 312 12\n",
      "111 333 13\n",
      "117 351 14\n",
      "126 378 15\n",
      "133 399 16\n",
      "139 417 17\n",
      "144 432 18\n",
      "151 453 19\n",
      "155 465 20\n",
      "160 480 21\n",
      "168 504 22\n",
      "173 519 23\n",
      "179 537 24\n",
      "183 549 25\n",
      "190 570 26\n",
      "197 591 27\n",
      "203 609 28\n",
      "209 627 29\n",
      "213 639 30\n",
      "219 657 31\n",
      "225 675 32\n",
      "229 687 33\n",
      "236 708 34\n",
      "240 720 35\n",
      "244 732 36\n",
      "250 750 37\n",
      "255 765 38\n",
      "259 777 39\n",
      "261 783 40\n",
      "265 795 41\n",
      "269 807 42\n",
      "272 816 43\n",
      "277 831 44\n",
      "281 843 45\n",
      "282 846 46\n",
      "284 852 47\n",
      "288 864 48\n",
      "292 876 49\n",
      "296 888 50\n",
      "301 903 51\n",
      "304 912 52\n",
      "310 930 53\n",
      "314 942 54\n",
      "318 954 55\n",
      "321 963 56\n",
      "323 969 57\n",
      "327 981 58\n",
      "329 987 59\n",
      "332 996 60\n",
      "335 1005 61\n",
      "339 1017 62\n",
      "343 1029 63\n",
      "346 1038 64\n",
      "351 1053 65\n",
      "352 1056 66\n",
      "352 1056 67\n",
      "357 1071 68\n",
      "361 1083 69\n",
      "364 1092 70\n",
      "367 1101 71\n",
      "368 1104 72\n",
      "369 1107 73\n",
      "370 1110 74\n",
      "373 1119 75\n",
      "375 1125 76\n",
      "376 1128 77\n",
      "377 1131 78\n",
      "379 1137 79\n",
      "382 1146 80\n",
      "384 1152 81\n",
      "384 1152 82\n",
      "387 1161 83\n",
      "390 1170 84\n",
      "393 1179 85\n",
      "394 1182 86\n",
      "396 1188 87\n",
      "398 1194 88\n",
      "400 1200 89\n",
      "403 1209 90\n",
      "405 1215 91\n",
      "408 1224 92\n",
      "409 1227 93\n",
      "412 1236 94\n",
      "412 1236 95\n",
      "414 1242 96\n",
      "416 1248 97\n",
      "419 1257 98\n",
      "421 1263 99\n",
      "424 1272 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 2.1047716956121634 \ttest: 0.8888888888888888 3.125070669828296\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 0.7147469216215971 \ttest: 0.8333333333333334 2.505164402497572\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 0.35355767374028335 \ttest: 0.8333333333333334 2.2845608138067015\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 0.20956314191163838 \ttest: 0.8333333333333334 2.167374221074448\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 0.13823200321886805 \ttest: 0.8333333333333334 2.092497782391918\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 0.09787031373813007 \ttest: 0.8888888888888888 2.0395168829911796\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 0.07287239990869133 \ttest: 0.8888888888888888 1.999560673927414\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.056340795338017974 \ttest: 0.8888888888888888 1.9680904312713101\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.04484985536151624 \ttest: 0.8888888888888888 1.9425129568464128\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.036543897522887524 \ttest: 0.8888888888888888 1.9212245371008871\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.03034763690328552 \ttest: 0.8888888888888888 1.903172649714156\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.025603495328348658 \ttest: 0.8888888888888888 1.887633851230191\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.021891193558911066 \ttest: 0.8888888888888888 1.8740921749638408\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.018932040354704784 \ttest: 0.8888888888888888 1.862168342999405\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.016535373666545845 \ttest: 0.8888888888888888 1.851576450418312\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.014567212586053282 \ttest: 0.8888888888888888 1.8420963408372832\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.012931191239162695 \ttest: 0.8888888888888888 1.833555364378579\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.011556571180792126 \ttest: 0.8888888888888888 1.8258159675595709\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.010390482466741954 \ttest: 0.8888888888888888 1.8187670307556907\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.009392771637384445 \ttest: 0.8888888888888888 1.8123176843053046\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        14\n",
      "           1    1.00000   1.00000   1.00000        25\n",
      "\n",
      "    accuracy                        1.00000        39\n",
      "   macro avg    1.00000   1.00000   1.00000        39\n",
      "weighted avg    1.00000   1.00000   1.00000        39\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.83333   0.83333   0.83333         6\n",
      "           1    0.91667   0.91667   0.91667        12\n",
      "\n",
      "    accuracy                        0.88889        18\n",
      "   macro avg    0.87500   0.87500   0.87500        18\n",
      "weighted avg    0.88889   0.88889   0.88889        18\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 424\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 1272\n",
      "9 27 1\n",
      "18 54 2\n",
      "28 84 3\n",
      "37 111 4\n",
      "45 135 5\n",
      "54 162 6\n",
      "62 186 7\n",
      "71 213 8\n",
      "81 243 9\n",
      "88 264 10\n",
      "96 288 11\n",
      "105 315 12\n",
      "111 333 13\n",
      "119 357 14\n",
      "126 378 15\n",
      "136 408 16\n",
      "144 432 17\n",
      "147 441 18\n",
      "155 465 19\n",
      "160 480 20\n",
      "167 501 21\n",
      "171 513 22\n",
      "177 531 23\n",
      "183 549 24\n",
      "187 561 25\n",
      "192 576 26\n",
      "199 597 27\n",
      "207 621 28\n",
      "211 633 29\n",
      "215 645 30\n",
      "219 657 31\n",
      "225 675 32\n",
      "231 693 33\n",
      "234 702 34\n",
      "238 714 35\n",
      "245 735 36\n",
      "249 747 37\n",
      "254 762 38\n",
      "258 774 39\n",
      "264 792 40\n",
      "266 798 41\n",
      "272 816 42\n",
      "276 828 43\n",
      "278 834 44\n",
      "279 837 45\n",
      "284 852 46\n",
      "289 867 47\n",
      "295 885 48\n",
      "300 900 49\n",
      "302 906 50\n",
      "306 918 51\n",
      "308 924 52\n",
      "311 933 53\n",
      "317 951 54\n",
      "321 963 55\n",
      "326 978 56\n",
      "331 993 57\n",
      "333 999 58\n",
      "336 1008 59\n",
      "339 1017 60\n",
      "341 1023 61\n",
      "343 1029 62\n",
      "345 1035 63\n",
      "347 1041 64\n",
      "351 1053 65\n",
      "353 1059 66\n",
      "358 1074 67\n",
      "359 1077 68\n",
      "364 1092 69\n",
      "367 1101 70\n",
      "371 1113 71\n",
      "376 1128 72\n",
      "379 1137 73\n",
      "380 1140 74\n",
      "381 1143 75\n",
      "382 1146 76\n",
      "385 1155 77\n",
      "386 1158 78\n",
      "390 1170 79\n",
      "390 1170 80\n",
      "391 1173 81\n",
      "393 1179 82\n",
      "397 1191 83\n",
      "402 1206 84\n",
      "404 1212 85\n",
      "405 1215 86\n",
      "406 1218 87\n",
      "411 1233 88\n",
      "413 1239 89\n",
      "414 1242 90\n",
      "416 1248 91\n",
      "417 1251 92\n",
      "419 1257 93\n",
      "422 1266 94\n",
      "423 1269 95\n",
      "425 1275 96\n",
      "426 1278 97\n",
      "427 1281 98\n",
      "427 1281 99\n",
      "429 1287 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 2.4054111036304375 \ttest: 0.9444444444444444 2.518263975830476\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 0.8922958650700229 \ttest: 1.0 1.5654650664424854\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 0.46229482146670986 \ttest: 1.0 1.175243721319688\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 0.2820922732996571 \ttest: 1.0 0.9587316246048172\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 0.18989994397623824 \ttest: 1.0 0.8193175657816281\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 0.13651240170004292 \ttest: 1.0 0.7211889959226228\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 0.10285643857809533 \ttest: 1.0 0.6478959378320055\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.08028344124858502 \ttest: 1.0 0.5907817329653215\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.0644114246818993 \ttest: 1.0 0.5448378584189218\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.05282782059327807 \ttest: 1.0 0.5069557965048678\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.04411557868121405 \ttest: 1.0 0.47509884407072844\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.037398058451736146 \ttest: 1.0 0.447873732303809\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.0321093537706464 \ttest: 1.0 0.4242932357014291\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.027870918674579324 \ttest: 1.0 0.4036370878259995\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.024421774287318874 \ttest: 1.0 0.38536665998932285\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.02157726483882736 \ttest: 1.0 0.369070558792951\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.019203757186667784 \ttest: 1.0 0.35442877603460465\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.017202610638697817 \ttest: 1.0 0.34118838262310314\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.015499729099329425 \ttest: 1.0 0.32914663531561206\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.014038579577128051 \ttest: 1.0 0.3181389763980815\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        14\n",
      "           1    1.00000   1.00000   1.00000        25\n",
      "\n",
      "    accuracy                        1.00000        39\n",
      "   macro avg    1.00000   1.00000   1.00000        39\n",
      "weighted avg    1.00000   1.00000   1.00000        39\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000         6\n",
      "           1    1.00000   1.00000   1.00000        12\n",
      "\n",
      "    accuracy                        1.00000        18\n",
      "   macro avg    1.00000   1.00000   1.00000        18\n",
      "weighted avg    1.00000   1.00000   1.00000        18\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 429\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 1287\n",
      "10 30 1\n",
      "20 60 2\n",
      "29 87 3\n",
      "37 111 4\n",
      "45 135 5\n",
      "54 162 6\n",
      "62 186 7\n",
      "70 210 8\n",
      "78 234 9\n",
      "87 261 10\n",
      "95 285 11\n",
      "102 306 12\n",
      "111 333 13\n",
      "117 351 14\n",
      "125 375 15\n",
      "132 396 16\n",
      "140 420 17\n",
      "145 435 18\n",
      "152 456 19\n",
      "161 483 20\n",
      "167 501 21\n",
      "173 519 22\n",
      "177 531 23\n",
      "186 558 24\n",
      "189 567 25\n",
      "195 585 26\n",
      "201 603 27\n",
      "208 624 28\n",
      "214 642 29\n",
      "219 657 30\n",
      "223 669 31\n",
      "226 678 32\n",
      "231 693 33\n",
      "237 711 34\n",
      "244 732 35\n",
      "251 753 36\n",
      "254 762 37\n",
      "259 777 38\n",
      "263 789 39\n",
      "267 801 40\n",
      "271 813 41\n",
      "277 831 42\n",
      "283 849 43\n",
      "288 864 44\n",
      "292 876 45\n",
      "294 882 46\n",
      "299 897 47\n",
      "303 909 48\n",
      "305 915 49\n",
      "308 924 50\n",
      "310 930 51\n",
      "315 945 52\n",
      "317 951 53\n",
      "321 963 54\n",
      "324 972 55\n",
      "327 981 56\n",
      "331 993 57\n",
      "332 996 58\n",
      "333 999 59\n",
      "335 1005 60\n",
      "339 1017 61\n",
      "344 1032 62\n",
      "348 1044 63\n",
      "350 1050 64\n",
      "355 1065 65\n",
      "359 1077 66\n",
      "365 1095 67\n",
      "367 1101 68\n",
      "369 1107 69\n",
      "371 1113 70\n",
      "375 1125 71\n",
      "379 1137 72\n",
      "381 1143 73\n",
      "386 1158 74\n",
      "389 1167 75\n",
      "394 1182 76\n",
      "396 1188 77\n",
      "399 1197 78\n",
      "402 1206 79\n",
      "404 1212 80\n",
      "405 1215 81\n",
      "408 1224 82\n",
      "411 1233 83\n",
      "413 1239 84\n",
      "417 1251 85\n",
      "419 1257 86\n",
      "420 1260 87\n",
      "422 1266 88\n",
      "424 1272 89\n",
      "427 1281 90\n",
      "429 1287 91\n",
      "432 1296 92\n",
      "433 1299 93\n",
      "434 1302 94\n",
      "435 1305 95\n",
      "436 1308 96\n",
      "439 1317 97\n",
      "440 1320 98\n",
      "440 1320 99\n",
      "441 1323 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 2.634043170704186 \ttest: 0.9444444444444444 2.3077739671152413\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 0.9940637431866145 \ttest: 0.9444444444444444 1.3714582188493125\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 0.5155734854822542 \ttest: 0.9444444444444444 1.0200484386357933\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 0.3132664078770936 \ttest: 1.0 0.8406985079791186\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 0.20966287296537842 \ttest: 1.0 0.7333183889532388\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 0.14982166449701564 \ttest: 1.0 0.6622741808484963\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 0.1122501853581858 \ttest: 1.0 0.6119172867268228\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.08716579920378796 \ttest: 1.0 0.5743761822204285\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.06960898013880464 \ttest: 1.0 0.5452900351622832\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.05685255303164887 \ttest: 1.0 0.522060755006851\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.047298293475053835 \ttest: 1.0 0.5030497871363401\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.0399602497022678 \ttest: 1.0 0.4871752435318111\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.0342039004962473 \ttest: 1.0 0.47369529835695734\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.029606141531072196 \ttest: 1.0 0.4620849463094362\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.02587619283036412 \ttest: 1.0 0.45196249853155357\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.022808947092950498 \ttest: 1.0 0.44304395972955823\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.02025641347921164 \ttest: 1.0 0.43511372539404336\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.0181096663392665 \ttest: 1.0 0.42800519422544797\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.016287108114881252 \ttest: 1.0 0.4215876028687859\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.014726645214291203 \ttest: 1.0 0.41575687822469926\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        14\n",
      "           1    1.00000   1.00000   1.00000        25\n",
      "\n",
      "    accuracy                        1.00000        39\n",
      "   macro avg    1.00000   1.00000   1.00000        39\n",
      "weighted avg    1.00000   1.00000   1.00000        39\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000         6\n",
      "           1    1.00000   1.00000   1.00000        12\n",
      "\n",
      "    accuracy                        1.00000        18\n",
      "   macro avg    1.00000   1.00000   1.00000        18\n",
      "weighted avg    1.00000   1.00000   1.00000        18\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 441\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 1323\n",
      "10 30 1\n",
      "20 60 2\n",
      "28 84 3\n",
      "38 114 4\n",
      "47 141 5\n",
      "56 168 6\n",
      "64 192 7\n",
      "73 219 8\n",
      "80 240 9\n",
      "90 270 10\n",
      "97 291 11\n",
      "106 318 12\n",
      "113 339 13\n",
      "120 360 14\n",
      "127 381 15\n",
      "135 405 16\n",
      "145 435 17\n",
      "151 453 18\n",
      "157 471 19\n",
      "164 492 20\n",
      "167 501 21\n",
      "174 522 22\n",
      "181 543 23\n",
      "188 564 24\n",
      "195 585 25\n",
      "201 603 26\n",
      "206 618 27\n",
      "213 639 28\n",
      "220 660 29\n",
      "225 675 30\n",
      "231 693 31\n",
      "235 705 32\n",
      "240 720 33\n",
      "246 738 34\n",
      "248 744 35\n",
      "253 759 36\n",
      "259 777 37\n",
      "265 795 38\n",
      "272 816 39\n",
      "277 831 40\n",
      "280 840 41\n",
      "284 852 42\n",
      "289 867 43\n",
      "296 888 44\n",
      "300 900 45\n",
      "305 915 46\n",
      "309 927 47\n",
      "311 933 48\n",
      "318 954 49\n",
      "322 966 50\n",
      "328 984 51\n",
      "334 1002 52\n",
      "339 1017 53\n",
      "344 1032 54\n",
      "347 1041 55\n",
      "351 1053 56\n",
      "353 1059 57\n",
      "357 1071 58\n",
      "361 1083 59\n",
      "362 1086 60\n",
      "362 1086 61\n",
      "365 1095 62\n",
      "368 1104 63\n",
      "372 1116 64\n",
      "374 1122 65\n",
      "377 1131 66\n",
      "379 1137 67\n",
      "381 1143 68\n",
      "384 1152 69\n",
      "385 1155 70\n",
      "389 1167 71\n",
      "393 1179 72\n",
      "399 1197 73\n",
      "401 1203 74\n",
      "404 1212 75\n",
      "405 1215 76\n",
      "407 1221 77\n",
      "409 1227 78\n",
      "411 1233 79\n",
      "412 1236 80\n",
      "413 1239 81\n",
      "416 1248 82\n",
      "418 1254 83\n",
      "420 1260 84\n",
      "422 1266 85\n",
      "423 1269 86\n",
      "427 1281 87\n",
      "428 1284 88\n",
      "428 1284 89\n",
      "431 1293 90\n",
      "435 1305 91\n",
      "436 1308 92\n",
      "438 1314 93\n",
      "439 1317 94\n",
      "441 1323 95\n",
      "442 1326 96\n",
      "443 1329 97\n",
      "444 1332 98\n",
      "445 1335 99\n",
      "449 1347 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 1.7084103338094612 \ttest: 0.8333333333333334 4.445895898488881\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 0.666306885758634 \ttest: 0.8888888888888888 3.6421786272662247\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 0.35549907853593443 \ttest: 0.8888888888888888 3.212515790789131\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 0.2188493502429214 \ttest: 0.8888888888888888 2.944653703445779\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 0.14728011710033456 \ttest: 0.8888888888888888 2.7608938235224394\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 0.10545415909932157 \ttest: 0.8888888888888888 2.6258234279798662\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 0.07903580129893463 \ttest: 0.8888888888888888 2.521370366596158\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.06134591155768043 \ttest: 0.8888888888888888 2.437457174922383\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.048948939351348274 \ttest: 0.8888888888888888 2.368045350594466\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.03993862675168772 \ttest: 0.9444444444444444 2.3092981804118162\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.03319153408714979 \ttest: 0.9444444444444444 2.2586578215285753\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.028012176534386153 \ttest: 0.9444444444444444 2.2143497137977124\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.02395201019230409 \ttest: 0.9444444444444444 2.1751009592391553\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.020711571376313243 \ttest: 0.9444444444444444 2.1399723726407878\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.018084920603077443 \ttest: 0.9444444444444444 2.108254084283947\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.015926760014849117 \ttest: 0.9444444444444444 2.079398280510141\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.014132257064996288 \ttest: 0.9444444444444444 2.052974498791253\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.012624269460627958 \ttest: 0.9444444444444444 2.0286390909298295\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.01134502959938378 \ttest: 0.9444444444444444 2.0061138552500886\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.010250597438747601 \ttest: 0.9444444444444444 1.9851707613446903\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        14\n",
      "           1    1.00000   1.00000   1.00000        25\n",
      "\n",
      "    accuracy                        1.00000        39\n",
      "   macro avg    1.00000   1.00000   1.00000        39\n",
      "weighted avg    1.00000   1.00000   1.00000        39\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   0.83333   0.90909         6\n",
      "           1    0.92308   1.00000   0.96000        12\n",
      "\n",
      "    accuracy                        0.94444        18\n",
      "   macro avg    0.96154   0.91667   0.93455        18\n",
      "weighted avg    0.94872   0.94444   0.94303        18\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 449\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 1347\n",
      "10 30 1\n",
      "20 60 2\n",
      "30 90 3\n",
      "38 114 4\n",
      "48 144 5\n",
      "57 171 6\n",
      "66 198 7\n",
      "76 228 8\n",
      "83 249 9\n",
      "91 273 10\n",
      "99 297 11\n",
      "108 324 12\n",
      "116 348 13\n",
      "123 369 14\n",
      "128 384 15\n",
      "132 396 16\n",
      "141 423 17\n",
      "149 447 18\n",
      "157 471 19\n",
      "165 495 20\n",
      "174 522 21\n",
      "180 540 22\n",
      "186 558 23\n",
      "192 576 24\n",
      "199 597 25\n",
      "202 606 26\n",
      "210 630 27\n",
      "215 645 28\n",
      "220 660 29\n",
      "227 681 30\n",
      "231 693 31\n",
      "234 702 32\n",
      "237 711 33\n",
      "241 723 34\n",
      "247 741 35\n",
      "250 750 36\n",
      "256 768 37\n",
      "261 783 38\n",
      "267 801 39\n",
      "270 810 40\n",
      "273 819 41\n",
      "280 840 42\n",
      "286 858 43\n",
      "292 876 44\n",
      "295 885 45\n",
      "301 903 46\n",
      "304 912 47\n",
      "305 915 48\n",
      "309 927 49\n",
      "315 945 50\n",
      "322 966 51\n",
      "324 972 52\n",
      "328 984 53\n",
      "332 996 54\n",
      "335 1005 55\n",
      "339 1017 56\n",
      "344 1032 57\n",
      "348 1044 58\n",
      "349 1047 59\n",
      "351 1053 60\n",
      "356 1068 61\n",
      "361 1083 62\n",
      "366 1098 63\n",
      "369 1107 64\n",
      "371 1113 65\n",
      "374 1122 66\n",
      "375 1125 67\n",
      "377 1131 68\n",
      "381 1143 69\n",
      "382 1146 70\n",
      "384 1152 71\n",
      "387 1161 72\n",
      "388 1164 73\n",
      "394 1182 74\n",
      "395 1185 75\n",
      "396 1188 76\n",
      "397 1191 77\n",
      "401 1203 78\n",
      "404 1212 79\n",
      "406 1218 80\n",
      "409 1227 81\n",
      "409 1227 82\n",
      "410 1230 83\n",
      "411 1233 84\n",
      "413 1239 85\n",
      "415 1245 86\n",
      "418 1254 87\n",
      "421 1263 88\n",
      "421 1263 89\n",
      "424 1272 90\n",
      "426 1278 91\n",
      "429 1287 92\n",
      "430 1290 93\n",
      "433 1299 94\n",
      "437 1311 95\n",
      "439 1317 96\n",
      "440 1320 97\n",
      "442 1326 98\n",
      "446 1338 99\n",
      "446 1338 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 2.1056062119437255 \ttest: 0.8888888888888888 3.7422812778619603\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 0.7381966664156727 \ttest: 0.8888888888888888 3.347938764343327\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 0.3713824834621714 \ttest: 0.8888888888888888 3.267904533534798\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 0.22239029990323808 \ttest: 0.8888888888888888 3.2534028921673865\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 0.147725078438229 \ttest: 0.8888888888888888 3.258337018315879\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 0.1051368318974932 \ttest: 0.8888888888888888 3.269797778466057\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 0.07860091959658833 \ttest: 0.8888888888888888 3.283319864972408\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.06096879592008708 \ttest: 0.8888888888888888 3.2971733115442983\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.04866532743135064 \ttest: 0.8888888888888888 3.31065693836048\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.03974315410111851 \ttest: 0.8888888888888888 3.3234953800249594\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.03306874763062361 \ttest: 0.8888888888888888 3.335600033241721\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.02794625773632695 \ttest: 0.8888888888888888 3.346966228401782\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.023929478592670958 \ttest: 0.8888888888888888 3.357626400146256\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.020721674569840875 \ttest: 0.8888888888888888 3.367627963773764\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.01811932162454114 \ttest: 0.8888888888888888 3.377022688906816\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.01597907506021205 \ttest: 0.8888888888888888 3.3858616373679205\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.014197622804186839 \ttest: 0.8888888888888888 3.394192865650889\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.012698986572827385 \ttest: 0.8888888888888888 3.402060518871881\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.011426283949417937 \ttest: 0.8888888888888888 3.409504622686568\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.010336247009172564 \ttest: 0.8888888888888888 3.416561215675384\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        14\n",
      "           1    1.00000   1.00000   1.00000        25\n",
      "\n",
      "    accuracy                        1.00000        39\n",
      "   macro avg    1.00000   1.00000   1.00000        39\n",
      "weighted avg    1.00000   1.00000   1.00000        39\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   0.66667   0.80000         6\n",
      "           1    0.85714   1.00000   0.92308        12\n",
      "\n",
      "    accuracy                        0.88889        18\n",
      "   macro avg    0.92857   0.83333   0.86154        18\n",
      "weighted avg    0.90476   0.88889   0.88205        18\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 446\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 1338\n",
      "10 30 1\n",
      "19 57 2\n",
      "27 81 3\n",
      "37 111 4\n",
      "47 141 5\n",
      "56 168 6\n",
      "61 183 7\n",
      "70 210 8\n",
      "78 234 9\n",
      "86 258 10\n",
      "94 282 11\n",
      "101 303 12\n",
      "109 327 13\n",
      "116 348 14\n",
      "122 366 15\n",
      "130 390 16\n",
      "138 414 17\n",
      "143 429 18\n",
      "149 447 19\n",
      "153 459 20\n",
      "159 477 21\n",
      "167 501 22\n",
      "173 519 23\n",
      "179 537 24\n",
      "184 552 25\n",
      "188 564 26\n",
      "195 585 27\n",
      "200 600 28\n",
      "203 609 29\n",
      "209 627 30\n",
      "215 645 31\n",
      "219 657 32\n",
      "225 675 33\n",
      "230 690 34\n",
      "236 708 35\n",
      "242 726 36\n",
      "248 744 37\n",
      "252 756 38\n",
      "257 771 39\n",
      "260 780 40\n",
      "262 786 41\n",
      "269 807 42\n",
      "275 825 43\n",
      "279 837 44\n",
      "284 852 45\n",
      "288 864 46\n",
      "291 873 47\n",
      "294 882 48\n",
      "296 888 49\n",
      "301 903 50\n",
      "303 909 51\n",
      "307 921 52\n",
      "312 936 53\n",
      "316 948 54\n",
      "318 954 55\n",
      "322 966 56\n",
      "323 969 57\n",
      "327 981 58\n",
      "331 993 59\n",
      "335 1005 60\n",
      "336 1008 61\n",
      "341 1023 62\n",
      "343 1029 63\n",
      "347 1041 64\n",
      "351 1053 65\n",
      "354 1062 66\n",
      "356 1068 67\n",
      "357 1071 68\n",
      "362 1086 69\n",
      "364 1092 70\n",
      "366 1098 71\n",
      "368 1104 72\n",
      "371 1113 73\n",
      "371 1113 74\n",
      "373 1119 75\n",
      "375 1125 76\n",
      "376 1128 77\n",
      "381 1143 78\n",
      "383 1149 79\n",
      "383 1149 80\n",
      "386 1158 81\n",
      "388 1164 82\n",
      "390 1170 83\n",
      "394 1182 84\n",
      "397 1191 85\n",
      "400 1200 86\n",
      "400 1200 87\n",
      "403 1209 88\n",
      "407 1221 89\n",
      "408 1224 90\n",
      "408 1224 91\n",
      "408 1224 92\n",
      "411 1233 93\n",
      "413 1239 94\n",
      "417 1251 95\n",
      "417 1251 96\n",
      "420 1260 97\n",
      "425 1275 98\n",
      "426 1278 99\n",
      "428 1284 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 2.373037684818957 \ttest: 0.8888888888888888 3.17526067200886\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 0.8736829444155024 \ttest: 0.8888888888888888 2.4560326868906097\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 0.45052334575025554 \ttest: 0.8888888888888888 2.1609156274991013\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 0.2733512202600811 \ttest: 0.8888888888888888 1.9917063416547822\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 0.1829426473637972 \ttest: 0.8888888888888888 1.8788642887557276\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 0.13079326748122433 \ttest: 0.8888888888888888 1.7968293631211196\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 0.09806351403016877 \ttest: 0.8888888888888888 1.7337445063883519\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.07620948817590109 \ttest: 0.9444444444444444 1.6832734885150376\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.060908270534211564 \ttest: 0.9444444444444444 1.6416892648774497\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.04978534515125396 \ttest: 0.9444444444444444 1.6066408013187772\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.04144994616465179 \ttest: 0.9444444444444444 1.576563633231686\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.03504430656586461 \ttest: 0.9444444444444444 1.550371718617372\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.030016412263335197 \ttest: 0.9444444444444444 1.5272847672173926\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.025998131241867162 \ttest: 0.9444444444444444 1.5067259528223205\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.02273640886895276 \ttest: 0.9444444444444444 1.4882584890109984\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.02005269810810462 \ttest: 0.9444444444444444 1.471544769638887\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.017818130425058223 \ttest: 0.9444444444444444 1.4563191757387135\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.015937821363949375 \ttest: 0.9444444444444444 1.442369463207977\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.014340665509994658 \ttest: 0.9444444444444444 1.4295237086035415\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.012972532947396006 \ttest: 0.9444444444444444 1.4176409544575161\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        14\n",
      "           1    1.00000   1.00000   1.00000        25\n",
      "\n",
      "    accuracy                        1.00000        39\n",
      "   macro avg    1.00000   1.00000   1.00000        39\n",
      "weighted avg    1.00000   1.00000   1.00000        39\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   0.83333   0.90909         6\n",
      "           1    0.92308   1.00000   0.96000        12\n",
      "\n",
      "    accuracy                        0.94444        18\n",
      "   macro avg    0.96154   0.91667   0.93455        18\n",
      "weighted avg    0.94872   0.94444   0.94303        18\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 428\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 1284\n",
      "10 30 1\n",
      "20 60 2\n",
      "30 90 3\n",
      "38 114 4\n",
      "48 144 5\n",
      "56 168 6\n",
      "63 189 7\n",
      "73 219 8\n",
      "81 243 9\n",
      "90 270 10\n",
      "98 294 11\n",
      "106 318 12\n",
      "115 345 13\n",
      "122 366 14\n",
      "129 387 15\n",
      "136 408 16\n",
      "141 423 17\n",
      "148 444 18\n",
      "155 465 19\n",
      "158 474 20\n",
      "165 495 21\n",
      "172 516 22\n",
      "177 531 23\n",
      "185 555 24\n",
      "192 576 25\n",
      "198 594 26\n",
      "203 609 27\n",
      "209 627 28\n",
      "216 648 29\n",
      "222 666 30\n",
      "225 675 31\n",
      "230 690 32\n",
      "232 696 33\n",
      "236 708 34\n",
      "244 732 35\n",
      "248 744 36\n",
      "253 759 37\n",
      "259 777 38\n",
      "263 789 39\n",
      "268 804 40\n",
      "272 816 41\n",
      "274 822 42\n",
      "276 828 43\n",
      "279 837 44\n",
      "282 846 45\n",
      "286 858 46\n",
      "288 864 47\n",
      "294 882 48\n",
      "300 900 49\n",
      "306 918 50\n",
      "308 924 51\n",
      "311 933 52\n",
      "316 948 53\n",
      "322 966 54\n",
      "326 978 55\n",
      "328 984 56\n",
      "331 993 57\n",
      "335 1005 58\n",
      "335 1005 59\n",
      "341 1023 60\n",
      "345 1035 61\n",
      "348 1044 62\n",
      "353 1059 63\n",
      "357 1071 64\n",
      "360 1080 65\n",
      "361 1083 66\n",
      "363 1089 67\n",
      "364 1092 68\n",
      "368 1104 69\n",
      "372 1116 70\n",
      "375 1125 71\n",
      "378 1134 72\n",
      "380 1140 73\n",
      "382 1146 74\n",
      "383 1149 75\n",
      "384 1152 76\n",
      "386 1158 77\n",
      "388 1164 78\n",
      "391 1173 79\n",
      "394 1182 80\n",
      "397 1191 81\n",
      "398 1194 82\n",
      "402 1206 83\n",
      "403 1209 84\n",
      "405 1215 85\n",
      "408 1224 86\n",
      "412 1236 87\n",
      "414 1242 88\n",
      "415 1245 89\n",
      "419 1257 90\n",
      "421 1263 91\n",
      "421 1263 92\n",
      "423 1269 93\n",
      "424 1272 94\n",
      "424 1272 95\n",
      "426 1278 96\n",
      "428 1284 97\n",
      "431 1293 98\n",
      "434 1302 99\n",
      "436 1308 100\n",
      "retrain  1 :\n",
      "\ttrain: 1.0 1.8097903281765508 \ttest: 0.8333333333333334 3.4830527313067963\n",
      "retrain  2 :\n",
      "\ttrain: 1.0 0.6156852423042749 \ttest: 0.8333333333333334 2.8214268769146056\n",
      "retrain  3 :\n",
      "\ttrain: 1.0 0.3086146275186784 \ttest: 0.8333333333333334 2.5760126398021317\n",
      "retrain  4 :\n",
      "\ttrain: 1.0 0.18519254279132 \ttest: 0.8333333333333334 2.4491331540084036\n",
      "retrain  5 :\n",
      "\ttrain: 1.0 0.12340692430509519 \ttest: 0.8888888888888888 2.37199591452102\n",
      "retrain  6 :\n",
      "\ttrain: 1.0 0.08810099365648913 \ttest: 0.8888888888888888 2.3204297545855948\n",
      "retrain  7 :\n",
      "\ttrain: 1.0 0.06604548789909628 \ttest: 0.8888888888888888 2.2837616762988127\n",
      "retrain  8 :\n",
      "\ttrain: 1.0 0.051351458352834244 \ttest: 0.8888888888888888 2.256541997682561\n",
      "retrain  9 :\n",
      "\ttrain: 1.0 0.041072644977424085 \ttest: 0.8888888888888888 2.235692782154865\n",
      "retrain  10 :\n",
      "\ttrain: 1.0 0.03360191715900588 \ttest: 0.8888888888888888 2.219341782761287\n",
      "retrain  11 :\n",
      "\ttrain: 1.0 0.02800203942976192 \ttest: 0.8888888888888888 2.206283532691101\n",
      "retrain  12 :\n",
      "\ttrain: 1.0 0.023696515661057287 \ttest: 0.8888888888888888 2.1957061995685905\n",
      "retrain  13 :\n",
      "\ttrain: 1.0 0.020314946498859045 \ttest: 0.8888888888888888 2.187042772809828\n",
      "retrain  14 :\n",
      "\ttrain: 1.0 0.017610545947222805 \ttest: 0.8888888888888888 2.1798851367750722\n",
      "retrain  15 :\n",
      "\ttrain: 1.0 0.015413750662684139 \ttest: 0.8888888888888888 2.1739320251238947\n",
      "retrain  16 :\n",
      "\ttrain: 1.0 0.013604939051697296 \ttest: 0.8888888888888888 2.1689562090915886\n",
      "retrain  17 :\n",
      "\ttrain: 1.0 0.012097765975188964 \ttest: 0.8888888888888888 2.16478309570183\n",
      "retrain  18 :\n",
      "\ttrain: 1.0 0.010828641961700783 \ttest: 0.8888888888888888 2.1612763535748143\n",
      "retrain  19 :\n",
      "\ttrain: 1.0 0.009749897963462711 \ttest: 0.8888888888888888 2.1583280098570135\n",
      "retrain  20 :\n",
      "\ttrain: 1.0 0.008825230777684755 \ttest: 0.8888888888888888 2.1558514734422247\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        14\n",
      "           1    1.00000   1.00000   1.00000        25\n",
      "\n",
      "    accuracy                        1.00000        39\n",
      "   macro avg    1.00000   1.00000   1.00000        39\n",
      "weighted avg    1.00000   1.00000   1.00000        39\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.83333   0.83333   0.83333         6\n",
      "           1    0.91667   0.91667   0.91667        12\n",
      "\n",
      "    accuracy                        0.88889        18\n",
      "   macro avg    0.87500   0.87500   0.87500        18\n",
      "weighted avg    0.88889   0.88889   0.88889        18\n",
      "\n",
      "----------------GTGP-------------\n",
      "Number of Trees: 436\n",
      "Average of depth: 1.0\n",
      "Number of nodes: 1308\n"
     ]
    }
   ],
   "source": [
    "def fit_trees():\n",
    "    learning_rate=0.1\n",
    "    max_depth=3\n",
    "    bins=8\n",
    "    lam=100\n",
    "\n",
    "    gtgp = GTGP(learning_rate=learning_rate,max_depth=max_depth,bins=bins,lam=lam)\n",
    "\n",
    "    total_size=10\n",
    "    elite_size = 10\n",
    "    epoch= 100\n",
    "    gp_epoch= 1\n",
    "    verbose = 1\n",
    "    tolerance=0.001\n",
    "\n",
    "    gtgp.fit(X_train,y_train,total_size=total_size,elite_size = elite_size,epoch=epoch,gp_epoch=gp_epoch,tolerance=tolerance,verbose=verbose)\n",
    "\n",
    "    retrain_epoch= 20\n",
    "    alpha=0\n",
    "    beta=1\n",
    "    gammer=0\n",
    "\n",
    "    verbose=1\n",
    "    gtgp.lam = 10\n",
    "    gtgp.retrain_estimators(X_test,y_test,retrain_epoch=retrain_epoch,alpha=alpha,beta=beta,gammer=gammer,verbose=verbose)\n",
    "\n",
    "    return gtgp\n",
    "\n",
    "for i in range(30):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size,stratify=y, random_state=seeds[i])\n",
    "    y_train,y_test,y_train_one_hot,y_test_one_hot = to_one_hot(y_train,y_test)\n",
    "    gtgp = fit_trees()\n",
    "\n",
    "    print(classification_report(y_train,np.argmax(gtgp.train_p,axis=1),digits=5))\n",
    "    print(classification_report(y_test,np.argmax(gtgp.test_p,axis=1),digits=5))\n",
    "\n",
    "    num_trees,depth,num_nodes = gtgp.print_model()\n",
    "\n",
    "    train_acc = accuracy_score(y_train,np.argmax(gtgp.train_p,axis=1))\n",
    "    test_acc = accuracy_score(y_test,np.argmax(gtgp.test_p,axis=1))\n",
    "    # train_f1 = f1_score(y_train,np.argmax(gtgp.train_p,axis=1),average='macro')\n",
    "    # test_f1 = f1_score(y_test,np.argmax(gtgp.test_p,axis=1),average='macro')\n",
    "\n",
    "    # train_f1 = roc_auc_score(gtgp.y_one_hot.toarray(),(gtgp.train_p.T/np.sum(gtgp.train_p,axis=1)).T)\n",
    "    # test_f1 = roc_auc_score(y_test_one_hot.toarray(),(gtgp.test_p.T/np.sum(gtgp.test_p,axis=1)).T)\n",
    "\n",
    "    train_f1 = roc_auc_score(gtgp.y_one_hot.toarray(),gtgp.train_p)\n",
    "    test_f1 = roc_auc_score(y_test_one_hot.toarray(),gtgp.test_p)\n",
    "\n",
    "\n",
    "    with open('./benchmark/'+dataset+'.csv','a') as f:\n",
    "        s = str(train_acc)+\",\"+str(test_acc)+\",\"+str(train_f1)+\",\"+str(test_f1)+\",\"+str(num_trees)+\",\"+str(depth)+\",\"+str(num_nodes)+\"\\n\"\n",
    "        f.writelines(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662e91a5",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ed15d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "661630ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size,stratify=y, random_state=seeds[i])\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_train,y_test,y_train_one_hot,y_test_one_hot = to_one_hot(y_train,y_test)\n",
    "\n",
    "    num_trees = 1\n",
    "    depth = clf.tree_.max_depth\n",
    "    num_nodes = clf.tree_.node_count\n",
    "\n",
    "    train_acc = accuracy_score(y_train,clf.predict(X_train))\n",
    "    test_acc = accuracy_score(y_test,clf.predict(X_test))\n",
    "    train_f1 = f1_score(y_train,clf.predict(X_train),average='macro')\n",
    "    test_f1 = f1_score(y_test,clf.predict(X_test),average='macro')\n",
    "\n",
    "    train_roc = roc_auc_score(y_train_one_hot.toarray(),clf.predict_proba(X_train))\n",
    "    test_roc = roc_auc_score(y_test_one_hot.toarray(),clf.predict_proba(X_test))\n",
    "\n",
    "    with open('./benchmark_DC/'+dataset+'.csv','a') as f:\n",
    "        s = str(train_acc)+\",\"+str(test_acc)+\",\"+str(train_f1)+\",\"+str(test_f1)+\",\"+str(num_trees)+\",\"+str(depth)+\",\"+str(num_nodes)+\"\\n\"\n",
    "        f.writelines(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63afbae1",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "28fa8541",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "acfdd7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./benchmark_xgb/'+dataset+'.csv','w') as f:\n",
    "    for i in range(30):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size,stratify=y, random_state=seeds[i])\n",
    "        y_train,y_test,y_train_one_hot,y_test_one_hot = to_one_hot(y_train,y_test)\n",
    "        # xgb = xgboost.XGBClassifier(n_estimators=100,max_depth=6)\n",
    "        # xgb = xgboost.XGBClassifier(min_child_weight=0,max_depth=4)\n",
    "        xgb = xgboost.XGBClassifier(n_estimators=1000)\n",
    "        xgb.fit(X_train,y_train)\n",
    "\n",
    "        import json\n",
    "\n",
    "        def item_generator(json_input, lookup_key):\n",
    "            if isinstance(json_input, dict):\n",
    "                for k, v in json_input.items():\n",
    "                    if k == lookup_key:\n",
    "                        yield v\n",
    "                    else:\n",
    "                        yield from item_generator(v, lookup_key)\n",
    "            elif isinstance(json_input, list):\n",
    "                for item in json_input:\n",
    "                    yield from item_generator(item, lookup_key)\n",
    "\n",
    "        def tree_depth(json_text):\n",
    "            json_input = json.loads(json_text)\n",
    "            depths = list(item_generator(json_input, 'depth'))\n",
    "            return max(depths) + 1 if len(depths) != 0 else 1\n",
    "\n",
    "        train_acc = accuracy_score(y_train,xgb.predict(X_train))\n",
    "        test_acc = accuracy_score(y_test,xgb.predict(X_test))\n",
    "\n",
    "        # train_f1 = f1_score(y_train,xgb.predict(X_train),average='macro')\n",
    "        # test_f1 = f1_score(y_test,xgb.predict(X_test),average='macro')\n",
    "        train_f1 = roc_auc_score(y_train_one_hot.toarray(),xgb.predict_proba(X_train))\n",
    "        test_f1 = roc_auc_score(y_test_one_hot.toarray(),xgb.predict_proba(X_test))\n",
    "\n",
    "        booster = xgb.get_booster()\n",
    "\n",
    "        tree_df = booster.trees_to_dataframe()\n",
    "        depths = [tree_depth(x) for x in booster.get_dump(dump_format = \"json\")]\n",
    "        num_trees = len(depths)\n",
    "        depth = np.average(depths)\n",
    "        num_nodes = len(tree_df)\n",
    "\n",
    "        s = str(train_acc)+\",\"+str(test_acc)+\",\"+str(train_f1)+\",\"+str(test_f1)+\",\"+str(num_trees)+\",\"+str(depth)+\",\"+str(num_nodes)+\"\\n\"\n",
    "        f.writelines(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc363f99",
   "metadata": {},
   "source": [
    "# GDBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e6d3435",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ef69c1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./benchmark_GBDT/'+dataset+'.csv','w') as f:\n",
    "    for i in range(30):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size,stratify=y, random_state=seeds[i])\n",
    "        y_train,y_test,y_train_one_hot,y_test_one_hot = to_one_hot(y_train,y_test)\n",
    "        # clf = GradientBoostingClassifier(n_estimators=1000)\n",
    "        clf = GradientBoostingClassifier(n_estimators=1000)\n",
    "        clf.fit(X_train,y_train)\n",
    "\n",
    "        train_acc = accuracy_score(y_train,clf.predict(X_train))\n",
    "        test_acc = accuracy_score(y_test,clf.predict(X_test))\n",
    "        # train_f1 = f1_score(y_train,clf.predict(X_train),average='macro')\n",
    "        # test_f1 = f1_score(y_test,clf.predict(X_test),average='macro')\n",
    "        train_f1 = roc_auc_score(y_train_one_hot.toarray(),clf.predict_proba(X_train))\n",
    "        test_f1 = roc_auc_score(y_test_one_hot.toarray(),clf.predict_proba(X_test))\n",
    "\n",
    "\n",
    "        num_trees = len([ est for ests in clf.estimators_ for est in ests])\n",
    "        depth = np.average([ max(1,est.tree_.max_depth) for ests in clf.estimators_ for est in ests])\n",
    "        num_nodes = sum([ est.tree_.node_count for ests in clf.estimators_ for est in ests])\n",
    "\n",
    "        s = str(train_acc)+\",\"+str(test_acc)+\",\"+str(train_f1)+\",\"+str(test_f1)+\",\"+str(num_trees)+\",\"+str(depth)+\",\"+str(num_nodes)+\"\\n\"\n",
    "        f.writelines(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0ef54f",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c8623bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e3edfc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./benchmark_RF/'+dataset+'.csv','w') as f:\n",
    "    for i in range(30):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size,stratify=y, random_state=seeds[i])\n",
    "        y_train,y_test,y_train_one_hot,y_test_one_hot = to_one_hot(y_train,y_test)\n",
    "        # rfc = RandomForestClassifier(n_estimators=100)\n",
    "        rfc = RandomForestClassifier(n_estimators=1000)\n",
    "        rfc.fit(X_train,y_train)\n",
    "\n",
    "        train_acc = accuracy_score(y_train,rfc.predict(X_train))\n",
    "        test_acc = accuracy_score(y_test,rfc.predict(X_test))\n",
    "        # train_f1 = f1_score(y_train,rfc.predict(X_train),average='macro')\n",
    "        # test_f1 = f1_score(y_test,rfc.predict(X_test),average='macro')\n",
    "        \n",
    "        train_f1 = roc_auc_score(y_train_one_hot.toarray(),rfc.predict_proba(X_train))\n",
    "        test_f1 = roc_auc_score(y_test_one_hot.toarray(),rfc.predict_proba(X_test))\n",
    "\n",
    "        num_trees = len(rfc.estimators_)\n",
    "        depth = np.average([est.tree_.max_depth for est in rfc.estimators_])\n",
    "        num_nodes = sum([est.tree_.node_count for est in rfc.estimators_])\n",
    "\n",
    "        s = str(train_acc)+\",\"+str(test_acc)+\",\"+str(train_f1)+\",\"+str(test_f1)+\",\"+str(num_trees)+\",\"+str(depth)+\",\"+str(num_nodes)+\"\\n\"\n",
    "        f.writelines(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49b66a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb3fc4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BStackGP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc-autonumbering": true,
  "toc-showcode": true,
  "toc-showmarkdowntxt": true,
  "vscode": {
   "interpreter": {
    "hash": "598cefc26d6e5a65b2978c65314d0610ea9dfe34c7d989c4b6d2528d500ccb7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
