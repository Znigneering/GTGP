{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a8bc990-ebc5-46bd-bab4-f4091ce5b834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../script/\")\n",
    "\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import importlib\n",
    "from time import time\n",
    "import Functions\n",
    "from matplotlib import pyplot as plt\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8230662c-fa72-42c7-bf5e-919cbf89080d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from Node import Node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a876dc",
   "metadata": {},
   "source": [
    "# Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44cce456",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Engine:\n",
    "    def __init__(self,opset,X,Y,log_odds,p,learning_rate):\n",
    "        self.generation = 0\n",
    "#         self.X_train,self.X_valid,self.y_train,self.y_valid = train_test_split(X,Y,train_size=0.9)\n",
    "        X = X.astype('float64')\n",
    "        self.opset = opset\n",
    "        \n",
    "        self.num_class = len(pd.unique(Y))\n",
    "        self.feature_space = X.shape[1]\n",
    "        \n",
    "        self.vals = X.T\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "\n",
    "        self.log_odds = log_odds\n",
    "        self.p = p\n",
    "        self.residual = self.Y - p\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.count_label = pd.value_counts(Y).reset_index().values\n",
    "        \n",
    "        self.best = (np.inf,None)\n",
    "        self.nodes = [Node(True,index=i) for i in range(self.feature_space)]\n",
    "    \n",
    "    def loss(self,vals,bins,beta):\n",
    "        fitness = []\n",
    "        \n",
    "        for val in vals:\n",
    "            val_max = np.max(val)\n",
    "            val_min = np.min(val)\n",
    "            width = ((val_max - val_min)/bins)\n",
    "\n",
    "            index = ((val - val_min)//width).astype('int32') if width != 0 else np.zeros(val.shape[0])\n",
    "            index = np.where(index >= bins,bins-1,index)\n",
    "            index = np.where(index < 0,0,index)\n",
    "\n",
    "            p_bin = [sum(self.p[index==i]*(1-self.p[index==i]))  for i in range(bins)]\n",
    "            residual_bin = [sum(self.residual[index==i])  for i in range(bins)]\n",
    "\n",
    "            grad_bin = [residual_bin[i]/p_bin[i] if p_bin[i] > 0 else 0 for i in range(bins)]\n",
    "\n",
    "            grads = np.zeros(index.shape[0])\n",
    "            for i in range(bins):\n",
    "                grads[index==i] = grad_bin[i]\n",
    "\n",
    "            log_odds_1 = self.log_odds + self.learning_rate * grads\n",
    "            p_1 = np.exp(log_odds_1)\n",
    "            p_1 = p_1/(1+p_1)\n",
    "\n",
    "            fitness.append(sum((self.Y-p_1)**2))\n",
    "\n",
    "        return fitness\n",
    "    \n",
    "    def dloss(self,vals):\n",
    "        return [0 for i in range(len(vals))]\n",
    "    \n",
    "    def evolve(self,total_size,batch_size,elite_size,bins,beta,verbose):\n",
    "        self.generation += 1\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"\\tgeneration:\",self.generation)\n",
    "            t = time()\n",
    "        \n",
    "        num_batches = total_size//batch_size\n",
    "        pool = self.nodes\n",
    "\n",
    "        elites_funcs = []\n",
    "        elite_sons = []\n",
    "        elite_vals = []\n",
    "\n",
    "        elites_fitness = []\n",
    "        for j in range(num_batches):\n",
    "\n",
    "            funcs = np.random.choice(list(self.opset.keys()),size=batch_size)\n",
    "            arg_count = [self.opset[func] for func in funcs]\n",
    "            sons = np.random.choice(pool,size = sum(arg_count))\n",
    "            it = iter(sons)\n",
    "            sons = [[next(it) for _ in range(arg_count[i])] for i in range(batch_size)]\n",
    "            vals = [funcs[i]([self.vals[s.index] for s in sons[i]]) for i in range(batch_size)]\n",
    "\n",
    "            vals = np.stack(vals)\n",
    "            # fitness = self.loss(vals,bins,beta)\n",
    "            fitness = self.dloss(vals)\n",
    "            \n",
    "            elites_funcs.extend(funcs)\n",
    "            elite_sons.extend(sons)\n",
    "            elite_vals.extend(vals)\n",
    "            elites_fitness.extend(fitness)\n",
    "\n",
    "            rank = np.argsort(elites_fitness)\n",
    "\n",
    "            elites_funcs = [elites_funcs[index] for index in rank[:elite_size]]\n",
    "            elite_sons = [elite_sons[index] for index in rank[:elite_size]]\n",
    "            elite_vals = [elite_vals[index] for index in rank[:elite_size]]\n",
    "            elites_fitness = [elites_fitness[index] for index in rank[:elite_size]]\n",
    "\n",
    "        for index in range(elite_size):\n",
    "            node = Node(False,\n",
    "                func=elites_funcs[index],\n",
    "                sons=elite_sons[index],\n",
    "                index=len(self.nodes),\n",
    "                fit=elites_fitness[index] \n",
    "            )\n",
    "            \n",
    "            self.nodes.append(node)\n",
    "            self.vals = np.append(self.vals,[elite_vals[index]],axis=0)\n",
    "            \n",
    "            if index == 0:\n",
    "                if self.best[0] > node.fitness:\n",
    "                    val = elite_vals[index]\n",
    "                    val_max = np.max(val)\n",
    "                    val_min = np.min(val)\n",
    "                    width = ((val_max - val_min)/bins)\n",
    "                                      \n",
    "                    self.best = (node.fitness,node,(val_max,val_min,width,bins))\n",
    "            # self.test_param_same(node)\n",
    "      \n",
    "\n",
    "        if verbose:\n",
    "            print(\"\\t\",np.min(elites_fitness))\n",
    "            print(\"\\ttime\",time()-t)\n",
    "        return None\n",
    "\n",
    "    def test_param_same(self,node):\n",
    "        v1 = node.predict(self.X)\n",
    "        v2 = self.vals[node.index]\n",
    "        if np.any(v1!=v2):\n",
    "            print(node.index,v1==v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "008aa155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref from 2segp github\n",
    "# Classification dataset names - choose from following datasets \n",
    "\n",
    "CLASS_DATASET_NAMES = ['bcw','heart','iono','parks','sonar']\n",
    "dataset_name = CLASS_DATASET_NAMES[1]\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "Xy = np.genfromtxt('test_data/'+dataset_name+'.csv', delimiter=',')\n",
    "X = Xy[:, :-1]\n",
    "y = Xy[:, -1]   # last column is the label\n",
    "\n",
    "# simple operators\n",
    "\n",
    "boost_num = 1000\n",
    "\n",
    "seed = np.random.randint(9999999)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=seed)\n",
    "\n",
    "init_log_odds = sum(y==1)/y_train.shape[0]    \n",
    "init_p = np.exp(init_log_odds)\n",
    "init_p = init_p/(1+init_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a98e0d7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/sleep.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39m../data/sleep.tsv\u001b[39;49m\u001b[39m'\u001b[39;49m,delimiter\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m\\t\u001b[39;49;00m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      2\u001b[0m X \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39miloc[:,:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mto_numpy()\n\u001b[0;32m      3\u001b[0m y \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39miloc[:,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mto_numpy()\n",
      "File \u001b[1;32mc:\\Users\\zhouz\\anaconda3\\envs\\BStackGP\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\zhouz\\anaconda3\\envs\\BStackGP\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\zhouz\\anaconda3\\envs\\BStackGP\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\zhouz\\anaconda3\\envs\\BStackGP\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\zhouz\\anaconda3\\envs\\BStackGP\\Lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/sleep.tsv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/sleep.tsv',delimiter='\\t')\n",
    "X = df.iloc[:,:-1].to_numpy()\n",
    "y = df.iloc[:,-1].to_numpy()\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5385e778",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "num_feature = 1500\n",
    "\n",
    "eg = Engine(Functions.simple_opset,X_train,y_train,init_log_odds,init_p,0)\n",
    "for i in range(3):\n",
    "    eg.evolve(500,500,500,2,[0,0,0],0)\n",
    "nodes = eg.nodes[60:60+num_feature]\n",
    "# nodes = eg.nodes[0:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6431c184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       111\n",
      "         1.0       1.00      1.00      1.00        78\n",
      "\n",
      "    accuracy                           1.00       189\n",
      "   macro avg       1.00      1.00      1.00       189\n",
      "weighted avg       1.00      1.00      1.00       189\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.72      0.67        39\n",
      "         1.0       0.69      0.60      0.64        42\n",
      "\n",
      "    accuracy                           0.65        81\n",
      "   macro avg       0.66      0.66      0.65        81\n",
      "weighted avg       0.66      0.65      0.65        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_estimator = 1\n",
    "max_depth = 100\n",
    "ratio = 1\n",
    "\n",
    "vals = np.stack([n.predict(X_train) for n in nodes]).T\n",
    "clfs = [DecisionTreeClassifier(max_depth=max_depth) for i in range(num_estimator)]\n",
    "all_index = [i for i in range(len(nodes))]\n",
    "indexes = [np.random.choice(all_index,size=int(len(all_index)*ratio),replace=False) for i in range(num_estimator)]\n",
    "\n",
    "for i in range(num_estimator):\n",
    "    feature_index = indexes[i]\n",
    "    feature_batch = vals[:,feature_index]\n",
    "    clfs[i].fit(feature_batch,y_train)\n",
    "\n",
    "vals = np.stack([n.predict(X_train) for n in nodes]).T\n",
    "\n",
    "feature_index = indexes[0]\n",
    "feature_batch = vals[:,feature_index]\n",
    "prob = clfs[0].predict_proba(feature_batch)\n",
    "\n",
    "for i in range(1,num_estimator):\n",
    "    feature_index = indexes[i]\n",
    "    feature_batch = vals[:,feature_index]\n",
    "    p = clfs[i].predict_proba(feature_batch)\n",
    "    prob += p\n",
    "    \n",
    "pred = np.argmax(prob,axis=1)\n",
    "print(classification_report(y_train,pred))\n",
    "\n",
    "\n",
    "vals = np.stack([n.predict(X_test) for n in nodes]).T\n",
    "\n",
    "feature_index = indexes[0]\n",
    "feature_batch = vals[:,feature_index]\n",
    "prob = clfs[0].predict_proba(feature_batch)\n",
    "\n",
    "for i in range(1,num_estimator):\n",
    "    feature_index = indexes[i]\n",
    "    feature_batch = vals[:,feature_index]\n",
    "    p = clfs[i].predict_proba(feature_batch)\n",
    "    prob += p\n",
    "    \n",
    "pred = np.argmax(prob,axis=1)\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3826738d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       108\n",
      "         1.0       1.00      1.00      1.00        81\n",
      "\n",
      "    accuracy                           1.00       189\n",
      "   macro avg       1.00      1.00      1.00       189\n",
      "weighted avg       1.00      1.00      1.00       189\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.90      0.84        42\n",
      "         1.0       0.88      0.74      0.81        39\n",
      "\n",
      "    accuracy                           0.83        81\n",
      "   macro avg       0.84      0.82      0.82        81\n",
      "weighted avg       0.83      0.83      0.83        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "num_feature = 1000\n",
    "num_estimator = 100\n",
    "max_depth = 40\n",
    "ratio = 0.1\n",
    "\n",
    "eg = Engine(Functions.simple_opset,X_train,y_train,0,0,0)\n",
    "for i in range(3):\n",
    "    eg.evolve(1000,1000,1000,2,[0,0,0],0)\n",
    "nodes = eg.nodes[60:60+num_feature]\n",
    "# nodes = eg.nodes[0:60]\n",
    "vals = np.stack([n.predict(X_train) for n in nodes]).T\n",
    "\n",
    "clfs = [DecisionTreeClassifier(max_depth=max_depth) for i in range(num_estimator)]\n",
    "all_index = [i for i in range(len(nodes))]\n",
    "indexes = [np.random.choice(all_index,size=int(len(all_index)*ratio),replace=False) for i in range(num_estimator)]\n",
    "\n",
    "for i in range(num_estimator):\n",
    "    feature_index = indexes[i]\n",
    "    feature_batch = vals[:,feature_index]\n",
    "    clfs[i].fit(feature_batch,y_train)\n",
    "    \n",
    "vals = np.stack([n.predict(X_train) for n in nodes]).T\n",
    "\n",
    "feature_index = indexes[0]\n",
    "feature_batch = vals[:,feature_index]\n",
    "prob = clfs[0].predict_proba(feature_batch)\n",
    "\n",
    "for i in range(1,num_estimator):\n",
    "    feature_index = indexes[i]\n",
    "    feature_batch = vals[:,feature_index]\n",
    "    p = clfs[i].predict_proba(feature_batch)\n",
    "    prob += p\n",
    "    \n",
    "pred = np.argmax(prob,axis=1)\n",
    "print(classification_report(y_train,pred))\n",
    "\n",
    "\n",
    "vals = np.stack([n.predict(X_test) for n in nodes]).T\n",
    "\n",
    "feature_index = indexes[0]\n",
    "feature_batch = vals[:,feature_index]\n",
    "prob = clfs[0].predict_proba(feature_batch)\n",
    "\n",
    "for i in range(1,num_estimator):\n",
    "    feature_index = indexes[i]\n",
    "    feature_batch = vals[:,feature_index]\n",
    "    p = clfs[i].predict_proba(feature_batch)\n",
    "    prob += p\n",
    "    \n",
    "pred = np.argmax(prob,axis=1)\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cece6967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99       108\n",
      "         1.0       0.99      0.99      0.99        81\n",
      "\n",
      "    accuracy                           0.99       189\n",
      "   macro avg       0.99      0.99      0.99       189\n",
      "weighted avg       0.99      0.99      0.99       189\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.90      0.84        42\n",
      "         1.0       0.88      0.74      0.81        39\n",
      "\n",
      "    accuracy                           0.83        81\n",
      "   macro avg       0.84      0.82      0.82        81\n",
      "weighted avg       0.83      0.83      0.83        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "num_feature = 3000\n",
    "num_estimator = 1000\n",
    "max_depth = 5\n",
    "ratio = 0.05\n",
    "\n",
    "eg = Engine(Functions.simple_opset,X_train,y_train,0,0,0)\n",
    "for i in range(3):\n",
    "    eg.evolve(1000,1000,1000,2,[0,0,0],0)\n",
    "nodes = eg.nodes[60:60+num_feature]\n",
    "vals = np.stack([n.predict(X_train) for n in nodes]).T\n",
    "\n",
    "clfs = [DecisionTreeClassifier(max_depth=max_depth) for i in range(num_estimator)]\n",
    "all_index = [i for i in range(len(nodes))]\n",
    "indexes = [np.random.choice(all_index,size=int(len(all_index)*ratio),replace=False) for i in range(num_estimator)]\n",
    "\n",
    "for i in range(num_estimator):\n",
    "    feature_index = indexes[i]\n",
    "    feature_batch = vals[:,feature_index]\n",
    "    clfs[i].fit(feature_batch,y_train)\n",
    "    \n",
    "vals = np.stack([n.predict(X_train) for n in nodes]).T\n",
    "\n",
    "feature_index = indexes[0]\n",
    "feature_batch = vals[:,feature_index]\n",
    "prob = clfs[0].predict_proba(feature_batch)\n",
    "\n",
    "for i in range(1,num_estimator):\n",
    "    feature_index = indexes[i]\n",
    "    feature_batch = vals[:,feature_index]\n",
    "    p = clfs[i].predict_proba(feature_batch)\n",
    "    prob += p\n",
    "    \n",
    "pred = np.argmax(prob,axis=1)\n",
    "print(classification_report(y_train,pred))\n",
    "\n",
    "\n",
    "vals = np.stack([n.predict(X_test) for n in nodes]).T\n",
    "\n",
    "feature_index = indexes[0]\n",
    "feature_batch = vals[:,feature_index]\n",
    "prob = clfs[0].predict_proba(feature_batch)\n",
    "\n",
    "for i in range(1,num_estimator):\n",
    "    feature_index = indexes[i]\n",
    "    feature_batch = vals[:,feature_index]\n",
    "    p = clfs[i].predict_proba(feature_batch)\n",
    "    prob += p\n",
    "    \n",
    "pred = np.argmax(prob,axis=1)\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd54d9f7",
   "metadata": {},
   "source": [
    "# Small datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6c3592e-5e72-41b0-bc7a-0bff336efeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref from 2segp github\n",
    "# Classification dataset names - choose from following datasets \n",
    "\n",
    "CLASS_DATASET_NAMES = ['bcw','heart','iono','parks','sonar']\n",
    "dataset_name = CLASS_DATASET_NAMES[1]\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "Xy = np.genfromtxt('test_data/'+dataset_name+'.csv', delimiter=',')\n",
    "X = Xy[:, :-1]\n",
    "y = Xy[:, -1]   # last column is the label\n",
    "\n",
    "# simple operators\n",
    "\n",
    "boost_num = 1000\n",
    "\n",
    "seed = np.random.randint(9999999)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171da7fb",
   "metadata": {},
   "source": [
    "# Higgs Boson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f813da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.utils import shuffle\n",
    "def plot_roc_curve(true_y, y_prob):\n",
    "    \"\"\"\n",
    "    plots the roc curve based of the probabilities\n",
    "    \"\"\"\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(true_y, y_prob)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    print(roc_auc_score(true_y,prob[:,1]))\n",
    "\n",
    "df = pd.read_csv('../data/HIGGS.csv',header=None)\n",
    "X = df.iloc[:,1:].to_numpy()\n",
    "y = df.iloc[:,0].to_numpy().astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0192e15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=500000)\n",
    "Xs,ys = shuffle(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25782751",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = Xs[:1050000]\n",
    "y_train = ys[:1050000]\n",
    "\n",
    "X_test = Xs[1050000:1210000]\n",
    "y_test = ys[1050000:1210000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8447e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train start\n",
      "Loss: 271919.0944547627\n",
      "train complete\n",
      "train auc: 0.5258654810848914 test auc 0.5246813939060924\n",
      "train start\n",
      "Loss: 260271.01078482388\n",
      "train complete\n",
      "train start\n",
      "Loss: 250622.0223460063\n",
      "train complete\n",
      "train start\n",
      "Loss: 249377.3030609782\n",
      "train complete\n",
      "train start\n",
      "Loss: 247674.13267773198\n",
      "train complete\n",
      "train start\n",
      "Loss: 246092.75683943022\n",
      "train complete\n",
      "train start\n",
      "Loss: 244864.77042022234\n",
      "train complete\n",
      "train start\n",
      "Loss: 244109.4138296209\n",
      "train complete\n",
      "train start\n",
      "Loss: 243205.71141343552\n",
      "train complete\n",
      "train start\n",
      "Loss: 242986.57455942972\n",
      "train complete\n",
      "train start\n",
      "Loss: 240457.04838524185\n",
      "train complete\n",
      "train auc: 0.6132988188301514 test auc 0.6120390153127323\n",
      "train start\n",
      "Loss: 239727.16239474286\n",
      "train complete\n",
      "train start\n",
      "Loss: 239158.3263821821\n",
      "train complete\n",
      "train start\n",
      "Loss: 238698.26702003824\n",
      "train complete\n",
      "train start\n",
      "Loss: 234226.41463685918\n",
      "train complete\n",
      "train start\n",
      "Loss: 233400.83277542077\n",
      "train complete\n",
      "train start\n",
      "Loss: 232759.91196994\n",
      "train complete\n",
      "train start\n",
      "Loss: 232479.51549038087\n",
      "train complete\n",
      "train start\n",
      "Loss: 232176.73679356545\n",
      "train complete\n",
      "train start\n",
      "Loss: 231638.6623393377\n",
      "train complete\n",
      "train start\n",
      "Loss: 231429.61727686087\n",
      "train complete\n",
      "train auc: 0.6436750800551445 test auc 0.6439444245431653\n",
      "train start\n",
      "Loss: 231034.80349014094\n",
      "train complete\n",
      "train start\n",
      "Loss: 230733.55105282084\n",
      "train complete\n",
      "train start\n",
      "Loss: 230461.72353156775\n",
      "train complete\n",
      "train start\n",
      "Loss: 230326.97380175695\n",
      "train complete\n",
      "train start\n",
      "Loss: 229803.44036067175\n",
      "train complete\n",
      "train start\n",
      "Loss: 229524.68233934636\n",
      "train complete\n",
      "train start\n",
      "Loss: 229238.437560293\n",
      "train complete\n",
      "train start\n",
      "Loss: 229111.30922442552\n",
      "train complete\n",
      "train start\n",
      "Loss: 228929.80092297817\n",
      "train complete\n",
      "train start\n",
      "Loss: 228719.22775046417\n",
      "train complete\n",
      "train auc: 0.6493980630859355 test auc 0.6495549522843039\n",
      "train start\n",
      "Loss: 228596.51022322164\n",
      "train complete\n",
      "train start\n",
      "Loss: 228408.01658976154\n",
      "train complete\n",
      "train start\n",
      "Loss: 228231.97351817542\n",
      "train complete\n",
      "train start\n",
      "Loss: 227935.82066636786\n",
      "train complete\n",
      "train start\n",
      "Loss: 227784.91547469553\n",
      "train complete\n",
      "train start\n",
      "Loss: 227658.04638886722\n",
      "train complete\n",
      "train start\n",
      "Loss: 227483.67378717038\n",
      "train complete\n",
      "train start\n",
      "Loss: 227301.84126888396\n",
      "train complete\n",
      "train start\n",
      "Loss: 227073.20590920912\n",
      "train complete\n",
      "train start\n",
      "Loss: 226943.4988927691\n",
      "train complete\n",
      "train auc: 0.6538173147351156 test auc 0.6532618358701032\n",
      "train start\n",
      "Loss: 226859.29061143275\n",
      "train complete\n",
      "train start\n",
      "Loss: 226767.51544913504\n",
      "train complete\n",
      "train start\n",
      "Loss: 226638.52588119314\n",
      "train complete\n",
      "train start\n",
      "Loss: 226550.19006891077\n",
      "train complete\n",
      "train start\n",
      "Loss: 226481.33427038472\n",
      "train complete\n",
      "train start\n",
      "Loss: 226378.5476505845\n",
      "train complete\n",
      "train start\n",
      "Loss: 226062.80271739015\n",
      "train complete\n",
      "train start\n",
      "Loss: 225958.80797115105\n",
      "train complete\n",
      "train start\n",
      "Loss: 225704.9438110638\n",
      "train complete\n",
      "train start\n",
      "Loss: 225572.01997949867\n",
      "train complete\n",
      "train auc: 0.6565614302154482 test auc 0.656305261737169\n",
      "train start\n",
      "Loss: 225264.74751350883\n",
      "train complete\n",
      "train start\n",
      "Loss: 225161.9073731425\n",
      "train complete\n",
      "train start\n",
      "Loss: 225080.52964378594\n",
      "train complete\n",
      "train start\n",
      "Loss: 224983.11179495344\n",
      "train complete\n",
      "train start\n",
      "Loss: 224828.83849666157\n",
      "train complete\n",
      "train start\n",
      "Loss: 224767.54486636913\n",
      "train complete\n",
      "train start\n",
      "Loss: 224713.78025881233\n",
      "train complete\n",
      "train start\n",
      "Loss: 224662.0801156653\n",
      "train complete\n",
      "train start\n",
      "Loss: 224583.19755028863\n",
      "train complete\n",
      "train start\n",
      "Loss: 224516.55177448565\n",
      "train complete\n",
      "train auc: 0.6582152004133821 test auc 0.6579249565743212\n",
      "train start\n",
      "Loss: 224421.2575528745\n",
      "train complete\n",
      "train start\n",
      "Loss: 224347.92526861152\n",
      "train complete\n",
      "train start\n",
      "Loss: 224240.41360623014\n",
      "train complete\n",
      "train start\n",
      "Loss: 223735.96525329616\n",
      "train complete\n",
      "train start\n",
      "Loss: 223666.8767613675\n",
      "train complete\n",
      "train start\n",
      "Loss: 223518.1157391032\n",
      "train complete\n",
      "train start\n",
      "Loss: 223470.37311898114\n",
      "train complete\n",
      "train start\n",
      "Loss: 223320.55705766645\n",
      "train complete\n",
      "train start\n",
      "Loss: 223272.70109175885\n",
      "train complete\n",
      "train start\n",
      "Loss: 223207.60556883216\n",
      "train complete\n",
      "train auc: 0.6613213626863199 test auc 0.660116813711289\n",
      "train start\n",
      "Loss: 223127.43246535928\n",
      "train complete\n",
      "train start\n",
      "Loss: 223003.04031848258\n",
      "train complete\n",
      "train start\n",
      "Loss: 222886.88492059486\n",
      "train complete\n",
      "train start\n",
      "Loss: 222788.47295609236\n",
      "train complete\n",
      "train start\n",
      "Loss: 222749.11670402644\n",
      "train complete\n",
      "train start\n",
      "Loss: 222554.82116534695\n",
      "train complete\n",
      "train start\n",
      "Loss: 222463.7667393563\n",
      "train complete\n",
      "train start\n",
      "Loss: 222356.86162142592\n",
      "train complete\n",
      "train start\n",
      "Loss: 222270.51854732115\n",
      "train complete\n",
      "train start\n",
      "Loss: 222154.20343048905\n",
      "train complete\n",
      "train auc: 0.6635383899160323 test auc 0.6622464775206425\n",
      "train start\n",
      "Loss: 222054.79733995674\n",
      "train complete\n",
      "train start\n",
      "Loss: 221937.46118966097\n",
      "train complete\n",
      "train start\n",
      "Loss: 221845.29211969624\n",
      "train complete\n",
      "train start\n",
      "Loss: 221254.05698572454\n",
      "train complete\n",
      "train start\n",
      "Loss: 221209.05917963837\n",
      "train complete\n",
      "train start\n",
      "Loss: 221159.17977658898\n",
      "train complete\n",
      "train start\n",
      "Loss: 221061.9268581068\n",
      "train complete\n",
      "train start\n",
      "Loss: 221018.834567811\n",
      "train complete\n",
      "train start\n",
      "Loss: 220969.8297788874\n",
      "train complete\n",
      "train start\n",
      "Loss: 220884.0713337778\n",
      "train complete\n",
      "train auc: 0.666353789575044 test auc 0.6663355080213031\n",
      "train start\n",
      "Loss: 220827.4379566712\n",
      "train complete\n",
      "train start\n",
      "Loss: 220754.22275922316\n",
      "train complete\n",
      "train start\n",
      "Loss: 220690.77060901118\n",
      "train complete\n",
      "train start\n",
      "Loss: 220637.72363095108\n",
      "train complete\n",
      "train start\n",
      "Loss: 220588.25767402822\n",
      "train complete\n",
      "train start\n",
      "Loss: 220525.54985688257\n",
      "train complete\n",
      "train start\n",
      "Loss: 220472.94557412894\n",
      "train complete\n",
      "train start\n",
      "Loss: 220333.00858530888\n",
      "train complete\n",
      "train start\n",
      "Loss: 220181.8943477724\n",
      "train complete\n",
      "train start\n",
      "Loss: 220044.13286650932\n",
      "train complete\n",
      "train auc: 0.668103252695043 test auc 0.6680409702604613\n",
      "train start\n",
      "Loss: 219876.78168468154\n",
      "train complete\n",
      "train start\n",
      "Loss: 219684.62435149553\n",
      "train complete\n",
      "train start\n",
      "Loss: 219644.3045598593\n",
      "train complete\n",
      "train start\n",
      "Loss: 219453.713231895\n",
      "train complete\n",
      "train start\n",
      "Loss: 219350.12899782904\n",
      "train complete\n",
      "train start\n",
      "Loss: 219211.20477050781\n",
      "train complete\n",
      "train start\n",
      "Loss: 219167.68878939375\n",
      "train complete\n",
      "train start\n",
      "Loss: 219105.52232624585\n",
      "train complete\n",
      "train start\n",
      "Loss: 218956.73711775593\n",
      "train complete\n",
      "train start\n",
      "Loss: 218805.93131845686\n",
      "train complete\n",
      "train auc: 0.6701625265444092 test auc 0.6692936653255734\n",
      "train start\n",
      "Loss: 218755.8025332866\n",
      "train complete\n",
      "train start\n",
      "Loss: 218723.4827247627\n",
      "train complete\n",
      "train start\n",
      "Loss: 218674.00485780454\n",
      "train complete\n",
      "train start\n",
      "Loss: 218627.76066679222\n",
      "train complete\n",
      "train start\n",
      "Loss: 218576.44373180595\n",
      "train complete\n",
      "train start\n",
      "Loss: 218554.0922243508\n",
      "train complete\n",
      "train start\n",
      "Loss: 218305.20598271047\n",
      "train complete\n",
      "train start\n",
      "Loss: 218143.06285583915\n",
      "train complete\n",
      "train start\n",
      "Loss: 218108.53713174467\n",
      "train complete\n",
      "train start\n",
      "Loss: 218068.76589592034\n",
      "train complete\n",
      "train auc: 0.6712143528187084 test auc 0.6705694497439576\n",
      "train start\n",
      "Loss: 218032.23357486242\n",
      "train complete\n",
      "train start\n",
      "Loss: 217962.6258240766\n",
      "train complete\n",
      "train start\n",
      "Loss: 217929.48784676535\n",
      "train complete\n",
      "train start\n",
      "Loss: 217863.40893452038\n",
      "train complete\n",
      "train start\n",
      "Loss: 217803.46283107158\n",
      "train complete\n",
      "train start\n",
      "Loss: 217749.19783123903\n",
      "train complete\n",
      "train start\n",
      "Loss: 217554.97945640897\n",
      "train complete\n",
      "train start\n",
      "Loss: 217502.70200028157\n",
      "train complete\n",
      "train start\n",
      "Loss: 217449.03337794682\n",
      "train complete\n",
      "train start\n",
      "Loss: 217306.93208713093\n",
      "train complete\n",
      "train auc: 0.6733713747050745 test auc 0.6728249763333738\n",
      "train start\n",
      "Loss: 217245.2072041841\n",
      "train complete\n",
      "train start\n",
      "Loss: 217200.22168803835\n",
      "train complete\n",
      "train start\n",
      "Loss: 217139.7142151391\n",
      "train complete\n",
      "train start\n",
      "Loss: 217080.32873329255\n",
      "train complete\n",
      "train start\n",
      "Loss: 217034.44278167366\n",
      "train complete\n",
      "train start\n",
      "Loss: 216984.2843777924\n",
      "train complete\n",
      "train start\n",
      "Loss: 216920.68569015607\n",
      "train complete\n",
      "train start\n",
      "Loss: 216878.62317215605\n",
      "train complete\n",
      "train start\n",
      "Loss: 216790.30905352827\n",
      "train complete\n",
      "train start\n",
      "Loss: 216720.05671222415\n",
      "train complete\n",
      "train auc: 0.6746181955322843 test auc 0.6733139846466702\n",
      "train start\n",
      "Loss: 216687.49935503118\n",
      "train complete\n",
      "train start\n",
      "Loss: 216645.20118172915\n",
      "train complete\n",
      "train start\n",
      "Loss: 216574.83577194397\n",
      "train complete\n",
      "train start\n",
      "Loss: 216534.90166191183\n",
      "train complete\n",
      "train start\n",
      "Loss: 216490.94945578594\n",
      "train complete\n",
      "train start\n",
      "Loss: 216412.4149162302\n",
      "train complete\n",
      "train start\n",
      "Loss: 216380.08441832382\n",
      "train complete\n",
      "train start\n",
      "Loss: 216314.53634791757\n",
      "train complete\n",
      "train start\n",
      "Loss: 216296.53792484794\n",
      "train complete\n",
      "train start\n",
      "Loss: 216240.12559159804\n",
      "train complete\n",
      "train auc: 0.6752672766485888 test auc 0.6740689934786342\n",
      "train start\n",
      "Loss: 216195.68949935192\n",
      "train complete\n",
      "train start\n",
      "Loss: 216100.48479636756\n",
      "train complete\n",
      "train start\n",
      "Loss: 216050.74265334944\n",
      "train complete\n",
      "train start\n",
      "Loss: 216014.93645357018\n",
      "train complete\n",
      "train start\n",
      "Loss: 215941.42284601228\n",
      "train complete\n",
      "train start\n",
      "Loss: 215629.91982670582\n",
      "train complete\n",
      "train start\n",
      "Loss: 215599.20938170375\n",
      "train complete\n",
      "train start\n",
      "Loss: 215558.17662698549\n",
      "train complete\n",
      "train start\n",
      "Loss: 215538.67215759764\n",
      "train complete\n",
      "train start\n",
      "Loss: 215511.70290674566\n",
      "train complete\n",
      "train auc: 0.6766407141634677 test auc 0.6750838034186988\n",
      "train start\n",
      "Loss: 215486.7053626417\n",
      "train complete\n",
      "train start\n",
      "Loss: 215440.95120800228\n",
      "train complete\n",
      "train start\n",
      "Loss: 215397.23168967513\n",
      "train complete\n",
      "train start\n",
      "Loss: 215368.54637950312\n",
      "train complete\n",
      "train start\n",
      "Loss: 215305.36649952925\n",
      "train complete\n",
      "train start\n",
      "Loss: 215273.97830756736\n",
      "train complete\n",
      "train start\n",
      "Loss: 215226.8393098097\n",
      "train complete\n",
      "train start\n",
      "Loss: 215185.91778494156\n",
      "train complete\n",
      "train start\n",
      "Loss: 215148.5316469187\n",
      "train complete\n",
      "train start\n",
      "Loss: 215120.31165083498\n",
      "train complete\n",
      "train auc: 0.6773970382984317 test auc 0.6761953897342905\n",
      "train start\n",
      "Loss: 215086.26064992134\n",
      "train complete\n",
      "train start\n",
      "Loss: 215022.74891771027\n",
      "train complete\n",
      "train start\n",
      "Loss: 215003.31444232038\n",
      "train complete\n",
      "train start\n",
      "Loss: 214963.2084401835\n",
      "train complete\n",
      "train start\n",
      "Loss: 214951.08314477422\n",
      "train complete\n",
      "train start\n",
      "Loss: 214920.5515415534\n",
      "train complete\n",
      "train start\n",
      "Loss: 214886.56280081897\n",
      "train complete\n",
      "train start\n",
      "Loss: 214778.6034450383\n",
      "train complete\n",
      "train start\n",
      "Loss: 214744.4440735656\n",
      "train complete\n",
      "train start\n",
      "Loss: 214688.85858868924\n",
      "train complete\n",
      "train auc: 0.6779983184430831 test auc 0.6771798238175204\n",
      "train start\n",
      "Loss: 214620.00948374945\n",
      "train complete\n",
      "train start\n",
      "Loss: 214548.63806354153\n",
      "train complete\n",
      "train start\n",
      "Loss: 214514.38348584974\n",
      "train complete\n",
      "train start\n",
      "Loss: 214450.05589226895\n",
      "train complete\n",
      "train start\n",
      "Loss: 214404.11185084353\n",
      "train complete\n",
      "train start\n",
      "Loss: 214371.28629347362\n",
      "train complete\n",
      "train start\n",
      "Loss: 214350.63445359145\n",
      "train complete\n",
      "train start\n",
      "Loss: 214234.4312222981\n",
      "train complete\n",
      "train start\n",
      "Loss: 214200.92645576998\n",
      "train complete\n",
      "train start\n",
      "Loss: 214174.41314006623\n",
      "train complete\n",
      "train auc: 0.6790438206285722 test auc 0.6778245515357063\n",
      "train start\n",
      "Loss: 214157.55524902415\n",
      "train complete\n",
      "train start\n",
      "Loss: 214117.30707522065\n",
      "train complete\n",
      "train start\n",
      "Loss: 214074.64611851607\n",
      "train complete\n",
      "train start\n",
      "Loss: 214046.48808878855\n",
      "train complete\n",
      "train start\n",
      "Loss: 213996.00668979425\n",
      "train complete\n",
      "train start\n",
      "Loss: 213952.8181209992\n",
      "train complete\n",
      "train start\n",
      "Loss: 213936.49714794868\n",
      "train complete\n",
      "train start\n",
      "Loss: 213913.08897563006\n",
      "train complete\n",
      "train start\n",
      "Loss: 213856.93292794412\n",
      "train complete\n",
      "train start\n",
      "Loss: 213620.1014329087\n",
      "train complete\n",
      "train auc: 0.6801295273961986 test auc 0.679246204068909\n",
      "train start\n",
      "Loss: 213602.22108235562\n",
      "train complete\n",
      "train start\n",
      "Loss: 213554.13754339895\n",
      "train complete\n",
      "train start\n",
      "Loss: 213533.76598756897\n",
      "train complete\n",
      "train start\n",
      "Loss: 213465.15110806056\n",
      "train complete\n",
      "train start\n",
      "Loss: 213435.63044708222\n",
      "train complete\n",
      "train start\n",
      "Loss: 213385.165483009\n",
      "train complete\n",
      "train start\n",
      "Loss: 213358.59854402998\n",
      "train complete\n",
      "train start\n",
      "Loss: 213327.27958808414\n",
      "train complete\n",
      "train start\n",
      "Loss: 213311.78806216916\n",
      "train complete\n",
      "train start\n",
      "Loss: 213237.4408871351\n",
      "train complete\n",
      "train auc: 0.6814559134172302 test auc 0.6801229704538477\n",
      "train start\n",
      "Loss: 213128.125225967\n",
      "train complete\n",
      "train start\n",
      "Loss: 213097.93650503267\n",
      "train complete\n",
      "train start\n",
      "Loss: 213063.787684399\n",
      "train complete\n",
      "train start\n",
      "Loss: 213020.95464037257\n",
      "train complete\n",
      "train start\n",
      "Loss: 212987.44162562938\n",
      "train complete\n",
      "train start\n",
      "Loss: 212964.12486431983\n",
      "train complete\n",
      "train start\n",
      "Loss: 212934.69857581524\n",
      "train complete\n",
      "train start\n",
      "Loss: 212905.00370153858\n",
      "train complete\n",
      "train start\n",
      "Loss: 212866.583828839\n",
      "train complete\n",
      "train start\n",
      "Loss: 212830.85134321032\n",
      "train complete\n",
      "train auc: 0.6821680827768668 test auc 0.680606617029969\n",
      "train start\n",
      "Loss: 212805.0215335328\n",
      "train complete\n",
      "train start\n",
      "Loss: 212776.82667431337\n",
      "train complete\n",
      "train start\n",
      "Loss: 212750.2156808696\n",
      "train complete\n",
      "train start\n",
      "Loss: 212726.26608224685\n",
      "train complete\n",
      "train start\n",
      "Loss: 212687.74365992678\n",
      "train complete\n",
      "train start\n",
      "Loss: 212658.46744494853\n",
      "train complete\n",
      "train start\n",
      "Loss: 212616.8248587203\n",
      "train complete\n",
      "train start\n",
      "Loss: 212594.7621072393\n",
      "train complete\n",
      "train start\n",
      "Loss: 212536.83592599756\n",
      "train complete\n",
      "train start\n",
      "Loss: 212469.0945472899\n",
      "train complete\n",
      "train auc: 0.6826158873088717 test auc 0.6820480066542014\n",
      "train start\n",
      "Loss: 212388.26271011273\n",
      "train complete\n",
      "train start\n",
      "Loss: 212360.1721423143\n",
      "train complete\n",
      "train start\n",
      "Loss: 212215.94964030726\n",
      "train complete\n",
      "train start\n",
      "Loss: 212173.73584184266\n",
      "train complete\n",
      "train start\n",
      "Loss: 212122.65971848552\n",
      "train complete\n",
      "train start\n",
      "Loss: 212063.1871501513\n",
      "train complete\n",
      "train start\n",
      "Loss: 212033.84943067678\n",
      "train complete\n",
      "train start\n",
      "Loss: 211977.64604903982\n",
      "train complete\n",
      "train start\n",
      "Loss: 211943.370812328\n",
      "train complete\n",
      "train start\n",
      "Loss: 211921.31458663344\n",
      "train complete\n",
      "train auc: 0.6833402715090398 test auc 0.6823997761435513\n",
      "train start\n",
      "Loss: 211891.92096088827\n",
      "train complete\n",
      "train start\n",
      "Loss: 211864.90104114258\n",
      "train complete\n",
      "train start\n",
      "Loss: 211827.50518974397\n",
      "train complete\n",
      "train start\n",
      "Loss: 211801.7867277157\n",
      "train complete\n",
      "train start\n",
      "Loss: 211776.05218664007\n",
      "train complete\n",
      "train start\n",
      "Loss: 211747.9285813969\n",
      "train complete\n",
      "train start\n",
      "Loss: 211723.760539776\n",
      "train complete\n",
      "train start\n",
      "Loss: 211679.45881608131\n",
      "train complete\n",
      "train start\n",
      "Loss: 211649.10999425038\n",
      "train complete\n",
      "train start\n",
      "Loss: 211626.18889759746\n",
      "train complete\n",
      "train auc: 0.6840135841631556 test auc 0.683068245784542\n",
      "train start\n",
      "Loss: 211610.72753814099\n",
      "train complete\n",
      "train start\n",
      "Loss: 211596.16462792084\n",
      "train complete\n",
      "train start\n",
      "Loss: 211560.33961581008\n",
      "train complete\n",
      "train start\n",
      "Loss: 211541.55029988775\n",
      "train complete\n",
      "train start\n",
      "Loss: 211477.1758407421\n",
      "train complete\n",
      "train start\n",
      "Loss: 211396.69629448256\n",
      "train complete\n",
      "train start\n",
      "Loss: 211346.15204606636\n",
      "train complete\n",
      "train start\n",
      "Loss: 211189.9331894192\n",
      "train complete\n",
      "train start\n",
      "Loss: 211158.7967922133\n",
      "train complete\n",
      "train start\n",
      "Loss: 211119.7357972676\n",
      "train complete\n",
      "train auc: 0.6850787003093606 test auc 0.6839835655382799\n",
      "train start\n",
      "Loss: 211092.71885287072\n",
      "train complete\n",
      "train start\n",
      "Loss: 211046.41001780567\n",
      "train complete\n",
      "train start\n",
      "Loss: 211030.93993636584\n",
      "train complete\n",
      "train start\n",
      "Loss: 210994.27753830602\n",
      "train complete\n",
      "train start\n",
      "Loss: 210979.24174674627\n",
      "train complete\n",
      "train start\n",
      "Loss: 210921.02566116006\n",
      "train complete\n",
      "train start\n",
      "Loss: 210886.07025044892\n",
      "train complete\n",
      "train start\n",
      "Loss: 210866.74845961784\n",
      "train complete\n",
      "train start\n",
      "Loss: 210806.78128422124\n",
      "train complete\n",
      "train start\n",
      "Loss: 210777.58420577587\n",
      "train complete\n",
      "train auc: 0.6858402956774915 test auc 0.6844823420017783\n",
      "train start\n",
      "Loss: 210749.03077059865\n",
      "train complete\n",
      "train start\n",
      "Loss: 210737.879787718\n",
      "train complete\n",
      "train start\n",
      "Loss: 210725.1466051344\n",
      "train complete\n",
      "train start\n",
      "Loss: 210712.445442041\n",
      "train complete\n",
      "train start\n",
      "Loss: 210684.56263222935\n",
      "train complete\n",
      "train start\n",
      "Loss: 210660.1362216054\n",
      "train complete\n",
      "train start\n",
      "Loss: 210633.12723856512\n",
      "train complete\n",
      "train start\n",
      "Loss: 210555.11612176054\n",
      "train complete\n",
      "train start\n",
      "Loss: 210531.672066638\n",
      "train complete\n",
      "train start\n",
      "Loss: 210489.78187736726\n",
      "train complete\n",
      "train auc: 0.68620554784639 test auc 0.6846477966146576\n",
      "train start\n",
      "Loss: 210430.74553121236\n",
      "train complete\n",
      "train start\n",
      "Loss: 210403.36472358322\n",
      "train complete\n",
      "train start\n",
      "Loss: 210380.07957054925\n",
      "train complete\n",
      "train start\n",
      "Loss: 210332.8206140509\n",
      "train complete\n",
      "train start\n",
      "Loss: 210315.63826979155\n",
      "train complete\n",
      "train start\n",
      "Loss: 210283.53934500235\n",
      "train complete\n",
      "train start\n",
      "Loss: 210231.17633083428\n",
      "train complete\n",
      "train start\n",
      "Loss: 210204.11711415113\n",
      "train complete\n",
      "train start\n",
      "Loss: 210190.27351971265\n",
      "train complete\n",
      "train start\n",
      "Loss: 210165.54573212084\n",
      "train complete\n",
      "train auc: 0.6870865464354777 test auc 0.6850633343830919\n",
      "train start\n",
      "Loss: 210137.85333187287\n",
      "train complete\n",
      "train start\n",
      "Loss: 210097.01429990222\n",
      "train complete\n",
      "train start\n",
      "Loss: 210077.31185622414\n",
      "train complete\n",
      "train start\n",
      "Loss: 210038.6846940539\n",
      "train complete\n",
      "train start\n",
      "Loss: 210010.56361510325\n",
      "train complete\n",
      "train start\n",
      "Loss: 209992.70913519623\n",
      "train complete\n",
      "train start\n",
      "Loss: 209974.6352949796\n",
      "train complete\n",
      "train start\n",
      "Loss: 209937.20433906416\n",
      "train complete\n",
      "train start\n",
      "Loss: 209921.3177871094\n",
      "train complete\n",
      "train start\n",
      "Loss: 209902.84649653887\n",
      "train complete\n",
      "train auc: 0.6873719000281152 test auc 0.6859587491973865\n",
      "train start\n",
      "Loss: 209891.6237029805\n",
      "train complete\n",
      "train start\n",
      "Loss: 209868.47197757926\n",
      "train complete\n",
      "train start\n",
      "Loss: 209842.0388575896\n",
      "train complete\n",
      "train start\n",
      "Loss: 209800.98943206444\n",
      "train complete\n",
      "train start\n",
      "Loss: 209766.56514541229\n",
      "train complete\n",
      "train start\n",
      "Loss: 209719.33141275813\n",
      "train complete\n",
      "train start\n",
      "Loss: 209697.44194983214\n",
      "train complete\n",
      "train start\n",
      "Loss: 209624.10981623753\n",
      "train complete\n",
      "train start\n",
      "Loss: 209598.37701947536\n",
      "train complete\n",
      "train start\n",
      "Loss: 209391.14979304955\n",
      "train complete\n",
      "train auc: 0.6887273207264919 test auc 0.6872866246650327\n",
      "train start\n",
      "Loss: 209314.45005935675\n",
      "train complete\n",
      "train start\n",
      "Loss: 209297.9405415081\n",
      "train complete\n",
      "train start\n",
      "Loss: 209250.51718684298\n",
      "train complete\n",
      "train start\n",
      "Loss: 209231.48656434388\n",
      "train complete\n",
      "train start\n",
      "Loss: 209212.70686762535\n",
      "train complete\n",
      "train start\n",
      "Loss: 209190.2460776818\n",
      "train complete\n",
      "train start\n",
      "Loss: 209173.53466981472\n",
      "train complete\n",
      "train start\n",
      "Loss: 209156.16894432102\n",
      "train complete\n",
      "train start\n",
      "Loss: 209133.5321036564\n",
      "train complete\n",
      "train start\n",
      "Loss: 209120.12818287377\n",
      "train complete\n",
      "train auc: 0.6894809947705653 test auc 0.6877930076421539\n",
      "train start\n",
      "Loss: 209085.55534415564\n",
      "train complete\n",
      "train start\n",
      "Loss: 209056.712420246\n",
      "train complete\n",
      "train start\n",
      "Loss: 209033.10096185617\n",
      "train complete\n",
      "train start\n",
      "Loss: 209018.06070700882\n",
      "train complete\n",
      "train start\n",
      "Loss: 208714.32531014644\n",
      "train complete\n",
      "train start\n",
      "Loss: 208687.893163762\n",
      "train complete\n",
      "train start\n",
      "Loss: 208656.49022670317\n",
      "train complete\n",
      "train start\n",
      "Loss: 208618.29780430248\n",
      "train complete\n",
      "train start\n",
      "Loss: 208597.12146378562\n",
      "train complete\n",
      "train start\n",
      "Loss: 208575.97373646067\n",
      "train complete\n",
      "train auc: 0.6904194369508995 test auc 0.6884289727319428\n",
      "train start\n",
      "Loss: 208565.6409013413\n",
      "train complete\n",
      "train start\n",
      "Loss: 208553.59740350925\n",
      "train complete\n",
      "train start\n",
      "Loss: 208531.31328503313\n",
      "train complete\n",
      "train start\n",
      "Loss: 208523.71262538177\n",
      "train complete\n",
      "train start\n",
      "Loss: 208512.7330692644\n",
      "train complete\n",
      "train start\n",
      "Loss: 208502.44294798307\n",
      "train complete\n",
      "train start\n",
      "Loss: 208481.15763982394\n",
      "train complete\n",
      "train start\n",
      "Loss: 208446.13421283857\n",
      "train complete\n",
      "train start\n",
      "Loss: 208427.85635769178\n",
      "train complete\n",
      "train start\n",
      "Loss: 208414.99248834717\n",
      "train complete\n",
      "train auc: 0.6906725440629418 test auc 0.6882337948317622\n",
      "train start\n",
      "Loss: 208403.05003737676\n",
      "train complete\n",
      "train start\n",
      "Loss: 208361.82041257533\n",
      "train complete\n",
      "train start\n",
      "Loss: 208347.02322283038\n",
      "train complete\n",
      "train start\n",
      "Loss: 208319.58998732228\n",
      "train complete\n",
      "train start\n",
      "Loss: 208305.25863518214\n",
      "train complete\n",
      "train start\n",
      "Loss: 208294.0677487842\n",
      "train complete\n",
      "train start\n",
      "Loss: 208247.92002998467\n",
      "train complete\n",
      "train start\n",
      "Loss: 208225.0398140863\n",
      "train complete\n",
      "train start\n",
      "Loss: 208182.81214037977\n",
      "train complete\n",
      "train start\n",
      "Loss: 208171.3395632072\n",
      "train complete\n",
      "train auc: 0.6909134399393745 test auc 0.6888231984578779\n",
      "train start\n",
      "Loss: 208147.02596646672\n",
      "train complete\n",
      "train start\n",
      "Loss: 208133.7797305053\n",
      "train complete\n",
      "train start\n",
      "Loss: 208120.88253553197\n",
      "train complete\n",
      "train start\n",
      "Loss: 208093.5530303466\n",
      "train complete\n",
      "train start\n",
      "Loss: 208062.21772603274\n",
      "train complete\n",
      "train start\n",
      "Loss: 208046.29784520183\n",
      "train complete\n",
      "train start\n",
      "Loss: 208028.8314302992\n",
      "train complete\n",
      "train start\n",
      "Loss: 208004.15218012407\n",
      "train complete\n",
      "train start\n",
      "Loss: 207961.2064540798\n",
      "train complete\n",
      "train start\n",
      "Loss: 207926.06319531772\n",
      "train complete\n",
      "train auc: 0.691144665303587 test auc 0.6891271154625787\n",
      "train start\n",
      "Loss: 207912.7195444229\n",
      "train complete\n",
      "train start\n",
      "Loss: 207901.07153522133\n",
      "train complete\n",
      "train start\n",
      "Loss: 207881.9292288086\n",
      "train complete\n",
      "train start\n",
      "Loss: 207872.68125740436\n",
      "train complete\n",
      "train start\n",
      "Loss: 207850.11905068054\n",
      "train complete\n",
      "train start\n",
      "Loss: 207804.5118680365\n",
      "train complete\n",
      "train start\n",
      "Loss: 207776.71591117332\n",
      "train complete\n",
      "train start\n",
      "Loss: 207754.23790950206\n",
      "train complete\n",
      "train start\n",
      "Loss: 207609.4515669777\n",
      "train complete\n",
      "train start\n",
      "Loss: 207455.11452682008\n",
      "train complete\n",
      "train auc: 0.6920069471387315 test auc 0.689308670973751\n",
      "train start\n",
      "Loss: 207441.663745572\n",
      "train complete\n",
      "train start\n",
      "Loss: 207362.5417130718\n",
      "train complete\n",
      "train start\n",
      "Loss: 207348.12450723222\n",
      "train complete\n",
      "train start\n",
      "Loss: 207328.9112441815\n",
      "train complete\n",
      "train start\n",
      "Loss: 207317.04075413328\n",
      "train complete\n",
      "train start\n",
      "Loss: 207303.3910920964\n",
      "train complete\n",
      "train start\n",
      "Loss: 207282.69206042503\n",
      "train complete\n",
      "train start\n",
      "Loss: 207249.72591345865\n",
      "train complete\n",
      "train start\n",
      "Loss: 207214.7111357269\n",
      "train complete\n",
      "train start\n",
      "Loss: 207198.02615222937\n",
      "train complete\n",
      "train auc: 0.6926548970014472 test auc 0.6898439395647826\n",
      "train start\n",
      "Loss: 207176.3207109485\n",
      "train complete\n",
      "train start\n",
      "Loss: 207164.90762745138\n",
      "train complete\n",
      "train start\n",
      "Loss: 207143.83893816164\n",
      "train complete\n",
      "train start\n",
      "Loss: 207127.97292715323\n",
      "train complete\n",
      "train start\n",
      "Loss: 207116.85751899346\n",
      "train complete\n",
      "train start\n",
      "Loss: 207049.24272928046\n",
      "train complete\n",
      "train start\n",
      "Loss: 207026.74677276693\n",
      "train complete\n",
      "train start\n",
      "Loss: 207020.7502930374\n",
      "train complete\n",
      "train start\n",
      "Loss: 207005.89237802546\n",
      "train complete\n",
      "train start\n",
      "Loss: 206976.6789404327\n",
      "train complete\n",
      "train auc: 0.6932927787363518 test auc 0.6907313792264151\n",
      "train start\n",
      "Loss: 206888.80719673226\n",
      "train complete\n",
      "train start\n",
      "Loss: 206877.62674201315\n",
      "train complete\n",
      "train start\n",
      "Loss: 206778.90058352158\n",
      "train complete\n",
      "train start\n",
      "Loss: 206740.05446289084\n",
      "train complete\n",
      "train start\n",
      "Loss: 206721.47215360793\n",
      "train complete\n",
      "train start\n",
      "Loss: 206693.52700687628\n",
      "train complete\n",
      "train start\n",
      "Loss: 206658.23218095294\n",
      "train complete\n",
      "train start\n",
      "Loss: 206613.2100601169\n",
      "train complete\n",
      "train start\n",
      "Loss: 206591.32565539164\n",
      "train complete\n",
      "train start\n",
      "Loss: 206559.5054652558\n",
      "train complete\n",
      "train auc: 0.69436308464085 test auc 0.6920086209455117\n",
      "train start\n",
      "Loss: 206534.67031802944\n",
      "train complete\n",
      "train start\n",
      "Loss: 206516.89699230553\n",
      "train complete\n",
      "train start\n",
      "Loss: 206499.1909520174\n",
      "train complete\n",
      "train start\n",
      "Loss: 206471.25469753298\n",
      "train complete\n",
      "train start\n",
      "Loss: 206456.79500549723\n",
      "train complete\n",
      "train start\n",
      "Loss: 206369.53831009925\n",
      "train complete\n",
      "train start\n",
      "Loss: 206353.40934232413\n",
      "train complete\n",
      "train start\n",
      "Loss: 206322.29375262617\n",
      "train complete\n",
      "train start\n",
      "Loss: 206309.11700609303\n",
      "train complete\n",
      "train start\n",
      "Loss: 206265.37156392215\n",
      "train complete\n",
      "train auc: 0.6945680994562209 test auc 0.6923587982279475\n",
      "train start\n",
      "Loss: 206236.32089493092\n",
      "train complete\n",
      "train start\n",
      "Loss: 206222.1700535905\n",
      "train complete\n",
      "train start\n",
      "Loss: 206214.8566312132\n",
      "train complete\n",
      "train start\n",
      "Loss: 206185.1098058992\n",
      "train complete\n",
      "train start\n",
      "Loss: 206161.8412017966\n",
      "train complete\n",
      "train start\n",
      "Loss: 206044.45099428078\n",
      "train complete\n",
      "train start\n",
      "Loss: 205991.4139218741\n",
      "train complete\n",
      "train start\n",
      "Loss: 205982.91468323607\n",
      "train complete\n",
      "train start\n",
      "Loss: 205968.94378072835\n",
      "train complete\n",
      "train start\n",
      "Loss: 205953.00380341584\n",
      "train complete\n",
      "train auc: 0.695180881395156 test auc 0.6917311267322035\n",
      "train start\n",
      "Loss: 205881.549731783\n",
      "train complete\n",
      "train start\n",
      "Loss: 205867.92140233534\n",
      "train complete\n",
      "train start\n",
      "Loss: 205860.13330924753\n",
      "train complete\n",
      "train start\n",
      "Loss: 205847.02292971956\n",
      "train complete\n",
      "train start\n",
      "Loss: 205813.7290537062\n",
      "train complete\n",
      "train start\n",
      "Loss: 205796.1275748655\n",
      "train complete\n",
      "train start\n",
      "Loss: 205780.81847860094\n",
      "train complete\n",
      "train start\n",
      "Loss: 205751.92446445365\n",
      "train complete\n",
      "train start\n",
      "Loss: 205725.72381653474\n",
      "train complete\n",
      "train start\n",
      "Loss: 205716.6275877205\n",
      "train complete\n",
      "train auc: 0.695675791622282 test auc 0.6923386752424342\n",
      "train start\n",
      "Loss: 205702.72706938715\n",
      "train complete\n",
      "train start\n",
      "Loss: 205676.14710201518\n",
      "train complete\n",
      "train start\n",
      "Loss: 205667.2488088697\n",
      "train complete\n",
      "train start\n",
      "Loss: 205653.4026760739\n",
      "train complete\n",
      "train start\n",
      "Loss: 205644.41365333207\n",
      "train complete\n",
      "train start\n",
      "Loss: 205632.61792932305\n",
      "train complete\n",
      "train start\n",
      "Loss: 205621.68941022866\n",
      "train complete\n",
      "train start\n",
      "Loss: 205567.02215928616\n",
      "train complete\n",
      "train start\n",
      "Loss: 205526.76611690366\n",
      "train complete\n",
      "train start\n",
      "Loss: 205512.92773349173\n",
      "train complete\n",
      "train auc: 0.6959153969002998 test auc 0.6930348241849045\n",
      "train start\n",
      "Loss: 205495.68633645942\n",
      "train complete\n",
      "train start\n",
      "Loss: 205483.39073540753\n",
      "train complete\n",
      "train start\n",
      "Loss: 205466.45327686536\n",
      "train complete\n",
      "train start\n",
      "Loss: 205420.7127573379\n",
      "train complete\n",
      "train start\n",
      "Loss: 205396.9138210422\n",
      "train complete\n",
      "train start\n",
      "Loss: 205382.65549740946\n",
      "train complete\n",
      "train start\n",
      "Loss: 205357.83674935673\n",
      "train complete\n",
      "train start\n",
      "Loss: 205344.86374916855\n",
      "train complete\n",
      "train start\n",
      "Loss: 205307.8113123749\n",
      "train complete\n",
      "train start\n",
      "Loss: 205278.7482350568\n",
      "train complete\n",
      "train auc: 0.6963643926040635 test auc 0.6931861042345551\n",
      "train start\n",
      "Loss: 205261.43148710637\n",
      "train complete\n",
      "train start\n",
      "Loss: 205237.76651961126\n",
      "train complete\n",
      "train start\n",
      "Loss: 205212.36444001686\n",
      "train complete\n",
      "train start\n",
      "Loss: 205196.1670095346\n",
      "train complete\n",
      "train start\n",
      "Loss: 205169.203370402\n",
      "train complete\n",
      "train start\n",
      "Loss: 205142.6279480082\n",
      "train complete\n",
      "train start\n",
      "Loss: 205116.3244089902\n",
      "train complete\n",
      "train start\n",
      "Loss: 205108.841222852\n",
      "train complete\n",
      "train start\n",
      "Loss: 205093.6153069411\n",
      "train complete\n",
      "train start\n",
      "Loss: 205073.95697746932\n",
      "train complete\n",
      "train auc: 0.6968332915726205 test auc 0.6937579151507759\n",
      "train start\n",
      "Loss: 205062.71881869843\n",
      "train complete\n",
      "train start\n",
      "Loss: 205051.8464108831\n",
      "train complete\n",
      "train start\n",
      "Loss: 205040.1643385647\n",
      "train complete\n",
      "train start\n",
      "Loss: 205005.7799240039\n",
      "train complete\n",
      "train start\n",
      "Loss: 204997.08699831733\n",
      "train complete\n",
      "train start\n",
      "Loss: 204983.8676369692\n",
      "train complete\n",
      "train start\n",
      "Loss: 204964.89597366846\n",
      "train complete\n",
      "train start\n",
      "Loss: 204916.80728815758\n",
      "train complete\n",
      "train start\n",
      "Loss: 204864.80503092904\n",
      "train complete\n",
      "train start\n",
      "Loss: 204844.8508029499\n",
      "train complete\n",
      "train auc: 0.6972606611320749 test auc 0.6940920244771303\n",
      "train start\n",
      "Loss: 204833.30467663554\n",
      "train complete\n",
      "train start\n",
      "Loss: 204820.4809710686\n",
      "train complete\n",
      "train start\n",
      "Loss: 204805.19297068898\n",
      "train complete\n",
      "train start\n",
      "Loss: 204787.23898602056\n",
      "train complete\n",
      "train start\n",
      "Loss: 204768.46185661064\n",
      "train complete\n",
      "train start\n",
      "Loss: 204760.69078348193\n",
      "train complete\n",
      "train start\n",
      "Loss: 204737.75433524945\n",
      "train complete\n",
      "train start\n",
      "Loss: 204704.41755390988\n",
      "train complete\n",
      "train start\n",
      "Loss: 204665.30710493165\n",
      "train complete\n",
      "train start\n",
      "Loss: 204654.7160040685\n",
      "train complete\n",
      "train auc: 0.6978221258622824 test auc 0.6945734090213597\n",
      "train start\n",
      "Loss: 204624.56028950922\n",
      "train complete\n",
      "train start\n",
      "Loss: 204605.14306283824\n",
      "train complete\n",
      "train start\n",
      "Loss: 204597.8154096472\n",
      "train complete\n",
      "train start\n",
      "Loss: 204588.25469086913\n",
      "train complete\n",
      "train start\n",
      "Loss: 204563.27572746284\n",
      "train complete\n",
      "train start\n",
      "Loss: 204550.46510685165\n",
      "train complete\n",
      "train start\n",
      "Loss: 204541.55459414446\n",
      "train complete\n",
      "train start\n",
      "Loss: 204532.65241626668\n",
      "train complete\n",
      "train start\n",
      "Loss: 204506.90192120167\n",
      "train complete\n",
      "train start\n",
      "Loss: 204495.7322076322\n",
      "train complete\n",
      "train auc: 0.6982341087234021 test auc 0.6951585066297614\n",
      "train start\n",
      "Loss: 204481.43696171616\n",
      "train complete\n",
      "train start\n",
      "Loss: 204470.85634897774\n",
      "train complete\n",
      "train start\n",
      "Loss: 204461.85969003517\n",
      "train complete\n",
      "train start\n",
      "Loss: 204431.0899496387\n",
      "train complete\n",
      "train start\n",
      "Loss: 204338.96463769107\n",
      "train complete\n",
      "train start\n",
      "Loss: 204317.25968644812\n",
      "train complete\n",
      "train start\n",
      "Loss: 204304.38020368075\n",
      "train complete\n",
      "train start\n",
      "Loss: 204286.94186319213\n",
      "train complete\n",
      "train start\n",
      "Loss: 204263.43784447855\n",
      "train complete\n",
      "train start\n",
      "Loss: 204251.33451024367\n",
      "train complete\n",
      "train auc: 0.698685481053787 test auc 0.6954991165526206\n",
      "train start\n",
      "Loss: 204240.0147123632\n",
      "train complete\n",
      "train start\n",
      "Loss: 204232.08589948376\n",
      "train complete\n",
      "train start\n",
      "Loss: 204208.9026708109\n",
      "train complete\n",
      "train start\n",
      "Loss: 204181.5743696068\n",
      "train complete\n",
      "train start\n",
      "Loss: 204172.68096044322\n",
      "train complete\n",
      "train start\n",
      "Loss: 204136.63440005473\n",
      "train complete\n",
      "train start\n",
      "Loss: 204118.99394431856\n",
      "train complete\n",
      "train start\n",
      "Loss: 204107.14625441478\n",
      "train complete\n",
      "train start\n",
      "Loss: 204089.4635868648\n",
      "train complete\n",
      "train start\n",
      "Loss: 204074.5964029208\n",
      "train complete\n",
      "train auc: 0.6987667180938133 test auc 0.6955662700361592\n",
      "train start\n",
      "Loss: 204062.51201771552\n",
      "train complete\n",
      "train start\n",
      "Loss: 204045.88166111414\n",
      "train complete\n",
      "train start\n",
      "Loss: 204032.10213589188\n",
      "train complete\n",
      "train start\n",
      "Loss: 204019.82587846852\n",
      "train complete\n",
      "train start\n",
      "Loss: 203984.64727168935\n",
      "train complete\n",
      "train start\n",
      "Loss: 203976.46524329312\n",
      "train complete\n",
      "train start\n",
      "Loss: 203951.76687106886\n",
      "train complete\n",
      "train start\n",
      "Loss: 203944.3457945424\n",
      "train complete\n",
      "train start\n",
      "Loss: 203933.7313087252\n",
      "train complete\n",
      "train start\n",
      "Loss: 203923.93990844948\n",
      "train complete\n",
      "train auc: 0.6991179193881744 test auc 0.6960345357366214\n",
      "train start\n",
      "Loss: 203908.48696179004\n",
      "train complete\n",
      "train start\n",
      "Loss: 203892.57097299598\n",
      "train complete\n",
      "train start\n",
      "Loss: 203884.11917871764\n",
      "train complete\n",
      "train start\n",
      "Loss: 203873.33358522548\n",
      "train complete\n",
      "train start\n",
      "Loss: 203854.9962270236\n",
      "train complete\n",
      "train start\n",
      "Loss: 203842.53112900647\n",
      "train complete\n",
      "train start\n",
      "Loss: 203823.61008131903\n",
      "train complete\n",
      "train start\n",
      "Loss: 203804.94886718667\n",
      "train complete\n",
      "train start\n",
      "Loss: 203794.51563485325\n",
      "train complete\n",
      "train start\n",
      "Loss: 203782.2463658702\n",
      "train complete\n",
      "train auc: 0.6993725900349073 test auc 0.6960227236005976\n",
      "train start\n",
      "Loss: 203771.3336403088\n",
      "train complete\n",
      "train start\n",
      "Loss: 203761.01473511435\n",
      "train complete\n",
      "train start\n",
      "Loss: 203742.85564447174\n",
      "train complete\n",
      "train start\n",
      "Loss: 203726.91056559017\n",
      "train complete\n",
      "train start\n",
      "Loss: 203709.27857818748\n",
      "train complete\n",
      "train start\n",
      "Loss: 203697.0883258504\n",
      "train complete\n",
      "train start\n",
      "Loss: 203685.22290340316\n",
      "train complete\n",
      "train start\n",
      "Loss: 203674.26803062865\n",
      "train complete\n",
      "train start\n",
      "Loss: 203664.79692416856\n",
      "train complete\n",
      "train start\n",
      "Loss: 203626.24688951144\n",
      "train complete\n",
      "train auc: 0.6997280033708685 test auc 0.696293398776018\n",
      "train start\n",
      "Loss: 203616.61627835265\n",
      "train complete\n",
      "train start\n",
      "Loss: 203609.11397074026\n",
      "train complete\n",
      "train start\n",
      "Loss: 203592.98240853738\n",
      "train complete\n",
      "train start\n",
      "Loss: 203564.86503705347\n",
      "train complete\n",
      "train start\n",
      "Loss: 203549.88351424664\n",
      "train complete\n",
      "train start\n",
      "Loss: 203536.43590956897\n",
      "train complete\n",
      "train start\n",
      "Loss: 203524.30250580356\n",
      "train complete\n",
      "train start\n",
      "Loss: 203488.51406588947\n",
      "train complete\n",
      "train start\n",
      "Loss: 203446.64124724863\n",
      "train complete\n",
      "train start\n",
      "Loss: 203332.10227433572\n",
      "train complete\n",
      "train auc: 0.7003942908517123 test auc 0.6968823835654379\n",
      "train start\n",
      "Loss: 203310.68629075124\n",
      "train complete\n",
      "train start\n",
      "Loss: 203299.0694546469\n",
      "train complete\n",
      "train start\n",
      "Loss: 203281.8840022416\n",
      "train complete\n",
      "train start\n",
      "Loss: 203262.5877250936\n",
      "train complete\n",
      "train start\n",
      "Loss: 203239.15850434132\n",
      "train complete\n",
      "train start\n",
      "Loss: 203225.14957125075\n",
      "train complete\n",
      "train start\n",
      "Loss: 203216.18993584273\n",
      "train complete\n",
      "train start\n",
      "Loss: 203204.00580211796\n",
      "train complete\n",
      "train start\n",
      "Loss: 203186.2956134634\n",
      "train complete\n",
      "train start\n",
      "Loss: 203175.95452195476\n",
      "train complete\n",
      "train auc: 0.7007817923794298 test auc 0.6968934082257268\n",
      "train start\n",
      "Loss: 203167.41606267996\n",
      "train complete\n",
      "train start\n",
      "Loss: 203085.88537505397\n",
      "train complete\n",
      "train start\n",
      "Loss: 203064.56685549818\n",
      "train complete\n",
      "train start\n",
      "Loss: 203045.4292206911\n",
      "train complete\n",
      "train start\n",
      "Loss: 203035.3910786874\n",
      "train complete\n",
      "train start\n",
      "Loss: 203001.25522866502\n",
      "train complete\n",
      "train start\n",
      "Loss: 202991.1074127916\n",
      "train complete\n",
      "train start\n",
      "Loss: 202984.70180266717\n",
      "train complete\n",
      "train start\n",
      "Loss: 202975.79213608516\n",
      "train complete\n",
      "train start\n",
      "Loss: 202969.45801530126\n",
      "train complete\n",
      "train auc: 0.7012283515384026 test auc 0.6975229731143234\n",
      "train start\n",
      "Loss: 202959.19215867063\n",
      "train complete\n",
      "train start\n",
      "Loss: 202943.92287523267\n",
      "train complete\n",
      "train start\n",
      "Loss: 202933.59644325325\n",
      "train complete\n",
      "train start\n",
      "Loss: 202897.92218367805\n",
      "train complete\n",
      "train start\n",
      "Loss: 202883.76338336032\n",
      "train complete\n",
      "train start\n",
      "Loss: 202876.47601352498\n",
      "train complete\n",
      "train start\n",
      "Loss: 202865.66762575676\n",
      "train complete\n",
      "train start\n",
      "Loss: 202853.7345173362\n",
      "train complete\n",
      "train start\n",
      "Loss: 202842.31561650994\n",
      "train complete\n",
      "train start\n",
      "Loss: 202832.36660399588\n",
      "train complete\n",
      "train auc: 0.7013312631160824 test auc 0.6974306031518229\n",
      "train start\n",
      "Loss: 202825.70191472358\n",
      "train complete\n",
      "train start\n",
      "Loss: 202816.78345960146\n",
      "train complete\n",
      "train start\n",
      "Loss: 202781.73586045066\n",
      "train complete\n",
      "train start\n",
      "Loss: 202774.28123433804\n",
      "train complete\n",
      "train start\n",
      "Loss: 202752.8673177297\n",
      "train complete\n",
      "train start\n",
      "Loss: 202734.69532653067\n",
      "train complete\n",
      "train start\n",
      "Loss: 202724.55811339308\n",
      "train complete\n",
      "train start\n",
      "Loss: 202707.33317970636\n",
      "train complete\n",
      "train start\n",
      "Loss: 202692.58154454015\n",
      "train complete\n",
      "train start\n",
      "Loss: 202676.0679510859\n",
      "train complete\n",
      "train auc: 0.701577551209042 test auc 0.6978105539192165\n",
      "train start\n",
      "Loss: 202663.26011044034\n",
      "train complete\n",
      "train start\n",
      "Loss: 202653.98352589272\n",
      "train complete\n",
      "train start\n",
      "Loss: 202643.19529967444\n",
      "train complete\n",
      "train start\n",
      "Loss: 202627.54556951518\n",
      "train complete\n",
      "train start\n",
      "Loss: 202613.7042395933\n",
      "train complete\n",
      "train start\n",
      "Loss: 202600.2745351621\n",
      "train complete\n",
      "train start\n",
      "Loss: 202590.23199001566\n",
      "train complete\n",
      "train start\n",
      "Loss: 202574.972153733\n",
      "train complete\n",
      "train start\n",
      "Loss: 202569.64175157584\n",
      "train complete\n",
      "train start\n",
      "Loss: 202554.69190006176\n",
      "train complete\n",
      "train auc: 0.7019892600778986 test auc 0.698118877336944\n",
      "train start\n",
      "Loss: 202549.71558520934\n",
      "train complete\n",
      "train start\n",
      "Loss: 202538.12894820236\n",
      "train complete\n",
      "train start\n",
      "Loss: 202527.08956540044\n",
      "train complete\n",
      "train start\n",
      "Loss: 202519.54771126684\n",
      "train complete\n",
      "train start\n",
      "Loss: 202510.26622678715\n",
      "train complete\n",
      "train start\n",
      "Loss: 202498.8493888646\n",
      "train complete\n",
      "train start\n",
      "Loss: 202492.29989757107\n",
      "train complete\n",
      "train start\n",
      "Loss: 202486.62537254722\n",
      "train complete\n",
      "train start\n",
      "Loss: 202478.69766247613\n",
      "train complete\n",
      "train start\n",
      "Loss: 202471.3013572403\n",
      "train complete\n",
      "train auc: 0.7021147649567087 test auc 0.6976792290066655\n",
      "train start\n",
      "Loss: 202462.67242838262\n",
      "train complete\n",
      "train start\n",
      "Loss: 202452.56480377566\n",
      "train complete\n",
      "train start\n",
      "Loss: 202440.56987287695\n",
      "train complete\n",
      "train start\n",
      "Loss: 202433.81163425036\n",
      "train complete\n",
      "train start\n",
      "Loss: 202429.63531146862\n",
      "train complete\n",
      "train start\n",
      "Loss: 202359.34461603226\n",
      "train complete\n",
      "train start\n",
      "Loss: 202345.54790063135\n",
      "train complete\n",
      "train start\n",
      "Loss: 202336.21400840415\n",
      "train complete\n",
      "train start\n",
      "Loss: 202329.10104664546\n",
      "train complete\n",
      "train start\n",
      "Loss: 202324.18947919004\n",
      "train complete\n",
      "train auc: 0.7022610981997115 test auc 0.6986665776913207\n",
      "train start\n",
      "Loss: 202265.4967040536\n",
      "train complete\n",
      "train start\n",
      "Loss: 202242.74227775558\n",
      "train complete\n",
      "train start\n",
      "Loss: 202228.22527027494\n",
      "train complete\n",
      "train start\n",
      "Loss: 202203.33704678644\n",
      "train complete\n",
      "train start\n",
      "Loss: 202191.23752304353\n",
      "train complete\n",
      "train start\n",
      "Loss: 202176.30904997783\n",
      "train complete\n",
      "train start\n",
      "Loss: 202171.60214142365\n",
      "train complete\n",
      "train start\n",
      "Loss: 202160.9135656904\n",
      "train complete\n",
      "train start\n",
      "Loss: 202143.5053771479\n",
      "train complete\n",
      "train start\n",
      "Loss: 202108.39571389792\n",
      "train complete\n",
      "train auc: 0.702798636972953 test auc 0.6990993897282669\n",
      "train start\n",
      "Loss: 202102.22431645737\n",
      "train complete\n",
      "train start\n",
      "Loss: 202094.84590953824\n",
      "train complete\n",
      "train start\n",
      "Loss: 202090.37154151686\n",
      "train complete\n",
      "train start\n",
      "Loss: 202077.88387893751\n",
      "train complete\n",
      "train start\n",
      "Loss: 202064.18252350323\n",
      "train complete\n",
      "train start\n",
      "Loss: 202050.43205197487\n",
      "train complete\n",
      "train start\n",
      "Loss: 202039.19544365935\n",
      "train complete\n",
      "train start\n",
      "Loss: 202034.59956570284\n",
      "train complete\n",
      "train start\n",
      "Loss: 202021.146511392\n",
      "train complete\n",
      "train start\n",
      "Loss: 202009.56712267725\n",
      "train complete\n",
      "train auc: 0.7030749811013522 test auc 0.6992704570666033\n",
      "train start\n",
      "Loss: 201988.70031131833\n",
      "train complete\n",
      "train start\n",
      "Loss: 201984.42644394867\n",
      "train complete\n",
      "train start\n",
      "Loss: 201976.9429725805\n",
      "train complete\n",
      "train start\n",
      "Loss: 201946.1382789463\n",
      "train complete\n",
      "train start\n",
      "Loss: 201934.6783960996\n",
      "train complete\n",
      "train start\n",
      "Loss: 201925.214348822\n",
      "train complete\n",
      "train start\n",
      "Loss: 201911.33954936505\n",
      "train complete\n",
      "train start\n",
      "Loss: 201895.3627022513\n",
      "train complete\n",
      "train start\n",
      "Loss: 201881.46493406457\n",
      "train complete\n",
      "train start\n",
      "Loss: 201873.74817197394\n",
      "train complete\n",
      "train auc: 0.7033387947764964 test auc 0.6996295648258496\n",
      "train start\n",
      "Loss: 201823.12245490495\n",
      "train complete\n",
      "train start\n",
      "Loss: 201809.89548252238\n",
      "train complete\n",
      "train start\n",
      "Loss: 201806.19850061333\n",
      "train complete\n",
      "train start\n",
      "Loss: 201794.94902713055\n",
      "train complete\n",
      "train start\n",
      "Loss: 201773.3821547924\n",
      "train complete\n",
      "train start\n",
      "Loss: 201761.7931680595\n",
      "train complete\n",
      "train start\n",
      "Loss: 201754.5810138735\n",
      "train complete\n",
      "train start\n",
      "Loss: 201735.12407706323\n",
      "train complete\n",
      "train start\n",
      "Loss: 201725.92058539664\n",
      "train complete\n",
      "train start\n",
      "Loss: 201718.19198253166\n",
      "train complete\n",
      "train auc: 0.7034657979918912 test auc 0.699374689362784\n",
      "train start\n",
      "Loss: 201711.4040232104\n",
      "train complete\n",
      "train start\n",
      "Loss: 201691.6954359545\n",
      "train complete\n",
      "train start\n",
      "Loss: 201682.63716514249\n",
      "train complete\n",
      "train start\n",
      "Loss: 201671.6025227511\n",
      "train complete\n",
      "train start\n",
      "Loss: 201662.22826702317\n",
      "train complete\n",
      "train start\n",
      "Loss: 201648.0448986472\n",
      "train complete\n",
      "train start\n",
      "Loss: 201639.751751551\n",
      "train complete\n",
      "train start\n",
      "Loss: 201630.81034300293\n",
      "train complete\n",
      "train start\n",
      "Loss: 201616.90558278986\n",
      "train complete\n",
      "train start\n",
      "Loss: 201608.75864938713\n",
      "train complete\n",
      "train auc: 0.7037020205970075 test auc 0.6997703394472197\n",
      "train start\n",
      "Loss: 201591.82067805028\n",
      "train complete\n",
      "train start\n",
      "Loss: 201582.97234955637\n",
      "train complete\n",
      "train start\n",
      "Loss: 201558.83892243108\n",
      "train complete\n",
      "train start\n",
      "Loss: 201551.68154379987\n",
      "train complete\n",
      "train start\n",
      "Loss: 201545.6728211395\n",
      "train complete\n",
      "train start\n",
      "Loss: 201540.21846026578\n",
      "train complete\n",
      "train start\n",
      "Loss: 201529.51051604652\n",
      "train complete\n",
      "train start\n",
      "Loss: 201523.02113822423\n",
      "train complete\n",
      "train start\n",
      "Loss: 201504.99295053427\n",
      "train complete\n",
      "train start\n",
      "Loss: 201496.48516939438\n",
      "train complete\n",
      "train auc: 0.7038204529651887 test auc 0.699903976589319\n",
      "train start\n",
      "Loss: 201486.19163739224\n",
      "train complete\n",
      "train start\n",
      "Loss: 201476.62452935497\n",
      "train complete\n",
      "train start\n",
      "Loss: 201469.58614284938\n",
      "train complete\n",
      "train start\n",
      "Loss: 201463.12407812453\n",
      "train complete\n",
      "train start\n",
      "Loss: 201454.34482520033\n",
      "train complete\n",
      "train start\n",
      "Loss: 201445.6532450398\n",
      "train complete\n",
      "train start\n",
      "Loss: 201431.05798336296\n",
      "train complete\n",
      "train start\n",
      "Loss: 201424.66365610214\n",
      "train complete\n",
      "train start\n",
      "Loss: 201415.11373474784\n",
      "train complete\n",
      "train start\n",
      "Loss: 201409.06510689278\n",
      "train complete\n",
      "train auc: 0.7039182989358972 test auc 0.6998387494408451\n",
      "train start\n",
      "Loss: 201395.0674274712\n",
      "train complete\n",
      "train start\n",
      "Loss: 201380.06804218155\n",
      "train complete\n",
      "train start\n",
      "Loss: 201369.23765570574\n",
      "train complete\n",
      "train start\n",
      "Loss: 201360.7788562477\n",
      "train complete\n",
      "train start\n",
      "Loss: 201354.77833302593\n",
      "train complete\n",
      "train start\n",
      "Loss: 201348.38267496627\n",
      "train complete\n",
      "train start\n",
      "Loss: 201339.21843975247\n",
      "train complete\n",
      "train start\n",
      "Loss: 201332.8137045965\n",
      "train complete\n",
      "train start\n",
      "Loss: 201318.3714173496\n",
      "train complete\n",
      "train start\n",
      "Loss: 201310.58061563483\n",
      "train complete\n",
      "train auc: 0.7040886438346886 test auc 0.7001357972100017\n",
      "train start\n",
      "Loss: 201300.17980994817\n",
      "train complete\n",
      "train start\n",
      "Loss: 201293.6042486308\n",
      "train complete\n",
      "train start\n",
      "Loss: 201286.9219682573\n",
      "train complete\n",
      "train start\n",
      "Loss: 201278.86051091578\n",
      "train complete\n",
      "train start\n",
      "Loss: 201241.53179548468\n",
      "train complete\n",
      "train start\n",
      "Loss: 201231.98258539062\n",
      "train complete\n",
      "train start\n",
      "Loss: 201221.0295610465\n",
      "train complete\n",
      "train start\n",
      "Loss: 201208.4336063425\n",
      "train complete\n",
      "train start\n",
      "Loss: 201201.77309205977\n",
      "train complete\n",
      "train start\n",
      "Loss: 201192.27619766997\n",
      "train complete\n",
      "train auc: 0.7043508019403966 test auc 0.7002682107842261\n",
      "train start\n",
      "Loss: 201160.075045025\n",
      "train complete\n",
      "train start\n",
      "Loss: 201145.64855637398\n",
      "train complete\n",
      "train start\n",
      "Loss: 201124.28784072187\n",
      "train complete\n",
      "train start\n",
      "Loss: 201108.8412919779\n",
      "train complete\n",
      "train start\n",
      "Loss: 201091.8162908325\n",
      "train complete\n",
      "train start\n",
      "Loss: 201072.40461225645\n",
      "train complete\n",
      "train start\n",
      "Loss: 201060.74758337892\n",
      "train complete\n",
      "train start\n",
      "Loss: 201048.94244456876\n",
      "train complete\n",
      "train start\n",
      "Loss: 201043.03791003276\n",
      "train complete\n",
      "train start\n",
      "Loss: 201038.04211981007\n",
      "train complete\n",
      "train auc: 0.7044271742477048 test auc 0.7003582685171782\n",
      "train start\n",
      "Loss: 201024.4711078651\n",
      "train complete\n",
      "train start\n",
      "Loss: 201011.17339165797\n",
      "train complete\n",
      "train start\n",
      "Loss: 201002.1986744183\n",
      "train complete\n",
      "train start\n",
      "Loss: 200991.73699174725\n",
      "train complete\n",
      "train start\n",
      "Loss: 200982.94622608332\n",
      "train complete\n",
      "train start\n",
      "Loss: 200976.67549971715\n",
      "train complete\n",
      "train start\n",
      "Loss: 200970.80052686087\n",
      "train complete\n",
      "train start\n",
      "Loss: 200963.94453657285\n",
      "train complete\n",
      "train start\n",
      "Loss: 200952.24403040347\n",
      "train complete\n",
      "train start\n",
      "Loss: 200947.35105428088\n",
      "train complete\n",
      "train auc: 0.7047246643739613 test auc 0.7008277405300709\n",
      "train start\n",
      "Loss: 200938.81116564892\n",
      "train complete\n",
      "train start\n",
      "Loss: 200932.807588211\n",
      "train complete\n",
      "train start\n",
      "Loss: 200924.0869800231\n",
      "train complete\n",
      "train start\n",
      "Loss: 200919.3561958629\n",
      "train complete\n",
      "train start\n",
      "Loss: 200915.71834606107\n",
      "train complete\n",
      "train start\n",
      "Loss: 200908.80678422816\n",
      "train complete\n",
      "train start\n",
      "Loss: 200903.57184269087\n",
      "train complete\n",
      "train start\n",
      "Loss: 200895.30615783972\n",
      "train complete\n",
      "train start\n",
      "Loss: 200889.2265224266\n",
      "train complete\n",
      "train start\n",
      "Loss: 200844.19154770413\n",
      "train complete\n",
      "train auc: 0.7049530776624895 test auc 0.7004029538434433\n",
      "train start\n",
      "Loss: 200823.3293906961\n",
      "train complete\n",
      "train start\n",
      "Loss: 200808.0186518758\n",
      "train complete\n",
      "train start\n",
      "Loss: 200796.2393332184\n",
      "train complete\n",
      "train start\n",
      "Loss: 200781.0871993989\n",
      "train complete\n",
      "train start\n",
      "Loss: 200769.47271709167\n",
      "train complete\n",
      "train start\n",
      "Loss: 200761.99468685628\n",
      "train complete\n",
      "train start\n",
      "Loss: 200758.1005977791\n",
      "train complete\n",
      "train start\n",
      "Loss: 200734.70488594007\n",
      "train complete\n",
      "train start\n",
      "Loss: 200727.22228552325\n",
      "train complete\n",
      "train start\n",
      "Loss: 200717.69652268727\n",
      "train complete\n",
      "train auc: 0.7051682252757838 test auc 0.7009556472959558\n",
      "train start\n",
      "Loss: 200708.6762798316\n",
      "train complete\n",
      "train start\n",
      "Loss: 200703.3552355813\n",
      "train complete\n",
      "train start\n",
      "Loss: 200698.4426769276\n",
      "train complete\n",
      "train start\n",
      "Loss: 200693.67017549934\n",
      "train complete\n",
      "train start\n",
      "Loss: 200672.92211977663\n",
      "train complete\n",
      "train start\n",
      "Loss: 200667.1289505553\n",
      "train complete\n",
      "train start\n",
      "Loss: 200660.05273888732\n",
      "train complete\n",
      "train start\n",
      "Loss: 200649.7570377838\n",
      "train complete\n",
      "train start\n",
      "Loss: 200645.0554052702\n",
      "train complete\n",
      "train start\n",
      "Loss: 200638.75213897674\n",
      "train complete\n",
      "train auc: 0.7053475549141478 test auc 0.7008363525654987\n",
      "train start\n",
      "Loss: 200626.2092754946\n",
      "train complete\n",
      "train start\n",
      "Loss: 200612.89127251954\n",
      "train complete\n",
      "train start\n",
      "Loss: 200606.15300441085\n",
      "train complete\n",
      "train start\n",
      "Loss: 200599.10445244066\n",
      "train complete\n",
      "train start\n",
      "Loss: 200588.91202983807\n",
      "train complete\n",
      "train start\n",
      "Loss: 200584.56070193066\n",
      "train complete\n",
      "train start\n",
      "Loss: 200575.60239149397\n",
      "train complete\n",
      "train start\n",
      "Loss: 200553.14500684798\n",
      "train complete\n",
      "train start\n",
      "Loss: 200547.74045326564\n",
      "train complete\n",
      "train start\n",
      "Loss: 200543.69834837617\n",
      "train complete\n",
      "train auc: 0.7054425877531847 test auc 0.7009740274815854\n",
      "train start\n",
      "Loss: 200526.28828523378\n",
      "train complete\n",
      "train start\n",
      "Loss: 200520.73957532804\n",
      "train complete\n",
      "train start\n",
      "Loss: 200516.15319728572\n",
      "train complete\n",
      "train start\n",
      "Loss: 200508.8834471151\n",
      "train complete\n",
      "train start\n",
      "Loss: 200480.32673848438\n",
      "train complete\n",
      "train start\n",
      "Loss: 200472.41807548018\n",
      "train complete\n",
      "train start\n",
      "Loss: 200467.93993106033\n",
      "train complete\n",
      "train start\n",
      "Loss: 200459.12788201318\n",
      "train complete\n",
      "train start\n",
      "Loss: 200450.23078698866\n",
      "train complete\n",
      "train start\n",
      "Loss: 200445.33139441823\n",
      "train complete\n",
      "train auc: 0.7056010748625621 test auc 0.7012054292655724\n",
      "train start\n",
      "Loss: 200438.2105449777\n",
      "train complete\n",
      "train start\n",
      "Loss: 200430.8623953656\n",
      "train complete\n",
      "train start\n",
      "Loss: 200423.33212025109\n",
      "train complete\n",
      "train start\n",
      "Loss: 200418.1858716854\n",
      "train complete\n",
      "train start\n",
      "Loss: 200413.5413624703\n",
      "train complete\n",
      "train start\n",
      "Loss: 200403.69643503084\n",
      "train complete\n",
      "train start\n",
      "Loss: 200394.99270233652\n",
      "train complete\n",
      "train start\n",
      "Loss: 200369.91147410977\n",
      "train complete\n",
      "train start\n",
      "Loss: 200366.01639719086\n",
      "train complete\n",
      "train start\n",
      "Loss: 200356.96124649508\n",
      "train complete\n",
      "train auc: 0.7056875163536686 test auc 0.7012500643941811\n",
      "train start\n",
      "Loss: 200350.154639855\n",
      "train complete\n",
      "train start\n",
      "Loss: 200343.8626617327\n",
      "train complete\n",
      "train start\n",
      "Loss: 200337.19003107763\n",
      "train complete\n",
      "train start\n",
      "Loss: 200334.1242295572\n",
      "train complete\n",
      "train start\n",
      "Loss: 200321.91327183854\n",
      "train complete\n",
      "train start\n",
      "Loss: 200313.23985318936\n",
      "train complete\n",
      "train start\n",
      "Loss: 200309.40980006728\n",
      "train complete\n",
      "train start\n",
      "Loss: 200303.82748399547\n",
      "train complete\n",
      "train start\n",
      "Loss: 200294.00673848612\n",
      "train complete\n",
      "train start\n",
      "Loss: 200288.24228976964\n",
      "train complete\n",
      "train auc: 0.7059131685998243 test auc 0.7014211317325175\n",
      "train start\n",
      "Loss: 200285.58908588972\n",
      "train complete\n",
      "train start\n",
      "Loss: 200282.6193152745\n",
      "train complete\n",
      "train start\n",
      "Loss: 200267.24791076285\n",
      "train complete\n",
      "train start\n",
      "Loss: 200259.897847285\n",
      "train complete\n",
      "train start\n",
      "Loss: 200255.28820006977\n",
      "train complete\n",
      "train start\n",
      "Loss: 200248.82166678333\n",
      "train complete\n",
      "train start\n",
      "Loss: 200242.20939460382\n",
      "train complete\n",
      "train start\n",
      "Loss: 200236.56860989283\n",
      "train complete\n",
      "train start\n",
      "Loss: 200228.51387430308\n",
      "train complete\n",
      "train start\n",
      "Loss: 200221.97617092327\n",
      "train complete\n",
      "train auc: 0.7059521862341518 test auc 0.7016573587662269\n",
      "train start\n",
      "Loss: 200212.88315453875\n",
      "train complete\n",
      "train start\n",
      "Loss: 200202.8008335424\n",
      "train complete\n",
      "train start\n",
      "Loss: 200184.82975533992\n",
      "train complete\n",
      "train start\n",
      "Loss: 200178.61595074183\n",
      "train complete\n",
      "train start\n",
      "Loss: 200172.53386643168\n",
      "train complete\n",
      "train start\n",
      "Loss: 200166.18763749662\n",
      "train complete\n",
      "train start\n",
      "Loss: 200158.15634892258\n",
      "train complete\n",
      "train start\n",
      "Loss: 200153.7719310801\n",
      "train complete\n",
      "train start\n",
      "Loss: 200143.91644479884\n",
      "train complete\n",
      "train start\n",
      "Loss: 200138.30402917558\n",
      "train complete\n",
      "train auc: 0.7060745108982941 test auc 0.7017509852388144\n",
      "train start\n",
      "Loss: 200128.88267575103\n",
      "train complete\n",
      "train start\n",
      "Loss: 200122.52932288725\n",
      "train complete\n",
      "train start\n",
      "Loss: 200115.25983872332\n",
      "train complete\n",
      "train start\n",
      "Loss: 200110.39926772422\n",
      "train complete\n",
      "train start\n",
      "Loss: 200093.96329905995\n",
      "train complete\n",
      "train start\n",
      "Loss: 200088.215649821\n",
      "train complete\n",
      "train start\n",
      "Loss: 200074.0482153915\n",
      "train complete\n",
      "train start\n",
      "Loss: 200063.40969390344\n",
      "train complete\n",
      "train start\n",
      "Loss: 200061.03361874013\n",
      "train complete\n",
      "train start\n",
      "Loss: 200037.27677716943\n",
      "train complete\n",
      "train auc: 0.7063291347356637 test auc 0.7024470337859718\n",
      "train start\n",
      "Loss: 200027.98751732067\n",
      "train complete\n",
      "train start\n",
      "Loss: 200022.9431760165\n",
      "train complete\n",
      "train start\n",
      "Loss: 200017.41372474603\n",
      "train complete\n",
      "train start\n",
      "Loss: 200010.51166517052\n",
      "train complete\n",
      "train start\n",
      "Loss: 200007.53107812398\n",
      "train complete\n",
      "train start\n",
      "Loss: 199998.60064932317\n",
      "train complete\n",
      "train start\n",
      "Loss: 199994.1354006487\n",
      "train complete\n",
      "train start\n",
      "Loss: 199986.13185160363\n",
      "train complete\n",
      "train start\n",
      "Loss: 199979.37606052074\n",
      "train complete\n",
      "train start\n",
      "Loss: 199974.4210606732\n",
      "train complete\n",
      "train auc: 0.7063035931547081 test auc 0.7022459247189511\n",
      "train start\n",
      "Loss: 199969.48395752467\n",
      "train complete\n",
      "train start\n",
      "Loss: 199960.0842288854\n",
      "train complete\n",
      "train start\n",
      "Loss: 199956.65935513054\n",
      "train complete\n",
      "train start\n",
      "Loss: 199951.58131008505\n",
      "train complete\n",
      "train start\n",
      "Loss: 199944.9341706586\n",
      "train complete\n",
      "train start\n",
      "Loss: 199940.0772399344\n",
      "train complete\n",
      "train start\n",
      "Loss: 199934.78257338007\n",
      "train complete\n",
      "train start\n",
      "Loss: 199930.55327702963\n",
      "train complete\n",
      "train start\n",
      "Loss: 199926.81486754032\n",
      "train complete\n",
      "train start\n",
      "Loss: 199921.22292182242\n",
      "train complete\n",
      "train auc: 0.7064941879005715 test auc 0.7021423795031925\n",
      "train start\n",
      "Loss: 199905.94681589107\n",
      "train complete\n",
      "train start\n",
      "Loss: 199898.90365237926\n",
      "train complete\n",
      "train start\n",
      "Loss: 199894.1416768653\n",
      "train complete\n",
      "train start\n",
      "Loss: 199889.39908002908\n",
      "train complete\n",
      "train start\n",
      "Loss: 199885.06035045316\n",
      "train complete\n",
      "train start\n",
      "Loss: 199879.65346358754\n",
      "train complete\n",
      "train start\n",
      "Loss: 199857.30387758015\n",
      "train complete\n",
      "train start\n",
      "Loss: 199850.9324125766\n",
      "train complete\n",
      "train start\n",
      "Loss: 199847.28894116136\n",
      "train complete\n",
      "train start\n",
      "Loss: 199840.4801213257\n",
      "train complete\n",
      "train auc: 0.7065328084473015 test auc 0.7023825611710208\n",
      "train start\n",
      "Loss: 199835.9955667662\n",
      "train complete\n",
      "train start\n",
      "Loss: 199828.88310609933\n",
      "train complete\n",
      "train start\n",
      "Loss: 199824.82429941697\n",
      "train complete\n",
      "train start\n",
      "Loss: 199816.16589206413\n",
      "train complete\n",
      "train start\n",
      "Loss: 199812.7546795686\n",
      "train complete\n",
      "train start\n",
      "Loss: 199804.8385392963\n",
      "train complete\n",
      "train start\n",
      "Loss: 199796.64169305682\n",
      "train complete\n",
      "train start\n",
      "Loss: 199778.20683015496\n",
      "train complete\n",
      "train start\n",
      "Loss: 199771.5809518837\n",
      "train complete\n",
      "train start\n",
      "Loss: 199756.17915317928\n",
      "train complete\n",
      "train auc: 0.7066298681627192 test auc 0.7028744009458745\n",
      "train start\n",
      "Loss: 199745.71614519297\n",
      "train complete\n",
      "train start\n",
      "Loss: 199738.21589638924\n",
      "train complete\n",
      "train start\n",
      "Loss: 199731.92428211885\n",
      "train complete\n",
      "train start\n",
      "Loss: 199725.5427170533\n",
      "train complete\n",
      "train start\n",
      "Loss: 199714.99263779089\n",
      "train complete\n",
      "train start\n",
      "Loss: 199705.90616411707\n",
      "train complete\n",
      "train start\n",
      "Loss: 199698.88296980652\n",
      "train complete\n",
      "train start\n",
      "Loss: 199683.95627776854\n",
      "train complete\n",
      "train start\n",
      "Loss: 199665.1438280873\n",
      "train complete\n",
      "train start\n",
      "Loss: 199659.93375369968\n",
      "train complete\n",
      "train auc: 0.706724577560162 test auc 0.7027543187396823\n",
      "train start\n",
      "Loss: 199650.03508856904\n",
      "train complete\n",
      "train start\n",
      "Loss: 199634.30962668627\n",
      "train complete\n",
      "train start\n",
      "Loss: 199628.22438322203\n",
      "train complete\n",
      "train start\n",
      "Loss: 199611.73851826173\n",
      "train complete\n",
      "train start\n",
      "Loss: 199604.66079936977\n",
      "train complete\n",
      "train start\n",
      "Loss: 199596.29265355098\n",
      "train complete\n",
      "train start\n",
      "Loss: 199590.2812658298\n",
      "train complete\n",
      "train start\n",
      "Loss: 199575.3639932662\n",
      "train complete\n",
      "train start\n",
      "Loss: 199569.55006077903\n",
      "train complete\n",
      "train start\n",
      "Loss: 199557.7134863731\n",
      "train complete\n",
      "train auc: 0.7069141599238221 test auc 0.7027316325363389\n",
      "train start\n",
      "Loss: 199552.3914708725\n",
      "train complete\n",
      "train start\n",
      "Loss: 199546.55845298193\n",
      "train complete\n",
      "train start\n",
      "Loss: 199541.09376135198\n",
      "train complete\n",
      "train start\n",
      "Loss: 199519.62847750285\n",
      "train complete\n",
      "train start\n",
      "Loss: 199513.7649006011\n",
      "train complete\n",
      "train start\n",
      "Loss: 199506.02345964027\n",
      "train complete\n",
      "train start\n",
      "Loss: 199487.39967981292\n",
      "train complete\n",
      "train start\n",
      "Loss: 199483.67023606933\n",
      "train complete\n",
      "train start\n",
      "Loss: 199468.073740553\n",
      "train complete\n",
      "train start\n",
      "Loss: 199463.45162952942\n",
      "train complete\n",
      "train auc: 0.7072824513513046 test auc 0.7029364107383078\n",
      "train start\n",
      "Loss: 199455.66359453302\n",
      "train complete\n",
      "train start\n",
      "Loss: 199445.6597582946\n",
      "train complete\n",
      "train start\n",
      "Loss: 199440.4336513343\n",
      "train complete\n",
      "train start\n",
      "Loss: 199436.2886219279\n",
      "train complete\n",
      "train start\n",
      "Loss: 199432.1150101355\n",
      "train complete\n",
      "train start\n",
      "Loss: 199428.74394721194\n",
      "train complete\n",
      "train start\n",
      "Loss: 199421.66484807\n",
      "train complete\n",
      "train start\n",
      "Loss: 199402.04920757518\n",
      "train complete\n",
      "train start\n",
      "Loss: 199397.07557185227\n",
      "train complete\n",
      "train start\n",
      "Loss: 199392.58268678232\n",
      "train complete\n",
      "train auc: 0.7074999703112843 test auc 0.7029982699377719\n",
      "train start\n",
      "Loss: 199385.00391921223\n",
      "train complete\n",
      "train start\n",
      "Loss: 199380.55986646147\n",
      "train complete\n",
      "train start\n",
      "Loss: 199376.14338192975\n",
      "train complete\n",
      "train start\n",
      "Loss: 199366.91761439588\n",
      "train complete\n",
      "train start\n",
      "Loss: 199362.85577717563\n",
      "train complete\n",
      "train start\n",
      "Loss: 199344.80583902518\n",
      "train complete\n",
      "train start\n",
      "Loss: 199337.93053840983\n",
      "train complete\n",
      "train start\n",
      "Loss: 199331.03392418128\n",
      "train complete\n",
      "train start\n",
      "Loss: 199326.76227078668\n",
      "train complete\n",
      "train start\n",
      "Loss: 199320.3048482916\n",
      "train complete\n",
      "train auc: 0.707570958849963 test auc 0.7034670548702426\n",
      "train start\n",
      "Loss: 199313.67127348806\n",
      "train complete\n",
      "train start\n",
      "Loss: 199309.0948919635\n",
      "train complete\n",
      "train start\n",
      "Loss: 199301.28284286478\n",
      "train complete\n",
      "train start\n",
      "Loss: 199295.69871821243\n",
      "train complete\n",
      "train start\n",
      "Loss: 199289.9133159815\n",
      "train complete\n",
      "train start\n",
      "Loss: 199285.71103230678\n",
      "train complete\n",
      "train start\n",
      "Loss: 199278.65635373897\n",
      "train complete\n",
      "train start\n",
      "Loss: 199274.08443881708\n",
      "train complete\n",
      "train start\n",
      "Loss: 199265.97192724247\n",
      "train complete\n",
      "train start\n",
      "Loss: 199216.5588112346\n",
      "train complete\n",
      "train auc: 0.7077701196910975 test auc 0.7034396940101459\n",
      "train start\n",
      "Loss: 199191.84157792054\n",
      "train complete\n",
      "train start\n",
      "Loss: 199184.5577024024\n",
      "train complete\n",
      "train start\n",
      "Loss: 199173.59611252954\n",
      "train complete\n",
      "train start\n",
      "Loss: 199158.9012743817\n",
      "train complete\n",
      "train start\n",
      "Loss: 199153.72008529116\n",
      "train complete\n",
      "train start\n",
      "Loss: 199148.4659705144\n",
      "train complete\n",
      "train start\n",
      "Loss: 199135.99322679598\n",
      "train complete\n",
      "train start\n",
      "Loss: 199129.67450631774\n",
      "train complete\n",
      "train start\n",
      "Loss: 199121.9796320636\n",
      "train complete\n",
      "train start\n",
      "Loss: 199115.51593818047\n",
      "train complete\n",
      "train auc: 0.7079750177470573 test auc 0.7038003767208619\n",
      "train start\n",
      "Loss: 199111.3762397015\n",
      "train complete\n",
      "train start\n",
      "Loss: 199107.98987141348\n",
      "train complete\n",
      "train start\n",
      "Loss: 199098.7714770182\n",
      "train complete\n",
      "train start\n",
      "Loss: 199094.00656270978\n",
      "train complete\n",
      "train start\n",
      "Loss: 199091.08949968615\n",
      "train complete\n",
      "train start\n",
      "Loss: 199086.5700299122\n",
      "train complete\n",
      "train start\n",
      "Loss: 199080.32642051578\n",
      "train complete\n",
      "train start\n",
      "Loss: 199077.18507797323\n",
      "train complete\n",
      "train start\n",
      "Loss: 199072.56953240233\n",
      "train complete\n",
      "train start\n",
      "Loss: 199068.30565265025\n",
      "train complete\n",
      "train auc: 0.7080703009096787 test auc 0.7036587142284442\n",
      "train start\n",
      "Loss: 199058.27347203458\n",
      "train complete\n",
      "train start\n",
      "Loss: 199050.24061604394\n",
      "train complete\n",
      "train start\n",
      "Loss: 199044.64710706368\n",
      "train complete\n",
      "train start\n",
      "Loss: 199040.2794221772\n",
      "train complete\n",
      "train start\n",
      "Loss: 199029.5859854396\n",
      "train complete\n",
      "train start\n",
      "Loss: 199023.6367628958\n",
      "train complete\n",
      "train start\n",
      "Loss: 199011.1775125026\n",
      "train complete\n",
      "train start\n",
      "Loss: 198994.52433520756\n",
      "train complete\n",
      "train start\n",
      "Loss: 198988.6515982087\n",
      "train complete\n",
      "train start\n",
      "Loss: 198977.5464429015\n",
      "train complete\n",
      "train auc: 0.7081617885630267 test auc 0.7039611566769879\n",
      "train start\n",
      "Loss: 198970.96824787415\n",
      "train complete\n",
      "train start\n",
      "Loss: 198963.2775548016\n",
      "train complete\n",
      "train start\n",
      "Loss: 198958.41793757633\n",
      "train complete\n",
      "train start\n",
      "Loss: 198953.65229369907\n",
      "train complete\n",
      "train start\n",
      "Loss: 198945.7686999146\n",
      "train complete\n",
      "train start\n",
      "Loss: 198935.01471915707\n",
      "train complete\n",
      "train start\n",
      "Loss: 198866.11319141832\n",
      "train complete\n",
      "train start\n",
      "Loss: 198858.03844932505\n",
      "train complete\n",
      "train start\n",
      "Loss: 198843.53325272055\n",
      "train complete\n",
      "train start\n",
      "Loss: 198828.47579793766\n",
      "train complete\n",
      "train auc: 0.7086021708341624 test auc 0.7039338460145478\n",
      "train start\n",
      "Loss: 198818.59509560504\n",
      "train complete\n",
      "train start\n",
      "Loss: 198813.33351987228\n",
      "train complete\n",
      "train start\n",
      "Loss: 198807.88321856057\n",
      "train complete\n",
      "train start\n",
      "Loss: 198799.39148795907\n",
      "train complete\n",
      "train start\n",
      "Loss: 198784.72911265877\n",
      "train complete\n",
      "train start\n",
      "Loss: 198778.31329757677\n",
      "train complete\n",
      "train start\n",
      "Loss: 198770.78046411116\n",
      "train complete\n",
      "train start\n",
      "Loss: 198758.55074109277\n",
      "train complete\n",
      "train start\n",
      "Loss: 198754.1291976198\n",
      "train complete\n",
      "train start\n",
      "Loss: 198731.0408838327\n",
      "train complete\n",
      "train auc: 0.7087429230392044 test auc 0.7037784779932532\n",
      "train start\n",
      "Loss: 198723.50655123964\n",
      "train complete\n",
      "train start\n",
      "Loss: 198718.0820963336\n",
      "train complete\n",
      "train start\n",
      "Loss: 198710.40133618424\n",
      "train complete\n",
      "train start\n",
      "Loss: 198703.00191650543\n",
      "train complete\n",
      "train start\n",
      "Loss: 198697.6479132874\n",
      "train complete\n",
      "train start\n",
      "Loss: 198675.79544113876\n",
      "train complete\n",
      "train start\n",
      "Loss: 198670.56525494118\n",
      "train complete\n",
      "train start\n",
      "Loss: 198665.50995831346\n",
      "train complete\n",
      "train start\n",
      "Loss: 198660.73790381468\n",
      "train complete\n",
      "train start\n",
      "Loss: 198654.24935582455\n",
      "train complete\n",
      "train auc: 0.7086992074088952 test auc 0.7042561934025345\n",
      "train start\n",
      "Loss: 198648.9956940746\n",
      "train complete\n",
      "train start\n",
      "Loss: 198643.3378285251\n",
      "train complete\n",
      "train start\n",
      "Loss: 198640.13616180423\n",
      "train complete\n",
      "train start\n",
      "Loss: 198631.6373137695\n",
      "train complete\n",
      "train start\n",
      "Loss: 198608.61112258912\n",
      "train complete\n",
      "train start\n",
      "Loss: 198482.92096768646\n",
      "train complete\n",
      "train start\n",
      "Loss: 198470.71741256418\n",
      "train complete\n",
      "train start\n",
      "Loss: 198464.450068652\n",
      "train complete\n",
      "train start\n",
      "Loss: 198458.29157292718\n",
      "train complete\n"
     ]
    }
   ],
   "source": [
    "train_acc = []\n",
    "test_acc = []\n",
    "\n",
    "gsgp = GStackGP(X_train,y_train,1)\n",
    "for i in range(1000):\n",
    "    print(\"train start\")\n",
    "    gsgp.evolve()\n",
    "    print(\"train complete\")\n",
    "    \n",
    "    if i%10 == 0:\n",
    "        pred = gsgp.predict(X_train)\n",
    "        train_acc.append(roc_auc_score(y_train,pred))\n",
    "        pred = gsgp.predict(X_test)\n",
    "        test_acc.append(roc_auc_score(y_test,pred))\n",
    "        print(\"train auc:\",train_acc[-1],\"test auc\",test_acc[-1])\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae26b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.5258654810848914,\n",
       "  0.6132988188301514,\n",
       "  0.6436750800551445,\n",
       "  0.6493980630859355,\n",
       "  0.6538173147351156,\n",
       "  0.6565614302154482,\n",
       "  0.6582152004133821,\n",
       "  0.6613213626863199,\n",
       "  0.6635383899160323,\n",
       "  0.666353789575044,\n",
       "  0.668103252695043,\n",
       "  0.6701625265444092,\n",
       "  0.6712143528187084,\n",
       "  0.6733713747050745,\n",
       "  0.6746181955322843,\n",
       "  0.6752672766485888,\n",
       "  0.6766407141634677,\n",
       "  0.6773970382984317,\n",
       "  0.6779983184430831,\n",
       "  0.6790438206285722,\n",
       "  0.6801295273961986,\n",
       "  0.6814559134172302,\n",
       "  0.6821680827768668,\n",
       "  0.6826158873088717,\n",
       "  0.6833402715090398,\n",
       "  0.6840135841631556,\n",
       "  0.6850787003093606,\n",
       "  0.6858402956774915,\n",
       "  0.68620554784639,\n",
       "  0.6870865464354777,\n",
       "  0.6873719000281152,\n",
       "  0.6887273207264919,\n",
       "  0.6894809947705653,\n",
       "  0.6904194369508995,\n",
       "  0.6906725440629418,\n",
       "  0.6909134399393745,\n",
       "  0.691144665303587,\n",
       "  0.6920069471387315,\n",
       "  0.6926548970014472,\n",
       "  0.6932927787363518,\n",
       "  0.69436308464085,\n",
       "  0.6945680994562209,\n",
       "  0.695180881395156,\n",
       "  0.695675791622282,\n",
       "  0.6959153969002998,\n",
       "  0.6963643926040635,\n",
       "  0.6968332915726205,\n",
       "  0.6972606611320749,\n",
       "  0.6978221258622824,\n",
       "  0.6982341087234021,\n",
       "  0.698685481053787,\n",
       "  0.6987667180938133,\n",
       "  0.6991179193881744,\n",
       "  0.6993725900349073,\n",
       "  0.6997280033708685,\n",
       "  0.7003942908517123,\n",
       "  0.7007817923794298,\n",
       "  0.7012283515384026,\n",
       "  0.7013312631160824,\n",
       "  0.701577551209042,\n",
       "  0.7019892600778986,\n",
       "  0.7021147649567087,\n",
       "  0.7022610981997115,\n",
       "  0.702798636972953,\n",
       "  0.7030749811013522,\n",
       "  0.7033387947764964,\n",
       "  0.7034657979918912,\n",
       "  0.7037020205970075,\n",
       "  0.7038204529651887,\n",
       "  0.7039182989358972,\n",
       "  0.7040886438346886,\n",
       "  0.7043508019403966,\n",
       "  0.7044271742477048,\n",
       "  0.7047246643739613,\n",
       "  0.7049530776624895,\n",
       "  0.7051682252757838,\n",
       "  0.7053475549141478,\n",
       "  0.7054425877531847,\n",
       "  0.7056010748625621,\n",
       "  0.7056875163536686,\n",
       "  0.7059131685998243,\n",
       "  0.7059521862341518,\n",
       "  0.7060745108982941,\n",
       "  0.7063291347356637,\n",
       "  0.7063035931547081,\n",
       "  0.7064941879005715,\n",
       "  0.7065328084473015,\n",
       "  0.7066298681627192,\n",
       "  0.706724577560162,\n",
       "  0.7069141599238221,\n",
       "  0.7072824513513046,\n",
       "  0.7074999703112843,\n",
       "  0.707570958849963,\n",
       "  0.7077701196910975,\n",
       "  0.7079750177470573,\n",
       "  0.7080703009096787,\n",
       "  0.7081617885630267,\n",
       "  0.7086021708341624,\n",
       "  0.7087429230392044,\n",
       "  0.7086992074088952],\n",
       " [0.5246813939060924,\n",
       "  0.6120390153127323,\n",
       "  0.6439444245431653,\n",
       "  0.6495549522843039,\n",
       "  0.6532618358701032,\n",
       "  0.656305261737169,\n",
       "  0.6579249565743212,\n",
       "  0.660116813711289,\n",
       "  0.6622464775206425,\n",
       "  0.6663355080213031,\n",
       "  0.6680409702604613,\n",
       "  0.6692936653255734,\n",
       "  0.6705694497439576,\n",
       "  0.6728249763333738,\n",
       "  0.6733139846466702,\n",
       "  0.6740689934786342,\n",
       "  0.6750838034186988,\n",
       "  0.6761953897342905,\n",
       "  0.6771798238175204,\n",
       "  0.6778245515357063,\n",
       "  0.679246204068909,\n",
       "  0.6801229704538477,\n",
       "  0.680606617029969,\n",
       "  0.6820480066542014,\n",
       "  0.6823997761435513,\n",
       "  0.683068245784542,\n",
       "  0.6839835655382799,\n",
       "  0.6844823420017783,\n",
       "  0.6846477966146576,\n",
       "  0.6850633343830919,\n",
       "  0.6859587491973865,\n",
       "  0.6872866246650327,\n",
       "  0.6877930076421539,\n",
       "  0.6884289727319428,\n",
       "  0.6882337948317622,\n",
       "  0.6888231984578779,\n",
       "  0.6891271154625787,\n",
       "  0.689308670973751,\n",
       "  0.6898439395647826,\n",
       "  0.6907313792264151,\n",
       "  0.6920086209455117,\n",
       "  0.6923587982279475,\n",
       "  0.6917311267322035,\n",
       "  0.6923386752424342,\n",
       "  0.6930348241849045,\n",
       "  0.6931861042345551,\n",
       "  0.6937579151507759,\n",
       "  0.6940920244771303,\n",
       "  0.6945734090213597,\n",
       "  0.6951585066297614,\n",
       "  0.6954991165526206,\n",
       "  0.6955662700361592,\n",
       "  0.6960345357366214,\n",
       "  0.6960227236005976,\n",
       "  0.696293398776018,\n",
       "  0.6968823835654379,\n",
       "  0.6968934082257268,\n",
       "  0.6975229731143234,\n",
       "  0.6974306031518229,\n",
       "  0.6978105539192165,\n",
       "  0.698118877336944,\n",
       "  0.6976792290066655,\n",
       "  0.6986665776913207,\n",
       "  0.6990993897282669,\n",
       "  0.6992704570666033,\n",
       "  0.6996295648258496,\n",
       "  0.699374689362784,\n",
       "  0.6997703394472197,\n",
       "  0.699903976589319,\n",
       "  0.6998387494408451,\n",
       "  0.7001357972100017,\n",
       "  0.7002682107842261,\n",
       "  0.7003582685171782,\n",
       "  0.7008277405300709,\n",
       "  0.7004029538434433,\n",
       "  0.7009556472959558,\n",
       "  0.7008363525654987,\n",
       "  0.7009740274815854,\n",
       "  0.7012054292655724,\n",
       "  0.7012500643941811,\n",
       "  0.7014211317325175,\n",
       "  0.7016573587662269,\n",
       "  0.7017509852388144,\n",
       "  0.7024470337859718,\n",
       "  0.7022459247189511,\n",
       "  0.7021423795031925,\n",
       "  0.7023825611710208,\n",
       "  0.7028744009458745,\n",
       "  0.7027543187396823,\n",
       "  0.7027316325363389,\n",
       "  0.7029364107383078,\n",
       "  0.7029982699377719,\n",
       "  0.7034670548702426,\n",
       "  0.7034396940101459,\n",
       "  0.7038003767208619,\n",
       "  0.7036587142284442,\n",
       "  0.7039611566769879,\n",
       "  0.7039338460145478,\n",
       "  0.7037784779932532,\n",
       "  0.7042561934025345])"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_acc,test_acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BStackGP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc-autonumbering": true,
  "toc-showcode": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
